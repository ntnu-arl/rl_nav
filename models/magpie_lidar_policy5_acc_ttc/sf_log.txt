[2025-11-09 01:03:19,517][12467] Saving configuration to /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_lidar_policy5_acc_ttc/config.json...
[2025-11-09 01:03:19,541][12467] Using GPUs [0] for process 0 (actually maps to GPUs [0])
[2025-11-09 01:03:19,541][12467] Rollout worker 0 uses device cuda:0
[2025-11-09 01:03:19,575][12467] Using GPUs [0] for process 0 (actually maps to GPUs [0])
[2025-11-09 01:03:19,576][12467] InferenceWorker_p0-w0: min num requests: 1
[2025-11-09 01:03:19,576][12467] Using GPUs [0] for process 0 (actually maps to GPUs [0])
[2025-11-09 01:03:19,576][12467] Starting seed is not provided
[2025-11-09 01:03:19,576][12467] Using GPUs [0] for process 0 (actually maps to GPUs [0])
[2025-11-09 01:03:19,576][12467] Initializing actor-critic model on device cuda:0
[2025-11-09 01:03:19,577][12467] RunningMeanStd input shape: (337,)
[2025-11-09 01:03:19,577][12467] RunningMeanStd input shape: (1,)
[2025-11-09 01:03:19,585][12467] Created Actor Critic model with architecture:
[2025-11-09 01:03:19,585][12467] ActorCriticSharedWeights(
  (obs_normalizer): ObservationNormalizer(
    (running_mean_std): RunningMeanStdDictInPlace(
      (running_mean_std): ModuleDict(
        (observations): RunningMeanStdInPlace()
      )
    )
  )
  (returns_normalizer): RecursiveScriptModule(original_name=RunningMeanStdInPlace)
  (encoder): CustomEncoder(
    (encoders): ModuleDict(
      (obs_image): Sequential(
        (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): ELU(alpha=1.0)
        (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
        (3): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (4): ELU(alpha=1.0)
        (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
        (6): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (7): ELU(alpha=1.0)
        (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        (9): Flatten(start_dim=1, end_dim=-1)
      )
    )
    (mlp_head_custom): Sequential(
      (0): Linear(in_features=145, out_features=256, bias=True)
      (1): ELU(alpha=1.0)
      (2): Linear(in_features=256, out_features=128, bias=True)
      (3): ELU(alpha=1.0)
      (4): Linear(in_features=128, out_features=64, bias=True)
      (5): ELU(alpha=1.0)
    )
  )
  (core): ModelCoreRNN(
    (core): GRU(64, 128)
  )
  (decoder): MlpDecoder(
    (mlp): Identity()
  )
  (critic_linear): Linear(in_features=128, out_features=1, bias=True)
  (action_parameterization): ActionParameterizationDefault(
    (distribution_linear): Linear(in_features=128, out_features=8, bias=True)
  )
)
[2025-11-09 01:03:19,962][12467] Using optimizer <class 'torch.optim.adam.Adam'>
[2025-11-09 01:03:19,962][12467] No checkpoints found
[2025-11-09 01:03:19,962][12467] Did not load from checkpoint, starting from scratch!
[2025-11-09 01:03:19,962][12467] Initialized policy 0 weights for model version 0
[2025-11-09 01:03:19,962][12467] LearnerWorker_p0 finished initialization!
[2025-11-09 01:03:19,963][12467] Using GPUs [0] for process 0 (actually maps to GPUs [0])
[2025-11-09 01:03:19,968][12467] Fps is (10 sec: nan, 60 sec: nan, 300 sec: nan). Total num frames: 0. Throughput: 0: nan. Samples: 0. Policy #0 lag: (min: -1.0, avg: -1.0, max: -1.0)
[2025-11-09 01:03:19,968][12467] Inference worker 0-0 is ready!
[2025-11-09 01:03:19,968][12467] All inference workers are ready! Signal rollout workers to start!
[2025-11-09 01:03:19,968][12467] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 0.0). Total num frames: 0. Throughput: 0: 0.0. Samples: 0. Policy #0 lag: (min: -1.0, avg: -1.0, max: -1.0)
[2025-11-09 01:03:19,968][12467] EnvRunner 0-0 uses policy 0
[2025-11-09 01:03:32,793][12467] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 0.0). Total num frames: 0. Throughput: 0: 0.0. Samples: 0. Policy #0 lag: (min: -1.0, avg: -1.0, max: -1.0)
[2025-11-09 01:03:36,819][12467] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 0.0). Total num frames: 0. Throughput: 0: 0.0. Samples: 0. Policy #0 lag: (min: -1.0, avg: -1.0, max: -1.0)
[2025-11-09 01:03:36,924][12467] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 0.0). Total num frames: 0. Throughput: 0: 30.2. Samples: 512. Policy #0 lag: (min: -1.0, avg: -1.0, max: -1.0)
[2025-11-09 01:03:36,924][12467] Avg episode reward: [(0, '-10.000')]
[2025-11-09 01:03:38,142][12467] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 0.0). Total num frames: 0. Throughput: 0: 56.3. Samples: 1024. Policy #0 lag: (min: -1.0, avg: -1.0, max: -1.0)
[2025-11-09 01:03:38,142][12467] Avg episode reward: [(0, '-10.000')]
[2025-11-09 01:03:40,058][12467] Heartbeat connected on Batcher_0
[2025-11-09 01:03:40,058][12467] Heartbeat connected on LearnerWorker_p0
[2025-11-09 01:03:40,058][12467] Heartbeat connected on InferenceWorker_p0-w0
[2025-11-09 01:03:40,058][12467] Heartbeat connected on RolloutWorker_w0
[2025-11-09 01:03:43,033][12467] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 0.0). Total num frames: 0. Throughput: 0: 399.6. Samples: 9216. Policy #0 lag: (min: -1.0, avg: -1.0, max: -1.0)
[2025-11-09 01:03:43,033][12467] Avg episode reward: [(0, '-14.627')]
[2025-11-09 01:03:43,325][12467] Signal inference workers to stop experience collection...
[2025-11-09 01:03:44,544][12467] InferenceWorker_p0-w0: stopping experience collection
[2025-11-09 01:03:44,546][12467] Signal inference workers to resume experience collection...
[2025-11-09 01:03:44,689][12467] InferenceWorker_p0-w0: resuming experience collection
[2025-11-09 01:03:48,082][12467] Fps is (10 sec: 1648.2, 60 sec: 582.8, 300 sec: 582.8). Total num frames: 16384. Throughput: 0: 910.6. Samples: 25600. Policy #0 lag: (min: 10.0, avg: 10.0, max: 10.0)
[2025-11-09 01:03:48,083][12467] Avg episode reward: [(0, '-20.671')]
[2025-11-09 01:03:53,114][12467] Fps is (10 sec: 3250.5, 60 sec: 988.6, 300 sec: 988.6). Total num frames: 32768. Throughput: 0: 1405.6. Samples: 46592. Policy #0 lag: (min: 8.0, avg: 11.0, max: 72.0)
[2025-11-09 01:03:53,114][12467] Avg episode reward: [(0, '-26.121')]
[2025-11-09 01:03:58,013][12467] Fps is (10 sec: 3299.7, 60 sec: 1291.9, 300 sec: 1291.9). Total num frames: 49152. Throughput: 0: 1426.5. Samples: 54272. Policy #0 lag: (min: 1.0, avg: 4.0, max: 65.0)
[2025-11-09 01:03:58,013][12467] Avg episode reward: [(0, '-193.581')]
[2025-11-09 01:04:03,025][12467] Fps is (10 sec: 3306.4, 60 sec: 1522.1, 300 sec: 1522.1). Total num frames: 65536. Throughput: 0: 1724.2. Samples: 74240. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-09 01:04:03,025][12467] Avg episode reward: [(0, '-118.444')]
[2025-11-09 01:04:08,059][12467] Fps is (10 sec: 3261.7, 60 sec: 1703.4, 300 sec: 1703.4). Total num frames: 81920. Throughput: 0: 2352.0. Samples: 82944. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-09 01:04:08,060][12467] Avg episode reward: [(0, '-35.438')]
[2025-11-09 01:04:13,066][12467] Fps is (10 sec: 3263.1, 60 sec: 1851.3, 300 sec: 1851.3). Total num frames: 98304. Throughput: 0: 2881.6. Samples: 104448. Policy #0 lag: (min: 6.0, avg: 9.0, max: 70.0)
[2025-11-09 01:04:13,067][12467] Avg episode reward: [(0, '-146.240')]
[2025-11-09 01:04:18,027][12467] Fps is (10 sec: 3287.6, 60 sec: 1975.4, 300 sec: 1975.4). Total num frames: 114688. Throughput: 0: 2964.7. Samples: 122368. Policy #0 lag: (min: 10.0, avg: 13.0, max: 74.0)
[2025-11-09 01:04:18,027][12467] Avg episode reward: [(0, '-113.116')]
[2025-11-09 01:04:18,167][12467] Saving new best policy, reward=-113.116!
[2025-11-09 01:04:22,994][12467] Fps is (10 sec: 3300.6, 60 sec: 2610.9, 300 sec: 2079.6). Total num frames: 131072. Throughput: 0: 2922.3. Samples: 132096. Policy #0 lag: (min: 6.0, avg: 9.0, max: 70.0)
[2025-11-09 01:04:22,995][12467] Avg episode reward: [(0, '-35.149')]
[2025-11-09 01:04:23,131][12467] Saving new best policy, reward=-35.149!
[2025-11-09 01:04:28,090][12467] Fps is (10 sec: 3256.2, 60 sec: 2876.1, 300 sec: 2164.6). Total num frames: 147456. Throughput: 0: 3204.5. Samples: 153600. Policy #0 lag: (min: 10.0, avg: 13.0, max: 74.0)
[2025-11-09 01:04:28,090][12467] Avg episode reward: [(0, '-89.638')]
[2025-11-09 01:04:33,101][12467] Fps is (10 sec: 3242.2, 60 sec: 2916.5, 300 sec: 2240.3). Total num frames: 163840. Throughput: 0: 3241.3. Samples: 171520. Policy #0 lag: (min: 12.0, avg: 15.0, max: 76.0)
[2025-11-09 01:04:33,101][12467] Avg episode reward: [(0, '-93.110')]
[2025-11-09 01:04:38,001][12467] Fps is (10 sec: 3306.0, 60 sec: 3010.8, 300 sec: 2309.6). Total num frames: 180224. Throughput: 0: 2999.9. Samples: 181248. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-09 01:04:38,002][12467] Avg episode reward: [(0, '-31.257')]
[2025-11-09 01:04:38,146][12467] Saving new best policy, reward=-31.257!
[2025-11-09 01:04:43,163][12467] Fps is (10 sec: 3256.5, 60 sec: 3269.7, 300 sec: 2363.2). Total num frames: 196608. Throughput: 0: 3243.2. Samples: 200704. Policy #0 lag: (min: 13.0, avg: 16.0, max: 77.0)
[2025-11-09 01:04:43,164][12467] Avg episode reward: [(0, '-17.788')]
[2025-11-09 01:04:43,314][12467] Saving new best policy, reward=-17.788!
[2025-11-09 01:04:48,012][12467] Fps is (10 sec: 3273.4, 60 sec: 3280.7, 300 sec: 2419.2). Total num frames: 212992. Throughput: 0: 3243.6. Samples: 220160. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-09 01:04:48,012][12467] Avg episode reward: [(0, '-14.612')]
[2025-11-09 01:04:48,162][12467] Saving new best policy, reward=-14.612!
[2025-11-09 01:04:53,083][12467] Fps is (10 sec: 3303.4, 60 sec: 3278.5, 300 sec: 2463.4). Total num frames: 229376. Throughput: 0: 3275.1. Samples: 230400. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-09 01:04:53,083][12467] Avg episode reward: [(0, '-10.522')]
[2025-11-09 01:04:53,225][12467] Saving new best policy, reward=-10.522!
[2025-11-09 01:04:58,071][12467] Fps is (10 sec: 3257.5, 60 sec: 3273.6, 300 sec: 2505.1). Total num frames: 245760. Throughput: 0: 3231.0. Samples: 249856. Policy #0 lag: (min: 13.0, avg: 16.0, max: 77.0)
[2025-11-09 01:04:58,071][12467] Avg episode reward: [(0, '-4.912')]
[2025-11-09 01:04:58,198][12467] Saving new best policy, reward=-4.912!
[2025-11-09 01:05:02,996][12467] Fps is (10 sec: 3305.5, 60 sec: 3278.4, 300 sec: 2544.4). Total num frames: 262144. Throughput: 0: 3279.0. Samples: 269824. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-09 01:05:02,996][12467] Avg episode reward: [(0, '-11.877')]
[2025-11-09 01:05:03,142][12467] Saving /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_lidar_policy5_acc_ttc/checkpoint_p0/checkpoint_000001024_262144.pth...
[2025-11-09 01:05:04,928][12467] Signal inference workers to stop experience collection... (50 times)
[2025-11-09 01:05:05,287][12467] InferenceWorker_p0-w0: stopping experience collection (50 times)
[2025-11-09 01:05:05,287][12467] Signal inference workers to resume experience collection... (50 times)
[2025-11-09 01:05:05,288][12467] InferenceWorker_p0-w0: resuming experience collection (50 times)
[2025-11-09 01:05:08,103][12467] Fps is (10 sec: 3266.4, 60 sec: 3274.4, 300 sec: 2575.7). Total num frames: 278528. Throughput: 0: 3495.9. Samples: 289792. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-09 01:05:08,103][12467] Avg episode reward: [(0, '-10.136')]
[2025-11-09 01:05:13,110][12467] Fps is (10 sec: 3239.8, 60 sec: 3274.4, 300 sec: 2606.6). Total num frames: 294912. Throughput: 0: 3241.2. Samples: 299520. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-09 01:05:13,111][12467] Avg episode reward: [(0, '-1.515')]
[2025-11-09 01:05:13,249][12467] Saving new best policy, reward=-1.515!
[2025-11-09 01:05:18,124][12467] Fps is (10 sec: 3270.0, 60 sec: 3271.5, 300 sec: 2634.6). Total num frames: 311296. Throughput: 0: 3297.9. Samples: 320000. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-09 01:05:18,124][12467] Avg episode reward: [(0, '1.716')]
[2025-11-09 01:05:18,276][12467] Saving new best policy, reward=1.716!
[2025-11-09 01:05:23,051][12467] Fps is (10 sec: 3296.4, 60 sec: 3273.7, 300 sec: 2662.3). Total num frames: 327680. Throughput: 0: 3273.2. Samples: 328704. Policy #0 lag: (min: 0.0, avg: 3.0, max: 64.0)
[2025-11-09 01:05:23,051][12467] Avg episode reward: [(0, '12.617')]
[2025-11-09 01:05:23,201][12467] Saving new best policy, reward=12.617!
[2025-11-09 01:05:28,078][12467] Fps is (10 sec: 3292.0, 60 sec: 3277.4, 300 sec: 2685.7). Total num frames: 344064. Throughput: 0: 3283.0. Samples: 348160. Policy #0 lag: (min: 4.0, avg: 7.0, max: 68.0)
[2025-11-09 01:05:28,078][12467] Avg episode reward: [(0, '30.044')]
[2025-11-09 01:05:28,243][12467] Saving new best policy, reward=30.044!
[2025-11-09 01:05:33,010][12467] Fps is (10 sec: 3290.3, 60 sec: 3281.8, 300 sec: 2709.3). Total num frames: 360448. Throughput: 0: 3265.6. Samples: 367104. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-09 01:05:33,010][12467] Avg episode reward: [(0, '42.147')]
[2025-11-09 01:05:33,162][12467] Saving new best policy, reward=42.147!
[2025-11-09 01:05:38,026][12467] Fps is (10 sec: 3294.0, 60 sec: 3275.5, 300 sec: 2729.5). Total num frames: 376832. Throughput: 0: 3281.0. Samples: 377856. Policy #0 lag: (min: 6.0, avg: 9.0, max: 70.0)
[2025-11-09 01:05:38,026][12467] Avg episode reward: [(0, '47.046')]
[2025-11-09 01:05:38,201][12467] Saving new best policy, reward=47.046!
[2025-11-09 01:05:43,118][12467] Fps is (10 sec: 3241.8, 60 sec: 3279.3, 300 sec: 2746.9). Total num frames: 393216. Throughput: 0: 3227.9. Samples: 395264. Policy #0 lag: (min: 14.0, avg: 17.0, max: 78.0)
[2025-11-09 01:05:43,118][12467] Avg episode reward: [(0, '52.023')]
[2025-11-09 01:05:43,271][12467] Saving new best policy, reward=52.023!
[2025-11-09 01:05:47,996][12467] Fps is (10 sec: 3286.4, 60 sec: 3277.6, 300 sec: 2767.0). Total num frames: 409600. Throughput: 0: 3219.9. Samples: 414720. Policy #0 lag: (min: 14.0, avg: 17.0, max: 78.0)
[2025-11-09 01:05:47,997][12467] Avg episode reward: [(0, '61.895')]
[2025-11-09 01:05:48,157][12467] Saving new best policy, reward=61.895!
[2025-11-09 01:05:53,062][12467] Fps is (10 sec: 3295.2, 60 sec: 3277.9, 300 sec: 2782.5). Total num frames: 425984. Throughput: 0: 3006.5. Samples: 424960. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-09 01:05:53,062][12467] Avg episode reward: [(0, '68.060')]
[2025-11-09 01:05:53,225][12467] Saving new best policy, reward=68.060!
[2025-11-09 01:05:58,076][12467] Fps is (10 sec: 3250.9, 60 sec: 3276.5, 300 sec: 2797.9). Total num frames: 442368. Throughput: 0: 3199.6. Samples: 443392. Policy #0 lag: (min: 2.0, avg: 5.0, max: 66.0)
[2025-11-09 01:05:58,076][12467] Avg episode reward: [(0, '77.175')]
[2025-11-09 01:05:58,211][12467] Saving new best policy, reward=77.175!
[2025-11-09 01:06:03,022][12467] Fps is (10 sec: 3289.9, 60 sec: 3275.4, 300 sec: 2813.5). Total num frames: 458752. Throughput: 0: 3227.2. Samples: 464896. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-09 01:06:03,022][12467] Avg episode reward: [(0, '81.506')]
[2025-11-09 01:06:03,144][12467] Saving new best policy, reward=81.506!
[2025-11-09 01:06:07,997][12467] Fps is (10 sec: 3302.9, 60 sec: 3282.6, 300 sec: 2827.7). Total num frames: 475136. Throughput: 0: 3280.7. Samples: 476160. Policy #0 lag: (min: 4.0, avg: 7.0, max: 68.0)
[2025-11-09 01:06:07,997][12467] Avg episode reward: [(0, '83.263')]
[2025-11-09 01:06:08,127][12467] Saving new best policy, reward=83.263!
[2025-11-09 01:06:13,049][12467] Fps is (10 sec: 3267.9, 60 sec: 3280.1, 300 sec: 2839.8). Total num frames: 491520. Throughput: 0: 3347.2. Samples: 498688. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-09 01:06:13,050][12467] Avg episode reward: [(0, '91.622')]
[2025-11-09 01:06:13,178][12467] Saving new best policy, reward=91.622!
[2025-11-09 01:06:18,125][12467] Fps is (10 sec: 4044.1, 60 sec: 3413.3, 300 sec: 2896.9). Total num frames: 516096. Throughput: 0: 3427.3. Samples: 521728. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-09 01:06:18,125][12467] Avg episode reward: [(0, '96.744')]
[2025-11-09 01:06:18,459][12467] Saving new best policy, reward=96.744!
[2025-11-09 01:06:22,994][12467] Fps is (10 sec: 4942.6, 60 sec: 3553.2, 300 sec: 2954.1). Total num frames: 540672. Throughput: 0: 3438.5. Samples: 532480. Policy #0 lag: (min: 9.0, avg: 12.0, max: 73.0)
[2025-11-09 01:06:22,994][12467] Avg episode reward: [(0, '98.217')]
[2025-11-09 01:06:23,128][12467] Saving new best policy, reward=98.217!
[2025-11-09 01:06:27,005][12467] Signal inference workers to stop experience collection... (100 times)
[2025-11-09 01:06:27,047][12467] Signal inference workers to resume experience collection... (100 times)
[2025-11-09 01:06:27,286][12467] InferenceWorker_p0-w0: stopping experience collection (100 times)
[2025-11-09 01:06:27,286][12467] InferenceWorker_p0-w0: resuming experience collection (100 times)
[2025-11-09 01:06:28,002][12467] Fps is (10 sec: 4147.1, 60 sec: 3554.4, 300 sec: 2962.5). Total num frames: 557056. Throughput: 0: 3559.0. Samples: 555008. Policy #0 lag: (min: 2.0, avg: 5.0, max: 66.0)
[2025-11-09 01:06:28,002][12467] Avg episode reward: [(0, '100.192')]
[2025-11-09 01:06:28,130][12467] Saving new best policy, reward=100.192!
[2025-11-09 01:06:33,055][12467] Fps is (10 sec: 3256.8, 60 sec: 3547.2, 300 sec: 2969.8). Total num frames: 573440. Throughput: 0: 3579.3. Samples: 576000. Policy #0 lag: (min: 3.0, avg: 6.0, max: 67.0)
[2025-11-09 01:06:33,056][12467] Avg episode reward: [(0, '103.334')]
[2025-11-09 01:06:33,184][12467] Saving new best policy, reward=103.334!
[2025-11-09 01:06:38,109][12467] Fps is (10 sec: 3242.1, 60 sec: 3544.9, 300 sec: 2976.8). Total num frames: 589824. Throughput: 0: 3864.4. Samples: 599040. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-09 01:06:38,109][12467] Avg episode reward: [(0, '105.891')]
[2025-11-09 01:06:38,243][12467] Saving new best policy, reward=105.891!
[2025-11-09 01:06:43,008][12467] Fps is (10 sec: 3292.3, 60 sec: 3556.4, 300 sec: 2985.7). Total num frames: 606208. Throughput: 0: 3703.4. Samples: 609792. Policy #0 lag: (min: 3.0, avg: 6.0, max: 67.0)
[2025-11-09 01:06:43,008][12467] Avg episode reward: [(0, '105.268')]
[2025-11-09 01:06:48,057][12467] Fps is (10 sec: 3294.1, 60 sec: 3546.3, 300 sec: 2992.0). Total num frames: 622592. Throughput: 0: 3729.1. Samples: 632832. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-09 01:06:48,057][12467] Avg episode reward: [(0, '107.793')]
[2025-11-09 01:06:48,184][12467] Saving new best policy, reward=107.793!
[2025-11-09 01:06:53,031][12467] Fps is (10 sec: 3269.2, 60 sec: 3551.7, 300 sec: 2999.0). Total num frames: 638976. Throughput: 0: 3706.3. Samples: 643072. Policy #0 lag: (min: 10.0, avg: 13.0, max: 74.0)
[2025-11-09 01:06:53,032][12467] Avg episode reward: [(0, '115.517')]
[2025-11-09 01:06:53,162][12467] Saving new best policy, reward=115.517!
[2025-11-09 01:06:58,249][12467] Fps is (10 sec: 4822.3, 60 sec: 3811.9, 300 sec: 3077.4). Total num frames: 671744. Throughput: 0: 3704.1. Samples: 666112. Policy #0 lag: (min: 1.0, avg: 4.0, max: 65.0)
[2025-11-09 01:06:58,249][12467] Avg episode reward: [(0, '119.644')]
[2025-11-09 01:06:58,250][12467] Saving new best policy, reward=119.644!
[2025-11-09 01:07:02,983][12467] Fps is (10 sec: 4939.2, 60 sec: 3825.5, 300 sec: 3085.6). Total num frames: 688128. Throughput: 0: 3732.3. Samples: 689152. Policy #0 lag: (min: 0.0, avg: 3.0, max: 64.0)
[2025-11-09 01:07:02,983][12467] Avg episode reward: [(0, '122.508')]
[2025-11-09 01:07:03,115][12467] Saving /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_lidar_policy5_acc_ttc/checkpoint_p0/checkpoint_000002688_688128.pth...
[2025-11-09 01:07:03,119][12467] Saving new best policy, reward=122.508!
[2025-11-09 01:07:07,998][12467] Fps is (10 sec: 3361.3, 60 sec: 3822.9, 300 sec: 3089.6). Total num frames: 704512. Throughput: 0: 3708.9. Samples: 699392. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-09 01:07:07,998][12467] Avg episode reward: [(0, '126.007')]
[2025-11-09 01:07:08,121][12467] Saving new best policy, reward=126.007!
[2025-11-09 01:07:12,996][12467] Fps is (10 sec: 3272.6, 60 sec: 3826.4, 300 sec: 3093.6). Total num frames: 720896. Throughput: 0: 3709.7. Samples: 721920. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-09 01:07:12,996][12467] Avg episode reward: [(0, '129.979')]
[2025-11-09 01:07:13,118][12467] Saving new best policy, reward=129.979!
[2025-11-09 01:07:18,042][12467] Fps is (10 sec: 3262.4, 60 sec: 3691.5, 300 sec: 3096.9). Total num frames: 737280. Throughput: 0: 3733.0. Samples: 743936. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-09 01:07:18,042][12467] Avg episode reward: [(0, '136.135')]
[2025-11-09 01:07:18,187][12467] Saving new best policy, reward=136.135!
[2025-11-09 01:07:23,095][12467] Fps is (10 sec: 3244.6, 60 sec: 3543.9, 300 sec: 3099.9). Total num frames: 753664. Throughput: 0: 3721.7. Samples: 766464. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-09 01:07:23,095][12467] Avg episode reward: [(0, '136.077')]
[2025-11-09 01:07:28,094][12467] Fps is (10 sec: 3259.8, 60 sec: 3544.4, 300 sec: 3103.5). Total num frames: 770048. Throughput: 0: 3713.4. Samples: 777216. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-09 01:07:28,094][12467] Avg episode reward: [(0, '136.824')]
[2025-11-09 01:07:28,217][12467] Saving new best policy, reward=136.824!
[2025-11-09 01:07:33,111][12467] Fps is (10 sec: 4089.3, 60 sec: 3683.0, 300 sec: 3139.0). Total num frames: 794624. Throughput: 0: 3716.0. Samples: 800256. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-09 01:07:33,111][12467] Avg episode reward: [(0, '141.137')]
[2025-11-09 01:07:33,449][12467] Saving new best policy, reward=141.137!
[2025-11-09 01:07:37,985][12467] Fps is (10 sec: 4969.4, 60 sec: 3830.8, 300 sec: 3175.0). Total num frames: 819200. Throughput: 0: 3724.4. Samples: 810496. Policy #0 lag: (min: 9.0, avg: 12.0, max: 73.0)
[2025-11-09 01:07:37,985][12467] Avg episode reward: [(0, '142.834')]
[2025-11-09 01:07:38,119][12467] Saving new best policy, reward=142.834!
[2025-11-09 01:07:41,605][12467] Signal inference workers to stop experience collection... (150 times)
[2025-11-09 01:07:41,952][12467] InferenceWorker_p0-w0: stopping experience collection (150 times)
[2025-11-09 01:07:41,954][12467] Signal inference workers to resume experience collection... (150 times)
[2025-11-09 01:07:42,078][12467] InferenceWorker_p0-w0: resuming experience collection (150 times)
[2025-11-09 01:07:43,052][12467] Fps is (10 sec: 4120.4, 60 sec: 3820.1, 300 sec: 3176.1). Total num frames: 835584. Throughput: 0: 3736.9. Samples: 833536. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-09 01:07:43,052][12467] Avg episode reward: [(0, '143.139')]
[2025-11-09 01:07:43,187][12467] Saving new best policy, reward=143.139!
[2025-11-09 01:07:48,077][12467] Fps is (10 sec: 3246.8, 60 sec: 3821.6, 300 sec: 3177.7). Total num frames: 851968. Throughput: 0: 3655.9. Samples: 854016. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-09 01:07:48,078][12467] Avg episode reward: [(0, '144.098')]
[2025-11-09 01:07:48,211][12467] Saving new best policy, reward=144.098!
[2025-11-09 01:07:52,983][12467] Fps is (10 sec: 3299.4, 60 sec: 3826.0, 300 sec: 3180.6). Total num frames: 868352. Throughput: 0: 3710.3. Samples: 866304. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-09 01:07:52,984][12467] Avg episode reward: [(0, '145.267')]
[2025-11-09 01:07:53,126][12467] Saving new best policy, reward=145.267!
[2025-11-09 01:07:58,005][12467] Fps is (10 sec: 3300.8, 60 sec: 3564.4, 300 sec: 3182.1). Total num frames: 884736. Throughput: 0: 3685.6. Samples: 887808. Policy #0 lag: (min: 9.0, avg: 12.0, max: 73.0)
[2025-11-09 01:07:58,005][12467] Avg episode reward: [(0, '145.879')]
[2025-11-09 01:07:58,133][12467] Saving new best policy, reward=145.879!
[2025-11-09 01:08:02,992][12467] Fps is (10 sec: 3274.2, 60 sec: 3549.3, 300 sec: 3183.9). Total num frames: 901120. Throughput: 0: 3701.9. Samples: 910336. Policy #0 lag: (min: 14.0, avg: 17.0, max: 78.0)
[2025-11-09 01:08:02,992][12467] Avg episode reward: [(0, '145.847')]
[2025-11-09 01:08:08,040][12467] Fps is (10 sec: 3265.2, 60 sec: 3547.3, 300 sec: 3185.0). Total num frames: 917504. Throughput: 0: 3440.3. Samples: 921088. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-09 01:08:08,041][12467] Avg episode reward: [(0, '146.241')]
[2025-11-09 01:08:08,171][12467] Saving new best policy, reward=146.241!
[2025-11-09 01:08:13,030][12467] Fps is (10 sec: 4080.2, 60 sec: 3684.3, 300 sec: 3214.6). Total num frames: 942080. Throughput: 0: 3714.4. Samples: 944128. Policy #0 lag: (min: 13.0, avg: 16.0, max: 77.0)
[2025-11-09 01:08:13,030][12467] Avg episode reward: [(0, '146.691')]
[2025-11-09 01:08:13,371][12467] Saving new best policy, reward=146.691!
[2025-11-09 01:08:17,998][12467] Fps is (10 sec: 4936.4, 60 sec: 3825.8, 300 sec: 3389.3). Total num frames: 966656. Throughput: 0: 3707.1. Samples: 966656. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-09 01:08:17,998][12467] Avg episode reward: [(0, '149.977')]
[2025-11-09 01:08:18,127][12467] Saving new best policy, reward=149.977!
[2025-11-09 01:08:23,024][12467] Fps is (10 sec: 4098.5, 60 sec: 3827.4, 300 sec: 3434.7). Total num frames: 983040. Throughput: 0: 3705.9. Samples: 977408. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-09 01:08:23,024][12467] Avg episode reward: [(0, '155.439')]
[2025-11-09 01:08:23,154][12467] Saving new best policy, reward=155.439!
[2025-11-09 01:08:28,083][12467] Fps is (10 sec: 3249.0, 60 sec: 3823.6, 300 sec: 3432.6). Total num frames: 999424. Throughput: 0: 3706.6. Samples: 1000448. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-09 01:08:28,083][12467] Avg episode reward: [(0, '153.977')]
[2025-11-09 01:08:33,105][12467] Fps is (10 sec: 3250.6, 60 sec: 3686.8, 300 sec: 3443.9). Total num frames: 1015808. Throughput: 0: 3718.3. Samples: 1021440. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-09 01:08:33,105][12467] Avg episode reward: [(0, '155.476')]
[2025-11-09 01:08:33,234][12467] Saving new best policy, reward=155.476!
[2025-11-09 01:08:38,001][12467] Fps is (10 sec: 3304.0, 60 sec: 3548.9, 300 sec: 3499.3). Total num frames: 1032192. Throughput: 0: 3707.7. Samples: 1033216. Policy #0 lag: (min: 9.0, avg: 12.0, max: 73.0)
[2025-11-09 01:08:38,001][12467] Avg episode reward: [(0, '154.893')]
[2025-11-09 01:08:43,091][12467] Fps is (10 sec: 3281.2, 60 sec: 3547.6, 300 sec: 3498.9). Total num frames: 1048576. Throughput: 0: 3713.4. Samples: 1055232. Policy #0 lag: (min: 31.0, avg: 34.0, max: 95.0)
[2025-11-09 01:08:43,091][12467] Avg episode reward: [(0, '155.978')]
[2025-11-09 01:08:43,217][12467] Saving new best policy, reward=155.978!
[2025-11-09 01:08:48,035][12467] Fps is (10 sec: 3265.5, 60 sec: 3552.4, 300 sec: 3499.9). Total num frames: 1064960. Throughput: 0: 3716.9. Samples: 1077760. Policy #0 lag: (min: 16.0, avg: 19.0, max: 80.0)
[2025-11-09 01:08:48,035][12467] Avg episode reward: [(0, '154.091')]
[2025-11-09 01:08:52,869][12467] Signal inference workers to stop experience collection... (200 times)
[2025-11-09 01:08:53,214][12467] InferenceWorker_p0-w0: stopping experience collection (200 times)
[2025-11-09 01:08:53,214][12467] Signal inference workers to resume experience collection... (200 times)
[2025-11-09 01:08:53,217][12467] Fps is (10 sec: 4853.9, 60 sec: 3808.1, 300 sec: 3552.0). Total num frames: 1097728. Throughput: 0: 3694.6. Samples: 1088000. Policy #0 lag: (min: 55.0, avg: 58.0, max: 119.0)
[2025-11-09 01:08:53,218][12467] Avg episode reward: [(0, '157.566')]
[2025-11-09 01:08:53,220][12467] InferenceWorker_p0-w0: resuming experience collection (200 times)
[2025-11-09 01:08:53,220][12467] Saving new best policy, reward=157.566!
[2025-11-09 01:08:58,031][12467] Fps is (10 sec: 4917.5, 60 sec: 3821.3, 300 sec: 3554.4). Total num frames: 1114112. Throughput: 0: 3709.1. Samples: 1111040. Policy #0 lag: (min: 55.0, avg: 58.0, max: 119.0)
[2025-11-09 01:08:58,031][12467] Avg episode reward: [(0, '159.332')]
[2025-11-09 01:08:58,158][12467] Saving new best policy, reward=159.332!
[2025-11-09 01:09:03,030][12467] Fps is (10 sec: 3339.5, 60 sec: 3820.5, 300 sec: 3554.9). Total num frames: 1130496. Throughput: 0: 3661.0. Samples: 1131520. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-09 01:09:03,030][12467] Avg episode reward: [(0, '161.653')]
[2025-11-09 01:09:03,167][12467] Saving /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_lidar_policy5_acc_ttc/checkpoint_p0/checkpoint_000004416_1130496.pth...
[2025-11-09 01:09:03,171][12467] Removing /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_lidar_policy5_acc_ttc/checkpoint_p0/checkpoint_000001024_262144.pth
[2025-11-09 01:09:03,171][12467] Saving new best policy, reward=161.653!
[2025-11-09 01:09:08,026][12467] Fps is (10 sec: 3278.2, 60 sec: 3823.8, 300 sec: 3555.0). Total num frames: 1146880. Throughput: 0: 3697.6. Samples: 1143808. Policy #0 lag: (min: 46.0, avg: 49.0, max: 110.0)
[2025-11-09 01:09:08,027][12467] Avg episode reward: [(0, '162.310')]
[2025-11-09 01:09:08,154][12467] Saving new best policy, reward=162.310!
[2025-11-09 01:09:13,000][12467] Fps is (10 sec: 3286.6, 60 sec: 3688.3, 300 sec: 3554.8). Total num frames: 1163264. Throughput: 0: 3647.7. Samples: 1164288. Policy #0 lag: (min: 46.0, avg: 49.0, max: 110.0)
[2025-11-09 01:09:13,000][12467] Avg episode reward: [(0, '164.432')]
[2025-11-09 01:09:13,135][12467] Saving new best policy, reward=164.432!
[2025-11-09 01:09:18,034][12467] Fps is (10 sec: 3274.3, 60 sec: 3547.7, 300 sec: 3554.0). Total num frames: 1179648. Throughput: 0: 3692.2. Samples: 1187328. Policy #0 lag: (min: 13.0, avg: 16.0, max: 77.0)
[2025-11-09 01:09:18,034][12467] Avg episode reward: [(0, '168.959')]
[2025-11-09 01:09:18,156][12467] Saving new best policy, reward=168.959!
[2025-11-09 01:09:23,053][12467] Fps is (10 sec: 3259.3, 60 sec: 3548.1, 300 sec: 3554.9). Total num frames: 1196032. Throughput: 0: 3659.4. Samples: 1198080. Policy #0 lag: (min: 63.0, avg: 66.0, max: 127.0)
[2025-11-09 01:09:23,054][12467] Avg episode reward: [(0, '170.622')]
[2025-11-09 01:09:23,195][12467] Saving new best policy, reward=170.622!
[2025-11-09 01:09:28,043][12467] Fps is (10 sec: 3273.8, 60 sec: 3552.2, 300 sec: 3555.2). Total num frames: 1212416. Throughput: 0: 3679.0. Samples: 1220608. Policy #0 lag: (min: 63.0, avg: 66.0, max: 127.0)
[2025-11-09 01:09:28,043][12467] Avg episode reward: [(0, '170.575')]
[2025-11-09 01:09:33,259][12467] Fps is (10 sec: 4816.3, 60 sec: 3813.1, 300 sec: 3606.9). Total num frames: 1245184. Throughput: 0: 3656.9. Samples: 1243136. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-09 01:09:33,259][12467] Avg episode reward: [(0, '171.909')]
[2025-11-09 01:09:33,261][12467] Saving new best policy, reward=171.909!
[2025-11-09 01:09:38,013][12467] Fps is (10 sec: 4929.9, 60 sec: 3822.2, 300 sec: 3611.9). Total num frames: 1261568. Throughput: 0: 3703.2. Samples: 1253888. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-09 01:09:38,013][12467] Avg episode reward: [(0, '170.371')]
[2025-11-09 01:09:43,084][12467] Fps is (10 sec: 3335.0, 60 sec: 3823.4, 300 sec: 3609.1). Total num frames: 1277952. Throughput: 0: 3682.0. Samples: 1276928. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-09 01:09:43,085][12467] Avg episode reward: [(0, '171.950')]
[2025-11-09 01:09:43,218][12467] Saving new best policy, reward=171.950!
[2025-11-09 01:09:48,064][12467] Fps is (10 sec: 3260.2, 60 sec: 3821.1, 300 sec: 3610.3). Total num frames: 1294336. Throughput: 0: 3695.0. Samples: 1297920. Policy #0 lag: (min: 7.0, avg: 10.0, max: 71.0)
[2025-11-09 01:09:48,064][12467] Avg episode reward: [(0, '172.903')]
[2025-11-09 01:09:48,194][12467] Saving new best policy, reward=172.903!
[2025-11-09 01:09:53,080][12467] Fps is (10 sec: 3278.3, 60 sec: 3558.0, 300 sec: 3609.9). Total num frames: 1310720. Throughput: 0: 3693.4. Samples: 1310208. Policy #0 lag: (min: 7.0, avg: 10.0, max: 71.0)
[2025-11-09 01:09:53,080][12467] Avg episode reward: [(0, '175.352')]
[2025-11-09 01:09:53,209][12467] Saving new best policy, reward=175.352!
[2025-11-09 01:09:57,999][12467] Fps is (10 sec: 3298.3, 60 sec: 3551.8, 300 sec: 3610.0). Total num frames: 1327104. Throughput: 0: 3709.2. Samples: 1331200. Policy #0 lag: (min: 2.0, avg: 5.0, max: 66.0)
[2025-11-09 01:09:57,999][12467] Avg episode reward: [(0, '175.963')]
[2025-11-09 01:09:58,128][12467] Saving new best policy, reward=175.963!
[2025-11-09 01:10:03,079][12467] Fps is (10 sec: 3277.0, 60 sec: 3546.9, 300 sec: 3610.3). Total num frames: 1343488. Throughput: 0: 3694.1. Samples: 1353728. Policy #0 lag: (min: 2.0, avg: 5.0, max: 66.0)
[2025-11-09 01:10:03,079][12467] Avg episode reward: [(0, '178.581')]
[2025-11-09 01:10:03,205][12467] Saving new best policy, reward=178.581!
[2025-11-09 01:10:07,999][12467] Fps is (10 sec: 3276.6, 60 sec: 3551.5, 300 sec: 3611.4). Total num frames: 1359872. Throughput: 0: 3702.2. Samples: 1364480. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-09 01:10:07,999][12467] Avg episode reward: [(0, '180.905')]
[2025-11-09 01:10:08,353][12467] Saving new best policy, reward=180.905!
[2025-11-09 01:10:08,357][12467] Signal inference workers to stop experience collection... (250 times)
[2025-11-09 01:10:08,357][12467] Signal inference workers to resume experience collection... (250 times)
[2025-11-09 01:10:08,597][12467] InferenceWorker_p0-w0: stopping experience collection (250 times)
[2025-11-09 01:10:08,598][12467] InferenceWorker_p0-w0: resuming experience collection (250 times)
[2025-11-09 01:10:13,107][12467] Fps is (10 sec: 4901.5, 60 sec: 3816.1, 300 sec: 3665.8). Total num frames: 1392640. Throughput: 0: 3703.9. Samples: 1387520. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-09 01:10:13,107][12467] Avg episode reward: [(0, '181.840')]
[2025-11-09 01:10:13,109][12467] Saving new best policy, reward=181.840!
[2025-11-09 01:10:18,069][12467] Fps is (10 sec: 4881.0, 60 sec: 3820.7, 300 sec: 3665.3). Total num frames: 1409024. Throughput: 0: 3724.8. Samples: 1410048. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-09 01:10:18,069][12467] Avg episode reward: [(0, '182.126')]
[2025-11-09 01:10:18,201][12467] Saving new best policy, reward=182.126!
[2025-11-09 01:10:23,018][12467] Fps is (10 sec: 3306.3, 60 sec: 3825.2, 300 sec: 3666.3). Total num frames: 1425408. Throughput: 0: 3697.4. Samples: 1420288. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-09 01:10:23,125][12467] Avg episode reward: [(0, '184.078')]
[2025-11-09 01:10:23,251][12467] Saving new best policy, reward=184.078!
[2025-11-09 01:10:28,083][12467] Fps is (10 sec: 3272.3, 60 sec: 3820.4, 300 sec: 3664.7). Total num frames: 1441792. Throughput: 0: 3686.5. Samples: 1442816. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-09 01:10:28,083][12467] Avg episode reward: [(0, '185.002')]
[2025-11-09 01:10:28,208][12467] Saving new best policy, reward=185.002!
[2025-11-09 01:10:33,089][12467] Fps is (10 sec: 3253.7, 60 sec: 3560.0, 300 sec: 3664.8). Total num frames: 1458176. Throughput: 0: 3695.7. Samples: 1464320. Policy #0 lag: (min: 6.0, avg: 9.0, max: 70.0)
[2025-11-09 01:10:33,089][12467] Avg episode reward: [(0, '186.595')]
[2025-11-09 01:10:33,221][12467] Saving new best policy, reward=186.595!
[2025-11-09 01:10:38,060][12467] Fps is (10 sec: 3284.3, 60 sec: 3547.1, 300 sec: 3666.3). Total num frames: 1474560. Throughput: 0: 3676.6. Samples: 1475584. Policy #0 lag: (min: 6.0, avg: 9.0, max: 70.0)
[2025-11-09 01:10:38,060][12467] Avg episode reward: [(0, '186.790')]
[2025-11-09 01:10:38,186][12467] Saving new best policy, reward=186.790!
[2025-11-09 01:10:43,046][12467] Fps is (10 sec: 3290.9, 60 sec: 3552.1, 300 sec: 3665.0). Total num frames: 1490944. Throughput: 0: 3705.3. Samples: 1498112. Policy #0 lag: (min: 6.0, avg: 9.0, max: 70.0)
[2025-11-09 01:10:43,046][12467] Avg episode reward: [(0, '185.613')]
[2025-11-09 01:10:48,274][12467] Fps is (10 sec: 4010.4, 60 sec: 3673.6, 300 sec: 3690.7). Total num frames: 1515520. Throughput: 0: 3693.2. Samples: 1520640. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-09 01:10:48,274][12467] Avg episode reward: [(0, '186.466')]
[2025-11-09 01:10:53,078][12467] Fps is (10 sec: 4899.3, 60 sec: 3823.0, 300 sec: 3721.1). Total num frames: 1540096. Throughput: 0: 3691.3. Samples: 1530880. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-09 01:10:53,079][12467] Avg episode reward: [(0, '187.865')]
[2025-11-09 01:10:53,081][12467] Saving new best policy, reward=187.865!
[2025-11-09 01:10:58,000][12467] Fps is (10 sec: 4211.3, 60 sec: 3822.9, 300 sec: 3721.4). Total num frames: 1556480. Throughput: 0: 3695.2. Samples: 1553408. Policy #0 lag: (min: 9.0, avg: 12.0, max: 73.0)
[2025-11-09 01:10:58,000][12467] Avg episode reward: [(0, '186.338')]
[2025-11-09 01:11:03,053][12467] Fps is (10 sec: 3285.2, 60 sec: 3824.6, 300 sec: 3720.4). Total num frames: 1572864. Throughput: 0: 3665.0. Samples: 1574912. Policy #0 lag: (min: 9.0, avg: 12.0, max: 73.0)
[2025-11-09 01:11:03,053][12467] Avg episode reward: [(0, '191.605')]
[2025-11-09 01:11:03,183][12467] Saving /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_lidar_policy5_acc_ttc/checkpoint_p0/checkpoint_000006144_1572864.pth...
[2025-11-09 01:11:03,186][12467] Removing /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_lidar_policy5_acc_ttc/checkpoint_p0/checkpoint_000002688_688128.pth
[2025-11-09 01:11:03,187][12467] Saving new best policy, reward=191.605!
[2025-11-09 01:11:08,008][12467] Fps is (10 sec: 3274.1, 60 sec: 3822.4, 300 sec: 3721.6). Total num frames: 1589248. Throughput: 0: 3698.6. Samples: 1586688. Policy #0 lag: (min: 1.0, avg: 4.0, max: 65.0)
[2025-11-09 01:11:08,008][12467] Avg episode reward: [(0, '193.153')]
[2025-11-09 01:11:08,145][12467] Saving new best policy, reward=193.153!
[2025-11-09 01:11:12,990][12467] Fps is (10 sec: 3297.5, 60 sec: 3556.8, 300 sec: 3695.0). Total num frames: 1605632. Throughput: 0: 3671.2. Samples: 1607680. Policy #0 lag: (min: 1.0, avg: 4.0, max: 65.0)
[2025-11-09 01:11:12,990][12467] Avg episode reward: [(0, '197.682')]
[2025-11-09 01:11:13,121][12467] Saving new best policy, reward=197.682!
[2025-11-09 01:11:18,062][12467] Fps is (10 sec: 3259.4, 60 sec: 3550.3, 300 sec: 3664.7). Total num frames: 1622016. Throughput: 0: 3700.0. Samples: 1630720. Policy #0 lag: (min: 6.0, avg: 9.0, max: 70.0)
[2025-11-09 01:11:18,062][12467] Avg episode reward: [(0, '198.486')]
[2025-11-09 01:11:18,192][12467] Saving new best policy, reward=198.486!
[2025-11-09 01:11:23,089][12467] Fps is (10 sec: 3244.7, 60 sec: 3545.7, 300 sec: 3664.5). Total num frames: 1638400. Throughput: 0: 3672.7. Samples: 1640960. Policy #0 lag: (min: 6.0, avg: 9.0, max: 70.0)
[2025-11-09 01:11:23,089][12467] Avg episode reward: [(0, '201.496')]
[2025-11-09 01:11:23,218][12467] Saving new best policy, reward=201.496!
[2025-11-09 01:11:23,487][12467] Signal inference workers to stop experience collection... (300 times)
[2025-11-09 01:11:23,833][12467] InferenceWorker_p0-w0: stopping experience collection (300 times)
[2025-11-09 01:11:23,835][12467] Signal inference workers to resume experience collection... (300 times)
[2025-11-09 01:11:23,959][12467] InferenceWorker_p0-w0: resuming experience collection (300 times)
[2025-11-09 01:11:28,298][12467] Fps is (10 sec: 4001.6, 60 sec: 3673.3, 300 sec: 3690.3). Total num frames: 1662976. Throughput: 0: 3665.9. Samples: 1664000. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-09 01:11:28,298][12467] Avg episode reward: [(0, '198.987')]
[2025-11-09 01:11:33,076][12467] Fps is (10 sec: 4921.7, 60 sec: 3823.8, 300 sec: 3721.5). Total num frames: 1687552. Throughput: 0: 3702.7. Samples: 1686528. Policy #0 lag: (min: 2.0, avg: 5.0, max: 66.0)
[2025-11-09 01:11:33,076][12467] Avg episode reward: [(0, '197.931')]
[2025-11-09 01:11:38,033][12467] Fps is (10 sec: 4207.5, 60 sec: 3824.7, 300 sec: 3720.8). Total num frames: 1703936. Throughput: 0: 3701.5. Samples: 1697280. Policy #0 lag: (min: 2.0, avg: 5.0, max: 66.0)
[2025-11-09 01:11:38,033][12467] Avg episode reward: [(0, '196.435')]
[2025-11-09 01:11:43,014][12467] Fps is (10 sec: 3297.3, 60 sec: 3825.0, 300 sec: 3721.7). Total num frames: 1720320. Throughput: 0: 3696.6. Samples: 1719808. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-09 01:11:43,014][12467] Avg episode reward: [(0, '200.483')]
[2025-11-09 01:11:48,067][12467] Fps is (10 sec: 3265.6, 60 sec: 3699.1, 300 sec: 3720.7). Total num frames: 1736704. Throughput: 0: 3673.9. Samples: 1740288. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-09 01:11:48,067][12467] Avg episode reward: [(0, '201.612')]
[2025-11-09 01:11:48,192][12467] Saving new best policy, reward=201.612!
[2025-11-09 01:11:52,987][12467] Fps is (10 sec: 3285.5, 60 sec: 3555.3, 300 sec: 3668.8). Total num frames: 1753088. Throughput: 0: 3699.5. Samples: 1753088. Policy #0 lag: (min: 4.0, avg: 7.0, max: 68.0)
[2025-11-09 01:11:52,987][12467] Avg episode reward: [(0, '205.924')]
[2025-11-09 01:11:53,110][12467] Saving new best policy, reward=205.924!
[2025-11-09 01:11:58,075][12467] Fps is (10 sec: 3274.0, 60 sec: 3545.4, 300 sec: 3664.4). Total num frames: 1769472. Throughput: 0: 3690.8. Samples: 1774080. Policy #0 lag: (min: 4.0, avg: 7.0, max: 68.0)
[2025-11-09 01:11:58,076][12467] Avg episode reward: [(0, '207.798')]
[2025-11-09 01:11:58,209][12467] Saving new best policy, reward=207.798!
[2025-11-09 01:12:03,105][12467] Fps is (10 sec: 3238.5, 60 sec: 3546.8, 300 sec: 3664.2). Total num frames: 1785856. Throughput: 0: 3682.8. Samples: 1796608. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-09 01:12:03,105][12467] Avg episode reward: [(0, '207.389')]
[2025-11-09 01:12:08,275][12467] Fps is (10 sec: 4015.9, 60 sec: 3670.1, 300 sec: 3689.8). Total num frames: 1810432. Throughput: 0: 3682.6. Samples: 1807360. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-09 01:12:08,275][12467] Avg episode reward: [(0, '207.963')]
[2025-11-09 01:12:08,616][12467] Saving new best policy, reward=207.963!
[2025-11-09 01:12:13,136][12467] Fps is (10 sec: 4900.3, 60 sec: 3813.7, 300 sec: 3719.9). Total num frames: 1835008. Throughput: 0: 3699.7. Samples: 1829888. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-09 01:12:13,136][12467] Avg episode reward: [(0, '212.979')]
[2025-11-09 01:12:13,137][12467] Saving new best policy, reward=212.979!
[2025-11-09 01:12:18,001][12467] Fps is (10 sec: 4211.1, 60 sec: 3826.8, 300 sec: 3722.3). Total num frames: 1851392. Throughput: 0: 3692.5. Samples: 1852416. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-09 01:12:18,002][12467] Avg episode reward: [(0, '212.516')]
[2025-11-09 01:12:23,079][12467] Fps is (10 sec: 3295.6, 60 sec: 3823.6, 300 sec: 3721.3). Total num frames: 1867776. Throughput: 0: 3682.6. Samples: 1863168. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-09 01:12:23,079][12467] Avg episode reward: [(0, '210.939')]
[2025-11-09 01:12:27,983][12467] Fps is (10 sec: 3282.8, 60 sec: 3705.8, 300 sec: 3694.9). Total num frames: 1884160. Throughput: 0: 3677.5. Samples: 1885184. Policy #0 lag: (min: 10.0, avg: 13.0, max: 74.0)
[2025-11-09 01:12:27,983][12467] Avg episode reward: [(0, '209.186')]
[2025-11-09 01:12:33,003][12467] Fps is (10 sec: 3301.6, 60 sec: 3554.2, 300 sec: 3665.3). Total num frames: 1900544. Throughput: 0: 3714.4. Samples: 1907200. Policy #0 lag: (min: 10.0, avg: 13.0, max: 74.0)
[2025-11-09 01:12:33,004][12467] Avg episode reward: [(0, '213.278')]
[2025-11-09 01:12:33,133][12467] Saving new best policy, reward=213.278!
[2025-11-09 01:12:34,858][12467] Signal inference workers to stop experience collection... (350 times)
[2025-11-09 01:12:35,205][12467] InferenceWorker_p0-w0: stopping experience collection (350 times)
[2025-11-09 01:12:35,205][12467] Signal inference workers to resume experience collection... (350 times)
[2025-11-09 01:12:35,206][12467] InferenceWorker_p0-w0: resuming experience collection (350 times)
[2025-11-09 01:12:38,068][12467] Fps is (10 sec: 3249.2, 60 sec: 3547.8, 300 sec: 3665.4). Total num frames: 1916928. Throughput: 0: 3657.0. Samples: 1917952. Policy #0 lag: (min: 3.0, avg: 6.0, max: 67.0)
[2025-11-09 01:12:38,068][12467] Avg episode reward: [(0, '213.627')]
[2025-11-09 01:12:38,204][12467] Saving new best policy, reward=213.627!
[2025-11-09 01:12:43,024][12467] Fps is (10 sec: 3269.9, 60 sec: 3549.2, 300 sec: 3666.2). Total num frames: 1933312. Throughput: 0: 3702.0. Samples: 1940480. Policy #0 lag: (min: 3.0, avg: 6.0, max: 67.0)
[2025-11-09 01:12:43,025][12467] Avg episode reward: [(0, '214.485')]
[2025-11-09 01:12:43,151][12467] Saving new best policy, reward=214.485!
[2025-11-09 01:12:48,251][12467] Fps is (10 sec: 4022.4, 60 sec: 3675.1, 300 sec: 3690.0). Total num frames: 1957888. Throughput: 0: 3685.8. Samples: 1963008. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-09 01:12:48,251][12467] Avg episode reward: [(0, '215.743')]
[2025-11-09 01:12:48,603][12467] Saving new best policy, reward=215.743!
[2025-11-09 01:12:53,048][12467] Fps is (10 sec: 4903.8, 60 sec: 3819.1, 300 sec: 3720.6). Total num frames: 1982464. Throughput: 0: 3705.1. Samples: 1973248. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-09 01:12:53,048][12467] Avg episode reward: [(0, '218.628')]
[2025-11-09 01:12:53,050][12467] Saving new best policy, reward=218.628!
[2025-11-09 01:12:57,990][12467] Fps is (10 sec: 4206.0, 60 sec: 3828.4, 300 sec: 3721.1). Total num frames: 1998848. Throughput: 0: 3709.8. Samples: 1996288. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-09 01:12:57,990][12467] Avg episode reward: [(0, '221.019')]
[2025-11-09 01:12:58,114][12467] Saving new best policy, reward=221.019!
[2025-11-09 01:13:03,102][12467] Fps is (10 sec: 3259.2, 60 sec: 3823.2, 300 sec: 3720.3). Total num frames: 2015232. Throughput: 0: 3655.5. Samples: 2017280. Policy #0 lag: (min: 0.0, avg: 3.0, max: 64.0)
[2025-11-09 01:13:03,102][12467] Avg episode reward: [(0, '226.007')]
[2025-11-09 01:13:03,106][12467] Saving /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_lidar_policy5_acc_ttc/checkpoint_p0/checkpoint_000007872_2015232.pth...
[2025-11-09 01:13:03,110][12467] Removing /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_lidar_policy5_acc_ttc/checkpoint_p0/checkpoint_000004416_1130496.pth
[2025-11-09 01:13:03,110][12467] Saving new best policy, reward=226.007!
[2025-11-09 01:13:08,075][12467] Fps is (10 sec: 3249.2, 60 sec: 3698.8, 300 sec: 3692.8). Total num frames: 2031616. Throughput: 0: 3686.7. Samples: 2029056. Policy #0 lag: (min: 0.0, avg: 3.0, max: 64.0)
[2025-11-09 01:13:08,075][12467] Avg episode reward: [(0, '227.915')]
[2025-11-09 01:13:08,215][12467] Saving new best policy, reward=227.915!
[2025-11-09 01:13:13,062][12467] Fps is (10 sec: 3289.8, 60 sec: 3554.2, 300 sec: 3664.8). Total num frames: 2048000. Throughput: 0: 3657.2. Samples: 2050048. Policy #0 lag: (min: 0.0, avg: 3.0, max: 64.0)
[2025-11-09 01:13:13,062][12467] Avg episode reward: [(0, '229.169')]
[2025-11-09 01:13:13,191][12467] Saving new best policy, reward=229.169!
[2025-11-09 01:13:18,095][12467] Fps is (10 sec: 3270.0, 60 sec: 3544.3, 300 sec: 3664.7). Total num frames: 2064384. Throughput: 0: 3656.2. Samples: 2072064. Policy #0 lag: (min: 0.0, avg: 3.0, max: 64.0)
[2025-11-09 01:13:18,096][12467] Avg episode reward: [(0, '227.551')]
[2025-11-09 01:13:22,987][12467] Fps is (10 sec: 3301.4, 60 sec: 3555.3, 300 sec: 3666.8). Total num frames: 2080768. Throughput: 0: 3670.2. Samples: 2082816. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-09 01:13:22,988][12467] Avg episode reward: [(0, '229.144')]
[2025-11-09 01:13:28,029][12467] Fps is (10 sec: 3298.5, 60 sec: 3547.1, 300 sec: 3666.5). Total num frames: 2097152. Throughput: 0: 3663.2. Samples: 2105344. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-09 01:13:28,030][12467] Avg episode reward: [(0, '231.323')]
[2025-11-09 01:13:28,157][12467] Saving new best policy, reward=231.323!
[2025-11-09 01:13:33,136][12467] Fps is (10 sec: 4036.2, 60 sec: 3678.3, 300 sec: 3691.7). Total num frames: 2121728. Throughput: 0: 3661.7. Samples: 2127360. Policy #0 lag: (min: 0.0, avg: 3.0, max: 64.0)
[2025-11-09 01:13:33,136][12467] Avg episode reward: [(0, '239.293')]
[2025-11-09 01:13:33,473][12467] Saving new best policy, reward=239.293!
[2025-11-09 01:13:38,007][12467] Fps is (10 sec: 4926.3, 60 sec: 3826.8, 300 sec: 3722.2). Total num frames: 2146304. Throughput: 0: 3655.6. Samples: 2137600. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-09 01:13:38,042][12467] Avg episode reward: [(0, '244.915')]
[2025-11-09 01:13:38,043][12467] Saving new best policy, reward=244.915!
[2025-11-09 01:13:43,031][12467] Fps is (10 sec: 4139.2, 60 sec: 3822.5, 300 sec: 3721.2). Total num frames: 2162688. Throughput: 0: 3626.2. Samples: 2159616. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-09 01:13:43,044][12467] Avg episode reward: [(0, '241.365')]
[2025-11-09 01:13:48,080][12467] Fps is (10 sec: 3253.1, 60 sec: 3697.0, 300 sec: 3667.3). Total num frames: 2179072. Throughput: 0: 3619.9. Samples: 2180096. Policy #0 lag: (min: 14.0, avg: 17.0, max: 78.0)
[2025-11-09 01:13:48,080][12467] Avg episode reward: [(0, '241.372')]
[2025-11-09 01:13:51,192][12467] Signal inference workers to stop experience collection... (400 times)
[2025-11-09 01:13:51,192][12467] Signal inference workers to resume experience collection... (400 times)
[2025-11-09 01:13:51,429][12467] InferenceWorker_p0-w0: stopping experience collection (400 times)
[2025-11-09 01:13:51,429][12467] InferenceWorker_p0-w0: resuming experience collection (400 times)
[2025-11-09 01:13:53,022][12467] Fps is (10 sec: 3279.9, 60 sec: 3551.4, 300 sec: 3665.7). Total num frames: 2195456. Throughput: 0: 3633.8. Samples: 2192384. Policy #0 lag: (min: 14.0, avg: 17.0, max: 78.0)
[2025-11-09 01:13:53,022][12467] Avg episode reward: [(0, '239.081')]
[2025-11-09 01:13:58,063][12467] Fps is (10 sec: 3282.2, 60 sec: 3545.5, 300 sec: 3665.2). Total num frames: 2211840. Throughput: 0: 3618.0. Samples: 2212864. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-09 01:13:58,064][12467] Avg episode reward: [(0, '239.706')]
[2025-11-09 01:14:03,109][12467] Fps is (10 sec: 3248.4, 60 sec: 3549.4, 300 sec: 3664.5). Total num frames: 2228224. Throughput: 0: 3639.8. Samples: 2235904. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-09 01:14:03,109][12467] Avg episode reward: [(0, '236.102')]
[2025-11-09 01:14:08,017][12467] Fps is (10 sec: 3292.0, 60 sec: 3553.3, 300 sec: 3665.4). Total num frames: 2244608. Throughput: 0: 3615.8. Samples: 2245632. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-09 01:14:08,044][12467] Avg episode reward: [(0, '241.150')]
[2025-11-09 01:14:13,004][12467] Fps is (10 sec: 3311.4, 60 sec: 3553.3, 300 sec: 3665.9). Total num frames: 2260992. Throughput: 0: 3631.5. Samples: 2268672. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-09 01:14:13,045][12467] Avg episode reward: [(0, '246.781')]
[2025-11-09 01:14:13,174][12467] Saving new best policy, reward=246.781!
[2025-11-09 01:14:18,123][12467] Fps is (10 sec: 4053.2, 60 sec: 3684.7, 300 sec: 3692.5). Total num frames: 2285568. Throughput: 0: 3641.9. Samples: 2291200. Policy #0 lag: (min: 10.0, avg: 13.0, max: 74.0)
[2025-11-09 01:14:18,123][12467] Avg episode reward: [(0, '253.359')]
[2025-11-09 01:14:18,468][12467] Saving new best policy, reward=253.359!
[2025-11-09 01:14:23,052][12467] Fps is (10 sec: 4891.9, 60 sec: 3818.8, 300 sec: 3721.0). Total num frames: 2310144. Throughput: 0: 3637.2. Samples: 2301440. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-09 01:14:23,052][12467] Avg episode reward: [(0, '260.146')]
[2025-11-09 01:14:23,190][12467] Saving new best policy, reward=260.146!
[2025-11-09 01:14:28,011][12467] Fps is (10 sec: 4142.3, 60 sec: 3824.1, 300 sec: 3668.7). Total num frames: 2326528. Throughput: 0: 3665.3. Samples: 2324480. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-09 01:14:28,011][12467] Avg episode reward: [(0, '267.205')]
[2025-11-09 01:14:28,141][12467] Saving new best policy, reward=267.205!
[2025-11-09 01:14:33,051][12467] Fps is (10 sec: 3277.0, 60 sec: 3691.6, 300 sec: 3665.1). Total num frames: 2342912. Throughput: 0: 3666.0. Samples: 2344960. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-09 01:14:33,052][12467] Avg episode reward: [(0, '272.296')]
[2025-11-09 01:14:33,186][12467] Saving new best policy, reward=272.296!
[2025-11-09 01:14:38,023][12467] Fps is (10 sec: 3272.9, 60 sec: 3548.9, 300 sec: 3666.3). Total num frames: 2359296. Throughput: 0: 3663.6. Samples: 2357248. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-09 01:14:38,023][12467] Avg episode reward: [(0, '271.986')]
[2025-11-09 01:14:43,004][12467] Fps is (10 sec: 3292.3, 60 sec: 3551.4, 300 sec: 3666.3). Total num frames: 2375680. Throughput: 0: 3679.8. Samples: 2378240. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-09 01:14:43,005][12467] Avg episode reward: [(0, '273.041')]
[2025-11-09 01:14:43,144][12467] Saving new best policy, reward=273.041!
[2025-11-09 01:14:48,035][12467] Fps is (10 sec: 3272.7, 60 sec: 3552.5, 300 sec: 3666.1). Total num frames: 2392064. Throughput: 0: 3658.3. Samples: 2400256. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-09 01:14:48,036][12467] Avg episode reward: [(0, '280.712')]
[2025-11-09 01:14:48,175][12467] Saving new best policy, reward=280.712!
[2025-11-09 01:14:53,047][12467] Fps is (10 sec: 3262.9, 60 sec: 3548.4, 300 sec: 3665.0). Total num frames: 2408448. Throughput: 0: 3661.2. Samples: 2410496. Policy #0 lag: (min: 11.0, avg: 14.0, max: 75.0)
[2025-11-09 01:14:53,047][12467] Avg episode reward: [(0, '277.353')]
[2025-11-09 01:14:58,032][12467] Fps is (10 sec: 3277.9, 60 sec: 3551.7, 300 sec: 3666.2). Total num frames: 2424832. Throughput: 0: 3650.0. Samples: 2433024. Policy #0 lag: (min: 11.0, avg: 14.0, max: 75.0)
[2025-11-09 01:14:58,042][12467] Avg episode reward: [(0, '281.732')]
[2025-11-09 01:14:58,167][12467] Saving new best policy, reward=281.732!
[2025-11-09 01:15:03,059][12467] Fps is (10 sec: 4091.2, 60 sec: 3689.5, 300 sec: 3692.6). Total num frames: 2449408. Throughput: 0: 3657.5. Samples: 2455552. Policy #0 lag: (min: 9.0, avg: 12.0, max: 73.0)
[2025-11-09 01:15:03,059][12467] Avg episode reward: [(0, '285.521')]
[2025-11-09 01:15:03,407][12467] Saving /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_lidar_policy5_acc_ttc/checkpoint_p0/checkpoint_000009600_2457600.pth...
[2025-11-09 01:15:03,411][12467] Removing /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_lidar_policy5_acc_ttc/checkpoint_p0/checkpoint_000006144_1572864.pth
[2025-11-09 01:15:03,411][12467] Saving new best policy, reward=285.521!
[2025-11-09 01:15:07,164][12467] Signal inference workers to stop experience collection... (450 times)
[2025-11-09 01:15:07,514][12467] InferenceWorker_p0-w0: stopping experience collection (450 times)
[2025-11-09 01:15:07,516][12467] Signal inference workers to resume experience collection... (450 times)
[2025-11-09 01:15:07,640][12467] InferenceWorker_p0-w0: resuming experience collection (450 times)
[2025-11-09 01:15:07,992][12467] Fps is (10 sec: 4935.1, 60 sec: 3824.5, 300 sec: 3667.0). Total num frames: 2473984. Throughput: 0: 3657.2. Samples: 2465792. Policy #0 lag: (min: 2.0, avg: 5.0, max: 66.0)
[2025-11-09 01:15:07,992][12467] Avg episode reward: [(0, '288.020')]
[2025-11-09 01:15:08,130][12467] Saving new best policy, reward=288.020!
[2025-11-09 01:15:13,056][12467] Fps is (10 sec: 4097.0, 60 sec: 3819.6, 300 sec: 3665.7). Total num frames: 2490368. Throughput: 0: 3637.2. Samples: 2488320. Policy #0 lag: (min: 2.0, avg: 5.0, max: 66.0)
[2025-11-09 01:15:13,056][12467] Avg episode reward: [(0, '293.935')]
[2025-11-09 01:15:13,195][12467] Saving new best policy, reward=293.935!
[2025-11-09 01:15:18,023][12467] Fps is (10 sec: 3266.4, 60 sec: 3692.5, 300 sec: 3665.5). Total num frames: 2506752. Throughput: 0: 3643.1. Samples: 2508800. Policy #0 lag: (min: 1.0, avg: 4.0, max: 65.0)
[2025-11-09 01:15:18,024][12467] Avg episode reward: [(0, '299.478')]
[2025-11-09 01:15:18,153][12467] Saving new best policy, reward=299.478!
[2025-11-09 01:15:23,034][12467] Fps is (10 sec: 3284.0, 60 sec: 3550.9, 300 sec: 3666.2). Total num frames: 2523136. Throughput: 0: 3640.0. Samples: 2521088. Policy #0 lag: (min: 1.0, avg: 4.0, max: 65.0)
[2025-11-09 01:15:23,034][12467] Avg episode reward: [(0, '304.392')]
[2025-11-09 01:15:23,168][12467] Saving new best policy, reward=304.392!
[2025-11-09 01:15:28,046][12467] Fps is (10 sec: 3269.4, 60 sec: 3547.8, 300 sec: 3666.1). Total num frames: 2539520. Throughput: 0: 3626.2. Samples: 2541568. Policy #0 lag: (min: 11.0, avg: 14.0, max: 75.0)
[2025-11-09 01:15:28,046][12467] Avg episode reward: [(0, '306.216')]
[2025-11-09 01:15:28,179][12467] Saving new best policy, reward=306.216!
[2025-11-09 01:15:33,051][12467] Fps is (10 sec: 3271.2, 60 sec: 3549.9, 300 sec: 3665.7). Total num frames: 2555904. Throughput: 0: 3639.6. Samples: 2564096. Policy #0 lag: (min: 11.0, avg: 14.0, max: 75.0)
[2025-11-09 01:15:33,051][12467] Avg episode reward: [(0, '308.995')]
[2025-11-09 01:15:33,180][12467] Saving new best policy, reward=308.995!
[2025-11-09 01:15:38,015][12467] Fps is (10 sec: 3287.1, 60 sec: 3550.3, 300 sec: 3666.0). Total num frames: 2572288. Throughput: 0: 3643.5. Samples: 2574336. Policy #0 lag: (min: 5.0, avg: 8.0, max: 69.0)
[2025-11-09 01:15:38,015][12467] Avg episode reward: [(0, '307.966')]
[2025-11-09 01:15:43,094][12467] Fps is (10 sec: 3262.6, 60 sec: 3544.5, 300 sec: 3640.0). Total num frames: 2588672. Throughput: 0: 3647.2. Samples: 2597376. Policy #0 lag: (min: 5.0, avg: 8.0, max: 69.0)
[2025-11-09 01:15:43,095][12467] Avg episode reward: [(0, '303.989')]
[2025-11-09 01:15:48,004][12467] Fps is (10 sec: 4100.3, 60 sec: 3688.3, 300 sec: 3638.7). Total num frames: 2613248. Throughput: 0: 3645.3. Samples: 2619392. Policy #0 lag: (min: 2.0, avg: 5.0, max: 66.0)
[2025-11-09 01:15:48,004][12467] Avg episode reward: [(0, '311.460')]
[2025-11-09 01:15:48,352][12467] Saving new best policy, reward=311.460!
[2025-11-09 01:15:53,051][12467] Fps is (10 sec: 4936.5, 60 sec: 3822.6, 300 sec: 3664.9). Total num frames: 2637824. Throughput: 0: 3647.4. Samples: 2630144. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-09 01:15:53,052][12467] Avg episode reward: [(0, '307.998')]
[2025-11-09 01:15:58,021][12467] Fps is (10 sec: 4089.0, 60 sec: 3823.6, 300 sec: 3666.0). Total num frames: 2654208. Throughput: 0: 3643.7. Samples: 2652160. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-09 01:15:58,021][12467] Avg episode reward: [(0, '314.466')]
[2025-11-09 01:15:58,157][12467] Saving new best policy, reward=314.466!
[2025-11-09 01:16:03,109][12467] Fps is (10 sec: 3257.9, 60 sec: 3683.3, 300 sec: 3664.3). Total num frames: 2670592. Throughput: 0: 3645.3. Samples: 2673152. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-09 01:16:03,110][12467] Avg episode reward: [(0, '307.996')]
[2025-11-09 01:16:08,081][12467] Fps is (10 sec: 3257.4, 60 sec: 3544.6, 300 sec: 3664.4). Total num frames: 2686976. Throughput: 0: 3637.1. Samples: 2684928. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-09 01:16:08,081][12467] Avg episode reward: [(0, '325.331')]
[2025-11-09 01:16:08,216][12467] Saving new best policy, reward=325.331!
[2025-11-09 01:16:13,049][12467] Fps is (10 sec: 3296.7, 60 sec: 3550.3, 300 sec: 3665.7). Total num frames: 2703360. Throughput: 0: 3629.3. Samples: 2704896. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-09 01:16:13,049][12467] Avg episode reward: [(0, '330.143')]
[2025-11-09 01:16:13,175][12467] Saving new best policy, reward=330.143!
[2025-11-09 01:16:17,995][12467] Fps is (10 sec: 3305.2, 60 sec: 3551.6, 300 sec: 3666.7). Total num frames: 2719744. Throughput: 0: 3622.7. Samples: 2726912. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-09 01:16:17,995][12467] Avg episode reward: [(0, '329.353')]
[2025-11-09 01:16:19,755][12467] Signal inference workers to stop experience collection... (500 times)
[2025-11-09 01:16:20,104][12467] InferenceWorker_p0-w0: stopping experience collection (500 times)
[2025-11-09 01:16:20,104][12467] Signal inference workers to resume experience collection... (500 times)
[2025-11-09 01:16:20,104][12467] InferenceWorker_p0-w0: resuming experience collection (500 times)
[2025-11-09 01:16:23,029][12467] Fps is (10 sec: 3283.4, 60 sec: 3550.2, 300 sec: 3641.1). Total num frames: 2736128. Throughput: 0: 3617.0. Samples: 2737152. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-09 01:16:23,029][12467] Avg episode reward: [(0, '328.145')]
[2025-11-09 01:16:28,012][12467] Fps is (10 sec: 3271.1, 60 sec: 3551.9, 300 sec: 3610.8). Total num frames: 2752512. Throughput: 0: 3624.7. Samples: 2760192. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-09 01:16:28,013][12467] Avg episode reward: [(0, '319.745')]
[2025-11-09 01:16:33,239][12467] Fps is (10 sec: 4011.7, 60 sec: 3674.9, 300 sec: 3635.3). Total num frames: 2777088. Throughput: 0: 3599.3. Samples: 2782208. Policy #0 lag: (min: 10.0, avg: 13.0, max: 74.0)
[2025-11-09 01:16:33,240][12467] Avg episode reward: [(0, '328.386')]
[2025-11-09 01:16:38,107][12467] Fps is (10 sec: 4869.1, 60 sec: 3817.1, 300 sec: 3664.4). Total num frames: 2801664. Throughput: 0: 3602.3. Samples: 2792448. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-09 01:16:38,107][12467] Avg episode reward: [(0, '338.403')]
[2025-11-09 01:16:38,108][12467] Saving new best policy, reward=338.403!
[2025-11-09 01:16:43,006][12467] Fps is (10 sec: 4193.8, 60 sec: 3828.6, 300 sec: 3666.3). Total num frames: 2818048. Throughput: 0: 3630.7. Samples: 2815488. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-09 01:16:43,006][12467] Avg episode reward: [(0, '337.399')]
[2025-11-09 01:16:48,071][12467] Fps is (10 sec: 3288.5, 60 sec: 3682.3, 300 sec: 3664.5). Total num frames: 2834432. Throughput: 0: 3609.8. Samples: 2835456. Policy #0 lag: (min: 5.0, avg: 8.0, max: 69.0)
[2025-11-09 01:16:48,072][12467] Avg episode reward: [(0, '335.380')]
[2025-11-09 01:16:53,000][12467] Fps is (10 sec: 3279.0, 60 sec: 3552.9, 300 sec: 3666.5). Total num frames: 2850816. Throughput: 0: 3624.7. Samples: 2847744. Policy #0 lag: (min: 5.0, avg: 8.0, max: 69.0)
[2025-11-09 01:16:53,000][12467] Avg episode reward: [(0, '338.156')]
[2025-11-09 01:16:58,053][12467] Fps is (10 sec: 3282.8, 60 sec: 3548.0, 300 sec: 3666.2). Total num frames: 2867200. Throughput: 0: 3629.2. Samples: 2868224. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-09 01:16:58,053][12467] Avg episode reward: [(0, '355.275')]
[2025-11-09 01:16:58,183][12467] Saving new best policy, reward=355.275!
[2025-11-09 01:17:03,092][12467] Fps is (10 sec: 3246.8, 60 sec: 3550.9, 300 sec: 3640.1). Total num frames: 2883584. Throughput: 0: 3644.4. Samples: 2891264. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-09 01:17:03,092][12467] Avg episode reward: [(0, '364.815')]
[2025-11-09 01:17:03,230][12467] Saving /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_lidar_policy5_acc_ttc/checkpoint_p0/checkpoint_000011264_2883584.pth...
[2025-11-09 01:17:03,234][12467] Removing /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_lidar_policy5_acc_ttc/checkpoint_p0/checkpoint_000007872_2015232.pth
[2025-11-09 01:17:03,235][12467] Saving new best policy, reward=364.815!
[2025-11-09 01:17:07,992][12467] Fps is (10 sec: 3296.9, 60 sec: 3555.1, 300 sec: 3611.8). Total num frames: 2899968. Throughput: 0: 3643.9. Samples: 2900992. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-09 01:17:07,992][12467] Avg episode reward: [(0, '383.367')]
[2025-11-09 01:17:08,117][12467] Saving new best policy, reward=383.367!
[2025-11-09 01:17:12,998][12467] Fps is (10 sec: 3307.9, 60 sec: 3552.9, 300 sec: 3610.1). Total num frames: 2916352. Throughput: 0: 3642.1. Samples: 2924032. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-09 01:17:12,998][12467] Avg episode reward: [(0, '383.525')]
[2025-11-09 01:17:13,132][12467] Saving new best policy, reward=383.525!
[2025-11-09 01:17:18,231][12467] Fps is (10 sec: 4000.4, 60 sec: 3671.9, 300 sec: 3635.9). Total num frames: 2940928. Throughput: 0: 3641.6. Samples: 2946048. Policy #0 lag: (min: 11.0, avg: 14.0, max: 75.0)
[2025-11-09 01:17:18,231][12467] Avg episode reward: [(0, '383.796')]
[2025-11-09 01:17:18,577][12467] Saving new best policy, reward=383.796!
[2025-11-09 01:17:23,141][12467] Fps is (10 sec: 4845.9, 60 sec: 3815.8, 300 sec: 3663.6). Total num frames: 2965504. Throughput: 0: 3638.1. Samples: 2956288. Policy #0 lag: (min: 1.0, avg: 4.0, max: 65.0)
[2025-11-09 01:17:23,141][12467] Avg episode reward: [(0, '384.643')]
[2025-11-09 01:17:23,144][12467] Saving new best policy, reward=384.643!
[2025-11-09 01:17:28,030][12467] Fps is (10 sec: 4180.1, 60 sec: 3821.8, 300 sec: 3665.2). Total num frames: 2981888. Throughput: 0: 3627.6. Samples: 2978816. Policy #0 lag: (min: 1.0, avg: 4.0, max: 65.0)
[2025-11-09 01:17:28,030][12467] Avg episode reward: [(0, '375.115')]
[2025-11-09 01:17:33,077][12467] Fps is (10 sec: 3297.7, 60 sec: 3696.4, 300 sec: 3665.5). Total num frames: 2998272. Throughput: 0: 3640.4. Samples: 2999296. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-09 01:17:33,078][12467] Avg episode reward: [(0, '380.769')]
[2025-11-09 01:17:36,298][12467] Signal inference workers to stop experience collection... (550 times)
[2025-11-09 01:17:36,298][12467] Signal inference workers to resume experience collection... (550 times)
[2025-11-09 01:17:36,541][12467] InferenceWorker_p0-w0: stopping experience collection (550 times)
[2025-11-09 01:17:36,541][12467] InferenceWorker_p0-w0: resuming experience collection (550 times)
[2025-11-09 01:17:38,041][12467] Fps is (10 sec: 3273.0, 60 sec: 3553.8, 300 sec: 3665.4). Total num frames: 3014656. Throughput: 0: 3637.5. Samples: 3011584. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-09 01:17:38,042][12467] Avg episode reward: [(0, '371.695')]
[2025-11-09 01:17:43,031][12467] Fps is (10 sec: 3292.2, 60 sec: 3548.4, 300 sec: 3640.5). Total num frames: 3031040. Throughput: 0: 3642.7. Samples: 3032064. Policy #0 lag: (min: 8.0, avg: 11.0, max: 72.0)
[2025-11-09 01:17:43,031][12467] Avg episode reward: [(0, '376.967')]
[2025-11-09 01:17:48,070][12467] Fps is (10 sec: 3267.5, 60 sec: 3550.0, 300 sec: 3609.8). Total num frames: 3047424. Throughput: 0: 3631.3. Samples: 3054592. Policy #0 lag: (min: 8.0, avg: 11.0, max: 72.0)
[2025-11-09 01:17:48,070][12467] Avg episode reward: [(0, '392.763')]
[2025-11-09 01:17:48,194][12467] Saving new best policy, reward=392.763!
[2025-11-09 01:17:53,017][12467] Fps is (10 sec: 3281.2, 60 sec: 3548.8, 300 sec: 3609.7). Total num frames: 3063808. Throughput: 0: 3638.9. Samples: 3064832. Policy #0 lag: (min: 31.0, avg: 34.0, max: 95.0)
[2025-11-09 01:17:53,017][12467] Avg episode reward: [(0, '411.105')]
[2025-11-09 01:17:53,142][12467] Saving new best policy, reward=411.105!
[2025-11-09 01:17:58,073][12467] Fps is (10 sec: 3275.7, 60 sec: 3548.7, 300 sec: 3610.4). Total num frames: 3080192. Throughput: 0: 3623.4. Samples: 3087360. Policy #0 lag: (min: 31.0, avg: 34.0, max: 95.0)
[2025-11-09 01:17:58,074][12467] Avg episode reward: [(0, '419.023')]
[2025-11-09 01:17:58,198][12467] Saving new best policy, reward=419.023!
[2025-11-09 01:18:03,265][12467] Fps is (10 sec: 3996.8, 60 sec: 3675.8, 300 sec: 3635.5). Total num frames: 3104768. Throughput: 0: 3638.1. Samples: 3109888. Policy #0 lag: (min: 45.0, avg: 48.0, max: 109.0)
[2025-11-09 01:18:03,266][12467] Avg episode reward: [(0, '419.065')]
[2025-11-09 01:18:03,601][12467] Saving new best policy, reward=419.065!
[2025-11-09 01:18:08,083][12467] Fps is (10 sec: 4910.2, 60 sec: 3817.1, 300 sec: 3665.3). Total num frames: 3129344. Throughput: 0: 3645.5. Samples: 3120128. Policy #0 lag: (min: 45.0, avg: 48.0, max: 109.0)
[2025-11-09 01:18:08,084][12467] Avg episode reward: [(0, '417.023')]
[2025-11-09 01:18:13,082][12467] Fps is (10 sec: 4172.7, 60 sec: 3817.6, 300 sec: 3665.7). Total num frames: 3145728. Throughput: 0: 3636.7. Samples: 3142656. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-09 01:18:13,082][12467] Avg episode reward: [(0, '419.899')]
[2025-11-09 01:18:13,207][12467] Saving new best policy, reward=419.899!
[2025-11-09 01:18:18,006][12467] Fps is (10 sec: 3302.3, 60 sec: 3700.3, 300 sec: 3665.3). Total num frames: 3162112. Throughput: 0: 3646.7. Samples: 3163136. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-09 01:18:18,007][12467] Avg episode reward: [(0, '422.864')]
[2025-11-09 01:18:18,143][12467] Saving new best policy, reward=422.864!
[2025-11-09 01:18:23,038][12467] Fps is (10 sec: 3291.2, 60 sec: 3556.0, 300 sec: 3665.5). Total num frames: 3178496. Throughput: 0: 3641.2. Samples: 3175424. Policy #0 lag: (min: 44.0, avg: 47.0, max: 108.0)
[2025-11-09 01:18:23,038][12467] Avg episode reward: [(0, '419.854')]
[2025-11-09 01:18:28,015][12467] Fps is (10 sec: 3273.9, 60 sec: 3550.7, 300 sec: 3639.3). Total num frames: 3194880. Throughput: 0: 3642.2. Samples: 3195904. Policy #0 lag: (min: 44.0, avg: 47.0, max: 108.0)
[2025-11-09 01:18:28,015][12467] Avg episode reward: [(0, '418.272')]
[2025-11-09 01:18:33,030][12467] Fps is (10 sec: 3279.4, 60 sec: 3552.7, 300 sec: 3609.8). Total num frames: 3211264. Throughput: 0: 3644.1. Samples: 3218432. Policy #0 lag: (min: 44.0, avg: 47.0, max: 108.0)
[2025-11-09 01:18:33,030][12467] Avg episode reward: [(0, '423.454')]
[2025-11-09 01:18:33,159][12467] Saving new best policy, reward=423.454!
[2025-11-09 01:18:38,074][12467] Fps is (10 sec: 3257.6, 60 sec: 3547.9, 300 sec: 3609.5). Total num frames: 3227648. Throughput: 0: 3636.3. Samples: 3228672. Policy #0 lag: (min: 7.0, avg: 10.0, max: 71.0)
[2025-11-09 01:18:38,074][12467] Avg episode reward: [(0, '441.390')]
[2025-11-09 01:18:38,207][12467] Saving new best policy, reward=441.390!
[2025-11-09 01:18:43,027][12467] Fps is (10 sec: 3277.9, 60 sec: 3550.1, 300 sec: 3610.7). Total num frames: 3244032. Throughput: 0: 3656.1. Samples: 3251712. Policy #0 lag: (min: 7.0, avg: 10.0, max: 71.0)
[2025-11-09 01:18:43,027][12467] Avg episode reward: [(0, '453.843')]
[2025-11-09 01:18:43,157][12467] Saving new best policy, reward=453.843!
[2025-11-09 01:18:48,285][12467] Fps is (10 sec: 4011.2, 60 sec: 3673.2, 300 sec: 3634.6). Total num frames: 3268608. Throughput: 0: 3639.3. Samples: 3273728. Policy #0 lag: (min: 50.0, avg: 53.0, max: 114.0)
[2025-11-09 01:18:48,286][12467] Avg episode reward: [(0, '459.139')]
[2025-11-09 01:18:48,619][12467] Saving new best policy, reward=459.139!
[2025-11-09 01:18:52,384][12467] Signal inference workers to stop experience collection... (600 times)
[2025-11-09 01:18:52,720][12467] InferenceWorker_p0-w0: stopping experience collection (600 times)
[2025-11-09 01:18:52,722][12467] Signal inference workers to resume experience collection... (600 times)
[2025-11-09 01:18:52,842][12467] InferenceWorker_p0-w0: resuming experience collection (600 times)
[2025-11-09 01:18:53,062][12467] Fps is (10 sec: 4897.8, 60 sec: 3820.1, 300 sec: 3665.6). Total num frames: 3293184. Throughput: 0: 3642.6. Samples: 3283968. Policy #0 lag: (min: 50.0, avg: 53.0, max: 114.0)
[2025-11-09 01:18:53,062][12467] Avg episode reward: [(0, '459.820')]
[2025-11-09 01:18:53,064][12467] Saving new best policy, reward=459.820!
[2025-11-09 01:18:58,100][12467] Fps is (10 sec: 4173.3, 60 sec: 3821.2, 300 sec: 3665.7). Total num frames: 3309568. Throughput: 0: 3639.4. Samples: 3306496. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-09 01:18:58,100][12467] Avg episode reward: [(0, '451.678')]
[2025-11-09 01:19:02,990][12467] Fps is (10 sec: 3300.5, 60 sec: 3703.4, 300 sec: 3665.9). Total num frames: 3325952. Throughput: 0: 3642.2. Samples: 3326976. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-09 01:19:02,991][12467] Avg episode reward: [(0, '447.851')]
[2025-11-09 01:19:03,120][12467] Saving /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_lidar_policy5_acc_ttc/checkpoint_p0/checkpoint_000012992_3325952.pth...
[2025-11-09 01:19:03,124][12467] Removing /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_lidar_policy5_acc_ttc/checkpoint_p0/checkpoint_000009600_2457600.pth
[2025-11-09 01:19:08,023][12467] Fps is (10 sec: 3302.3, 60 sec: 3553.5, 300 sec: 3665.3). Total num frames: 3342336. Throughput: 0: 3642.1. Samples: 3339264. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-09 01:19:08,023][12467] Avg episode reward: [(0, '442.445')]
[2025-11-09 01:19:13,025][12467] Fps is (10 sec: 3265.5, 60 sec: 3553.2, 300 sec: 3639.0). Total num frames: 3358720. Throughput: 0: 3640.1. Samples: 3359744. Policy #0 lag: (min: 10.0, avg: 13.0, max: 74.0)
[2025-11-09 01:19:13,025][12467] Avg episode reward: [(0, '447.924')]
[2025-11-09 01:19:18,027][12467] Fps is (10 sec: 3275.4, 60 sec: 3548.6, 300 sec: 3610.3). Total num frames: 3375104. Throughput: 0: 3641.1. Samples: 3382272. Policy #0 lag: (min: 10.0, avg: 13.0, max: 74.0)
[2025-11-09 01:19:18,027][12467] Avg episode reward: [(0, '450.566')]
[2025-11-09 01:19:23,101][12467] Fps is (10 sec: 3252.2, 60 sec: 3546.1, 300 sec: 3608.9). Total num frames: 3391488. Throughput: 0: 3911.6. Samples: 3404800. Policy #0 lag: (min: 10.0, avg: 13.0, max: 74.0)
[2025-11-09 01:19:23,101][12467] Avg episode reward: [(0, '448.998')]
[2025-11-09 01:19:28,081][12467] Fps is (10 sec: 3259.4, 60 sec: 3546.0, 300 sec: 3609.7). Total num frames: 3407872. Throughput: 0: 3636.5. Samples: 3415552. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-09 01:19:28,081][12467] Avg episode reward: [(0, '462.859')]
[2025-11-09 01:19:28,210][12467] Saving new best policy, reward=462.859!
[2025-11-09 01:19:33,230][12467] Fps is (10 sec: 4043.7, 60 sec: 3674.1, 300 sec: 3635.2). Total num frames: 3432448. Throughput: 0: 3645.4. Samples: 3437568. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-09 01:19:33,230][12467] Avg episode reward: [(0, '473.148')]
[2025-11-09 01:19:33,575][12467] Saving new best policy, reward=473.148!
[2025-11-09 01:19:38,030][12467] Fps is (10 sec: 4940.0, 60 sec: 3825.7, 300 sec: 3665.2). Total num frames: 3457024. Throughput: 0: 3643.5. Samples: 3447808. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-09 01:19:38,031][12467] Avg episode reward: [(0, '468.850')]
[2025-11-09 01:19:43,033][12467] Fps is (10 sec: 4178.3, 60 sec: 3822.5, 300 sec: 3665.6). Total num frames: 3473408. Throughput: 0: 3657.7. Samples: 3470848. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-09 01:19:43,033][12467] Avg episode reward: [(0, '474.472')]
[2025-11-09 01:19:43,161][12467] Saving new best policy, reward=474.472!
[2025-11-09 01:19:48,051][12467] Fps is (10 sec: 3270.1, 60 sec: 3700.9, 300 sec: 3665.5). Total num frames: 3489792. Throughput: 0: 3636.0. Samples: 3490816. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-09 01:19:48,051][12467] Avg episode reward: [(0, '489.541')]
[2025-11-09 01:19:48,177][12467] Saving new best policy, reward=489.541!
[2025-11-09 01:19:53,074][12467] Fps is (10 sec: 3263.4, 60 sec: 3549.2, 300 sec: 3665.1). Total num frames: 3506176. Throughput: 0: 3648.1. Samples: 3503616. Policy #0 lag: (min: 5.0, avg: 8.0, max: 69.0)
[2025-11-09 01:19:53,074][12467] Avg episode reward: [(0, '477.053')]
[2025-11-09 01:19:58,069][12467] Fps is (10 sec: 3271.0, 60 sec: 3551.7, 300 sec: 3637.7). Total num frames: 3522560. Throughput: 0: 3637.4. Samples: 3523584. Policy #0 lag: (min: 5.0, avg: 8.0, max: 69.0)
[2025-11-09 01:19:58,069][12467] Avg episode reward: [(0, '460.873')]
[2025-11-09 01:20:03,041][12467] Fps is (10 sec: 3287.6, 60 sec: 3546.9, 300 sec: 3609.4). Total num frames: 3538944. Throughput: 0: 3651.1. Samples: 3546624. Policy #0 lag: (min: 5.0, avg: 8.0, max: 69.0)
[2025-11-09 01:20:03,041][12467] Avg episode reward: [(0, '468.259')]
[2025-11-09 01:20:04,663][12467] Signal inference workers to stop experience collection... (650 times)
[2025-11-09 01:20:05,000][12467] InferenceWorker_p0-w0: stopping experience collection (650 times)
[2025-11-09 01:20:05,001][12467] Signal inference workers to resume experience collection... (650 times)
[2025-11-09 01:20:05,001][12467] InferenceWorker_p0-w0: resuming experience collection (650 times)
[2025-11-09 01:20:08,048][12467] Fps is (10 sec: 3283.5, 60 sec: 3548.4, 300 sec: 3610.1). Total num frames: 3555328. Throughput: 0: 3371.7. Samples: 3556352. Policy #0 lag: (min: 5.0, avg: 8.0, max: 69.0)
[2025-11-09 01:20:08,049][12467] Avg episode reward: [(0, '476.086')]
[2025-11-09 01:20:13,070][12467] Fps is (10 sec: 3267.3, 60 sec: 3547.2, 300 sec: 3609.5). Total num frames: 3571712. Throughput: 0: 3641.7. Samples: 3579392. Policy #0 lag: (min: 5.0, avg: 8.0, max: 69.0)
[2025-11-09 01:20:13,071][12467] Avg episode reward: [(0, '487.787')]
[2025-11-09 01:20:18,242][12467] Fps is (10 sec: 4018.1, 60 sec: 3673.2, 300 sec: 3635.2). Total num frames: 3596288. Throughput: 0: 3639.9. Samples: 3601408. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-09 01:20:18,243][12467] Avg episode reward: [(0, '500.975')]
[2025-11-09 01:20:18,576][12467] Saving new best policy, reward=500.975!
[2025-11-09 01:20:23,238][12467] Fps is (10 sec: 4834.2, 60 sec: 3814.2, 300 sec: 3663.2). Total num frames: 3620864. Throughput: 0: 3624.2. Samples: 3611648. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-09 01:20:23,238][12467] Avg episode reward: [(0, '496.503')]
[2025-11-09 01:20:28,101][12467] Fps is (10 sec: 4154.6, 60 sec: 3821.6, 300 sec: 3664.9). Total num frames: 3637248. Throughput: 0: 3601.3. Samples: 3633152. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-09 01:20:28,102][12467] Avg episode reward: [(0, '504.168')]
[2025-11-09 01:20:28,232][12467] Saving new best policy, reward=504.168!
[2025-11-09 01:20:32,995][12467] Fps is (10 sec: 3358.2, 60 sec: 3700.9, 300 sec: 3665.8). Total num frames: 3653632. Throughput: 0: 3622.6. Samples: 3653632. Policy #0 lag: (min: 6.0, avg: 9.0, max: 70.0)
[2025-11-09 01:20:32,996][12467] Avg episode reward: [(0, '509.439')]
[2025-11-09 01:20:32,997][12467] Saving new best policy, reward=509.439!
[2025-11-09 01:20:38,273][12467] Fps is (10 sec: 3221.3, 60 sec: 3535.5, 300 sec: 3663.4). Total num frames: 3670016. Throughput: 0: 3511.6. Samples: 3662336. Policy #0 lag: (min: 6.0, avg: 9.0, max: 70.0)
[2025-11-09 01:20:38,274][12467] Avg episode reward: [(0, '512.792')]
[2025-11-09 01:20:38,274][12467] Saving new best policy, reward=512.792!
[2025-11-09 01:20:43,131][12467] Fps is (10 sec: 2424.7, 60 sec: 3407.8, 300 sec: 3608.5). Total num frames: 3678208. Throughput: 0: 3488.1. Samples: 3680768. Policy #0 lag: (min: 3.0, avg: 6.0, max: 67.0)
[2025-11-09 01:20:43,131][12467] Avg episode reward: [(0, '501.629')]
[2025-11-09 01:20:48,045][12467] Fps is (10 sec: 1676.7, 60 sec: 3277.1, 300 sec: 3554.6). Total num frames: 3686400. Throughput: 0: 3401.7. Samples: 3699712. Policy #0 lag: (min: 3.0, avg: 6.0, max: 67.0)
[2025-11-09 01:20:48,045][12467] Avg episode reward: [(0, '485.363')]
[2025-11-09 01:20:53,114][12467] Fps is (10 sec: 2461.8, 60 sec: 3274.6, 300 sec: 3553.4). Total num frames: 3702784. Throughput: 0: 3601.5. Samples: 3718656. Policy #0 lag: (min: 3.0, avg: 6.0, max: 67.0)
[2025-11-09 01:20:53,114][12467] Avg episode reward: [(0, '494.728')]
[2025-11-09 01:20:58,007][12467] Fps is (10 sec: 3289.1, 60 sec: 3280.2, 300 sec: 3555.7). Total num frames: 3719168. Throughput: 0: 3315.6. Samples: 3728384. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-09 01:20:58,008][12467] Avg episode reward: [(0, '499.831')]
[2025-11-09 01:21:03,325][12467] Fps is (10 sec: 4011.5, 60 sec: 3397.3, 300 sec: 3579.3). Total num frames: 3743744. Throughput: 0: 3270.8. Samples: 3748864. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-09 01:21:03,325][12467] Avg episode reward: [(0, '505.800')]
[2025-11-09 01:21:03,683][12467] Saving /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_lidar_policy5_acc_ttc/checkpoint_p0/checkpoint_000014656_3751936.pth...
[2025-11-09 01:21:03,687][12467] Removing /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_lidar_policy5_acc_ttc/checkpoint_p0/checkpoint_000011264_2883584.pth
[2025-11-09 01:21:08,315][12467] Fps is (10 sec: 3973.9, 60 sec: 3398.3, 300 sec: 3579.0). Total num frames: 3760128. Throughput: 0: 3259.9. Samples: 3758592. Policy #0 lag: (min: 8.0, avg: 11.0, max: 72.0)
[2025-11-09 01:21:08,315][12467] Avg episode reward: [(0, '497.984')]
[2025-11-09 01:21:13,262][12467] Fps is (10 sec: 3297.5, 60 sec: 3402.5, 300 sec: 3579.0). Total num frames: 3776512. Throughput: 0: 3219.8. Samples: 3778560. Policy #0 lag: (min: 8.0, avg: 11.0, max: 72.0)
[2025-11-09 01:21:13,262][12467] Avg episode reward: [(0, '510.194')]
[2025-11-09 01:21:18,239][12467] Fps is (10 sec: 3301.6, 60 sec: 3277.0, 300 sec: 3579.7). Total num frames: 3792896. Throughput: 0: 3202.6. Samples: 3798528. Policy #0 lag: (min: 8.0, avg: 11.0, max: 72.0)
[2025-11-09 01:21:18,240][12467] Avg episode reward: [(0, '506.830')]
[2025-11-09 01:21:23,342][12467] Fps is (10 sec: 3250.6, 60 sec: 3134.8, 300 sec: 3578.3). Total num frames: 3809280. Throughput: 0: 3226.3. Samples: 3807744. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-09 01:21:23,343][12467] Avg episode reward: [(0, '517.426')]
[2025-11-09 01:21:23,719][12467] Saving new best policy, reward=517.426!
[2025-11-09 01:21:28,054][12467] Fps is (10 sec: 2504.1, 60 sec: 3006.1, 300 sec: 3528.9). Total num frames: 3817472. Throughput: 0: 3259.7. Samples: 3827200. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-09 01:21:28,054][12467] Avg episode reward: [(0, '514.299')]
[2025-11-09 01:21:28,437][12467] Signal inference workers to stop experience collection... (700 times)
[2025-11-09 01:21:28,438][12467] Signal inference workers to resume experience collection... (700 times)
[2025-11-09 01:21:28,713][12467] InferenceWorker_p0-w0: stopping experience collection (700 times)
[2025-11-09 01:21:28,714][12467] InferenceWorker_p0-w0: resuming experience collection (700 times)
[2025-11-09 01:21:33,053][12467] Fps is (10 sec: 2530.8, 60 sec: 3000.8, 300 sec: 3499.6). Total num frames: 3833856. Throughput: 0: 3276.2. Samples: 3847168. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-09 01:21:33,053][12467] Avg episode reward: [(0, '517.032')]
[2025-11-09 01:21:37,982][12467] Fps is (10 sec: 3300.5, 60 sec: 3018.4, 300 sec: 3499.2). Total num frames: 3850240. Throughput: 0: 3069.7. Samples: 3856384. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-09 01:21:37,982][12467] Avg episode reward: [(0, '508.284')]
[2025-11-09 01:21:43,113][12467] Fps is (10 sec: 3257.2, 60 sec: 3141.2, 300 sec: 3498.5). Total num frames: 3866624. Throughput: 0: 3269.1. Samples: 3875840. Policy #0 lag: (min: 6.0, avg: 9.0, max: 70.0)
[2025-11-09 01:21:43,113][12467] Avg episode reward: [(0, '509.932')]
[2025-11-09 01:21:48,062][12467] Fps is (10 sec: 3250.7, 60 sec: 3275.9, 300 sec: 3498.2). Total num frames: 3883008. Throughput: 0: 3296.0. Samples: 3896320. Policy #0 lag: (min: 6.0, avg: 9.0, max: 70.0)
[2025-11-09 01:21:48,062][12467] Avg episode reward: [(0, '514.659')]
[2025-11-09 01:21:52,992][12467] Fps is (10 sec: 3317.1, 60 sec: 3283.5, 300 sec: 3499.7). Total num frames: 3899392. Throughput: 0: 3289.0. Samples: 3905536. Policy #0 lag: (min: 6.0, avg: 9.0, max: 70.0)
[2025-11-09 01:21:52,992][12467] Avg episode reward: [(0, '514.923')]
[2025-11-09 01:21:58,035][12467] Fps is (10 sec: 3285.6, 60 sec: 3275.3, 300 sec: 3499.6). Total num frames: 3915776. Throughput: 0: 3293.4. Samples: 3926016. Policy #0 lag: (min: 13.0, avg: 16.0, max: 77.0)
[2025-11-09 01:21:58,036][12467] Avg episode reward: [(0, '518.510')]
[2025-11-09 01:21:58,439][12467] Saving new best policy, reward=518.510!
[2025-11-09 01:22:03,073][12467] Fps is (10 sec: 3250.3, 60 sec: 3153.5, 300 sec: 3498.0). Total num frames: 3932160. Throughput: 0: 3266.1. Samples: 3944960. Policy #0 lag: (min: 13.0, avg: 16.0, max: 77.0)
[2025-11-09 01:22:03,073][12467] Avg episode reward: [(0, '523.725')]
[2025-11-09 01:22:03,440][12467] Saving new best policy, reward=523.725!
[2025-11-09 01:22:08,069][12467] Fps is (10 sec: 3265.7, 60 sec: 3153.2, 300 sec: 3498.1). Total num frames: 3948544. Throughput: 0: 3285.4. Samples: 3954688. Policy #0 lag: (min: 13.0, avg: 16.0, max: 77.0)
[2025-11-09 01:22:08,070][12467] Avg episode reward: [(0, '533.241')]
[2025-11-09 01:22:08,435][12467] Saving new best policy, reward=533.241!
[2025-11-09 01:22:13,080][12467] Fps is (10 sec: 3274.6, 60 sec: 3149.8, 300 sec: 3473.0). Total num frames: 3964928. Throughput: 0: 3274.9. Samples: 3974656. Policy #0 lag: (min: 3.0, avg: 6.0, max: 67.0)
[2025-11-09 01:22:13,080][12467] Avg episode reward: [(0, '557.307')]
[2025-11-09 01:22:13,445][12467] Saving new best policy, reward=557.307!
[2025-11-09 01:22:18,035][12467] Fps is (10 sec: 3288.1, 60 sec: 3151.0, 300 sec: 3444.7). Total num frames: 3981312. Throughput: 0: 3266.7. Samples: 3994112. Policy #0 lag: (min: 3.0, avg: 6.0, max: 67.0)
[2025-11-09 01:22:18,035][12467] Avg episode reward: [(0, '560.013')]
[2025-11-09 01:22:18,175][12467] Saving new best policy, reward=560.013!
[2025-11-09 01:22:23,047][12467] Fps is (10 sec: 3287.5, 60 sec: 3155.8, 300 sec: 3443.2). Total num frames: 3997696. Throughput: 0: 3260.7. Samples: 4003328. Policy #0 lag: (min: 3.0, avg: 6.0, max: 67.0)
[2025-11-09 01:22:23,047][12467] Avg episode reward: [(0, '572.518')]
[2025-11-09 01:22:23,189][12467] Saving new best policy, reward=572.518!
[2025-11-09 01:22:28,083][12467] Fps is (10 sec: 3261.2, 60 sec: 3275.2, 300 sec: 3443.4). Total num frames: 4014080. Throughput: 0: 3279.0. Samples: 4023296. Policy #0 lag: (min: 9.0, avg: 12.0, max: 73.0)
[2025-11-09 01:22:28,083][12467] Avg episode reward: [(0, '574.045')]
[2025-11-09 01:22:28,443][12467] Saving new best policy, reward=574.045!
[2025-11-09 01:22:33,067][12467] Fps is (10 sec: 3270.2, 60 sec: 3276.0, 300 sec: 3443.1). Total num frames: 4030464. Throughput: 0: 3276.4. Samples: 4043776. Policy #0 lag: (min: 9.0, avg: 12.0, max: 73.0)
[2025-11-09 01:22:33,067][12467] Avg episode reward: [(0, '591.931')]
[2025-11-09 01:22:33,431][12467] Saving new best policy, reward=591.931!
[2025-11-09 01:22:38,013][12467] Fps is (10 sec: 3300.0, 60 sec: 3275.1, 300 sec: 3443.6). Total num frames: 4046848. Throughput: 0: 3275.3. Samples: 4052992. Policy #0 lag: (min: 9.0, avg: 12.0, max: 73.0)
[2025-11-09 01:22:38,013][12467] Avg episode reward: [(0, '579.673')]
[2025-11-09 01:22:43,300][12467] Fps is (10 sec: 4002.7, 60 sec: 3402.7, 300 sec: 3468.5). Total num frames: 4071424. Throughput: 0: 3246.3. Samples: 4072960. Policy #0 lag: (min: 7.0, avg: 10.0, max: 71.0)
[2025-11-09 01:22:43,301][12467] Avg episode reward: [(0, '561.615')]
[2025-11-09 01:22:48,257][12467] Fps is (10 sec: 3998.1, 60 sec: 3402.2, 300 sec: 3468.4). Total num frames: 4087808. Throughput: 0: 3286.1. Samples: 4093440. Policy #0 lag: (min: 7.0, avg: 10.0, max: 71.0)
[2025-11-09 01:22:48,258][12467] Avg episode reward: [(0, '571.637')]
[2025-11-09 01:22:52,809][12467] Signal inference workers to stop experience collection... (750 times)
[2025-11-09 01:22:53,171][12467] InferenceWorker_p0-w0: stopping experience collection (750 times)
[2025-11-09 01:22:53,173][12467] Signal inference workers to resume experience collection... (750 times)
[2025-11-09 01:22:53,177][12467] Fps is (10 sec: 3317.9, 60 sec: 3402.8, 300 sec: 3470.0). Total num frames: 4104192. Throughput: 0: 3280.4. Samples: 4102656. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-09 01:22:53,177][12467] Avg episode reward: [(0, '589.235')]
[2025-11-09 01:22:53,317][12467] InferenceWorker_p0-w0: resuming experience collection (750 times)
[2025-11-09 01:22:58,055][12467] Fps is (10 sec: 3344.6, 60 sec: 3412.2, 300 sec: 3445.9). Total num frames: 4120576. Throughput: 0: 3301.4. Samples: 4123136. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-09 01:22:58,055][12467] Avg episode reward: [(0, '602.591')]
[2025-11-09 01:22:58,413][12467] Saving new best policy, reward=602.591!
[2025-11-09 01:23:03,333][12467] Fps is (10 sec: 4033.1, 60 sec: 3534.6, 300 sec: 3440.5). Total num frames: 4145152. Throughput: 0: 3300.5. Samples: 4143616. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-09 01:23:03,333][12467] Avg episode reward: [(0, '600.011')]
[2025-11-09 01:23:03,335][12467] Saving /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_lidar_policy5_acc_ttc/checkpoint_p0/checkpoint_000016192_4145152.pth...
[2025-11-09 01:23:03,339][12467] Removing /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_lidar_policy5_acc_ttc/checkpoint_p0/checkpoint_000012992_3325952.pth
[2025-11-09 01:23:08,043][12467] Fps is (10 sec: 3280.7, 60 sec: 3414.8, 300 sec: 3416.1). Total num frames: 4153344. Throughput: 0: 3322.6. Samples: 4152832. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-09 01:23:08,043][12467] Avg episode reward: [(0, '601.155')]
[2025-11-09 01:23:13,043][12467] Fps is (10 sec: 2530.9, 60 sec: 3415.4, 300 sec: 3415.2). Total num frames: 4169728. Throughput: 0: 3313.9. Samples: 4172288. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-09 01:23:13,043][12467] Avg episode reward: [(0, '593.638')]
[2025-11-09 01:23:18,247][12467] Fps is (10 sec: 3211.1, 60 sec: 3401.3, 300 sec: 3413.2). Total num frames: 4186112. Throughput: 0: 3286.4. Samples: 4192256. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-09 01:23:18,248][12467] Avg episode reward: [(0, '572.522')]
[2025-11-09 01:23:23,317][12467] Fps is (10 sec: 3189.5, 60 sec: 3398.1, 300 sec: 3412.2). Total num frames: 4202496. Throughput: 0: 3254.8. Samples: 4200448. Policy #0 lag: (min: 2.0, avg: 5.0, max: 66.0)
[2025-11-09 01:23:23,317][12467] Avg episode reward: [(0, '564.756')]
[2025-11-09 01:23:28,289][12467] Fps is (10 sec: 3263.3, 60 sec: 3401.7, 300 sec: 3412.7). Total num frames: 4218880. Throughput: 0: 3277.6. Samples: 4220416. Policy #0 lag: (min: 2.0, avg: 5.0, max: 66.0)
[2025-11-09 01:23:28,289][12467] Avg episode reward: [(0, '564.983')]
[2025-11-09 01:23:33,170][12467] Fps is (10 sec: 3325.8, 60 sec: 3407.5, 300 sec: 3414.5). Total num frames: 4235264. Throughput: 0: 3283.2. Samples: 4240896. Policy #0 lag: (min: 2.0, avg: 5.0, max: 66.0)
[2025-11-09 01:23:33,170][12467] Avg episode reward: [(0, '585.518')]
