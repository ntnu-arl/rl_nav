[2025-11-03 14:58:20,218][200377] Saving configuration to /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_lidar_policy2/config.json...
[2025-11-03 14:58:20,257][200377] Using GPUs [0] for process 0 (actually maps to GPUs [0])
[2025-11-03 14:58:20,257][200377] Rollout worker 0 uses device cuda:0
[2025-11-03 14:58:20,279][200377] Using GPUs [0] for process 0 (actually maps to GPUs [0])
[2025-11-03 14:58:20,279][200377] InferenceWorker_p0-w0: min num requests: 1
[2025-11-03 14:58:20,280][200377] Using GPUs [0] for process 0 (actually maps to GPUs [0])
[2025-11-03 14:58:20,280][200377] Starting seed is not provided
[2025-11-03 14:58:20,280][200377] Using GPUs [0] for process 0 (actually maps to GPUs [0])
[2025-11-03 14:58:20,280][200377] Initializing actor-critic model on device cuda:0
[2025-11-03 14:58:20,280][200377] RunningMeanStd input shape: (337,)
[2025-11-03 14:58:20,281][200377] RunningMeanStd input shape: (1,)
[2025-11-03 14:58:20,290][200377] Created Actor Critic model with architecture:
[2025-11-03 14:58:20,290][200377] ActorCriticSharedWeights(
  (obs_normalizer): ObservationNormalizer(
    (running_mean_std): RunningMeanStdDictInPlace(
      (running_mean_std): ModuleDict(
        (observations): RunningMeanStdInPlace()
      )
    )
  )
  (returns_normalizer): RecursiveScriptModule(original_name=RunningMeanStdInPlace)
  (encoder): CustomEncoder(
    (encoders): ModuleDict(
      (obs_image): Sequential(
        (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): ELU(alpha=1.0)
        (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
        (3): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (4): ELU(alpha=1.0)
        (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
        (6): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (7): ELU(alpha=1.0)
        (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        (9): Flatten(start_dim=1, end_dim=-1)
      )
    )
    (mlp_head_custom): Sequential(
      (0): Linear(in_features=145, out_features=256, bias=True)
      (1): ELU(alpha=1.0)
      (2): Linear(in_features=256, out_features=128, bias=True)
      (3): ELU(alpha=1.0)
      (4): Linear(in_features=128, out_features=64, bias=True)
      (5): ELU(alpha=1.0)
    )
  )
  (core): ModelCoreRNN(
    (core): GRU(64, 128)
  )
  (decoder): MlpDecoder(
    (mlp): Identity()
  )
  (critic_linear): Linear(in_features=128, out_features=1, bias=True)
  (action_parameterization): ActionParameterizationDefault(
    (distribution_linear): Linear(in_features=128, out_features=8, bias=True)
  )
)
[2025-11-03 14:58:20,645][200377] Using optimizer <class 'torch.optim.adam.Adam'>
[2025-11-03 14:58:20,645][200377] No checkpoints found
[2025-11-03 14:58:20,645][200377] Did not load from checkpoint, starting from scratch!
[2025-11-03 14:58:20,645][200377] Initialized policy 0 weights for model version 0
[2025-11-03 14:58:20,645][200377] LearnerWorker_p0 finished initialization!
[2025-11-03 14:58:20,646][200377] Using GPUs [0] for process 0 (actually maps to GPUs [0])
[2025-11-03 14:58:20,651][200377] Fps is (10 sec: nan, 60 sec: nan, 300 sec: nan). Total num frames: 0. Throughput: 0: nan. Samples: 0. Policy #0 lag: (min: -1.0, avg: -1.0, max: -1.0)
[2025-11-03 14:58:20,651][200377] Inference worker 0-0 is ready!
[2025-11-03 14:58:20,652][200377] All inference workers are ready! Signal rollout workers to start!
[2025-11-03 14:58:20,652][200377] EnvRunner 0-0 uses policy 0
[2025-11-03 14:58:29,218][200377] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 0.0). Total num frames: 0. Throughput: 0: 0.0. Samples: 0. Policy #0 lag: (min: -1.0, avg: -1.0, max: -1.0)
[2025-11-03 14:58:32,679][200377] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 0.0). Total num frames: 0. Throughput: 0: 0.0. Samples: 0. Policy #0 lag: (min: -1.0, avg: -1.0, max: -1.0)
[2025-11-03 14:58:33,646][200377] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 0.0). Total num frames: 0. Throughput: 0: 78.8. Samples: 1024. Policy #0 lag: (min: -1.0, avg: -1.0, max: -1.0)
[2025-11-03 14:58:33,646][200377] Avg episode reward: [(0, '-100.000')]
[2025-11-03 14:58:37,279][200377] Signal inference workers to stop experience collection...
[2025-11-03 14:58:38,480][200377] InferenceWorker_p0-w0: stopping experience collection
[2025-11-03 14:58:38,482][200377] Signal inference workers to resume experience collection...
[2025-11-03 14:58:38,486][200377] Fps is (10 sec: 1410.6, 60 sec: 459.3, 300 sec: 459.3). Total num frames: 8192. Throughput: 0: 545.5. Samples: 9728. Policy #0 lag: (min: 8.0, avg: 8.0, max: 8.0)
[2025-11-03 14:58:38,486][200377] Avg episode reward: [(0, '-84.505')]
[2025-11-03 14:58:38,604][200377] InferenceWorker_p0-w0: resuming experience collection
[2025-11-03 14:58:40,412][200377] Heartbeat connected on Batcher_0
[2025-11-03 14:58:40,412][200377] Heartbeat connected on LearnerWorker_p0
[2025-11-03 14:58:40,412][200377] Heartbeat connected on InferenceWorker_p0-w0
[2025-11-03 14:58:40,412][200377] Heartbeat connected on RolloutWorker_w0
[2025-11-03 14:58:42,783][200377] Fps is (10 sec: 2689.7, 60 sec: 1110.4, 300 sec: 1110.4). Total num frames: 24576. Throughput: 0: 1388.0. Samples: 30720. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 14:58:42,783][200377] Avg episode reward: [(0, '-80.272')]
[2025-11-03 14:58:47,846][200377] Fps is (10 sec: 4376.0, 60 sec: 1807.4, 300 sec: 1807.4). Total num frames: 49152. Throughput: 0: 1939.2. Samples: 52736. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 14:58:47,846][200377] Avg episode reward: [(0, '-78.148')]
[2025-11-03 14:58:52,785][200377] Fps is (10 sec: 4095.4, 60 sec: 2039.5, 300 sec: 2039.5). Total num frames: 65536. Throughput: 0: 2071.4. Samples: 66560. Policy #0 lag: (min: 10.0, avg: 13.0, max: 74.0)
[2025-11-03 14:58:52,785][200377] Avg episode reward: [(0, '-76.104')]
[2025-11-03 14:58:57,789][200377] Fps is (10 sec: 3295.6, 60 sec: 2205.9, 300 sec: 2205.9). Total num frames: 81920. Throughput: 0: 2440.2. Samples: 90624. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 14:58:57,789][200377] Avg episode reward: [(0, '-72.890')]
[2025-11-03 14:59:02,773][200377] Fps is (10 sec: 4920.9, 60 sec: 2722.8, 300 sec: 2722.8). Total num frames: 114688. Throughput: 0: 2771.4. Samples: 116736. Policy #0 lag: (min: 4.0, avg: 7.0, max: 68.0)
[2025-11-03 14:59:02,773][200377] Avg episode reward: [(0, '-67.335')]
[2025-11-03 14:59:02,879][200377] Saving new best policy, reward=-67.335!
[2025-11-03 14:59:07,780][200377] Fps is (10 sec: 4919.6, 60 sec: 2781.2, 300 sec: 2781.2). Total num frames: 131072. Throughput: 0: 3425.6. Samples: 132096. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 14:59:07,780][200377] Avg episode reward: [(0, '-56.606')]
[2025-11-03 14:59:07,874][200377] Saving new best policy, reward=-56.606!
[2025-11-03 14:59:12,997][200377] Fps is (10 sec: 4807.3, 60 sec: 3129.9, 300 sec: 3129.9). Total num frames: 163840. Throughput: 0: 3987.4. Samples: 160768. Policy #0 lag: (min: 0.0, avg: 3.0, max: 64.0)
[2025-11-03 14:59:12,998][200377] Avg episode reward: [(0, '-40.754')]
[2025-11-03 14:59:12,998][200377] Saving new best policy, reward=-40.754!
[2025-11-03 14:59:17,814][200377] Fps is (10 sec: 4898.5, 60 sec: 3152.8, 300 sec: 3152.8). Total num frames: 180224. Throughput: 0: 4265.9. Samples: 189440. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 14:59:17,814][200377] Avg episode reward: [(0, '-12.015')]
[2025-11-03 14:59:17,902][200377] Saving new best policy, reward=-12.015!
[2025-11-03 14:59:22,836][200377] Fps is (10 sec: 3330.8, 60 sec: 3666.9, 300 sec: 3161.7). Total num frames: 196608. Throughput: 0: 4340.8. Samples: 202240. Policy #0 lag: (min: 5.0, avg: 8.0, max: 69.0)
[2025-11-03 14:59:22,836][200377] Avg episode reward: [(0, '40.031')]
[2025-11-03 14:59:22,942][200377] Saving new best policy, reward=40.031!
[2025-11-03 14:59:27,789][200377] Fps is (10 sec: 4927.7, 60 sec: 4162.1, 300 sec: 3416.5). Total num frames: 229376. Throughput: 0: 4391.3. Samples: 228352. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 14:59:27,789][200377] Avg episode reward: [(0, '82.517')]
[2025-11-03 14:59:27,901][200377] Saving new best policy, reward=82.517!
[2025-11-03 14:59:32,770][200377] Fps is (10 sec: 4947.8, 60 sec: 4156.7, 300 sec: 3407.7). Total num frames: 245760. Throughput: 0: 4467.7. Samples: 253440. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 14:59:32,770][200377] Avg episode reward: [(0, '121.037')]
[2025-11-03 14:59:32,888][200377] Saving new best policy, reward=121.037!
[2025-11-03 14:59:37,828][200377] Fps is (10 sec: 3263.9, 60 sec: 4279.4, 300 sec: 3396.7). Total num frames: 262144. Throughput: 0: 4421.7. Samples: 265728. Policy #0 lag: (min: 14.0, avg: 17.0, max: 78.0)
[2025-11-03 14:59:37,828][200377] Avg episode reward: [(0, '148.578')]
[2025-11-03 14:59:37,925][200377] Saving new best policy, reward=148.578!
[2025-11-03 14:59:38,444][200377] Signal inference workers to stop experience collection... (50 times)
[2025-11-03 14:59:38,755][200377] InferenceWorker_p0-w0: stopping experience collection (50 times)
[2025-11-03 14:59:38,755][200377] Signal inference workers to resume experience collection... (50 times)
[2025-11-03 14:59:38,755][200377] InferenceWorker_p0-w0: resuming experience collection (50 times)
[2025-11-03 14:59:42,763][200377] Fps is (10 sec: 4918.6, 60 sec: 4507.1, 300 sec: 3591.6). Total num frames: 294912. Throughput: 0: 4565.1. Samples: 295936. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 14:59:42,763][200377] Avg episode reward: [(0, '163.787')]
[2025-11-03 14:59:42,852][200377] Saving new best policy, reward=163.787!
[2025-11-03 14:59:47,830][200377] Fps is (10 sec: 4914.4, 60 sec: 4370.3, 300 sec: 3570.8). Total num frames: 311296. Throughput: 0: 4659.0. Samples: 326656. Policy #0 lag: (min: 9.0, avg: 12.0, max: 73.0)
[2025-11-03 14:59:47,830][200377] Avg episode reward: [(0, '169.486')]
[2025-11-03 14:59:47,928][200377] Saving new best policy, reward=169.486!
[2025-11-03 14:59:52,813][200377] Fps is (10 sec: 4890.4, 60 sec: 4639.9, 300 sec: 3733.2). Total num frames: 344064. Throughput: 0: 4638.7. Samples: 340992. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 14:59:52,814][200377] Avg episode reward: [(0, '177.501')]
[2025-11-03 14:59:52,908][200377] Saving new best policy, reward=177.501!
[2025-11-03 14:59:57,783][200377] Fps is (10 sec: 4938.3, 60 sec: 4642.6, 300 sec: 3710.9). Total num frames: 360448. Throughput: 0: 4664.4. Samples: 369664. Policy #0 lag: (min: 1.0, avg: 4.0, max: 65.0)
[2025-11-03 14:59:57,783][200377] Avg episode reward: [(0, '181.801')]
[2025-11-03 14:59:57,880][200377] Saving new best policy, reward=181.801!
[2025-11-03 15:00:02,841][200377] Fps is (10 sec: 4901.6, 60 sec: 4636.9, 300 sec: 3847.9). Total num frames: 393216. Throughput: 0: 4650.7. Samples: 398848. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 15:00:02,841][200377] Avg episode reward: [(0, '185.195')]
[2025-11-03 15:00:02,843][200377] Saving new best policy, reward=185.195!
[2025-11-03 15:00:07,769][200377] Fps is (10 sec: 4921.8, 60 sec: 4642.9, 300 sec: 3823.8). Total num frames: 409600. Throughput: 0: 4705.9. Samples: 413696. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 15:00:07,770][200377] Avg episode reward: [(0, '192.795')]
[2025-11-03 15:00:07,861][200377] Saving /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_lidar_policy2/checkpoint_p0/checkpoint_000001600_409600.pth...
[2025-11-03 15:00:07,865][200377] Saving new best policy, reward=192.795!
[2025-11-03 15:00:12,809][200377] Fps is (10 sec: 4931.2, 60 sec: 4656.8, 300 sec: 3944.2). Total num frames: 442368. Throughput: 0: 4776.5. Samples: 443392. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 15:00:12,809][200377] Avg episode reward: [(0, '200.369')]
[2025-11-03 15:00:12,903][200377] Saving new best policy, reward=200.369!
[2025-11-03 15:00:17,790][200377] Fps is (10 sec: 4905.0, 60 sec: 4644.0, 300 sec: 3916.3). Total num frames: 458752. Throughput: 0: 4912.9. Samples: 474624. Policy #0 lag: (min: 11.0, avg: 14.0, max: 75.0)
[2025-11-03 15:00:17,791][200377] Avg episode reward: [(0, '217.306')]
[2025-11-03 15:00:17,880][200377] Saving new best policy, reward=217.306!
[2025-11-03 15:00:22,758][200377] Fps is (10 sec: 4940.0, 60 sec: 4921.5, 300 sec: 4025.3). Total num frames: 491520. Throughput: 0: 4968.4. Samples: 488960. Policy #0 lag: (min: 2.0, avg: 5.0, max: 66.0)
[2025-11-03 15:00:22,759][200377] Avg episode reward: [(0, '233.839')]
[2025-11-03 15:00:22,848][200377] Saving new best policy, reward=233.839!
[2025-11-03 15:00:27,819][200377] Fps is (10 sec: 4901.0, 60 sec: 4639.8, 300 sec: 3994.0). Total num frames: 507904. Throughput: 0: 4920.4. Samples: 517632. Policy #0 lag: (min: 9.0, avg: 12.0, max: 73.0)
[2025-11-03 15:00:27,820][200377] Avg episode reward: [(0, '254.444')]
[2025-11-03 15:00:27,927][200377] Saving new best policy, reward=254.444!
[2025-11-03 15:00:32,761][200377] Fps is (10 sec: 4914.2, 60 sec: 4915.9, 300 sec: 4092.6). Total num frames: 540672. Throughput: 0: 4888.6. Samples: 546304. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 15:00:32,761][200377] Avg episode reward: [(0, '267.626')]
[2025-11-03 15:00:32,857][200377] Saving new best policy, reward=267.626!
[2025-11-03 15:00:35,055][200377] Signal inference workers to stop experience collection... (100 times)
[2025-11-03 15:00:35,058][200377] Signal inference workers to resume experience collection... (100 times)
[2025-11-03 15:00:35,263][200377] InferenceWorker_p0-w0: stopping experience collection (100 times)
[2025-11-03 15:00:35,264][200377] InferenceWorker_p0-w0: resuming experience collection (100 times)
[2025-11-03 15:00:37,776][200377] Fps is (10 sec: 4936.8, 60 sec: 4919.5, 300 sec: 4062.4). Total num frames: 557056. Throughput: 0: 4873.8. Samples: 560128. Policy #0 lag: (min: 1.0, avg: 4.0, max: 65.0)
[2025-11-03 15:00:37,776][200377] Avg episode reward: [(0, '282.946')]
[2025-11-03 15:00:37,869][200377] Saving new best policy, reward=282.946!
[2025-11-03 15:00:42,762][200377] Fps is (10 sec: 4914.7, 60 sec: 4915.3, 300 sec: 4150.5). Total num frames: 589824. Throughput: 0: 4917.5. Samples: 590848. Policy #0 lag: (min: 2.0, avg: 5.0, max: 66.0)
[2025-11-03 15:00:42,762][200377] Avg episode reward: [(0, '309.091')]
[2025-11-03 15:00:42,852][200377] Saving new best policy, reward=309.091!
[2025-11-03 15:00:47,754][200377] Fps is (10 sec: 4926.1, 60 sec: 4921.4, 300 sec: 4121.0). Total num frames: 606208. Throughput: 0: 4902.0. Samples: 619008. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 15:00:47,754][200377] Avg episode reward: [(0, '326.156')]
[2025-11-03 15:00:47,850][200377] Saving new best policy, reward=326.156!
[2025-11-03 15:00:52,776][200377] Fps is (10 sec: 4908.4, 60 sec: 4918.3, 300 sec: 4200.4). Total num frames: 638976. Throughput: 0: 4880.4. Samples: 633344. Policy #0 lag: (min: 47.0, avg: 50.0, max: 111.0)
[2025-11-03 15:00:52,776][200377] Avg episode reward: [(0, '343.093')]
[2025-11-03 15:00:52,870][200377] Saving new best policy, reward=343.093!
[2025-11-03 15:00:57,825][200377] Fps is (10 sec: 4880.3, 60 sec: 4911.7, 300 sec: 4169.7). Total num frames: 655360. Throughput: 0: 4856.5. Samples: 662016. Policy #0 lag: (min: 47.0, avg: 50.0, max: 111.0)
[2025-11-03 15:00:57,825][200377] Avg episode reward: [(0, '371.382')]
[2025-11-03 15:00:57,922][200377] Saving new best policy, reward=371.382!
[2025-11-03 15:01:02,825][200377] Fps is (10 sec: 4890.8, 60 sec: 4916.5, 300 sec: 4243.1). Total num frames: 688128. Throughput: 0: 4809.1. Samples: 691200. Policy #0 lag: (min: 63.0, avg: 66.0, max: 127.0)
[2025-11-03 15:01:02,826][200377] Avg episode reward: [(0, '366.488')]
[2025-11-03 15:01:07,789][200377] Fps is (10 sec: 4933.1, 60 sec: 4913.6, 300 sec: 4215.2). Total num frames: 704512. Throughput: 0: 4809.6. Samples: 705536. Policy #0 lag: (min: 63.0, avg: 66.0, max: 127.0)
[2025-11-03 15:01:07,789][200377] Avg episode reward: [(0, '378.493')]
[2025-11-03 15:01:07,886][200377] Saving new best policy, reward=378.493!
[2025-11-03 15:01:12,806][200377] Fps is (10 sec: 4924.7, 60 sec: 4915.4, 300 sec: 4282.7). Total num frames: 737280. Throughput: 0: 4837.0. Samples: 735232. Policy #0 lag: (min: 47.0, avg: 50.0, max: 111.0)
[2025-11-03 15:01:12,806][200377] Avg episode reward: [(0, '405.404')]
[2025-11-03 15:01:12,903][200377] Saving new best policy, reward=405.404!
[2025-11-03 15:01:17,767][200377] Fps is (10 sec: 4925.9, 60 sec: 4917.1, 300 sec: 4255.2). Total num frames: 753664. Throughput: 0: 4834.9. Samples: 763904. Policy #0 lag: (min: 47.0, avg: 50.0, max: 111.0)
[2025-11-03 15:01:17,767][200377] Avg episode reward: [(0, '411.055')]
[2025-11-03 15:01:17,863][200377] Saving new best policy, reward=411.055!
[2025-11-03 15:01:22,935][200377] Fps is (10 sec: 4852.8, 60 sec: 4900.8, 300 sec: 4314.3). Total num frames: 786432. Throughput: 0: 4818.5. Samples: 777728. Policy #0 lag: (min: 57.0, avg: 60.0, max: 121.0)
[2025-11-03 15:01:22,935][200377] Avg episode reward: [(0, '431.228')]
[2025-11-03 15:01:22,939][200377] Saving new best policy, reward=431.228!
[2025-11-03 15:01:27,758][200377] Fps is (10 sec: 4919.6, 60 sec: 4920.2, 300 sec: 4290.7). Total num frames: 802816. Throughput: 0: 4813.2. Samples: 807424. Policy #0 lag: (min: 57.0, avg: 60.0, max: 121.0)
[2025-11-03 15:01:27,758][200377] Avg episode reward: [(0, '460.766')]
[2025-11-03 15:01:27,856][200377] Saving new best policy, reward=460.766!
[2025-11-03 15:01:32,182][200377] Signal inference workers to stop experience collection... (150 times)
[2025-11-03 15:01:32,492][200377] InferenceWorker_p0-w0: stopping experience collection (150 times)
[2025-11-03 15:01:32,494][200377] Signal inference workers to resume experience collection... (150 times)
[2025-11-03 15:01:32,578][200377] InferenceWorker_p0-w0: resuming experience collection (150 times)
[2025-11-03 15:01:32,799][200377] Fps is (10 sec: 4983.0, 60 sec: 4912.1, 300 sec: 4348.7). Total num frames: 835584. Throughput: 0: 4501.1. Samples: 821760. Policy #0 lag: (min: 6.0, avg: 9.0, max: 70.0)
[2025-11-03 15:01:32,799][200377] Avg episode reward: [(0, '488.448')]
[2025-11-03 15:01:32,799][200377] Saving new best policy, reward=488.448!
[2025-11-03 15:01:37,820][200377] Fps is (10 sec: 4885.2, 60 sec: 4911.6, 300 sec: 4321.0). Total num frames: 851968. Throughput: 0: 4876.3. Samples: 852992. Policy #0 lag: (min: 13.0, avg: 16.0, max: 77.0)
[2025-11-03 15:01:37,820][200377] Avg episode reward: [(0, '494.579')]
[2025-11-03 15:01:37,916][200377] Saving new best policy, reward=494.579!
[2025-11-03 15:01:42,756][200377] Fps is (10 sec: 4936.0, 60 sec: 4915.6, 300 sec: 4377.6). Total num frames: 884736. Throughput: 0: 4922.7. Samples: 883200. Policy #0 lag: (min: 10.0, avg: 13.0, max: 74.0)
[2025-11-03 15:01:42,757][200377] Avg episode reward: [(0, '501.354')]
[2025-11-03 15:01:42,844][200377] Saving new best policy, reward=501.354!
[2025-11-03 15:01:47,769][200377] Fps is (10 sec: 4940.1, 60 sec: 4913.9, 300 sec: 4350.8). Total num frames: 901120. Throughput: 0: 4910.0. Samples: 911872. Policy #0 lag: (min: 10.0, avg: 13.0, max: 74.0)
[2025-11-03 15:01:47,769][200377] Avg episode reward: [(0, '520.104')]
[2025-11-03 15:01:47,860][200377] Saving new best policy, reward=520.104!
[2025-11-03 15:01:52,791][200377] Fps is (10 sec: 4898.4, 60 sec: 4914.0, 300 sec: 4402.2). Total num frames: 933888. Throughput: 0: 4892.2. Samples: 925696. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 15:01:52,791][200377] Avg episode reward: [(0, '537.479')]
[2025-11-03 15:01:52,791][200377] Saving new best policy, reward=537.479!
[2025-11-03 15:01:57,817][200377] Fps is (10 sec: 4891.7, 60 sec: 4915.8, 300 sec: 4375.8). Total num frames: 950272. Throughput: 0: 4879.9. Samples: 954880. Policy #0 lag: (min: 3.0, avg: 6.0, max: 67.0)
[2025-11-03 15:01:57,817][200377] Avg episode reward: [(0, '578.367')]
[2025-11-03 15:01:57,913][200377] Saving new best policy, reward=578.367!
[2025-11-03 15:02:02,772][200377] Fps is (10 sec: 4924.6, 60 sec: 4919.6, 300 sec: 4425.7). Total num frames: 983040. Throughput: 0: 4892.0. Samples: 984064. Policy #0 lag: (min: 8.0, avg: 11.0, max: 72.0)
[2025-11-03 15:02:02,772][200377] Avg episode reward: [(0, '594.364')]
[2025-11-03 15:02:02,861][200377] Saving new best policy, reward=594.364!
[2025-11-03 15:02:07,801][200377] Fps is (10 sec: 4923.2, 60 sec: 4914.2, 300 sec: 4399.8). Total num frames: 999424. Throughput: 0: 4964.1. Samples: 1000448. Policy #0 lag: (min: 8.0, avg: 11.0, max: 72.0)
[2025-11-03 15:02:07,801][200377] Avg episode reward: [(0, '597.312')]
[2025-11-03 15:02:07,893][200377] Saving /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_lidar_policy2/checkpoint_p0/checkpoint_000003904_999424.pth...
[2025-11-03 15:02:07,896][200377] Saving new best policy, reward=597.312!
[2025-11-03 15:02:12,849][200377] Fps is (10 sec: 4877.3, 60 sec: 4911.7, 300 sec: 4445.3). Total num frames: 1032192. Throughput: 0: 4950.7. Samples: 1030656. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 15:02:12,849][200377] Avg episode reward: [(0, '618.415')]
[2025-11-03 15:02:12,961][200377] Saving new best policy, reward=618.415!
[2025-11-03 15:02:17,761][200377] Fps is (10 sec: 4935.0, 60 sec: 4915.7, 300 sec: 4422.3). Total num frames: 1048576. Throughput: 0: 5249.6. Samples: 1057792. Policy #0 lag: (min: 14.0, avg: 17.0, max: 78.0)
[2025-11-03 15:02:17,761][200377] Avg episode reward: [(0, '668.960')]
[2025-11-03 15:02:17,854][200377] Saving new best policy, reward=668.960!
[2025-11-03 15:02:23,024][200377] Fps is (10 sec: 4830.8, 60 sec: 4907.9, 300 sec: 4461.5). Total num frames: 1081344. Throughput: 0: 4859.0. Samples: 1072640. Policy #0 lag: (min: 11.0, avg: 14.0, max: 75.0)
[2025-11-03 15:02:23,024][200377] Avg episode reward: [(0, '706.459')]
[2025-11-03 15:02:23,024][200377] Saving new best policy, reward=706.459!
[2025-11-03 15:02:26,124][200377] Signal inference workers to stop experience collection... (200 times)
[2025-11-03 15:02:26,447][200377] InferenceWorker_p0-w0: stopping experience collection (200 times)
[2025-11-03 15:02:26,447][200377] Signal inference workers to resume experience collection... (200 times)
[2025-11-03 15:02:26,447][200377] InferenceWorker_p0-w0: resuming experience collection (200 times)
[2025-11-03 15:02:27,809][200377] Fps is (10 sec: 4891.8, 60 sec: 4911.1, 300 sec: 4441.4). Total num frames: 1097728. Throughput: 0: 4830.0. Samples: 1100800. Policy #0 lag: (min: 11.0, avg: 14.0, max: 75.0)
[2025-11-03 15:02:27,809][200377] Avg episode reward: [(0, '685.164')]
[2025-11-03 15:02:32,749][200377] Fps is (10 sec: 3369.6, 60 sec: 4646.0, 300 sec: 4419.4). Total num frames: 1114112. Throughput: 0: 4860.5. Samples: 1130496. Policy #0 lag: (min: 6.0, avg: 9.0, max: 70.0)
[2025-11-03 15:02:32,749][200377] Avg episode reward: [(0, '692.032')]
[2025-11-03 15:02:37,777][200377] Fps is (10 sec: 4930.9, 60 sec: 4918.7, 300 sec: 4460.4). Total num frames: 1146880. Throughput: 0: 4871.2. Samples: 1144832. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 15:02:37,777][200377] Avg episode reward: [(0, '720.715')]
[2025-11-03 15:02:37,885][200377] Saving new best policy, reward=720.715!
[2025-11-03 15:02:42,759][200377] Fps is (10 sec: 4910.0, 60 sec: 4641.9, 300 sec: 4438.1). Total num frames: 1163264. Throughput: 0: 4841.8. Samples: 1172480. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 15:02:42,760][200377] Avg episode reward: [(0, '716.040')]
[2025-11-03 15:02:47,798][200377] Fps is (10 sec: 4904.5, 60 sec: 4912.8, 300 sec: 4477.1). Total num frames: 1196032. Throughput: 0: 4821.3. Samples: 1201152. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 15:02:47,799][200377] Avg episode reward: [(0, '696.156')]
[2025-11-03 15:02:52,817][200377] Fps is (10 sec: 4886.9, 60 sec: 4640.1, 300 sec: 4454.7). Total num frames: 1212416. Throughput: 0: 4776.9. Samples: 1215488. Policy #0 lag: (min: 13.0, avg: 16.0, max: 77.0)
[2025-11-03 15:02:52,817][200377] Avg episode reward: [(0, '746.372')]
[2025-11-03 15:02:52,913][200377] Saving new best policy, reward=746.372!
[2025-11-03 15:02:57,747][200377] Fps is (10 sec: 4940.4, 60 sec: 4920.9, 300 sec: 4493.7). Total num frames: 1245184. Throughput: 0: 4789.5. Samples: 1245696. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 15:02:57,748][200377] Avg episode reward: [(0, '784.970')]
[2025-11-03 15:02:57,844][200377] Saving new best policy, reward=784.970!
[2025-11-03 15:03:02,839][200377] Fps is (10 sec: 4904.3, 60 sec: 4636.9, 300 sec: 4470.7). Total num frames: 1261568. Throughput: 0: 4770.3. Samples: 1272832. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 15:03:02,840][200377] Avg episode reward: [(0, '761.864')]
[2025-11-03 15:03:07,816][200377] Fps is (10 sec: 4881.9, 60 sec: 4914.0, 300 sec: 4507.3). Total num frames: 1294336. Throughput: 0: 4778.0. Samples: 1286656. Policy #0 lag: (min: 12.0, avg: 15.0, max: 76.0)
[2025-11-03 15:03:07,816][200377] Avg episode reward: [(0, '708.211')]
[2025-11-03 15:03:12,789][200377] Fps is (10 sec: 4940.2, 60 sec: 4646.8, 300 sec: 4486.7). Total num frames: 1310720. Throughput: 0: 4769.4. Samples: 1315328. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 15:03:12,789][200377] Avg episode reward: [(0, '676.615')]
[2025-11-03 15:03:17,968][200377] Fps is (10 sec: 4841.6, 60 sec: 4898.3, 300 sec: 4652.8). Total num frames: 1343488. Throughput: 0: 4404.5. Samples: 1329664. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 15:03:17,968][200377] Avg episode reward: [(0, '693.652')]
[2025-11-03 15:03:22,755][200377] Fps is (10 sec: 4931.8, 60 sec: 4663.0, 300 sec: 4688.0). Total num frames: 1359872. Throughput: 0: 4781.0. Samples: 1359872. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 15:03:22,755][200377] Avg episode reward: [(0, '753.929')]
[2025-11-03 15:03:24,386][200377] Signal inference workers to stop experience collection... (250 times)
[2025-11-03 15:03:24,389][200377] Signal inference workers to resume experience collection... (250 times)
[2025-11-03 15:03:24,591][200377] InferenceWorker_p0-w0: stopping experience collection (250 times)
[2025-11-03 15:03:24,591][200377] InferenceWorker_p0-w0: resuming experience collection (250 times)
[2025-11-03 15:03:27,749][200377] Fps is (10 sec: 4187.8, 60 sec: 4783.5, 300 sec: 4707.4). Total num frames: 1384448. Throughput: 0: 4802.6. Samples: 1388544. Policy #0 lag: (min: 9.0, avg: 12.0, max: 73.0)
[2025-11-03 15:03:27,749][200377] Avg episode reward: [(0, '779.853')]
[2025-11-03 15:03:32,781][200377] Fps is (10 sec: 4902.5, 60 sec: 4912.6, 300 sec: 4760.0). Total num frames: 1409024. Throughput: 0: 4814.7. Samples: 1417728. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 15:03:32,781][200377] Avg episode reward: [(0, '743.925')]
[2025-11-03 15:03:37,863][200377] Fps is (10 sec: 4859.4, 60 sec: 4771.8, 300 sec: 4775.1). Total num frames: 1433600. Throughput: 0: 4807.9. Samples: 1432064. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 15:03:37,864][200377] Avg episode reward: [(0, '743.602')]
[2025-11-03 15:03:42,753][200377] Fps is (10 sec: 4928.8, 60 sec: 4915.7, 300 sec: 4777.9). Total num frames: 1458176. Throughput: 0: 4778.0. Samples: 1460736. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 15:03:42,754][200377] Avg episode reward: [(0, '763.453')]
[2025-11-03 15:03:47,906][200377] Fps is (10 sec: 4894.5, 60 sec: 4770.1, 300 sec: 4802.2). Total num frames: 1482752. Throughput: 0: 4499.0. Samples: 1475584. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 15:03:47,906][200377] Avg episode reward: [(0, '815.165')]
[2025-11-03 15:03:48,215][200377] Saving new best policy, reward=815.165!
[2025-11-03 15:03:52,796][200377] Fps is (10 sec: 4894.4, 60 sec: 4916.9, 300 sec: 4831.8). Total num frames: 1507328. Throughput: 0: 4871.8. Samples: 1505792. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 15:03:52,796][200377] Avg episode reward: [(0, '796.770')]
[2025-11-03 15:03:57,771][200377] Fps is (10 sec: 4151.8, 60 sec: 4640.3, 300 sec: 4776.4). Total num frames: 1523712. Throughput: 0: 4871.6. Samples: 1534464. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 15:03:57,772][200377] Avg episode reward: [(0, '769.590')]
[2025-11-03 15:04:02,808][200377] Fps is (10 sec: 4909.0, 60 sec: 4917.7, 300 sec: 4831.4). Total num frames: 1556480. Throughput: 0: 5229.5. Samples: 1564160. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 15:04:02,809][200377] Avg episode reward: [(0, '788.286')]
[2025-11-03 15:04:07,905][200377] Fps is (10 sec: 5658.6, 60 sec: 4771.5, 300 sec: 4805.6). Total num frames: 1581056. Throughput: 0: 4853.5. Samples: 1579008. Policy #0 lag: (min: 3.0, avg: 6.0, max: 67.0)
[2025-11-03 15:04:07,905][200377] Avg episode reward: [(0, '793.918')]
[2025-11-03 15:04:08,213][200377] Saving /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_lidar_policy2/checkpoint_p0/checkpoint_000006208_1589248.pth...
[2025-11-03 15:04:08,217][200377] Removing /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_lidar_policy2/checkpoint_p0/checkpoint_000001600_409600.pth
[2025-11-03 15:04:12,777][200377] Fps is (10 sec: 4930.9, 60 sec: 4916.2, 300 sec: 4832.5). Total num frames: 1605632. Throughput: 0: 4866.6. Samples: 1607680. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 15:04:12,777][200377] Avg episode reward: [(0, '807.893')]
[2025-11-03 15:04:17,973][200377] Fps is (10 sec: 4881.9, 60 sec: 4778.2, 300 sec: 4857.4). Total num frames: 1630208. Throughput: 0: 4894.3. Samples: 1638912. Policy #0 lag: (min: 13.0, avg: 16.0, max: 77.0)
[2025-11-03 15:04:17,974][200377] Avg episode reward: [(0, '749.227')]
[2025-11-03 15:04:20,998][200377] Signal inference workers to stop experience collection... (300 times)
[2025-11-03 15:04:21,310][200377] InferenceWorker_p0-w0: stopping experience collection (300 times)
[2025-11-03 15:04:21,312][200377] Signal inference workers to resume experience collection... (300 times)
[2025-11-03 15:04:21,401][200377] InferenceWorker_p0-w0: resuming experience collection (300 times)
[2025-11-03 15:04:22,799][200377] Fps is (10 sec: 4904.2, 60 sec: 4911.6, 300 sec: 4831.7). Total num frames: 1654784. Throughput: 0: 4933.6. Samples: 1653760. Policy #0 lag: (min: 13.0, avg: 16.0, max: 77.0)
[2025-11-03 15:04:22,799][200377] Avg episode reward: [(0, '718.652')]
[2025-11-03 15:04:27,750][200377] Fps is (10 sec: 4189.8, 60 sec: 4778.6, 300 sec: 4832.2). Total num frames: 1671168. Throughput: 0: 4915.6. Samples: 1681920. Policy #0 lag: (min: 10.0, avg: 13.0, max: 74.0)
[2025-11-03 15:04:27,750][200377] Avg episode reward: [(0, '761.547')]
[2025-11-03 15:04:32,812][200377] Fps is (10 sec: 4908.7, 60 sec: 4912.6, 300 sec: 4887.7). Total num frames: 1703936. Throughput: 0: 5233.2. Samples: 1710592. Policy #0 lag: (min: 10.0, avg: 13.0, max: 74.0)
[2025-11-03 15:04:32,813][200377] Avg episode reward: [(0, '775.102')]
[2025-11-03 15:04:37,784][200377] Fps is (10 sec: 4898.5, 60 sec: 4785.0, 300 sec: 4831.5). Total num frames: 1720320. Throughput: 0: 4871.0. Samples: 1724928. Policy #0 lag: (min: 10.0, avg: 13.0, max: 74.0)
[2025-11-03 15:04:37,784][200377] Avg episode reward: [(0, '784.339')]
[2025-11-03 15:04:42,834][200377] Fps is (10 sec: 4904.4, 60 sec: 4908.6, 300 sec: 4887.4). Total num frames: 1753088. Throughput: 0: 4874.2. Samples: 1754112. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 15:04:42,835][200377] Avg episode reward: [(0, '787.816')]
[2025-11-03 15:04:47,763][200377] Fps is (10 sec: 4925.2, 60 sec: 4790.0, 300 sec: 4832.7). Total num frames: 1769472. Throughput: 0: 4908.7. Samples: 1784832. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 15:04:47,764][200377] Avg episode reward: [(0, '751.606')]
[2025-11-03 15:04:52,781][200377] Fps is (10 sec: 4941.3, 60 sec: 4916.4, 300 sec: 4887.5). Total num frames: 1802240. Throughput: 0: 4917.3. Samples: 1799680. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 15:04:52,782][200377] Avg episode reward: [(0, '770.446')]
[2025-11-03 15:04:57,828][200377] Fps is (10 sec: 4883.6, 60 sec: 4910.6, 300 sec: 4832.1). Total num frames: 1818624. Throughput: 0: 4909.6. Samples: 1828864. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 15:04:57,828][200377] Avg episode reward: [(0, '790.006')]
[2025-11-03 15:05:02,824][200377] Fps is (10 sec: 4894.2, 60 sec: 4913.9, 300 sec: 4886.5). Total num frames: 1851392. Throughput: 0: 4874.4. Samples: 1857536. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 15:05:02,825][200377] Avg episode reward: [(0, '831.308')]
[2025-11-03 15:05:02,923][200377] Saving new best policy, reward=831.308!
[2025-11-03 15:05:07,801][200377] Fps is (10 sec: 4928.5, 60 sec: 4787.0, 300 sec: 4832.0). Total num frames: 1867776. Throughput: 0: 4835.3. Samples: 1871360. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 15:05:07,801][200377] Avg episode reward: [(0, '860.549')]
[2025-11-03 15:05:07,894][200377] Saving new best policy, reward=860.549!
[2025-11-03 15:05:12,769][200377] Fps is (10 sec: 4942.4, 60 sec: 4915.8, 300 sec: 4887.8). Total num frames: 1900544. Throughput: 0: 4878.9. Samples: 1901568. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 15:05:12,770][200377] Avg episode reward: [(0, '863.037')]
[2025-11-03 15:05:12,859][200377] Saving new best policy, reward=863.037!
[2025-11-03 15:05:15,025][200377] Signal inference workers to stop experience collection... (350 times)
[2025-11-03 15:05:15,334][200377] InferenceWorker_p0-w0: stopping experience collection (350 times)
[2025-11-03 15:05:15,334][200377] Signal inference workers to resume experience collection... (350 times)
[2025-11-03 15:05:15,334][200377] InferenceWorker_p0-w0: resuming experience collection (350 times)
[2025-11-03 15:05:17,820][200377] Fps is (10 sec: 4906.1, 60 sec: 4790.9, 300 sec: 4830.9). Total num frames: 1916928. Throughput: 0: 4903.0. Samples: 1931264. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 15:05:17,820][200377] Avg episode reward: [(0, '826.073')]
[2025-11-03 15:05:22,766][200377] Fps is (10 sec: 4916.9, 60 sec: 4917.9, 300 sec: 4888.3). Total num frames: 1949696. Throughput: 0: 4905.8. Samples: 1945600. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 15:05:22,766][200377] Avg episode reward: [(0, '782.741')]
[2025-11-03 15:05:27,747][200377] Fps is (10 sec: 4951.1, 60 sec: 4915.4, 300 sec: 4832.1). Total num frames: 1966080. Throughput: 0: 4913.3. Samples: 1974784. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 15:05:27,747][200377] Avg episode reward: [(0, '757.303')]
[2025-11-03 15:05:32,802][200377] Fps is (10 sec: 4897.6, 60 sec: 4916.1, 300 sec: 4887.0). Total num frames: 1998848. Throughput: 0: 4854.2. Samples: 2003456. Policy #0 lag: (min: 10.0, avg: 13.0, max: 74.0)
[2025-11-03 15:05:32,802][200377] Avg episode reward: [(0, '788.110')]
[2025-11-03 15:05:37,827][200377] Fps is (10 sec: 4876.5, 60 sec: 4911.7, 300 sec: 4830.8). Total num frames: 2015232. Throughput: 0: 4842.1. Samples: 2017792. Policy #0 lag: (min: 10.0, avg: 13.0, max: 74.0)
[2025-11-03 15:05:37,827][200377] Avg episode reward: [(0, '805.956')]
[2025-11-03 15:05:42,793][200377] Fps is (10 sec: 4919.6, 60 sec: 4918.6, 300 sec: 4886.8). Total num frames: 2048000. Throughput: 0: 4896.3. Samples: 2049024. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 15:05:42,793][200377] Avg episode reward: [(0, '805.816')]
[2025-11-03 15:05:47,789][200377] Fps is (10 sec: 4933.9, 60 sec: 4913.1, 300 sec: 4831.7). Total num frames: 2064384. Throughput: 0: 4896.3. Samples: 2077696. Policy #0 lag: (min: 18.0, avg: 21.0, max: 82.0)
[2025-11-03 15:05:47,789][200377] Avg episode reward: [(0, '862.546')]
[2025-11-03 15:05:52,773][200377] Fps is (10 sec: 4924.9, 60 sec: 4915.9, 300 sec: 4888.3). Total num frames: 2097152. Throughput: 0: 4906.8. Samples: 2092032. Policy #0 lag: (min: 47.0, avg: 50.0, max: 111.0)
[2025-11-03 15:05:52,774][200377] Avg episode reward: [(0, '861.973')]
[2025-11-03 15:05:57,756][200377] Fps is (10 sec: 4931.3, 60 sec: 4921.1, 300 sec: 4833.0). Total num frames: 2113536. Throughput: 0: 4871.1. Samples: 2120704. Policy #0 lag: (min: 47.0, avg: 50.0, max: 111.0)
[2025-11-03 15:05:57,756][200377] Avg episode reward: [(0, '848.699')]
[2025-11-03 15:06:02,747][200377] Fps is (10 sec: 4928.0, 60 sec: 4921.5, 300 sec: 4888.1). Total num frames: 2146304. Throughput: 0: 4854.7. Samples: 2149376. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 15:06:02,748][200377] Avg episode reward: [(0, '841.711')]
[2025-11-03 15:06:07,836][200377] Fps is (10 sec: 4876.0, 60 sec: 4912.3, 300 sec: 4831.4). Total num frames: 2162688. Throughput: 0: 4839.4. Samples: 2163712. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 15:06:07,837][200377] Avg episode reward: [(0, '828.149')]
[2025-11-03 15:06:07,937][200377] Saving /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_lidar_policy2/checkpoint_p0/checkpoint_000008448_2162688.pth...
[2025-11-03 15:06:07,941][200377] Removing /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_lidar_policy2/checkpoint_p0/checkpoint_000003904_999424.pth
[2025-11-03 15:06:12,204][200377] Signal inference workers to stop experience collection... (400 times)
[2025-11-03 15:06:12,204][200377] Signal inference workers to resume experience collection... (400 times)
[2025-11-03 15:06:12,404][200377] InferenceWorker_p0-w0: stopping experience collection (400 times)
[2025-11-03 15:06:12,405][200377] InferenceWorker_p0-w0: resuming experience collection (400 times)
[2025-11-03 15:06:12,784][200377] Fps is (10 sec: 4897.2, 60 sec: 4914.0, 300 sec: 4887.1). Total num frames: 2195456. Throughput: 0: 4888.4. Samples: 2194944. Policy #0 lag: (min: 37.0, avg: 40.0, max: 101.0)
[2025-11-03 15:06:12,784][200377] Avg episode reward: [(0, '853.156')]
[2025-11-03 15:06:17,786][200377] Fps is (10 sec: 4940.2, 60 sec: 4918.0, 300 sec: 4834.3). Total num frames: 2211840. Throughput: 0: 4894.2. Samples: 2223616. Policy #0 lag: (min: 37.0, avg: 40.0, max: 101.0)
[2025-11-03 15:06:17,786][200377] Avg episode reward: [(0, '880.105')]
[2025-11-03 15:06:17,880][200377] Saving new best policy, reward=880.105!
[2025-11-03 15:06:22,759][200377] Fps is (10 sec: 4927.9, 60 sec: 4915.8, 300 sec: 4887.4). Total num frames: 2244608. Throughput: 0: 4899.9. Samples: 2237952. Policy #0 lag: (min: 9.0, avg: 12.0, max: 73.0)
[2025-11-03 15:06:22,759][200377] Avg episode reward: [(0, '902.324')]
[2025-11-03 15:06:22,859][200377] Saving new best policy, reward=902.324!
[2025-11-03 15:06:27,771][200377] Fps is (10 sec: 4922.5, 60 sec: 4913.2, 300 sec: 4832.3). Total num frames: 2260992. Throughput: 0: 4826.5. Samples: 2266112. Policy #0 lag: (min: 53.0, avg: 56.0, max: 117.0)
[2025-11-03 15:06:27,771][200377] Avg episode reward: [(0, '907.557')]
[2025-11-03 15:06:27,867][200377] Saving new best policy, reward=907.557!
[2025-11-03 15:06:32,778][200377] Fps is (10 sec: 4905.5, 60 sec: 4917.1, 300 sec: 4888.1). Total num frames: 2293760. Throughput: 0: 4506.7. Samples: 2280448. Policy #0 lag: (min: 53.0, avg: 56.0, max: 117.0)
[2025-11-03 15:06:32,778][200377] Avg episode reward: [(0, '897.476')]
[2025-11-03 15:06:37,787][200377] Fps is (10 sec: 4907.2, 60 sec: 4918.4, 300 sec: 4831.4). Total num frames: 2310144. Throughput: 0: 4868.2. Samples: 2311168. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 15:06:37,788][200377] Avg episode reward: [(0, '948.502')]
[2025-11-03 15:06:37,891][200377] Saving new best policy, reward=948.502!
[2025-11-03 15:06:42,865][200377] Fps is (10 sec: 4873.1, 60 sec: 4909.3, 300 sec: 4885.8). Total num frames: 2342912. Throughput: 0: 4869.3. Samples: 2340352. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 15:06:42,865][200377] Avg episode reward: [(0, '969.150')]
[2025-11-03 15:06:42,865][200377] Saving new best policy, reward=969.150!
[2025-11-03 15:06:47,800][200377] Fps is (10 sec: 4909.2, 60 sec: 4914.3, 300 sec: 4831.7). Total num frames: 2359296. Throughput: 0: 4852.7. Samples: 2368000. Policy #0 lag: (min: 11.0, avg: 14.0, max: 75.0)
[2025-11-03 15:06:47,800][200377] Avg episode reward: [(0, '951.572')]
[2025-11-03 15:06:52,847][200377] Fps is (10 sec: 4103.3, 60 sec: 4772.8, 300 sec: 4859.2). Total num frames: 2383872. Throughput: 0: 4845.8. Samples: 2381824. Policy #0 lag: (min: 11.0, avg: 14.0, max: 75.0)
[2025-11-03 15:06:52,847][200377] Avg episode reward: [(0, '944.847')]
[2025-11-03 15:06:57,829][200377] Fps is (10 sec: 4901.0, 60 sec: 4909.3, 300 sec: 4831.0). Total num frames: 2408448. Throughput: 0: 4808.1. Samples: 2411520. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 15:06:57,829][200377] Avg episode reward: [(0, '953.557')]
[2025-11-03 15:07:02,842][200377] Fps is (10 sec: 4917.5, 60 sec: 4771.1, 300 sec: 4859.0). Total num frames: 2433024. Throughput: 0: 4488.6. Samples: 2425856. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 15:07:02,842][200377] Avg episode reward: [(0, '980.863')]
[2025-11-03 15:07:03,161][200377] Saving new best policy, reward=980.863!
[2025-11-03 15:07:07,800][200377] Fps is (10 sec: 4929.2, 60 sec: 4918.2, 300 sec: 4832.7). Total num frames: 2457600. Throughput: 0: 4865.2. Samples: 2457088. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 15:07:07,800][200377] Avg episode reward: [(0, '1000.548')]
[2025-11-03 15:07:07,892][200377] Saving new best policy, reward=1000.548!
[2025-11-03 15:07:09,269][200377] Signal inference workers to stop experience collection... (450 times)
[2025-11-03 15:07:09,598][200377] InferenceWorker_p0-w0: stopping experience collection (450 times)
[2025-11-03 15:07:09,600][200377] Signal inference workers to resume experience collection... (450 times)
[2025-11-03 15:07:09,691][200377] InferenceWorker_p0-w0: resuming experience collection (450 times)
[2025-11-03 15:07:12,953][200377] Fps is (10 sec: 4861.6, 60 sec: 4765.3, 300 sec: 4856.5). Total num frames: 2482176. Throughput: 0: 4850.1. Samples: 2485248. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 15:07:12,953][200377] Avg episode reward: [(0, '1021.282')]
[2025-11-03 15:07:13,265][200377] Saving new best policy, reward=1021.282!
[2025-11-03 15:07:17,793][200377] Fps is (10 sec: 4918.9, 60 sec: 4914.7, 300 sec: 4835.7). Total num frames: 2506752. Throughput: 0: 5198.0. Samples: 2514432. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 15:07:17,793][200377] Avg episode reward: [(0, '983.805')]
[2025-11-03 15:07:23,001][200377] Fps is (10 sec: 4891.5, 60 sec: 4759.4, 300 sec: 4856.5). Total num frames: 2531328. Throughput: 0: 4812.7. Samples: 2528768. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 15:07:23,001][200377] Avg episode reward: [(0, '969.116')]
[2025-11-03 15:07:27,838][200377] Fps is (10 sec: 4892.9, 60 sec: 4909.7, 300 sec: 4885.9). Total num frames: 2555904. Throughput: 0: 4815.6. Samples: 2556928. Policy #0 lag: (min: 0.0, avg: 3.0, max: 64.0)
[2025-11-03 15:07:27,838][200377] Avg episode reward: [(0, '1000.697')]
[2025-11-03 15:07:32,782][200377] Fps is (10 sec: 4187.6, 60 sec: 4641.8, 300 sec: 4831.8). Total num frames: 2572288. Throughput: 0: 4894.3. Samples: 2588160. Policy #0 lag: (min: 0.0, avg: 3.0, max: 64.0)
[2025-11-03 15:07:32,783][200377] Avg episode reward: [(0, '997.699')]
[2025-11-03 15:07:37,748][200377] Fps is (10 sec: 4959.8, 60 sec: 4918.4, 300 sec: 4887.6). Total num frames: 2605056. Throughput: 0: 4914.6. Samples: 2602496. Policy #0 lag: (min: 2.0, avg: 5.0, max: 66.0)
[2025-11-03 15:07:37,748][200377] Avg episode reward: [(0, '1021.461')]
[2025-11-03 15:07:37,840][200377] Saving new best policy, reward=1021.461!
[2025-11-03 15:07:42,766][200377] Fps is (10 sec: 4923.2, 60 sec: 4649.8, 300 sec: 4832.4). Total num frames: 2621440. Throughput: 0: 4887.9. Samples: 2631168. Policy #0 lag: (min: 2.0, avg: 5.0, max: 66.0)
[2025-11-03 15:07:42,766][200377] Avg episode reward: [(0, '999.021')]
[2025-11-03 15:07:47,840][200377] Fps is (10 sec: 4870.3, 60 sec: 4911.9, 300 sec: 4887.0). Total num frames: 2654208. Throughput: 0: 5120.2. Samples: 2656256. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 15:07:47,841][200377] Avg episode reward: [(0, '958.138')]
[2025-11-03 15:07:52,825][200377] Fps is (10 sec: 4886.6, 60 sec: 4780.4, 300 sec: 4830.6). Total num frames: 2670592. Throughput: 0: 4742.0. Samples: 2670592. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 15:07:52,825][200377] Avg episode reward: [(0, '982.346')]
[2025-11-03 15:07:57,754][200377] Fps is (10 sec: 3305.5, 60 sec: 4647.9, 300 sec: 4833.3). Total num frames: 2686976. Throughput: 0: 4685.6. Samples: 2695168. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 15:07:57,754][200377] Avg episode reward: [(0, '1015.359')]
[2025-11-03 15:08:02,970][200377] Fps is (10 sec: 4844.5, 60 sec: 4768.5, 300 sec: 4829.4). Total num frames: 2719744. Throughput: 0: 4567.2. Samples: 2720768. Policy #0 lag: (min: 7.0, avg: 10.0, max: 71.0)
[2025-11-03 15:08:02,971][200377] Avg episode reward: [(0, '992.328')]
[2025-11-03 15:08:06,264][200377] Signal inference workers to stop experience collection... (500 times)
[2025-11-03 15:08:06,584][200377] InferenceWorker_p0-w0: stopping experience collection (500 times)
[2025-11-03 15:08:06,584][200377] Signal inference workers to resume experience collection... (500 times)
[2025-11-03 15:08:06,585][200377] InferenceWorker_p0-w0: resuming experience collection (500 times)
[2025-11-03 15:08:07,764][200377] Fps is (10 sec: 4910.3, 60 sec: 4645.0, 300 sec: 4832.3). Total num frames: 2736128. Throughput: 0: 4609.6. Samples: 2735104. Policy #0 lag: (min: 7.0, avg: 10.0, max: 71.0)
[2025-11-03 15:08:07,764][200377] Avg episode reward: [(0, '1029.990')]
[2025-11-03 15:08:07,866][200377] Saving /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_lidar_policy2/checkpoint_p0/checkpoint_000010688_2736128.pth...
[2025-11-03 15:08:07,870][200377] Removing /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_lidar_policy2/checkpoint_p0/checkpoint_000006208_1589248.pth
[2025-11-03 15:08:07,870][200377] Saving new best policy, reward=1029.990!
[2025-11-03 15:08:12,791][200377] Fps is (10 sec: 3336.8, 60 sec: 4517.8, 300 sec: 4779.2). Total num frames: 2752512. Throughput: 0: 4544.5. Samples: 2761216. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 15:08:12,791][200377] Avg episode reward: [(0, '1032.743')]
[2025-11-03 15:08:12,891][200377] Saving new best policy, reward=1032.743!
[2025-11-03 15:08:17,787][200377] Fps is (10 sec: 4903.5, 60 sec: 4642.5, 300 sec: 4831.4). Total num frames: 2785280. Throughput: 0: 4425.5. Samples: 2787328. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 15:08:17,788][200377] Avg episode reward: [(0, '1061.505')]
[2025-11-03 15:08:17,889][200377] Saving new best policy, reward=1061.505!
[2025-11-03 15:08:22,784][200377] Fps is (10 sec: 4918.6, 60 sec: 4522.0, 300 sec: 4803.5). Total num frames: 2801664. Throughput: 0: 4445.2. Samples: 2802688. Policy #0 lag: (min: 12.0, avg: 15.0, max: 76.0)
[2025-11-03 15:08:22,784][200377] Avg episode reward: [(0, '1081.885')]
[2025-11-03 15:08:22,875][200377] Saving new best policy, reward=1081.885!
[2025-11-03 15:08:27,967][200377] Fps is (10 sec: 4828.3, 60 sec: 4632.2, 300 sec: 4828.8). Total num frames: 2834432. Throughput: 0: 4428.9. Samples: 2831360. Policy #0 lag: (min: 12.0, avg: 15.0, max: 76.0)
[2025-11-03 15:08:27,968][200377] Avg episode reward: [(0, '1063.514')]
[2025-11-03 15:08:32,843][200377] Fps is (10 sec: 4886.1, 60 sec: 4637.4, 300 sec: 4804.4). Total num frames: 2850816. Throughput: 0: 4516.7. Samples: 2859520. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 15:08:32,844][200377] Avg episode reward: [(0, '1076.253')]
[2025-11-03 15:08:38,021][200377] Fps is (10 sec: 4074.3, 60 sec: 4485.2, 300 sec: 4799.8). Total num frames: 2875392. Throughput: 0: 4486.1. Samples: 2873344. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 15:08:38,021][200377] Avg episode reward: [(0, '1089.226')]
[2025-11-03 15:08:38,344][200377] Saving new best policy, reward=1089.226!
[2025-11-03 15:08:42,821][200377] Fps is (10 sec: 4926.4, 60 sec: 4637.9, 300 sec: 4805.5). Total num frames: 2899968. Throughput: 0: 4567.1. Samples: 2900992. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 15:08:42,821][200377] Avg episode reward: [(0, '1109.790')]
[2025-11-03 15:08:42,914][200377] Saving new best policy, reward=1109.790!
[2025-11-03 15:08:47,758][200377] Fps is (10 sec: 4206.6, 60 sec: 4375.1, 300 sec: 4777.0). Total num frames: 2916352. Throughput: 0: 4687.1. Samples: 2930688. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 15:08:47,758][200377] Avg episode reward: [(0, '1162.344')]
[2025-11-03 15:08:47,855][200377] Saving new best policy, reward=1162.344!
[2025-11-03 15:08:52,832][200377] Fps is (10 sec: 4909.4, 60 sec: 4641.5, 300 sec: 4830.9). Total num frames: 2949120. Throughput: 0: 4657.8. Samples: 2945024. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 15:08:52,833][200377] Avg episode reward: [(0, '1158.099')]
[2025-11-03 15:08:57,821][200377] Fps is (10 sec: 4884.3, 60 sec: 4636.9, 300 sec: 4776.2). Total num frames: 2965504. Throughput: 0: 4707.2. Samples: 2973184. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 15:08:57,821][200377] Avg episode reward: [(0, '1117.870')]
[2025-11-03 15:09:02,770][200377] Fps is (10 sec: 4946.0, 60 sec: 4657.7, 300 sec: 4806.3). Total num frames: 2998272. Throughput: 0: 4757.7. Samples: 3001344. Policy #0 lag: (min: 0.0, avg: 3.0, max: 64.0)
[2025-11-03 15:09:02,770][200377] Avg episode reward: [(0, '1080.113')]
[2025-11-03 15:09:05,454][200377] Signal inference workers to stop experience collection... (550 times)
[2025-11-03 15:09:05,454][200377] Signal inference workers to resume experience collection... (550 times)
[2025-11-03 15:09:05,664][200377] InferenceWorker_p0-w0: stopping experience collection (550 times)
[2025-11-03 15:09:05,664][200377] InferenceWorker_p0-w0: resuming experience collection (550 times)
[2025-11-03 15:09:07,796][200377] Fps is (10 sec: 4927.6, 60 sec: 4639.6, 300 sec: 4776.0). Total num frames: 3014656. Throughput: 0: 4731.9. Samples: 3015680. Policy #0 lag: (min: 0.0, avg: 3.0, max: 64.0)
[2025-11-03 15:09:07,796][200377] Avg episode reward: [(0, '1077.465')]
[2025-11-03 15:09:12,791][200377] Fps is (10 sec: 4904.9, 60 sec: 4915.2, 300 sec: 4807.1). Total num frames: 3047424. Throughput: 0: 4797.4. Samples: 3046400. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 15:09:12,791][200377] Avg episode reward: [(0, '1094.342')]
[2025-11-03 15:09:17,749][200377] Fps is (10 sec: 4938.2, 60 sec: 4645.1, 300 sec: 4777.2). Total num frames: 3063808. Throughput: 0: 4788.7. Samples: 3074560. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 15:09:17,749][200377] Avg episode reward: [(0, '1119.289')]
[2025-11-03 15:09:22,767][200377] Fps is (10 sec: 4927.2, 60 sec: 4916.6, 300 sec: 4831.6). Total num frames: 3096576. Throughput: 0: 4817.2. Samples: 3088896. Policy #0 lag: (min: 0.0, avg: 3.0, max: 64.0)
[2025-11-03 15:09:22,767][200377] Avg episode reward: [(0, '1114.112')]
[2025-11-03 15:09:27,761][200377] Fps is (10 sec: 4909.4, 60 sec: 4658.1, 300 sec: 4777.2). Total num frames: 3112960. Throughput: 0: 4807.8. Samples: 3117056. Policy #0 lag: (min: 0.0, avg: 3.0, max: 64.0)
[2025-11-03 15:09:27,761][200377] Avg episode reward: [(0, '1098.659')]
[2025-11-03 15:09:33,005][200377] Fps is (10 sec: 4801.0, 60 sec: 4902.0, 300 sec: 4828.3). Total num frames: 3145728. Throughput: 0: 4775.2. Samples: 3146752. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 15:09:33,005][200377] Avg episode reward: [(0, '1051.760')]
[2025-11-03 15:09:37,772][200377] Fps is (10 sec: 4910.0, 60 sec: 4798.6, 300 sec: 4777.4). Total num frames: 3162112. Throughput: 0: 4842.1. Samples: 3162624. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 15:09:37,772][200377] Avg episode reward: [(0, '1058.503')]
[2025-11-03 15:09:42,988][200377] Fps is (10 sec: 4923.3, 60 sec: 4901.5, 300 sec: 4828.2). Total num frames: 3194880. Throughput: 0: 4829.0. Samples: 3191296. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 15:09:42,988][200377] Avg episode reward: [(0, '1063.142')]
[2025-11-03 15:09:47,751][200377] Fps is (10 sec: 4925.4, 60 sec: 4915.7, 300 sec: 4776.8). Total num frames: 3211264. Throughput: 0: 4871.8. Samples: 3220480. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 15:09:47,751][200377] Avg episode reward: [(0, '1074.819')]
[2025-11-03 15:09:53,008][200377] Fps is (10 sec: 4905.6, 60 sec: 4900.9, 300 sec: 4829.0). Total num frames: 3244032. Throughput: 0: 4846.9. Samples: 3234816. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 15:09:53,008][200377] Avg episode reward: [(0, '1055.836')]
[2025-11-03 15:09:57,768][200377] Fps is (10 sec: 4906.7, 60 sec: 4919.5, 300 sec: 4777.3). Total num frames: 3260416. Throughput: 0: 4815.2. Samples: 3262976. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 15:09:57,769][200377] Avg episode reward: [(0, '1091.025')]
[2025-11-03 15:10:02,655][200377] Signal inference workers to stop experience collection... (600 times)
[2025-11-03 15:10:02,978][200377] InferenceWorker_p0-w0: stopping experience collection (600 times)
[2025-11-03 15:10:02,980][200377] Signal inference workers to resume experience collection... (600 times)
[2025-11-03 15:10:02,983][200377] Fps is (10 sec: 4106.0, 60 sec: 4761.7, 300 sec: 4801.2). Total num frames: 3284992. Throughput: 0: 4844.5. Samples: 3293696. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 15:10:02,983][200377] Avg episode reward: [(0, '1113.211')]
[2025-11-03 15:10:03,076][200377] InferenceWorker_p0-w0: resuming experience collection (600 times)
[2025-11-03 15:10:07,753][200377] Fps is (10 sec: 4922.6, 60 sec: 4918.7, 300 sec: 4776.6). Total num frames: 3309568. Throughput: 0: 4871.2. Samples: 3308032. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 15:10:07,753][200377] Avg episode reward: [(0, '1055.163')]
[2025-11-03 15:10:07,849][200377] Saving /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_lidar_policy2/checkpoint_p0/checkpoint_000012928_3309568.pth...
[2025-11-03 15:10:07,853][200377] Removing /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_lidar_policy2/checkpoint_p0/checkpoint_000008448_2162688.pth
[2025-11-03 15:10:13,040][200377] Fps is (10 sec: 4887.4, 60 sec: 4758.9, 300 sec: 4800.5). Total num frames: 3334144. Throughput: 0: 4851.0. Samples: 3336704. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 15:10:13,040][200377] Avg episode reward: [(0, '1077.944')]
[2025-11-03 15:10:17,757][200377] Fps is (10 sec: 4913.5, 60 sec: 4914.6, 300 sec: 4776.5). Total num frames: 3358720. Throughput: 0: 4885.2. Samples: 3365376. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 15:10:17,757][200377] Avg episode reward: [(0, '1126.670')]
[2025-11-03 15:10:22,750][200377] Fps is (10 sec: 4218.4, 60 sec: 4643.4, 300 sec: 4776.3). Total num frames: 3375104. Throughput: 0: 4815.1. Samples: 3379200. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 15:10:22,750][200377] Avg episode reward: [(0, '1103.252')]
[2025-11-03 15:10:27,785][200377] Fps is (10 sec: 4901.4, 60 sec: 4913.3, 300 sec: 4776.6). Total num frames: 3407872. Throughput: 0: 4857.5. Samples: 3408896. Policy #0 lag: (min: 5.0, avg: 8.0, max: 69.0)
[2025-11-03 15:10:27,785][200377] Avg episode reward: [(0, '1037.387')]
[2025-11-03 15:10:32,766][200377] Fps is (10 sec: 4907.5, 60 sec: 4660.7, 300 sec: 4777.3). Total num frames: 3424256. Throughput: 0: 4811.2. Samples: 3437056. Policy #0 lag: (min: 5.0, avg: 8.0, max: 69.0)
[2025-11-03 15:10:32,766][200377] Avg episode reward: [(0, '1083.114')]
[2025-11-03 15:10:37,830][200377] Fps is (10 sec: 4892.8, 60 sec: 4910.4, 300 sec: 4775.7). Total num frames: 3457024. Throughput: 0: 4820.4. Samples: 3450880. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 15:10:37,831][200377] Avg episode reward: [(0, '1122.166')]
[2025-11-03 15:10:42,792][200377] Fps is (10 sec: 4902.2, 60 sec: 4657.3, 300 sec: 4776.3). Total num frames: 3473408. Throughput: 0: 4821.6. Samples: 3480064. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 15:10:42,793][200377] Avg episode reward: [(0, '1125.041')]
[2025-11-03 15:10:47,788][200377] Fps is (10 sec: 4936.2, 60 sec: 4912.2, 300 sec: 4776.1). Total num frames: 3506176. Throughput: 0: 4799.5. Samples: 3508736. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 15:10:47,788][200377] Avg episode reward: [(0, '1125.459')]
[2025-11-03 15:10:52,806][200377] Fps is (10 sec: 4908.4, 60 sec: 4657.8, 300 sec: 4775.5). Total num frames: 3522560. Throughput: 0: 4784.4. Samples: 3523584. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 15:10:52,806][200377] Avg episode reward: [(0, '1089.526')]
[2025-11-03 15:10:57,353][200377] Signal inference workers to stop experience collection... (650 times)
[2025-11-03 15:10:57,696][200377] InferenceWorker_p0-w0: stopping experience collection (650 times)
[2025-11-03 15:10:57,696][200377] Signal inference workers to resume experience collection... (650 times)
[2025-11-03 15:10:57,697][200377] InferenceWorker_p0-w0: resuming experience collection (650 times)
[2025-11-03 15:10:57,798][200377] Fps is (10 sec: 4910.1, 60 sec: 4912.7, 300 sec: 4775.5). Total num frames: 3555328. Throughput: 0: 4850.3. Samples: 3553792. Policy #0 lag: (min: 9.0, avg: 12.0, max: 73.0)
[2025-11-03 15:10:57,799][200377] Avg episode reward: [(0, '1055.892')]
[2025-11-03 15:11:02,759][200377] Fps is (10 sec: 4938.5, 60 sec: 4796.6, 300 sec: 4777.6). Total num frames: 3571712. Throughput: 0: 4812.5. Samples: 3581952. Policy #0 lag: (min: 9.0, avg: 12.0, max: 73.0)
[2025-11-03 15:11:02,759][200377] Avg episode reward: [(0, '1044.064')]
[2025-11-03 15:11:07,842][200377] Fps is (10 sec: 4894.0, 60 sec: 4908.0, 300 sec: 4775.4). Total num frames: 3604480. Throughput: 0: 4814.4. Samples: 3596288. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 15:11:07,842][200377] Avg episode reward: [(0, '1068.474')]
[2025-11-03 15:11:12,806][200377] Fps is (10 sec: 4892.1, 60 sec: 4797.4, 300 sec: 4776.0). Total num frames: 3620864. Throughput: 0: 4810.5. Samples: 3625472. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 15:11:12,806][200377] Avg episode reward: [(0, '1081.536')]
[2025-11-03 15:11:17,804][200377] Fps is (10 sec: 4933.9, 60 sec: 4911.3, 300 sec: 4775.6). Total num frames: 3653632. Throughput: 0: 4513.2. Samples: 3640320. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 15:11:17,804][200377] Avg episode reward: [(0, '1147.853')]
[2025-11-03 15:11:22,837][200377] Fps is (10 sec: 4900.1, 60 sec: 4908.1, 300 sec: 4775.3). Total num frames: 3670016. Throughput: 0: 4891.7. Samples: 3671040. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 15:11:22,837][200377] Avg episode reward: [(0, '1175.824')]
[2025-11-03 15:11:22,936][200377] Saving new best policy, reward=1175.824!
[2025-11-03 15:11:28,048][200377] Fps is (10 sec: 4797.8, 60 sec: 4893.7, 300 sec: 4772.0). Total num frames: 3702784. Throughput: 0: 4842.1. Samples: 3699200. Policy #0 lag: (min: 47.0, avg: 50.0, max: 111.0)
[2025-11-03 15:11:28,049][200377] Avg episode reward: [(0, '1126.877')]
[2025-11-03 15:11:32,755][200377] Fps is (10 sec: 4955.8, 60 sec: 4916.1, 300 sec: 4776.9). Total num frames: 3719168. Throughput: 0: 4861.9. Samples: 3727360. Policy #0 lag: (min: 47.0, avg: 50.0, max: 111.0)
[2025-11-03 15:11:32,755][200377] Avg episode reward: [(0, '1163.609')]
[2025-11-03 15:11:37,771][200377] Fps is (10 sec: 4212.6, 60 sec: 4783.4, 300 sec: 4750.1). Total num frames: 3743744. Throughput: 0: 4862.1. Samples: 3742208. Policy #0 lag: (min: 47.0, avg: 50.0, max: 111.0)
[2025-11-03 15:11:37,772][200377] Avg episode reward: [(0, '1145.931')]
[2025-11-03 15:11:42,816][200377] Fps is (10 sec: 4885.2, 60 sec: 4913.2, 300 sec: 4776.1). Total num frames: 3768320. Throughput: 0: 4833.6. Samples: 3771392. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 15:11:42,817][200377] Avg episode reward: [(0, '1096.007')]
[2025-11-03 15:11:47,771][200377] Fps is (10 sec: 4915.3, 60 sec: 4780.0, 300 sec: 4777.6). Total num frames: 3792896. Throughput: 0: 4527.1. Samples: 3785728. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 15:11:47,771][200377] Avg episode reward: [(0, '1084.423')]
[2025-11-03 15:11:52,823][200377] Fps is (10 sec: 4911.7, 60 sec: 4913.8, 300 sec: 4776.4). Total num frames: 3817472. Throughput: 0: 4905.8. Samples: 3816960. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 15:11:52,824][200377] Avg episode reward: [(0, '1090.995')]
[2025-11-03 15:11:54,610][200377] Signal inference workers to stop experience collection... (700 times)
[2025-11-03 15:11:54,612][200377] Signal inference workers to resume experience collection... (700 times)
[2025-11-03 15:11:54,816][200377] InferenceWorker_p0-w0: stopping experience collection (700 times)
[2025-11-03 15:11:54,816][200377] InferenceWorker_p0-w0: resuming experience collection (700 times)
[2025-11-03 15:11:57,948][200377] Fps is (10 sec: 4829.9, 60 sec: 4766.8, 300 sec: 4774.6). Total num frames: 3842048. Throughput: 0: 4865.8. Samples: 3845120. Policy #0 lag: (min: 3.0, avg: 6.0, max: 67.0)
[2025-11-03 15:11:57,948][200377] Avg episode reward: [(0, '1065.759')]
[2025-11-03 15:12:02,776][200377] Fps is (10 sec: 4938.9, 60 sec: 4913.8, 300 sec: 4776.8). Total num frames: 3866624. Throughput: 0: 5191.5. Samples: 3873792. Policy #0 lag: (min: 3.0, avg: 6.0, max: 67.0)
[2025-11-03 15:12:02,776][200377] Avg episode reward: [(0, '1108.950')]
[2025-11-03 15:12:07,781][200377] Fps is (10 sec: 4165.3, 60 sec: 4646.8, 300 sec: 4751.3). Total num frames: 3883008. Throughput: 0: 4830.1. Samples: 3888128. Policy #0 lag: (min: 3.0, avg: 6.0, max: 67.0)
[2025-11-03 15:12:07,782][200377] Avg episode reward: [(0, '1168.743')]
[2025-11-03 15:12:08,097][200377] Saving /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_lidar_policy2/checkpoint_p0/checkpoint_000015200_3891200.pth...
[2025-11-03 15:12:08,100][200377] Removing /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_lidar_policy2/checkpoint_p0/checkpoint_000010688_2736128.pth
[2025-11-03 15:12:12,783][200377] Fps is (10 sec: 4911.7, 60 sec: 4917.1, 300 sec: 4776.5). Total num frames: 3915776. Throughput: 0: 4864.3. Samples: 3916800. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 15:12:12,783][200377] Avg episode reward: [(0, '1142.743')]
[2025-11-03 15:12:17,753][200377] Fps is (10 sec: 4929.2, 60 sec: 4646.1, 300 sec: 4752.6). Total num frames: 3932160. Throughput: 0: 4892.7. Samples: 3947520. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 15:12:17,753][200377] Avg episode reward: [(0, '1134.647')]
[2025-11-03 15:12:22,771][200377] Fps is (10 sec: 4920.9, 60 sec: 4920.6, 300 sec: 4777.4). Total num frames: 3964928. Throughput: 0: 4881.1. Samples: 3961856. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 15:12:22,771][200377] Avg episode reward: [(0, '1153.215')]
[2025-11-03 15:12:27,822][200377] Fps is (10 sec: 4881.3, 60 sec: 4659.7, 300 sec: 4775.7). Total num frames: 3981312. Throughput: 0: 4869.0. Samples: 3990528. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 15:12:27,823][200377] Avg episode reward: [(0, '1203.077')]
[2025-11-03 15:12:27,919][200377] Saving new best policy, reward=1203.077!
[2025-11-03 15:12:32,772][200377] Fps is (10 sec: 4914.8, 60 sec: 4913.8, 300 sec: 4776.0). Total num frames: 4014080. Throughput: 0: 5199.6. Samples: 4019712. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 15:12:32,772][200377] Avg episode reward: [(0, '1161.448')]
[2025-11-03 15:12:37,771][200377] Fps is (10 sec: 4940.7, 60 sec: 4778.7, 300 sec: 4776.3). Total num frames: 4030464. Throughput: 0: 4841.2. Samples: 4034560. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 15:12:37,771][200377] Avg episode reward: [(0, '1136.027')]
[2025-11-03 15:12:42,816][200377] Fps is (10 sec: 4893.7, 60 sec: 4915.2, 300 sec: 4776.7). Total num frames: 4063232. Throughput: 0: 4884.0. Samples: 4064256. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 15:12:42,816][200377] Avg episode reward: [(0, '1159.252')]
[2025-11-03 15:12:47,768][200377] Fps is (10 sec: 4916.7, 60 sec: 4779.0, 300 sec: 4777.3). Total num frames: 4079616. Throughput: 0: 4893.3. Samples: 4093952. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 15:12:47,768][200377] Avg episode reward: [(0, '1178.141')]
[2025-11-03 15:12:51,513][200377] Signal inference workers to stop experience collection... (750 times)
[2025-11-03 15:12:51,824][200377] InferenceWorker_p0-w0: stopping experience collection (750 times)
[2025-11-03 15:12:51,826][200377] Signal inference workers to resume experience collection... (750 times)
[2025-11-03 15:12:51,913][200377] InferenceWorker_p0-w0: resuming experience collection (750 times)
[2025-11-03 15:12:52,784][200377] Fps is (10 sec: 4931.0, 60 sec: 4918.4, 300 sec: 4831.4). Total num frames: 4112384. Throughput: 0: 4892.2. Samples: 4108288. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 15:12:52,784][200377] Avg episode reward: [(0, '1192.144')]
[2025-11-03 15:12:57,751][200377] Fps is (10 sec: 4923.5, 60 sec: 4794.4, 300 sec: 4779.9). Total num frames: 4128768. Throughput: 0: 4884.5. Samples: 4136448. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 15:12:57,751][200377] Avg episode reward: [(0, '1204.339')]
[2025-11-03 15:12:57,842][200377] Saving new best policy, reward=1204.339!
[2025-11-03 15:13:02,785][200377] Fps is (10 sec: 4914.4, 60 sec: 4914.4, 300 sec: 4831.5). Total num frames: 4161536. Throughput: 0: 4843.4. Samples: 4165632. Policy #0 lag: (min: 12.0, avg: 15.0, max: 76.0)
[2025-11-03 15:13:02,786][200377] Avg episode reward: [(0, '1181.796')]
[2025-11-03 15:13:07,782][200377] Fps is (10 sec: 4899.7, 60 sec: 4915.1, 300 sec: 4832.0). Total num frames: 4177920. Throughput: 0: 4845.7. Samples: 4179968. Policy #0 lag: (min: 12.0, avg: 15.0, max: 76.0)
[2025-11-03 15:13:07,783][200377] Avg episode reward: [(0, '1134.109')]
[2025-11-03 15:13:12,805][200377] Fps is (10 sec: 4905.5, 60 sec: 4913.4, 300 sec: 4831.6). Total num frames: 4210688. Throughput: 0: 4905.7. Samples: 4211200. Policy #0 lag: (min: 12.0, avg: 15.0, max: 76.0)
[2025-11-03 15:13:12,805][200377] Avg episode reward: [(0, '1097.846')]
[2025-11-03 15:13:17,802][200377] Fps is (10 sec: 4905.5, 60 sec: 4911.2, 300 sec: 4831.6). Total num frames: 4227072. Throughput: 0: 4889.2. Samples: 4239872. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 15:13:17,802][200377] Avg episode reward: [(0, '1150.417')]
[2025-11-03 15:13:22,817][200377] Fps is (10 sec: 4909.6, 60 sec: 4911.5, 300 sec: 4834.4). Total num frames: 4259840. Throughput: 0: 4876.1. Samples: 4254208. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 15:13:22,817][200377] Avg episode reward: [(0, '1169.541')]
[2025-11-03 15:13:27,751][200377] Fps is (10 sec: 4940.3, 60 sec: 4921.0, 300 sec: 4833.4). Total num frames: 4276224. Throughput: 0: 4876.7. Samples: 4283392. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 15:13:27,751][200377] Avg episode reward: [(0, '1177.079')]
[2025-11-03 15:13:32,814][200377] Fps is (10 sec: 4916.3, 60 sec: 4911.7, 300 sec: 4863.1). Total num frames: 4308992. Throughput: 0: 4853.3. Samples: 4312576. Policy #0 lag: (min: 3.0, avg: 6.0, max: 67.0)
[2025-11-03 15:13:32,815][200377] Avg episode reward: [(0, '1218.523')]
[2025-11-03 15:13:32,905][200377] Saving new best policy, reward=1218.523!
[2025-11-03 15:13:37,824][200377] Fps is (10 sec: 4879.5, 60 sec: 4910.8, 300 sec: 4831.8). Total num frames: 4325376. Throughput: 0: 4842.6. Samples: 4326400. Policy #0 lag: (min: 3.0, avg: 6.0, max: 67.0)
[2025-11-03 15:13:37,825][200377] Avg episode reward: [(0, '1185.077')]
[2025-11-03 15:13:42,752][200377] Fps is (10 sec: 4945.9, 60 sec: 4920.4, 300 sec: 4887.5). Total num frames: 4358144. Throughput: 0: 4915.0. Samples: 4357632. Policy #0 lag: (min: 5.0, avg: 8.0, max: 69.0)
[2025-11-03 15:13:42,753][200377] Avg episode reward: [(0, '1232.893')]
[2025-11-03 15:13:42,854][200377] Saving new best policy, reward=1232.893!
[2025-11-03 15:13:45,473][200377] Signal inference workers to stop experience collection... (800 times)
[2025-11-03 15:13:45,782][200377] InferenceWorker_p0-w0: stopping experience collection (800 times)
[2025-11-03 15:13:45,783][200377] Signal inference workers to resume experience collection... (800 times)
[2025-11-03 15:13:45,783][200377] InferenceWorker_p0-w0: resuming experience collection (800 times)
[2025-11-03 15:13:47,776][200377] Fps is (10 sec: 4939.1, 60 sec: 4914.5, 300 sec: 4832.8). Total num frames: 4374528. Throughput: 0: 4904.9. Samples: 4386304. Policy #0 lag: (min: 5.0, avg: 8.0, max: 69.0)
[2025-11-03 15:13:47,776][200377] Avg episode reward: [(0, '1290.357')]
[2025-11-03 15:13:47,871][200377] Saving new best policy, reward=1290.357!
[2025-11-03 15:13:52,805][200377] Fps is (10 sec: 4889.5, 60 sec: 4913.5, 300 sec: 4887.7). Total num frames: 4407296. Throughput: 0: 4901.4. Samples: 4400640. Policy #0 lag: (min: 5.0, avg: 8.0, max: 69.0)
[2025-11-03 15:13:52,805][200377] Avg episode reward: [(0, '1313.547')]
[2025-11-03 15:13:52,893][200377] Saving new best policy, reward=1313.547!
[2025-11-03 15:13:57,823][200377] Fps is (10 sec: 4892.0, 60 sec: 4909.3, 300 sec: 4831.0). Total num frames: 4423680. Throughput: 0: 4856.4. Samples: 4429824. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 15:13:57,823][200377] Avg episode reward: [(0, '1288.041')]
[2025-11-03 15:14:02,774][200377] Fps is (10 sec: 4930.5, 60 sec: 4916.2, 300 sec: 4887.8). Total num frames: 4456448. Throughput: 0: 4861.4. Samples: 4458496. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 15:14:02,774][200377] Avg episode reward: [(0, '1262.017')]
[2025-11-03 15:14:07,760][200377] Fps is (10 sec: 4946.3, 60 sec: 4917.0, 300 sec: 4832.4). Total num frames: 4472832. Throughput: 0: 4887.2. Samples: 4473856. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 15:14:07,761][200377] Avg episode reward: [(0, '1254.897')]
[2025-11-03 15:14:07,852][200377] Saving /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_lidar_policy2/checkpoint_p0/checkpoint_000017472_4472832.pth...
[2025-11-03 15:14:07,856][200377] Removing /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_lidar_policy2/checkpoint_p0/checkpoint_000012928_3309568.pth
[2025-11-03 15:14:12,794][200377] Fps is (10 sec: 4905.3, 60 sec: 4916.1, 300 sec: 4886.7). Total num frames: 4505600. Throughput: 0: 4910.5. Samples: 4504576. Policy #0 lag: (min: 1.0, avg: 4.0, max: 65.0)
[2025-11-03 15:14:12,794][200377] Avg episode reward: [(0, '1263.268')]
[2025-11-03 15:14:17,804][200377] Fps is (10 sec: 4893.9, 60 sec: 4915.1, 300 sec: 4831.3). Total num frames: 4521984. Throughput: 0: 4905.0. Samples: 4533248. Policy #0 lag: (min: 1.0, avg: 4.0, max: 65.0)
[2025-11-03 15:14:17,804][200377] Avg episode reward: [(0, '1290.906')]
[2025-11-03 15:14:22,780][200377] Fps is (10 sec: 4922.1, 60 sec: 4918.2, 300 sec: 4887.1). Total num frames: 4554752. Throughput: 0: 4908.7. Samples: 4547072. Policy #0 lag: (min: 11.0, avg: 14.0, max: 75.0)
[2025-11-03 15:14:22,780][200377] Avg episode reward: [(0, '1295.938')]
[2025-11-03 15:14:27,767][200377] Fps is (10 sec: 4933.4, 60 sec: 4913.9, 300 sec: 4835.8). Total num frames: 4571136. Throughput: 0: 4856.7. Samples: 4576256. Policy #0 lag: (min: 11.0, avg: 14.0, max: 75.0)
[2025-11-03 15:14:27,767][200377] Avg episode reward: [(0, '1291.056')]
[2025-11-03 15:14:32,794][200377] Fps is (10 sec: 4908.3, 60 sec: 4916.9, 300 sec: 4887.1). Total num frames: 4603904. Throughput: 0: 4537.9. Samples: 4590592. Policy #0 lag: (min: 11.0, avg: 14.0, max: 75.0)
[2025-11-03 15:14:32,794][200377] Avg episode reward: [(0, '1279.294')]
[2025-11-03 15:14:37,787][200377] Fps is (10 sec: 4905.4, 60 sec: 4918.3, 300 sec: 4835.2). Total num frames: 4620288. Throughput: 0: 4905.8. Samples: 4621312. Policy #0 lag: (min: 1.0, avg: 4.0, max: 65.0)
[2025-11-03 15:14:37,787][200377] Avg episode reward: [(0, '1314.612')]
[2025-11-03 15:14:37,881][200377] Saving new best policy, reward=1314.612!
[2025-11-03 15:14:42,478][200377] Signal inference workers to stop experience collection... (850 times)
[2025-11-03 15:14:42,479][200377] Signal inference workers to resume experience collection... (850 times)
[2025-11-03 15:14:42,681][200377] InferenceWorker_p0-w0: stopping experience collection (850 times)
[2025-11-03 15:14:42,682][200377] InferenceWorker_p0-w0: resuming experience collection (850 times)
[2025-11-03 15:14:42,794][200377] Fps is (10 sec: 4915.4, 60 sec: 4911.8, 300 sec: 4886.7). Total num frames: 4653056. Throughput: 0: 4918.4. Samples: 4651008. Policy #0 lag: (min: 1.0, avg: 4.0, max: 65.0)
[2025-11-03 15:14:42,794][200377] Avg episode reward: [(0, '1283.857')]
[2025-11-03 15:14:47,752][200377] Fps is (10 sec: 4932.5, 60 sec: 4917.2, 300 sec: 4836.1). Total num frames: 4669440. Throughput: 0: 4917.6. Samples: 4679680. Policy #0 lag: (min: 1.0, avg: 4.0, max: 65.0)
[2025-11-03 15:14:47,752][200377] Avg episode reward: [(0, '1297.476')]
[2025-11-03 15:14:52,884][200377] Fps is (10 sec: 4871.2, 60 sec: 4908.7, 300 sec: 4885.5). Total num frames: 4702208. Throughput: 0: 4879.0. Samples: 4694016. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 15:14:52,884][200377] Avg episode reward: [(0, '1332.091')]
[2025-11-03 15:14:52,884][200377] Saving new best policy, reward=1332.091!
[2025-11-03 15:14:57,777][200377] Fps is (10 sec: 4902.8, 60 sec: 4919.0, 300 sec: 4863.1). Total num frames: 4718592. Throughput: 0: 4848.8. Samples: 4722688. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 15:14:57,777][200377] Avg episode reward: [(0, '1287.859')]
[2025-11-03 15:15:02,925][200377] Fps is (10 sec: 4895.1, 60 sec: 4902.8, 300 sec: 4884.6). Total num frames: 4751360. Throughput: 0: 4516.2. Samples: 4737024. Policy #0 lag: (min: 10.0, avg: 13.0, max: 74.0)
[2025-11-03 15:15:02,925][200377] Avg episode reward: [(0, '1232.677')]
[2025-11-03 15:15:07,750][200377] Fps is (10 sec: 4928.8, 60 sec: 4916.1, 300 sec: 4864.5). Total num frames: 4767744. Throughput: 0: 4918.5. Samples: 4768256. Policy #0 lag: (min: 10.0, avg: 13.0, max: 74.0)
[2025-11-03 15:15:07,750][200377] Avg episode reward: [(0, '1226.228')]
[2025-11-03 15:15:12,784][200377] Fps is (10 sec: 4154.6, 60 sec: 4779.5, 300 sec: 4859.2). Total num frames: 4792320. Throughput: 0: 4890.6. Samples: 4796416. Policy #0 lag: (min: 10.0, avg: 13.0, max: 74.0)
[2025-11-03 15:15:12,784][200377] Avg episode reward: [(0, '1210.608')]
[2025-11-03 15:15:17,795][200377] Fps is (10 sec: 4893.0, 60 sec: 4915.9, 300 sec: 4886.7). Total num frames: 4816896. Throughput: 0: 5210.9. Samples: 4825088. Policy #0 lag: (min: 3.0, avg: 6.0, max: 67.0)
[2025-11-03 15:15:17,795][200377] Avg episode reward: [(0, '1278.086')]
[2025-11-03 15:15:22,785][200377] Fps is (10 sec: 4095.6, 60 sec: 4641.7, 300 sec: 4831.9). Total num frames: 4833280. Throughput: 0: 4835.7. Samples: 4838912. Policy #0 lag: (min: 3.0, avg: 6.0, max: 67.0)
[2025-11-03 15:15:22,785][200377] Avg episode reward: [(0, '1277.191')]
[2025-11-03 15:15:27,794][200377] Fps is (10 sec: 4915.5, 60 sec: 4912.9, 300 sec: 4887.0). Total num frames: 4866048. Throughput: 0: 4801.3. Samples: 4867072. Policy #0 lag: (min: 3.0, avg: 6.0, max: 67.0)
[2025-11-03 15:15:27,795][200377] Avg episode reward: [(0, '1264.260')]
[2025-11-03 15:15:32,777][200377] Fps is (10 sec: 4919.0, 60 sec: 4643.4, 300 sec: 4832.8). Total num frames: 4882432. Throughput: 0: 4855.5. Samples: 4898304. Policy #0 lag: (min: 9.0, avg: 12.0, max: 73.0)
[2025-11-03 15:15:32,778][200377] Avg episode reward: [(0, '1265.008')]
[2025-11-03 15:15:37,780][200377] Fps is (10 sec: 4922.5, 60 sec: 4915.8, 300 sec: 4887.6). Total num frames: 4915200. Throughput: 0: 4869.6. Samples: 4912640. Policy #0 lag: (min: 9.0, avg: 12.0, max: 73.0)
[2025-11-03 15:15:37,780][200377] Avg episode reward: [(0, '1267.365')]
[2025-11-03 15:15:39,630][200377] Signal inference workers to stop experience collection... (900 times)
[2025-11-03 15:15:39,937][200377] InferenceWorker_p0-w0: stopping experience collection (900 times)
[2025-11-03 15:15:39,938][200377] Signal inference workers to resume experience collection... (900 times)
[2025-11-03 15:15:40,028][200377] InferenceWorker_p0-w0: resuming experience collection (900 times)
[2025-11-03 15:15:42,786][200377] Fps is (10 sec: 4910.8, 60 sec: 4642.7, 300 sec: 4831.9). Total num frames: 4931584. Throughput: 0: 4857.3. Samples: 4941312. Policy #0 lag: (min: 9.0, avg: 12.0, max: 73.0)
[2025-11-03 15:15:42,787][200377] Avg episode reward: [(0, '1345.819')]
[2025-11-03 15:15:42,880][200377] Saving new best policy, reward=1345.819!
[2025-11-03 15:15:47,799][200377] Fps is (10 sec: 4905.8, 60 sec: 4911.4, 300 sec: 4887.6). Total num frames: 4964352. Throughput: 0: 5202.9. Samples: 4970496. Policy #0 lag: (min: 7.0, avg: 10.0, max: 71.0)
[2025-11-03 15:15:47,799][200377] Avg episode reward: [(0, '1329.435')]
[2025-11-03 15:15:52,763][200377] Fps is (10 sec: 4926.6, 60 sec: 4651.5, 300 sec: 4832.5). Total num frames: 4980736. Throughput: 0: 4811.3. Samples: 4984832. Policy #0 lag: (min: 7.0, avg: 10.0, max: 71.0)
[2025-11-03 15:15:52,763][200377] Avg episode reward: [(0, '1311.550')]
[2025-11-03 15:15:57,805][200377] Fps is (10 sec: 4912.0, 60 sec: 4912.9, 300 sec: 4886.7). Total num frames: 5013504. Throughput: 0: 4844.7. Samples: 5014528. Policy #0 lag: (min: 3.0, avg: 6.0, max: 67.0)
[2025-11-03 15:15:57,805][200377] Avg episode reward: [(0, '1320.006')]
[2025-11-03 15:16:02,829][200377] Fps is (10 sec: 4882.9, 60 sec: 4649.5, 300 sec: 4832.1). Total num frames: 5029888. Throughput: 0: 4843.2. Samples: 5043200. Policy #0 lag: (min: 3.0, avg: 6.0, max: 67.0)
[2025-11-03 15:16:02,830][200377] Avg episode reward: [(0, '1367.871')]
[2025-11-03 15:16:02,920][200377] Saving new best policy, reward=1367.871!
[2025-11-03 15:16:07,793][200377] Fps is (10 sec: 4921.1, 60 sec: 4911.6, 300 sec: 4887.6). Total num frames: 5062656. Throughput: 0: 4857.4. Samples: 5057536. Policy #0 lag: (min: 3.0, avg: 6.0, max: 67.0)
[2025-11-03 15:16:07,793][200377] Avg episode reward: [(0, '1313.604')]
[2025-11-03 15:16:07,894][200377] Saving /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_lidar_policy2/checkpoint_p0/checkpoint_000019776_5062656.pth...
[2025-11-03 15:16:07,898][200377] Removing /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_lidar_policy2/checkpoint_p0/checkpoint_000015200_3891200.pth
[2025-11-03 15:16:12,753][200377] Fps is (10 sec: 4952.8, 60 sec: 4781.1, 300 sec: 4832.7). Total num frames: 5079040. Throughput: 0: 4862.7. Samples: 5085696. Policy #0 lag: (min: 13.0, avg: 16.0, max: 77.0)
[2025-11-03 15:16:12,754][200377] Avg episode reward: [(0, '1316.457')]
[2025-11-03 15:16:17,814][200377] Fps is (10 sec: 4905.1, 60 sec: 4913.7, 300 sec: 4887.8). Total num frames: 5111808. Throughput: 0: 4808.9. Samples: 5114880. Policy #0 lag: (min: 13.0, avg: 16.0, max: 77.0)
[2025-11-03 15:16:17,814][200377] Avg episode reward: [(0, '1317.544')]
[2025-11-03 15:16:22,824][200377] Fps is (10 sec: 4881.0, 60 sec: 4912.1, 300 sec: 4835.6). Total num frames: 5128192. Throughput: 0: 4808.1. Samples: 5129216. Policy #0 lag: (min: 13.0, avg: 16.0, max: 77.0)
[2025-11-03 15:16:22,824][200377] Avg episode reward: [(0, '1287.151')]
[2025-11-03 15:16:27,783][200377] Fps is (10 sec: 4930.1, 60 sec: 4916.1, 300 sec: 4887.0). Total num frames: 5160960. Throughput: 0: 4870.0. Samples: 5160448. Policy #0 lag: (min: 53.0, avg: 56.0, max: 117.0)
[2025-11-03 15:16:27,784][200377] Avg episode reward: [(0, '1310.247')]
[2025-11-03 15:16:32,784][200377] Fps is (10 sec: 4934.6, 60 sec: 4914.7, 300 sec: 4859.5). Total num frames: 5177344. Throughput: 0: 4848.5. Samples: 5188608. Policy #0 lag: (min: 53.0, avg: 56.0, max: 117.0)
[2025-11-03 15:16:32,784][200377] Avg episode reward: [(0, '1241.111')]
[2025-11-03 15:16:34,015][200377] Signal inference workers to stop experience collection... (950 times)
[2025-11-03 15:16:34,321][200377] InferenceWorker_p0-w0: stopping experience collection (950 times)
[2025-11-03 15:16:34,321][200377] Signal inference workers to resume experience collection... (950 times)
[2025-11-03 15:16:34,321][200377] InferenceWorker_p0-w0: resuming experience collection (950 times)
[2025-11-03 15:16:37,830][200377] Fps is (10 sec: 4892.4, 60 sec: 4911.1, 300 sec: 4887.2). Total num frames: 5210112. Throughput: 0: 4839.8. Samples: 5202944. Policy #0 lag: (min: 53.0, avg: 56.0, max: 117.0)
[2025-11-03 15:16:37,830][200377] Avg episode reward: [(0, '1196.559')]
[2025-11-03 15:16:42,835][200377] Fps is (10 sec: 4890.3, 60 sec: 4911.2, 300 sec: 4858.6). Total num frames: 5226496. Throughput: 0: 4809.6. Samples: 5231104. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 15:16:42,835][200377] Avg episode reward: [(0, '1305.632')]
[2025-11-03 15:16:47,823][200377] Fps is (10 sec: 4918.8, 60 sec: 4913.2, 300 sec: 4887.4). Total num frames: 5259264. Throughput: 0: 4494.9. Samples: 5245440. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 15:16:47,823][200377] Avg episode reward: [(0, '1248.953')]
[2025-11-03 15:16:52,756][200377] Fps is (10 sec: 4954.3, 60 sec: 4915.8, 300 sec: 4862.8). Total num frames: 5275648. Throughput: 0: 4873.7. Samples: 5276672. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 15:16:52,756][200377] Avg episode reward: [(0, '1235.163')]
[2025-11-03 15:16:57,874][200377] Fps is (10 sec: 4890.1, 60 sec: 4909.6, 300 sec: 4885.8). Total num frames: 5308416. Throughput: 0: 4879.4. Samples: 5305856. Policy #0 lag: (min: 6.0, avg: 9.0, max: 70.0)
[2025-11-03 15:16:57,874][200377] Avg episode reward: [(0, '1374.618')]
[2025-11-03 15:16:57,876][200377] Saving new best policy, reward=1374.618!
[2025-11-03 15:17:02,761][200377] Fps is (10 sec: 4912.6, 60 sec: 4920.8, 300 sec: 4887.8). Total num frames: 5324800. Throughput: 0: 4875.4. Samples: 5334016. Policy #0 lag: (min: 6.0, avg: 9.0, max: 70.0)
[2025-11-03 15:17:02,762][200377] Avg episode reward: [(0, '1386.831')]
[2025-11-03 15:17:02,855][200377] Saving new best policy, reward=1386.831!
[2025-11-03 15:17:07,801][200377] Fps is (10 sec: 4126.0, 60 sec: 4778.0, 300 sec: 4859.4). Total num frames: 5349376. Throughput: 0: 4872.1. Samples: 5348352. Policy #0 lag: (min: 6.0, avg: 9.0, max: 70.0)
[2025-11-03 15:17:07,801][200377] Avg episode reward: [(0, '1323.772')]
[2025-11-03 15:17:12,810][200377] Fps is (10 sec: 4891.2, 60 sec: 4910.5, 300 sec: 4886.5). Total num frames: 5373952. Throughput: 0: 4798.6. Samples: 5376512. Policy #0 lag: (min: 6.0, avg: 9.0, max: 70.0)
[2025-11-03 15:17:12,811][200377] Avg episode reward: [(0, '1342.545')]
[2025-11-03 15:17:17,940][200377] Fps is (10 sec: 4848.1, 60 sec: 4768.7, 300 sec: 4856.9). Total num frames: 5398528. Throughput: 0: 4490.1. Samples: 5391360. Policy #0 lag: (min: 4.0, avg: 7.0, max: 68.0)
[2025-11-03 15:17:17,940][200377] Avg episode reward: [(0, '1342.146')]
[2025-11-03 15:17:22,775][200377] Fps is (10 sec: 4932.6, 60 sec: 4919.2, 300 sec: 4888.2). Total num frames: 5423104. Throughput: 0: 4875.6. Samples: 5422080. Policy #0 lag: (min: 4.0, avg: 7.0, max: 68.0)
[2025-11-03 15:17:22,775][200377] Avg episode reward: [(0, '1321.092')]
[2025-11-03 15:17:27,983][200377] Fps is (10 sec: 4893.9, 60 sec: 4762.8, 300 sec: 4856.2). Total num frames: 5447680. Throughput: 0: 4865.1. Samples: 5450752. Policy #0 lag: (min: 4.0, avg: 7.0, max: 68.0)
[2025-11-03 15:17:27,983][200377] Avg episode reward: [(0, '1356.908')]
[2025-11-03 15:17:31,383][200377] Signal inference workers to stop experience collection... (1000 times)
[2025-11-03 15:17:31,386][200377] Signal inference workers to resume experience collection... (1000 times)
[2025-11-03 15:17:31,596][200377] InferenceWorker_p0-w0: stopping experience collection (1000 times)
[2025-11-03 15:17:31,596][200377] InferenceWorker_p0-w0: resuming experience collection (1000 times)
[2025-11-03 15:17:32,823][200377] Fps is (10 sec: 4891.6, 60 sec: 4912.0, 300 sec: 4886.6). Total num frames: 5472256. Throughput: 0: 5199.6. Samples: 5479424. Policy #0 lag: (min: 3.0, avg: 6.0, max: 67.0)
[2025-11-03 15:17:32,824][200377] Avg episode reward: [(0, '1409.073')]
[2025-11-03 15:17:32,923][200377] Saving new best policy, reward=1409.073!
[2025-11-03 15:17:37,818][200377] Fps is (10 sec: 4164.6, 60 sec: 4643.0, 300 sec: 4831.9). Total num frames: 5488640. Throughput: 0: 4817.5. Samples: 5493760. Policy #0 lag: (min: 3.0, avg: 6.0, max: 67.0)
[2025-11-03 15:17:37,819][200377] Avg episode reward: [(0, '1302.891')]
[2025-11-03 15:17:42,821][200377] Fps is (10 sec: 4916.1, 60 sec: 4916.3, 300 sec: 4886.5). Total num frames: 5521408. Throughput: 0: 4818.4. Samples: 5522432. Policy #0 lag: (min: 3.0, avg: 6.0, max: 67.0)
[2025-11-03 15:17:42,822][200377] Avg episode reward: [(0, '1277.427')]
[2025-11-03 15:17:47,830][200377] Fps is (10 sec: 4909.5, 60 sec: 4641.6, 300 sec: 4831.1). Total num frames: 5537792. Throughput: 0: 4862.3. Samples: 5553152. Policy #0 lag: (min: 3.0, avg: 6.0, max: 67.0)
[2025-11-03 15:17:47,830][200377] Avg episode reward: [(0, '1366.303')]
[2025-11-03 15:17:52,772][200377] Fps is (10 sec: 4939.5, 60 sec: 4913.9, 300 sec: 4887.1). Total num frames: 5570560. Throughput: 0: 4872.8. Samples: 5567488. Policy #0 lag: (min: 13.0, avg: 16.0, max: 77.0)
[2025-11-03 15:17:52,772][200377] Avg episode reward: [(0, '1439.488')]
[2025-11-03 15:17:52,870][200377] Saving new best policy, reward=1439.488!
[2025-11-03 15:17:57,793][200377] Fps is (10 sec: 4933.7, 60 sec: 4648.4, 300 sec: 4831.8). Total num frames: 5586944. Throughput: 0: 4871.6. Samples: 5595648. Policy #0 lag: (min: 13.0, avg: 16.0, max: 77.0)
[2025-11-03 15:17:57,793][200377] Avg episode reward: [(0, '1394.517')]
[2025-11-03 15:18:02,805][200377] Fps is (10 sec: 4899.0, 60 sec: 4911.6, 300 sec: 4887.1). Total num frames: 5619712. Throughput: 0: 5192.4. Samples: 5624320. Policy #0 lag: (min: 13.0, avg: 16.0, max: 77.0)
[2025-11-03 15:18:02,805][200377] Avg episode reward: [(0, '1410.844')]
[2025-11-03 15:18:07,818][200377] Fps is (10 sec: 4902.6, 60 sec: 4777.3, 300 sec: 4831.7). Total num frames: 5636096. Throughput: 0: 4808.2. Samples: 5638656. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 15:18:07,818][200377] Avg episode reward: [(0, '1429.666')]
[2025-11-03 15:18:07,916][200377] Saving /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_lidar_policy2/checkpoint_p0/checkpoint_000022016_5636096.pth...
[2025-11-03 15:18:07,920][200377] Removing /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_lidar_policy2/checkpoint_p0/checkpoint_000017472_4472832.pth
[2025-11-03 15:18:12,807][200377] Fps is (10 sec: 4914.5, 60 sec: 4915.5, 300 sec: 4887.4). Total num frames: 5668864. Throughput: 0: 4888.9. Samples: 5669888. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 15:18:12,807][200377] Avg episode reward: [(0, '1398.594')]
[2025-11-03 15:18:17,766][200377] Fps is (10 sec: 4940.9, 60 sec: 4792.5, 300 sec: 4832.7). Total num frames: 5685248. Throughput: 0: 4853.1. Samples: 5697536. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 15:18:17,766][200377] Avg episode reward: [(0, '1428.346')]
[2025-11-03 15:18:22,806][200377] Fps is (10 sec: 4915.3, 60 sec: 4912.6, 300 sec: 4886.5). Total num frames: 5718016. Throughput: 0: 4848.2. Samples: 5711872. Policy #0 lag: (min: 3.0, avg: 6.0, max: 67.0)
[2025-11-03 15:18:22,807][200377] Avg episode reward: [(0, '1415.593')]
[2025-11-03 15:18:27,803][200377] Fps is (10 sec: 4897.1, 60 sec: 4793.0, 300 sec: 4832.1). Total num frames: 5734400. Throughput: 0: 4848.9. Samples: 5740544. Policy #0 lag: (min: 3.0, avg: 6.0, max: 67.0)
[2025-11-03 15:18:27,803][200377] Avg episode reward: [(0, '1359.449')]
[2025-11-03 15:18:28,672][200377] Signal inference workers to stop experience collection... (1050 times)
[2025-11-03 15:18:28,987][200377] InferenceWorker_p0-w0: stopping experience collection (1050 times)
[2025-11-03 15:18:28,989][200377] Signal inference workers to resume experience collection... (1050 times)
[2025-11-03 15:18:29,074][200377] InferenceWorker_p0-w0: resuming experience collection (1050 times)
[2025-11-03 15:18:32,831][200377] Fps is (10 sec: 4903.2, 60 sec: 4914.6, 300 sec: 4887.3). Total num frames: 5767168. Throughput: 0: 4778.6. Samples: 5768192. Policy #0 lag: (min: 3.0, avg: 6.0, max: 67.0)
[2025-11-03 15:18:32,831][200377] Avg episode reward: [(0, '1303.066')]
[2025-11-03 15:18:37,773][200377] Fps is (10 sec: 4930.1, 60 sec: 4918.9, 300 sec: 4831.6). Total num frames: 5783552. Throughput: 0: 4824.1. Samples: 5784576. Policy #0 lag: (min: 3.0, avg: 6.0, max: 67.0)
[2025-11-03 15:18:37,773][200377] Avg episode reward: [(0, '1350.683')]
[2025-11-03 15:18:42,784][200377] Fps is (10 sec: 4938.6, 60 sec: 4918.3, 300 sec: 4887.3). Total num frames: 5816320. Throughput: 0: 4859.3. Samples: 5814272. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 15:18:42,784][200377] Avg episode reward: [(0, '1340.733')]
[2025-11-03 15:18:47,760][200377] Fps is (10 sec: 4921.5, 60 sec: 4920.9, 300 sec: 4832.6). Total num frames: 5832704. Throughput: 0: 4851.8. Samples: 5842432. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 15:18:47,760][200377] Avg episode reward: [(0, '1313.060')]
[2025-11-03 15:18:52,953][200377] Fps is (10 sec: 4833.2, 60 sec: 4900.4, 300 sec: 4885.3). Total num frames: 5865472. Throughput: 0: 4832.4. Samples: 5856768. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 15:18:52,953][200377] Avg episode reward: [(0, '1409.786')]
[2025-11-03 15:18:57,805][200377] Fps is (10 sec: 4893.2, 60 sec: 4914.2, 300 sec: 4831.4). Total num frames: 5881856. Throughput: 0: 4801.6. Samples: 5885952. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 15:18:57,805][200377] Avg episode reward: [(0, '1388.893')]
[2025-11-03 15:19:02,972][200377] Fps is (10 sec: 4905.9, 60 sec: 4901.6, 300 sec: 4883.9). Total num frames: 5914624. Throughput: 0: 4824.8. Samples: 5915648. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 15:19:02,972][200377] Avg episode reward: [(0, '1383.826')]
[2025-11-03 15:19:07,781][200377] Fps is (10 sec: 4927.2, 60 sec: 4918.3, 300 sec: 4832.1). Total num frames: 5931008. Throughput: 0: 4883.9. Samples: 5931520. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 15:19:07,781][200377] Avg episode reward: [(0, '1399.805')]
[2025-11-03 15:19:13,038][200377] Fps is (10 sec: 4883.0, 60 sec: 4896.3, 300 sec: 4883.5). Total num frames: 5963776. Throughput: 0: 4855.7. Samples: 5960192. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 15:19:13,038][200377] Avg episode reward: [(0, '1439.684')]
[2025-11-03 15:19:13,039][200377] Saving new best policy, reward=1439.684!
[2025-11-03 15:19:17,790][200377] Fps is (10 sec: 4910.8, 60 sec: 4913.3, 300 sec: 4831.7). Total num frames: 5980160. Throughput: 0: 4908.3. Samples: 5988864. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 15:19:17,790][200377] Avg episode reward: [(0, '1364.355')]
[2025-11-03 15:19:22,948][200377] Signal inference workers to stop experience collection... (1100 times)
[2025-11-03 15:19:22,948][200377] Fps is (10 sec: 4133.4, 60 sec: 4767.4, 300 sec: 4856.7). Total num frames: 6004736. Throughput: 0: 4828.2. Samples: 6002688. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 15:19:22,948][200377] Avg episode reward: [(0, '1355.386')]
[2025-11-03 15:19:23,266][200377] InferenceWorker_p0-w0: stopping experience collection (1100 times)
[2025-11-03 15:19:23,267][200377] Signal inference workers to resume experience collection... (1100 times)
[2025-11-03 15:19:23,267][200377] InferenceWorker_p0-w0: resuming experience collection (1100 times)
[2025-11-03 15:19:27,763][200377] Fps is (10 sec: 4928.5, 60 sec: 4918.5, 300 sec: 4832.4). Total num frames: 6029312. Throughput: 0: 4826.4. Samples: 6031360. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 15:19:27,763][200377] Avg episode reward: [(0, '1418.510')]
[2025-11-03 15:19:33,034][200377] Fps is (10 sec: 4873.1, 60 sec: 4762.5, 300 sec: 4855.6). Total num frames: 6053888. Throughput: 0: 4862.8. Samples: 6062592. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 15:19:33,034][200377] Avg episode reward: [(0, '1446.431')]
[2025-11-03 15:19:33,344][200377] Saving new best policy, reward=1446.431!
[2025-11-03 15:19:37,831][200377] Fps is (10 sec: 4881.9, 60 sec: 4910.5, 300 sec: 4831.3). Total num frames: 6078464. Throughput: 0: 4905.8. Samples: 6076928. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 15:19:37,831][200377] Avg episode reward: [(0, '1428.772')]
[2025-11-03 15:19:42,822][200377] Fps is (10 sec: 4184.9, 60 sec: 4639.2, 300 sec: 4830.7). Total num frames: 6094848. Throughput: 0: 4879.3. Samples: 6105600. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 15:19:42,822][200377] Avg episode reward: [(0, '1444.778')]
[2025-11-03 15:19:47,779][200377] Fps is (10 sec: 4940.9, 60 sec: 4913.7, 300 sec: 4833.6). Total num frames: 6127616. Throughput: 0: 4879.3. Samples: 6134272. Policy #0 lag: (min: 4.0, avg: 7.0, max: 68.0)
[2025-11-03 15:19:47,779][200377] Avg episode reward: [(0, '1429.548')]
[2025-11-03 15:19:52,818][200377] Fps is (10 sec: 4916.9, 60 sec: 4652.6, 300 sec: 4831.2). Total num frames: 6144000. Throughput: 0: 4808.8. Samples: 6148096. Policy #0 lag: (min: 4.0, avg: 7.0, max: 68.0)
[2025-11-03 15:19:52,818][200377] Avg episode reward: [(0, '1413.660')]
[2025-11-03 15:19:57,776][200377] Fps is (10 sec: 4916.7, 60 sec: 4917.6, 300 sec: 4834.3). Total num frames: 6176768. Throughput: 0: 4863.9. Samples: 6177792. Policy #0 lag: (min: 4.0, avg: 7.0, max: 68.0)
[2025-11-03 15:19:57,776][200377] Avg episode reward: [(0, '1397.957')]
[2025-11-03 15:20:02,833][200377] Fps is (10 sec: 4908.0, 60 sec: 4652.9, 300 sec: 4830.5). Total num frames: 6193152. Throughput: 0: 4853.7. Samples: 6207488. Policy #0 lag: (min: 4.0, avg: 7.0, max: 68.0)
[2025-11-03 15:20:02,833][200377] Avg episode reward: [(0, '1410.299')]
[2025-11-03 15:20:07,831][200377] Fps is (10 sec: 4888.5, 60 sec: 4911.1, 300 sec: 4858.9). Total num frames: 6225920. Throughput: 0: 4871.0. Samples: 6221312. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 15:20:07,831][200377] Avg episode reward: [(0, '1401.353')]
[2025-11-03 15:20:07,928][200377] Saving /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_lidar_policy2/checkpoint_p0/checkpoint_000024320_6225920.pth...
[2025-11-03 15:20:07,932][200377] Removing /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_lidar_policy2/checkpoint_p0/checkpoint_000019776_5062656.pth
[2025-11-03 15:20:12,760][200377] Fps is (10 sec: 4951.1, 60 sec: 4663.7, 300 sec: 4832.5). Total num frames: 6242304. Throughput: 0: 4869.9. Samples: 6250496. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 15:20:12,761][200377] Avg episode reward: [(0, '1392.212')]
[2025-11-03 15:20:17,798][200377] Fps is (10 sec: 4931.4, 60 sec: 4914.5, 300 sec: 4887.2). Total num frames: 6275072. Throughput: 0: 4849.6. Samples: 6279680. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 15:20:17,798][200377] Avg episode reward: [(0, '1473.669')]
[2025-11-03 15:20:17,888][200377] Saving new best policy, reward=1473.669!
[2025-11-03 15:20:20,254][200377] Signal inference workers to stop experience collection... (1150 times)
[2025-11-03 15:20:20,257][200377] Signal inference workers to resume experience collection... (1150 times)
[2025-11-03 15:20:20,495][200377] InferenceWorker_p0-w0: stopping experience collection (1150 times)
[2025-11-03 15:20:20,495][200377] InferenceWorker_p0-w0: resuming experience collection (1150 times)
[2025-11-03 15:20:22,790][200377] Fps is (10 sec: 4900.8, 60 sec: 4791.3, 300 sec: 4832.0). Total num frames: 6291456. Throughput: 0: 4817.2. Samples: 6293504. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 15:20:22,790][200377] Avg episode reward: [(0, '1412.239')]
[2025-11-03 15:20:27,782][200377] Fps is (10 sec: 4923.2, 60 sec: 4913.7, 300 sec: 4887.4). Total num frames: 6324224. Throughput: 0: 4839.9. Samples: 6323200. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 15:20:27,782][200377] Avg episode reward: [(0, '1309.324')]
[2025-11-03 15:20:32,799][200377] Fps is (10 sec: 4910.6, 60 sec: 4797.4, 300 sec: 4831.6). Total num frames: 6340608. Throughput: 0: 4822.0. Samples: 6351360. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 15:20:32,800][200377] Avg episode reward: [(0, '1299.349')]
[2025-11-03 15:20:37,852][200377] Fps is (10 sec: 4880.8, 60 sec: 4913.5, 300 sec: 4886.3). Total num frames: 6373376. Throughput: 0: 4831.9. Samples: 6365696. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 15:20:37,852][200377] Avg episode reward: [(0, '1373.989')]
[2025-11-03 15:20:42,783][200377] Fps is (10 sec: 4923.4, 60 sec: 4918.4, 300 sec: 4832.2). Total num frames: 6389760. Throughput: 0: 4800.7. Samples: 6393856. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 15:20:42,783][200377] Avg episode reward: [(0, '1384.048')]
[2025-11-03 15:20:47,897][200377] Fps is (10 sec: 4893.4, 60 sec: 4905.6, 300 sec: 4885.2). Total num frames: 6422528. Throughput: 0: 4465.1. Samples: 6408704. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 15:20:47,897][200377] Avg episode reward: [(0, '1299.842')]
[2025-11-03 15:20:52,787][200377] Fps is (10 sec: 4913.0, 60 sec: 4917.8, 300 sec: 4832.2). Total num frames: 6438912. Throughput: 0: 4863.0. Samples: 6439936. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 15:20:52,787][200377] Avg episode reward: [(0, '1332.326')]
[2025-11-03 15:20:57,786][200377] Fps is (10 sec: 4141.8, 60 sec: 4777.9, 300 sec: 4860.4). Total num frames: 6463488. Throughput: 0: 4832.8. Samples: 6468096. Policy #0 lag: (min: 3.0, avg: 6.0, max: 67.0)
[2025-11-03 15:20:57,786][200377] Avg episode reward: [(0, '1396.631')]
[2025-11-03 15:21:02,816][200377] Fps is (10 sec: 4901.1, 60 sec: 4916.6, 300 sec: 4831.5). Total num frames: 6488064. Throughput: 0: 4822.3. Samples: 6496768. Policy #0 lag: (min: 3.0, avg: 6.0, max: 67.0)
[2025-11-03 15:21:02,816][200377] Avg episode reward: [(0, '1406.115')]
[2025-11-03 15:21:07,904][200377] Fps is (10 sec: 4857.6, 60 sec: 4772.8, 300 sec: 4857.2). Total num frames: 6512640. Throughput: 0: 4811.9. Samples: 6510592. Policy #0 lag: (min: 3.0, avg: 6.0, max: 67.0)
[2025-11-03 15:21:07,905][200377] Avg episode reward: [(0, '1414.287')]
[2025-11-03 15:21:12,783][200377] Fps is (10 sec: 4931.3, 60 sec: 4913.4, 300 sec: 4832.4). Total num frames: 6537216. Throughput: 0: 4801.3. Samples: 6539264. Policy #0 lag: (min: 3.0, avg: 6.0, max: 67.0)
[2025-11-03 15:21:12,783][200377] Avg episode reward: [(0, '1383.814')]
[2025-11-03 15:21:17,692][200377] Signal inference workers to stop experience collection... (1200 times)
[2025-11-03 15:21:18,006][200377] InferenceWorker_p0-w0: stopping experience collection (1200 times)
[2025-11-03 15:21:18,008][200377] Signal inference workers to resume experience collection... (1200 times)
[2025-11-03 15:21:18,008][200377] Fps is (10 sec: 4864.6, 60 sec: 4762.0, 300 sec: 4856.6). Total num frames: 6561792. Throughput: 0: 4847.2. Samples: 6570496. Policy #0 lag: (min: 3.0, avg: 6.0, max: 67.0)
[2025-11-03 15:21:18,009][200377] Avg episode reward: [(0, '1389.327')]
[2025-11-03 15:21:18,101][200377] InferenceWorker_p0-w0: resuming experience collection (1200 times)
[2025-11-03 15:21:22,777][200377] Fps is (10 sec: 4918.1, 60 sec: 4916.3, 300 sec: 4832.0). Total num frames: 6586368. Throughput: 0: 4877.8. Samples: 6584832. Policy #0 lag: (min: 3.0, avg: 6.0, max: 67.0)
[2025-11-03 15:21:22,777][200377] Avg episode reward: [(0, '1368.269')]
[2025-11-03 15:21:27,813][200377] Fps is (10 sec: 4177.7, 60 sec: 4639.7, 300 sec: 4831.4). Total num frames: 6602752. Throughput: 0: 4866.4. Samples: 6612992. Policy #0 lag: (min: 3.0, avg: 6.0, max: 67.0)
[2025-11-03 15:21:27,813][200377] Avg episode reward: [(0, '1375.228')]
[2025-11-03 15:21:32,803][200377] Fps is (10 sec: 4902.5, 60 sec: 4914.9, 300 sec: 4832.3). Total num frames: 6635520. Throughput: 0: 5187.7. Samples: 6641664. Policy #0 lag: (min: 20.0, avg: 23.0, max: 84.0)
[2025-11-03 15:21:32,803][200377] Avg episode reward: [(0, '1343.964')]
[2025-11-03 15:21:37,779][200377] Fps is (10 sec: 4931.7, 60 sec: 4647.8, 300 sec: 4832.8). Total num frames: 6651904. Throughput: 0: 4802.2. Samples: 6656000. Policy #0 lag: (min: 20.0, avg: 23.0, max: 84.0)
[2025-11-03 15:21:37,779][200377] Avg episode reward: [(0, '1420.172')]
[2025-11-03 15:21:42,758][200377] Fps is (10 sec: 4937.6, 60 sec: 4917.2, 300 sec: 4833.0). Total num frames: 6684672. Throughput: 0: 4838.6. Samples: 6685696. Policy #0 lag: (min: 20.0, avg: 23.0, max: 84.0)
[2025-11-03 15:21:42,758][200377] Avg episode reward: [(0, '1442.515')]
[2025-11-03 15:21:47,759][200377] Fps is (10 sec: 4925.1, 60 sec: 4652.8, 300 sec: 4831.8). Total num frames: 6701056. Throughput: 0: 4875.8. Samples: 6715904. Policy #0 lag: (min: 20.0, avg: 23.0, max: 84.0)
[2025-11-03 15:21:47,759][200377] Avg episode reward: [(0, '1383.765')]
[2025-11-03 15:21:52,769][200377] Fps is (10 sec: 4909.6, 60 sec: 4916.7, 300 sec: 4833.6). Total num frames: 6733824. Throughput: 0: 4895.8. Samples: 6730240. Policy #0 lag: (min: 6.0, avg: 9.0, max: 70.0)
[2025-11-03 15:21:52,769][200377] Avg episode reward: [(0, '1397.373')]
[2025-11-03 15:21:57,789][200377] Fps is (10 sec: 4900.3, 60 sec: 4778.4, 300 sec: 4831.4). Total num frames: 6750208. Throughput: 0: 4880.4. Samples: 6758912. Policy #0 lag: (min: 6.0, avg: 9.0, max: 70.0)
[2025-11-03 15:21:57,790][200377] Avg episode reward: [(0, '1363.876')]
[2025-11-03 15:22:02,790][200377] Fps is (10 sec: 4904.6, 60 sec: 4917.3, 300 sec: 4859.8). Total num frames: 6782976. Throughput: 0: 4859.1. Samples: 6788096. Policy #0 lag: (min: 6.0, avg: 9.0, max: 70.0)
[2025-11-03 15:22:02,791][200377] Avg episode reward: [(0, '1395.069')]
[2025-11-03 15:22:07,806][200377] Fps is (10 sec: 4907.1, 60 sec: 4786.5, 300 sec: 4832.0). Total num frames: 6799360. Throughput: 0: 4809.7. Samples: 6801408. Policy #0 lag: (min: 6.0, avg: 9.0, max: 70.0)
[2025-11-03 15:22:07,806][200377] Avg episode reward: [(0, '1414.325')]
[2025-11-03 15:22:07,901][200377] Saving /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_lidar_policy2/checkpoint_p0/checkpoint_000026560_6799360.pth...
[2025-11-03 15:22:07,905][200377] Removing /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_lidar_policy2/checkpoint_p0/checkpoint_000022016_5636096.pth
[2025-11-03 15:22:12,126][200377] Signal inference workers to stop experience collection... (1250 times)
[2025-11-03 15:22:12,436][200377] InferenceWorker_p0-w0: stopping experience collection (1250 times)
[2025-11-03 15:22:12,436][200377] Signal inference workers to resume experience collection... (1250 times)
[2025-11-03 15:22:12,436][200377] InferenceWorker_p0-w0: resuming experience collection (1250 times)
[2025-11-03 15:22:12,810][200377] Fps is (10 sec: 4905.7, 60 sec: 4913.0, 300 sec: 4861.8). Total num frames: 6832128. Throughput: 0: 4870.0. Samples: 6832128. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 15:22:12,810][200377] Avg episode reward: [(0, '1360.686')]
[2025-11-03 15:22:17,771][200377] Fps is (10 sec: 4932.4, 60 sec: 4797.6, 300 sec: 4832.0). Total num frames: 6848512. Throughput: 0: 4861.8. Samples: 6860288. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 15:22:17,771][200377] Avg episode reward: [(0, '1321.531')]
[2025-11-03 15:22:22,749][200377] Fps is (10 sec: 4945.2, 60 sec: 4917.5, 300 sec: 4863.5). Total num frames: 6881280. Throughput: 0: 4861.6. Samples: 6874624. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 15:22:22,749][200377] Avg episode reward: [(0, '1456.353')]
[2025-11-03 15:22:27,832][200377] Fps is (10 sec: 4885.4, 60 sec: 4913.6, 300 sec: 4831.7). Total num frames: 6897664. Throughput: 0: 4838.9. Samples: 6903808. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 15:22:27,832][200377] Avg episode reward: [(0, '1480.552')]
[2025-11-03 15:22:27,928][200377] Saving new best policy, reward=1480.552!
[2025-11-03 15:22:32,785][200377] Fps is (10 sec: 4897.4, 60 sec: 4916.6, 300 sec: 4888.0). Total num frames: 6930432. Throughput: 0: 4787.2. Samples: 6931456. Policy #0 lag: (min: 13.0, avg: 16.0, max: 77.0)
[2025-11-03 15:22:32,786][200377] Avg episode reward: [(0, '1443.965')]
[2025-11-03 15:22:37,748][200377] Fps is (10 sec: 4957.0, 60 sec: 4917.8, 300 sec: 4833.1). Total num frames: 6946816. Throughput: 0: 4837.8. Samples: 6947840. Policy #0 lag: (min: 13.0, avg: 16.0, max: 77.0)
[2025-11-03 15:22:37,748][200377] Avg episode reward: [(0, '1400.747')]
[2025-11-03 15:22:42,757][200377] Fps is (10 sec: 4929.2, 60 sec: 4915.3, 300 sec: 4888.6). Total num frames: 6979584. Throughput: 0: 4861.8. Samples: 6977536. Policy #0 lag: (min: 13.0, avg: 16.0, max: 77.0)
[2025-11-03 15:22:42,757][200377] Avg episode reward: [(0, '1374.664')]
[2025-11-03 15:22:47,757][200377] Fps is (10 sec: 4910.5, 60 sec: 4915.3, 300 sec: 4832.1). Total num frames: 6995968. Throughput: 0: 4839.1. Samples: 7005696. Policy #0 lag: (min: 13.0, avg: 16.0, max: 77.0)
[2025-11-03 15:22:47,758][200377] Avg episode reward: [(0, '1325.323')]
[2025-11-03 15:22:52,913][200377] Fps is (10 sec: 4839.7, 60 sec: 4903.4, 300 sec: 4885.4). Total num frames: 7028736. Throughput: 0: 4846.8. Samples: 7020032. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 15:22:52,913][200377] Avg episode reward: [(0, '1334.340')]
[2025-11-03 15:22:57,757][200377] Fps is (10 sec: 4915.6, 60 sec: 4917.9, 300 sec: 4832.7). Total num frames: 7045120. Throughput: 0: 4829.9. Samples: 7049216. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 15:22:57,757][200377] Avg episode reward: [(0, '1400.954')]
[2025-11-03 15:23:03,011][200377] Fps is (10 sec: 4867.4, 60 sec: 4897.2, 300 sec: 4884.2). Total num frames: 7077888. Throughput: 0: 4832.5. Samples: 7078912. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 15:23:03,011][200377] Avg episode reward: [(0, '1396.254')]
[2025-11-03 15:23:07,814][200377] Fps is (10 sec: 4887.2, 60 sec: 4914.6, 300 sec: 4831.8). Total num frames: 7094272. Throughput: 0: 4874.1. Samples: 7094272. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 15:23:07,814][200377] Avg episode reward: [(0, '1409.563')]
[2025-11-03 15:23:09,448][200377] Signal inference workers to stop experience collection... (1300 times)
[2025-11-03 15:23:09,450][200377] Signal inference workers to resume experience collection... (1300 times)
[2025-11-03 15:23:09,661][200377] InferenceWorker_p0-w0: stopping experience collection (1300 times)
[2025-11-03 15:23:09,661][200377] InferenceWorker_p0-w0: resuming experience collection (1300 times)
[2025-11-03 15:23:12,848][200377] Fps is (10 sec: 4163.8, 60 sec: 4775.6, 300 sec: 4858.3). Total num frames: 7118848. Throughput: 0: 4867.9. Samples: 7122944. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 15:23:12,849][200377] Avg episode reward: [(0, '1346.468')]
[2025-11-03 15:23:17,840][200377] Fps is (10 sec: 4902.5, 60 sec: 4909.6, 300 sec: 4831.3). Total num frames: 7143424. Throughput: 0: 4875.2. Samples: 7151104. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 15:23:17,840][200377] Avg episode reward: [(0, '1296.920')]
[2025-11-03 15:23:23,041][200377] Fps is (10 sec: 4822.4, 60 sec: 4755.5, 300 sec: 4855.7). Total num frames: 7168000. Throughput: 0: 4804.3. Samples: 7165440. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 15:23:23,041][200377] Avg episode reward: [(0, '1383.316')]
[2025-11-03 15:23:27,821][200377] Fps is (10 sec: 4924.4, 60 sec: 4916.1, 300 sec: 4832.1). Total num frames: 7192576. Throughput: 0: 4794.6. Samples: 7193600. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 15:23:27,821][200377] Avg episode reward: [(0, '1437.281')]
[2025-11-03 15:23:32,775][200377] Fps is (10 sec: 4207.7, 60 sec: 4642.9, 300 sec: 4831.9). Total num frames: 7208960. Throughput: 0: 4867.8. Samples: 7224832. Policy #0 lag: (min: 14.0, avg: 17.0, max: 78.0)
[2025-11-03 15:23:32,776][200377] Avg episode reward: [(0, '1432.395')]
[2025-11-03 15:23:37,802][200377] Fps is (10 sec: 4924.4, 60 sec: 4910.8, 300 sec: 4831.6). Total num frames: 7241728. Throughput: 0: 4870.3. Samples: 7238656. Policy #0 lag: (min: 14.0, avg: 17.0, max: 78.0)
[2025-11-03 15:23:37,802][200377] Avg episode reward: [(0, '1401.980')]
[2025-11-03 15:23:42,801][200377] Fps is (10 sec: 4902.9, 60 sec: 4638.8, 300 sec: 4831.2). Total num frames: 7258112. Throughput: 0: 4842.2. Samples: 7267328. Policy #0 lag: (min: 14.0, avg: 17.0, max: 78.0)
[2025-11-03 15:23:42,801][200377] Avg episode reward: [(0, '1341.480')]
[2025-11-03 15:23:47,754][200377] Fps is (10 sec: 4939.1, 60 sec: 4915.5, 300 sec: 4835.2). Total num frames: 7290880. Throughput: 0: 4840.5. Samples: 7295488. Policy #0 lag: (min: 14.0, avg: 17.0, max: 78.0)
[2025-11-03 15:23:47,754][200377] Avg episode reward: [(0, '1375.566')]
[2025-11-03 15:23:52,751][200377] Fps is (10 sec: 4939.5, 60 sec: 4654.7, 300 sec: 4832.8). Total num frames: 7307264. Throughput: 0: 4796.7. Samples: 7309824. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 15:23:52,752][200377] Avg episode reward: [(0, '1379.691')]
[2025-11-03 15:23:57,777][200377] Fps is (10 sec: 4903.9, 60 sec: 4913.5, 300 sec: 4835.1). Total num frames: 7340032. Throughput: 0: 4854.6. Samples: 7341056. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 15:23:57,777][200377] Avg episode reward: [(0, '1391.742')]
[2025-11-03 15:24:02,751][200377] Fps is (10 sec: 4915.2, 60 sec: 4662.3, 300 sec: 4832.4). Total num frames: 7356416. Throughput: 0: 4845.1. Samples: 7368704. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 15:24:02,751][200377] Avg episode reward: [(0, '1323.058')]
[2025-11-03 15:24:06,949][200377] Signal inference workers to stop experience collection... (1350 times)
[2025-11-03 15:24:07,276][200377] InferenceWorker_p0-w0: stopping experience collection (1350 times)
[2025-11-03 15:24:07,278][200377] Signal inference workers to resume experience collection... (1350 times)
[2025-11-03 15:24:07,367][200377] InferenceWorker_p0-w0: resuming experience collection (1350 times)
[2025-11-03 15:24:07,783][200377] Fps is (10 sec: 4912.4, 60 sec: 4917.8, 300 sec: 4836.1). Total num frames: 7389184. Throughput: 0: 4863.5. Samples: 7383040. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 15:24:07,783][200377] Avg episode reward: [(0, '1311.172')]
[2025-11-03 15:24:07,886][200377] Saving /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_lidar_policy2/checkpoint_p0/checkpoint_000028864_7389184.pth...
[2025-11-03 15:24:07,890][200377] Removing /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_lidar_policy2/checkpoint_p0/checkpoint_000024320_6225920.pth
[2025-11-03 15:24:12,807][200377] Fps is (10 sec: 4888.0, 60 sec: 4782.0, 300 sec: 4831.6). Total num frames: 7405568. Throughput: 0: 4837.1. Samples: 7411200. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 15:24:12,807][200377] Avg episode reward: [(0, '1396.101')]
[2025-11-03 15:24:17,771][200377] Fps is (10 sec: 4921.0, 60 sec: 4920.8, 300 sec: 4862.6). Total num frames: 7438336. Throughput: 0: 4460.5. Samples: 7425536. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 15:24:17,771][200377] Avg episode reward: [(0, '1451.342')]
[2025-11-03 15:24:22,764][200377] Fps is (10 sec: 4936.5, 60 sec: 4800.8, 300 sec: 4831.9). Total num frames: 7454720. Throughput: 0: 4828.3. Samples: 7455744. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 15:24:22,764][200377] Avg episode reward: [(0, '1368.735')]
[2025-11-03 15:24:28,027][200377] Fps is (10 sec: 4792.4, 60 sec: 4898.4, 300 sec: 4859.8). Total num frames: 7487488. Throughput: 0: 4800.0. Samples: 7484416. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 15:24:28,027][200377] Avg episode reward: [(0, '1388.582')]
[2025-11-03 15:24:32,760][200377] Fps is (10 sec: 4917.2, 60 sec: 4916.5, 300 sec: 4833.1). Total num frames: 7503872. Throughput: 0: 4823.6. Samples: 7512576. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 15:24:32,760][200377] Avg episode reward: [(0, '1402.541')]
[2025-11-03 15:24:37,896][200377] Fps is (10 sec: 4150.3, 60 sec: 4771.2, 300 sec: 4858.4). Total num frames: 7528448. Throughput: 0: 4808.7. Samples: 7526912. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 15:24:37,897][200377] Avg episode reward: [(0, '1345.206')]
[2025-11-03 15:24:42,793][200377] Fps is (10 sec: 4898.8, 60 sec: 4915.8, 300 sec: 4831.7). Total num frames: 7553024. Throughput: 0: 4754.2. Samples: 7555072. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 15:24:42,793][200377] Avg episode reward: [(0, '1405.227')]
[2025-11-03 15:24:48,001][200377] Fps is (10 sec: 4864.1, 60 sec: 4759.0, 300 sec: 4856.6). Total num frames: 7577600. Throughput: 0: 4808.8. Samples: 7586304. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 15:24:48,002][200377] Avg episode reward: [(0, '1393.570')]
[2025-11-03 15:24:52,782][200377] Fps is (10 sec: 4920.4, 60 sec: 4912.7, 300 sec: 4831.8). Total num frames: 7602176. Throughput: 0: 4835.6. Samples: 7600640. Policy #0 lag: (min: 11.0, avg: 14.0, max: 75.0)
[2025-11-03 15:24:52,783][200377] Avg episode reward: [(0, '1368.776')]
[2025-11-03 15:24:57,786][200377] Fps is (10 sec: 4186.3, 60 sec: 4641.5, 300 sec: 4832.7). Total num frames: 7618560. Throughput: 0: 4849.2. Samples: 7629312. Policy #0 lag: (min: 11.0, avg: 14.0, max: 75.0)
[2025-11-03 15:24:57,786][200377] Avg episode reward: [(0, '1373.199')]
[2025-11-03 15:25:01,480][200377] Signal inference workers to stop experience collection... (1400 times)
[2025-11-03 15:25:01,786][200377] InferenceWorker_p0-w0: stopping experience collection (1400 times)
[2025-11-03 15:25:01,786][200377] Signal inference workers to resume experience collection... (1400 times)
[2025-11-03 15:25:01,786][200377] InferenceWorker_p0-w0: resuming experience collection (1400 times)
[2025-11-03 15:25:02,773][200377] Fps is (10 sec: 4920.0, 60 sec: 4913.5, 300 sec: 4832.8). Total num frames: 7651328. Throughput: 0: 5165.3. Samples: 7657984. Policy #0 lag: (min: 11.0, avg: 14.0, max: 75.0)
[2025-11-03 15:25:02,773][200377] Avg episode reward: [(0, '1380.268')]
[2025-11-03 15:25:07,770][200377] Fps is (10 sec: 4922.9, 60 sec: 4643.1, 300 sec: 4831.7). Total num frames: 7667712. Throughput: 0: 4812.1. Samples: 7672320. Policy #0 lag: (min: 11.0, avg: 14.0, max: 75.0)
[2025-11-03 15:25:07,770][200377] Avg episode reward: [(0, '1353.399')]
[2025-11-03 15:25:12,789][200377] Fps is (10 sec: 4907.2, 60 sec: 4916.7, 300 sec: 4832.0). Total num frames: 7700480. Throughput: 0: 4849.8. Samples: 7701504. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 15:25:12,789][200377] Avg episode reward: [(0, '1389.633')]
[2025-11-03 15:25:17,760][200377] Fps is (10 sec: 4919.9, 60 sec: 4642.9, 300 sec: 4832.4). Total num frames: 7716864. Throughput: 0: 4869.6. Samples: 7731712. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 15:25:17,761][200377] Avg episode reward: [(0, '1385.506')]
[2025-11-03 15:25:22,823][200377] Fps is (10 sec: 4898.4, 60 sec: 4910.3, 300 sec: 4831.2). Total num frames: 7749632. Throughput: 0: 4877.6. Samples: 7746048. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 15:25:22,823][200377] Avg episode reward: [(0, '1399.706')]
[2025-11-03 15:25:27,776][200377] Fps is (10 sec: 4907.4, 60 sec: 4661.6, 300 sec: 4832.3). Total num frames: 7766016. Throughput: 0: 4871.5. Samples: 7774208. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 15:25:27,776][200377] Avg episode reward: [(0, '1386.754')]
[2025-11-03 15:25:32,783][200377] Fps is (10 sec: 4934.9, 60 sec: 4913.3, 300 sec: 4833.0). Total num frames: 7798784. Throughput: 0: 4836.2. Samples: 7802880. Policy #0 lag: (min: 13.0, avg: 16.0, max: 77.0)
[2025-11-03 15:25:32,784][200377] Avg episode reward: [(0, '1445.389')]
[2025-11-03 15:25:37,827][200377] Fps is (10 sec: 4890.4, 60 sec: 4784.2, 300 sec: 4831.2). Total num frames: 7815168. Throughput: 0: 4808.0. Samples: 7817216. Policy #0 lag: (min: 13.0, avg: 16.0, max: 77.0)
[2025-11-03 15:25:37,827][200377] Avg episode reward: [(0, '1437.883')]
[2025-11-03 15:25:42,813][200377] Fps is (10 sec: 4900.7, 60 sec: 4913.6, 300 sec: 4833.3). Total num frames: 7847936. Throughput: 0: 4855.4. Samples: 7847936. Policy #0 lag: (min: 13.0, avg: 16.0, max: 77.0)
[2025-11-03 15:25:42,813][200377] Avg episode reward: [(0, '1401.401')]
[2025-11-03 15:25:47,768][200377] Fps is (10 sec: 4944.4, 60 sec: 4797.3, 300 sec: 4832.2). Total num frames: 7864320. Throughput: 0: 4847.4. Samples: 7876096. Policy #0 lag: (min: 13.0, avg: 16.0, max: 77.0)
[2025-11-03 15:25:47,768][200377] Avg episode reward: [(0, '1365.788')]
[2025-11-03 15:25:52,770][200377] Fps is (10 sec: 4936.3, 60 sec: 4916.2, 300 sec: 4859.9). Total num frames: 7897088. Throughput: 0: 4846.9. Samples: 7890432. Policy #0 lag: (min: 4.0, avg: 7.0, max: 68.0)
[2025-11-03 15:25:52,770][200377] Avg episode reward: [(0, '1355.486')]
[2025-11-03 15:25:57,757][200377] Fps is (10 sec: 4920.7, 60 sec: 4917.6, 300 sec: 4832.9). Total num frames: 7913472. Throughput: 0: 4850.4. Samples: 7919616. Policy #0 lag: (min: 4.0, avg: 7.0, max: 68.0)
[2025-11-03 15:25:57,757][200377] Avg episode reward: [(0, '1398.009')]
[2025-11-03 15:25:58,979][200377] Signal inference workers to stop experience collection... (1450 times)
[2025-11-03 15:25:58,979][200377] Signal inference workers to resume experience collection... (1450 times)
[2025-11-03 15:25:59,180][200377] InferenceWorker_p0-w0: stopping experience collection (1450 times)
[2025-11-03 15:25:59,180][200377] InferenceWorker_p0-w0: resuming experience collection (1450 times)
[2025-11-03 15:26:02,771][200377] Fps is (10 sec: 4914.7, 60 sec: 4915.3, 300 sec: 4861.9). Total num frames: 7946240. Throughput: 0: 4788.9. Samples: 7947264. Policy #0 lag: (min: 4.0, avg: 7.0, max: 68.0)
[2025-11-03 15:26:02,771][200377] Avg episode reward: [(0, '1389.777')]
[2025-11-03 15:26:07,836][200377] Fps is (10 sec: 4876.5, 60 sec: 4909.8, 300 sec: 4831.0). Total num frames: 7962624. Throughput: 0: 4834.2. Samples: 7963648. Policy #0 lag: (min: 4.0, avg: 7.0, max: 68.0)
[2025-11-03 15:26:07,836][200377] Avg episode reward: [(0, '1353.583')]
[2025-11-03 15:26:07,840][200377] Saving /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_lidar_policy2/checkpoint_p0/checkpoint_000031104_7962624.pth...
[2025-11-03 15:26:07,844][200377] Removing /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_lidar_policy2/checkpoint_p0/checkpoint_000026560_6799360.pth
[2025-11-03 15:26:12,917][200377] Fps is (10 sec: 4844.5, 60 sec: 4904.7, 300 sec: 4861.2). Total num frames: 7995392. Throughput: 0: 4831.8. Samples: 7992320. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 15:26:12,917][200377] Avg episode reward: [(0, '1366.356')]
[2025-11-03 15:26:17,749][200377] Fps is (10 sec: 4958.2, 60 sec: 4916.1, 300 sec: 4832.3). Total num frames: 8011776. Throughput: 0: 4839.2. Samples: 8020480. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 15:26:17,750][200377] Avg episode reward: [(0, '1420.368')]
[2025-11-03 15:26:23,061][200377] Fps is (10 sec: 4037.7, 60 sec: 4759.8, 300 sec: 4855.6). Total num frames: 8036352. Throughput: 0: 4821.8. Samples: 8035328. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 15:26:23,062][200377] Avg episode reward: [(0, '1470.533')]
[2025-11-03 15:26:27,748][200377] Fps is (10 sec: 4916.0, 60 sec: 4917.5, 300 sec: 4832.8). Total num frames: 8060928. Throughput: 0: 4808.4. Samples: 8064000. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 15:26:27,748][200377] Avg episode reward: [(0, '1437.035')]
[2025-11-03 15:26:32,782][200377] Fps is (10 sec: 5056.5, 60 sec: 4778.8, 300 sec: 4859.6). Total num frames: 8085504. Throughput: 0: 4492.8. Samples: 8078336. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 15:26:32,782][200377] Avg episode reward: [(0, '1421.315')]
[2025-11-03 15:26:37,829][200377] Fps is (10 sec: 4875.7, 60 sec: 4915.1, 300 sec: 4830.7). Total num frames: 8110080. Throughput: 0: 4874.7. Samples: 8110080. Policy #0 lag: (min: 47.0, avg: 50.0, max: 111.0)
[2025-11-03 15:26:37,829][200377] Avg episode reward: [(0, '1440.353')]
[2025-11-03 15:26:42,947][200377] Fps is (10 sec: 4835.4, 60 sec: 4768.0, 300 sec: 4856.6). Total num frames: 8134656. Throughput: 0: 4837.8. Samples: 8138240. Policy #0 lag: (min: 47.0, avg: 50.0, max: 111.0)
[2025-11-03 15:26:42,947][200377] Avg episode reward: [(0, '1429.540')]
[2025-11-03 15:26:47,755][200377] Fps is (10 sec: 4951.7, 60 sec: 4916.3, 300 sec: 4832.1). Total num frames: 8159232. Throughput: 0: 4871.4. Samples: 8166400. Policy #0 lag: (min: 47.0, avg: 50.0, max: 111.0)
[2025-11-03 15:26:47,755][200377] Avg episode reward: [(0, '1413.996')]
[2025-11-03 15:26:52,810][200377] Fps is (10 sec: 4153.1, 60 sec: 4639.1, 300 sec: 4831.6). Total num frames: 8175616. Throughput: 0: 4827.0. Samples: 8180736. Policy #0 lag: (min: 47.0, avg: 50.0, max: 111.0)
[2025-11-03 15:26:52,810][200377] Avg episode reward: [(0, '1420.506')]
[2025-11-03 15:26:56,316][200377] Signal inference workers to stop experience collection... (1500 times)
[2025-11-03 15:26:56,634][200377] InferenceWorker_p0-w0: stopping experience collection (1500 times)
[2025-11-03 15:26:56,635][200377] Signal inference workers to resume experience collection... (1500 times)
[2025-11-03 15:26:56,725][200377] InferenceWorker_p0-w0: resuming experience collection (1500 times)
[2025-11-03 15:26:57,754][200377] Fps is (10 sec: 4915.6, 60 sec: 4915.4, 300 sec: 4832.5). Total num frames: 8208384. Throughput: 0: 4841.7. Samples: 8209408. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 15:26:57,754][200377] Avg episode reward: [(0, '1396.230')]
[2025-11-03 15:27:02,751][200377] Fps is (10 sec: 4944.4, 60 sec: 4643.7, 300 sec: 4832.8). Total num frames: 8224768. Throughput: 0: 4858.2. Samples: 8239104. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 15:27:02,751][200377] Avg episode reward: [(0, '1429.718')]
[2025-11-03 15:27:07,810][200377] Fps is (10 sec: 4888.0, 60 sec: 4917.3, 300 sec: 4831.9). Total num frames: 8257536. Throughput: 0: 4874.2. Samples: 8253440. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 15:27:07,810][200377] Avg episode reward: [(0, '1374.027')]
[2025-11-03 15:27:12,772][200377] Fps is (10 sec: 4904.8, 60 sec: 4653.4, 300 sec: 4831.9). Total num frames: 8273920. Throughput: 0: 4844.3. Samples: 8282112. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 15:27:12,772][200377] Avg episode reward: [(0, '1387.669')]
[2025-11-03 15:27:17,829][200377] Fps is (10 sec: 4906.1, 60 sec: 4908.7, 300 sec: 4830.6). Total num frames: 8306688. Throughput: 0: 5171.5. Samples: 8311296. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 15:27:17,829][200377] Avg episode reward: [(0, '1478.523')]
[2025-11-03 15:27:22,766][200377] Fps is (10 sec: 4917.9, 60 sec: 4802.3, 300 sec: 4833.0). Total num frames: 8323072. Throughput: 0: 4785.3. Samples: 8325120. Policy #0 lag: (min: 12.0, avg: 15.0, max: 76.0)
[2025-11-03 15:27:22,767][200377] Avg episode reward: [(0, '1404.292')]
[2025-11-03 15:27:27,778][200377] Fps is (10 sec: 4940.3, 60 sec: 4912.7, 300 sec: 4832.0). Total num frames: 8355840. Throughput: 0: 4865.3. Samples: 8356352. Policy #0 lag: (min: 12.0, avg: 15.0, max: 76.0)
[2025-11-03 15:27:27,778][200377] Avg episode reward: [(0, '1372.308')]
[2025-11-03 15:27:32,793][200377] Fps is (10 sec: 4901.9, 60 sec: 4777.8, 300 sec: 4831.1). Total num frames: 8372224. Throughput: 0: 4854.2. Samples: 8385024. Policy #0 lag: (min: 12.0, avg: 15.0, max: 76.0)
[2025-11-03 15:27:32,794][200377] Avg episode reward: [(0, '1356.461')]
[2025-11-03 15:27:37,792][200377] Fps is (10 sec: 4908.3, 60 sec: 4918.2, 300 sec: 4831.3). Total num frames: 8404992. Throughput: 0: 4860.3. Samples: 8399360. Policy #0 lag: (min: 12.0, avg: 15.0, max: 76.0)
[2025-11-03 15:27:37,792][200377] Avg episode reward: [(0, '1391.029')]
[2025-11-03 15:27:42,778][200377] Fps is (10 sec: 4922.6, 60 sec: 4792.1, 300 sec: 4831.5). Total num frames: 8421376. Throughput: 0: 4855.7. Samples: 8428032. Policy #0 lag: (min: 12.0, avg: 15.0, max: 76.0)
[2025-11-03 15:27:42,779][200377] Avg episode reward: [(0, '1383.910')]
[2025-11-03 15:27:47,806][200377] Fps is (10 sec: 4907.9, 60 sec: 4911.0, 300 sec: 4833.6). Total num frames: 8454144. Throughput: 0: 4829.6. Samples: 8456704. Policy #0 lag: (min: 2.0, avg: 5.0, max: 66.0)
[2025-11-03 15:27:47,807][200377] Avg episode reward: [(0, '1398.583')]
[2025-11-03 15:27:50,538][200377] Signal inference workers to stop experience collection... (1550 times)
[2025-11-03 15:27:50,856][200377] InferenceWorker_p0-w0: stopping experience collection (1550 times)
[2025-11-03 15:27:50,856][200377] Signal inference workers to resume experience collection... (1550 times)
[2025-11-03 15:27:50,857][200377] InferenceWorker_p0-w0: resuming experience collection (1550 times)
[2025-11-03 15:27:52,824][200377] Fps is (10 sec: 4892.9, 60 sec: 4914.0, 300 sec: 4830.8). Total num frames: 8470528. Throughput: 0: 4845.4. Samples: 8471552. Policy #0 lag: (min: 2.0, avg: 5.0, max: 66.0)
[2025-11-03 15:27:52,824][200377] Avg episode reward: [(0, '1434.403')]
[2025-11-03 15:27:57,831][200377] Fps is (10 sec: 4903.3, 60 sec: 4908.9, 300 sec: 4834.9). Total num frames: 8503296. Throughput: 0: 4886.1. Samples: 8502272. Policy #0 lag: (min: 2.0, avg: 5.0, max: 66.0)
[2025-11-03 15:27:57,831][200377] Avg episode reward: [(0, '1427.723')]
[2025-11-03 15:28:02,760][200377] Fps is (10 sec: 4946.6, 60 sec: 4914.4, 300 sec: 4832.8). Total num frames: 8519680. Throughput: 0: 4888.5. Samples: 8530944. Policy #0 lag: (min: 2.0, avg: 5.0, max: 66.0)
[2025-11-03 15:28:02,761][200377] Avg episode reward: [(0, '1394.732')]
[2025-11-03 15:28:07,776][200377] Fps is (10 sec: 4942.0, 60 sec: 4918.0, 300 sec: 4860.8). Total num frames: 8552448. Throughput: 0: 4891.4. Samples: 8545280. Policy #0 lag: (min: 0.0, avg: 3.0, max: 64.0)
[2025-11-03 15:28:07,777][200377] Avg episode reward: [(0, '1412.987')]
[2025-11-03 15:28:07,873][200377] Saving /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_lidar_policy2/checkpoint_p0/checkpoint_000033408_8552448.pth...
[2025-11-03 15:28:07,877][200377] Removing /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_lidar_policy2/checkpoint_p0/checkpoint_000028864_7389184.pth
[2025-11-03 15:28:12,810][200377] Fps is (10 sec: 4891.1, 60 sec: 4912.1, 300 sec: 4832.4). Total num frames: 8568832. Throughput: 0: 4820.7. Samples: 8573440. Policy #0 lag: (min: 0.0, avg: 3.0, max: 64.0)
[2025-11-03 15:28:12,810][200377] Avg episode reward: [(0, '1461.992')]
[2025-11-03 15:28:17,842][200377] Fps is (10 sec: 4883.4, 60 sec: 4914.1, 300 sec: 4862.9). Total num frames: 8601600. Throughput: 0: 4512.2. Samples: 8588288. Policy #0 lag: (min: 0.0, avg: 3.0, max: 64.0)
[2025-11-03 15:28:17,842][200377] Avg episode reward: [(0, '1482.155')]
[2025-11-03 15:28:17,844][200377] Saving new best policy, reward=1482.155!
[2025-11-03 15:28:22,752][200377] Fps is (10 sec: 4944.0, 60 sec: 4916.4, 300 sec: 4833.0). Total num frames: 8617984. Throughput: 0: 4874.0. Samples: 8618496. Policy #0 lag: (min: 0.0, avg: 3.0, max: 64.0)
[2025-11-03 15:28:22,752][200377] Avg episode reward: [(0, '1524.000')]
[2025-11-03 15:28:22,851][200377] Saving new best policy, reward=1524.000!
[2025-11-03 15:28:28,044][200377] Fps is (10 sec: 4817.8, 60 sec: 4893.5, 300 sec: 4883.0). Total num frames: 8650752. Throughput: 0: 4841.2. Samples: 8647168. Policy #0 lag: (min: 0.0, avg: 3.0, max: 64.0)
[2025-11-03 15:28:28,044][200377] Avg episode reward: [(0, '1396.797')]
[2025-11-03 15:28:32,795][200377] Fps is (10 sec: 4894.1, 60 sec: 4915.1, 300 sec: 4832.0). Total num frames: 8667136. Throughput: 0: 4871.0. Samples: 8675840. Policy #0 lag: (min: 4.0, avg: 7.0, max: 68.0)
[2025-11-03 15:28:32,795][200377] Avg episode reward: [(0, '1457.295')]
[2025-11-03 15:28:37,824][200377] Fps is (10 sec: 4187.9, 60 sec: 4776.1, 300 sec: 4859.3). Total num frames: 8691712. Throughput: 0: 4858.3. Samples: 8690176. Policy #0 lag: (min: 4.0, avg: 7.0, max: 68.0)
[2025-11-03 15:28:37,824][200377] Avg episode reward: [(0, '1442.849')]
[2025-11-03 15:28:42,828][200377] Fps is (10 sec: 4898.9, 60 sec: 4911.2, 300 sec: 4830.7). Total num frames: 8716288. Throughput: 0: 4801.7. Samples: 8718336. Policy #0 lag: (min: 4.0, avg: 7.0, max: 68.0)
[2025-11-03 15:28:42,828][200377] Avg episode reward: [(0, '1438.380')]
[2025-11-03 15:28:48,013][200377] Signal inference workers to stop experience collection... (1600 times)
[2025-11-03 15:28:48,013][200377] Signal inference workers to resume experience collection... (1600 times)
[2025-11-03 15:28:48,013][200377] Fps is (10 sec: 4824.1, 60 sec: 4762.3, 300 sec: 4855.4). Total num frames: 8740864. Throughput: 0: 4831.2. Samples: 8749568. Policy #0 lag: (min: 4.0, avg: 7.0, max: 68.0)
[2025-11-03 15:28:48,013][200377] Avg episode reward: [(0, '1485.238')]
[2025-11-03 15:28:48,219][200377] InferenceWorker_p0-w0: stopping experience collection (1600 times)
[2025-11-03 15:28:48,219][200377] InferenceWorker_p0-w0: resuming experience collection (1600 times)
[2025-11-03 15:28:52,792][200377] Fps is (10 sec: 4932.8, 60 sec: 4917.8, 300 sec: 4831.6). Total num frames: 8765440. Throughput: 0: 4845.2. Samples: 8763392. Policy #0 lag: (min: 4.0, avg: 7.0, max: 68.0)
[2025-11-03 15:28:52,792][200377] Avg episode reward: [(0, '1480.538')]
[2025-11-03 15:28:58,051][200377] Fps is (10 sec: 4896.9, 60 sec: 4761.2, 300 sec: 4854.7). Total num frames: 8790016. Throughput: 0: 4843.8. Samples: 8792576. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 15:28:58,051][200377] Avg episode reward: [(0, '1499.338')]
[2025-11-03 15:29:02,826][200377] Fps is (10 sec: 4898.9, 60 sec: 4909.9, 300 sec: 4831.2). Total num frames: 8814592. Throughput: 0: 5178.7. Samples: 8821248. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 15:29:02,826][200377] Avg episode reward: [(0, '1491.695')]
[2025-11-03 15:29:07,757][200377] Fps is (10 sec: 4219.8, 60 sec: 4643.6, 300 sec: 4832.7). Total num frames: 8830976. Throughput: 0: 4834.9. Samples: 8836096. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 15:29:07,757][200377] Avg episode reward: [(0, '1496.461')]
[2025-11-03 15:29:12,752][200377] Fps is (10 sec: 4951.5, 60 sec: 4919.9, 300 sec: 4832.2). Total num frames: 8863744. Throughput: 0: 4867.1. Samples: 8864768. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 15:29:12,753][200377] Avg episode reward: [(0, '1510.102')]
[2025-11-03 15:29:17,781][200377] Fps is (10 sec: 4903.6, 60 sec: 4646.8, 300 sec: 4831.6). Total num frames: 8880128. Throughput: 0: 4882.6. Samples: 8895488. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 15:29:17,781][200377] Avg episode reward: [(0, '1563.572')]
[2025-11-03 15:29:17,878][200377] Saving new best policy, reward=1563.572!
[2025-11-03 15:29:22,771][200377] Fps is (10 sec: 4905.9, 60 sec: 4913.6, 300 sec: 4836.1). Total num frames: 8912896. Throughput: 0: 4875.4. Samples: 8909312. Policy #0 lag: (min: 1.0, avg: 4.0, max: 65.0)
[2025-11-03 15:29:22,771][200377] Avg episode reward: [(0, '1577.432')]
[2025-11-03 15:29:22,873][200377] Saving new best policy, reward=1577.432!
[2025-11-03 15:29:27,827][200377] Fps is (10 sec: 4892.6, 60 sec: 4659.0, 300 sec: 4830.8). Total num frames: 8929280. Throughput: 0: 4869.8. Samples: 8937472. Policy #0 lag: (min: 1.0, avg: 4.0, max: 65.0)
[2025-11-03 15:29:27,827][200377] Avg episode reward: [(0, '1500.239')]
[2025-11-03 15:29:32,772][200377] Fps is (10 sec: 4914.9, 60 sec: 4917.1, 300 sec: 4861.7). Total num frames: 8962048. Throughput: 0: 4827.3. Samples: 8965632. Policy #0 lag: (min: 1.0, avg: 4.0, max: 65.0)
[2025-11-03 15:29:32,772][200377] Avg episode reward: [(0, '1454.035')]
[2025-11-03 15:29:37,825][200377] Fps is (10 sec: 4916.4, 60 sec: 4778.6, 300 sec: 4831.4). Total num frames: 8978432. Throughput: 0: 4820.7. Samples: 8980480. Policy #0 lag: (min: 1.0, avg: 4.0, max: 65.0)
[2025-11-03 15:29:37,825][200377] Avg episode reward: [(0, '1502.216')]
[2025-11-03 15:29:42,785][200377] Fps is (10 sec: 4908.8, 60 sec: 4918.7, 300 sec: 4863.2). Total num frames: 9011200. Throughput: 0: 4898.6. Samples: 9011712. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 15:29:42,785][200377] Avg episode reward: [(0, '1451.994')]
[2025-11-03 15:29:45,036][200377] Signal inference workers to stop experience collection... (1650 times)
[2025-11-03 15:29:45,345][200377] InferenceWorker_p0-w0: stopping experience collection (1650 times)
[2025-11-03 15:29:45,347][200377] Signal inference workers to resume experience collection... (1650 times)
[2025-11-03 15:29:45,436][200377] InferenceWorker_p0-w0: resuming experience collection (1650 times)
[2025-11-03 15:29:47,816][200377] Fps is (10 sec: 4919.3, 60 sec: 4794.4, 300 sec: 4831.3). Total num frames: 9027584. Throughput: 0: 4882.1. Samples: 9040896. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 15:29:47,817][200377] Avg episode reward: [(0, '1451.337')]
[2025-11-03 15:29:52,785][200377] Fps is (10 sec: 4915.4, 60 sec: 4915.8, 300 sec: 4887.4). Total num frames: 9060352. Throughput: 0: 4855.4. Samples: 9054720. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 15:29:52,785][200377] Avg episode reward: [(0, '1503.918')]
[2025-11-03 15:29:57,766][200377] Fps is (10 sec: 4940.2, 60 sec: 4801.5, 300 sec: 4832.0). Total num frames: 9076736. Throughput: 0: 4856.9. Samples: 9083392. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 15:29:57,766][200377] Avg episode reward: [(0, '1515.823')]
[2025-11-03 15:30:02,837][200377] Fps is (10 sec: 4889.7, 60 sec: 4914.3, 300 sec: 4886.3). Total num frames: 9109504. Throughput: 0: 4806.8. Samples: 9112064. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 15:30:02,837][200377] Avg episode reward: [(0, '1420.522')]
[2025-11-03 15:30:07,801][200377] Fps is (10 sec: 4897.7, 60 sec: 4911.6, 300 sec: 4831.7). Total num frames: 9125888. Throughput: 0: 4832.3. Samples: 9126912. Policy #0 lag: (min: 8.0, avg: 11.0, max: 72.0)
[2025-11-03 15:30:07,802][200377] Avg episode reward: [(0, '1483.916')]
[2025-11-03 15:30:07,898][200377] Saving /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_lidar_policy2/checkpoint_p0/checkpoint_000035648_9125888.pth...
[2025-11-03 15:30:07,902][200377] Removing /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_lidar_policy2/checkpoint_p0/checkpoint_000031104_7962624.pth
[2025-11-03 15:30:12,781][200377] Fps is (10 sec: 4942.7, 60 sec: 4912.8, 300 sec: 4887.1). Total num frames: 9158656. Throughput: 0: 4886.1. Samples: 9157120. Policy #0 lag: (min: 8.0, avg: 11.0, max: 72.0)
[2025-11-03 15:30:12,781][200377] Avg episode reward: [(0, '1545.190')]
[2025-11-03 15:30:17,802][200377] Fps is (10 sec: 4915.1, 60 sec: 4913.5, 300 sec: 4832.2). Total num frames: 9175040. Throughput: 0: 4889.2. Samples: 9185792. Policy #0 lag: (min: 8.0, avg: 11.0, max: 72.0)
[2025-11-03 15:30:17,802][200377] Avg episode reward: [(0, '1508.603')]
[2025-11-03 15:30:22,830][200377] Fps is (10 sec: 4891.2, 60 sec: 4910.4, 300 sec: 4886.5). Total num frames: 9207808. Throughput: 0: 4880.5. Samples: 9200128. Policy #0 lag: (min: 8.0, avg: 11.0, max: 72.0)
[2025-11-03 15:30:22,830][200377] Avg episode reward: [(0, '1451.678')]
[2025-11-03 15:30:27,802][200377] Fps is (10 sec: 4915.2, 60 sec: 4917.3, 300 sec: 4831.6). Total num frames: 9224192. Throughput: 0: 4822.4. Samples: 9228800. Policy #0 lag: (min: 8.0, avg: 11.0, max: 72.0)
[2025-11-03 15:30:27,802][200377] Avg episode reward: [(0, '1463.663')]
[2025-11-03 15:30:32,845][200377] Fps is (10 sec: 4907.7, 60 sec: 4909.2, 300 sec: 4887.1). Total num frames: 9256960. Throughput: 0: 4491.3. Samples: 9243136. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 15:30:32,846][200377] Avg episode reward: [(0, '1469.456')]
[2025-11-03 15:30:37,831][200377] Fps is (10 sec: 4900.9, 60 sec: 4914.7, 300 sec: 4831.6). Total num frames: 9273344. Throughput: 0: 4876.1. Samples: 9274368. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 15:30:37,831][200377] Avg episode reward: [(0, '1456.304')]
[2025-11-03 15:30:39,328][200377] Signal inference workers to stop experience collection... (1700 times)
[2025-11-03 15:30:39,651][200377] InferenceWorker_p0-w0: stopping experience collection (1700 times)
[2025-11-03 15:30:39,651][200377] Signal inference workers to resume experience collection... (1700 times)
[2025-11-03 15:30:39,651][200377] InferenceWorker_p0-w0: resuming experience collection (1700 times)
[2025-11-03 15:30:43,028][200377] Fps is (10 sec: 4827.3, 60 sec: 4895.4, 300 sec: 4883.1). Total num frames: 9306112. Throughput: 0: 4841.5. Samples: 9302528. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 15:30:43,028][200377] Avg episode reward: [(0, '1518.125')]
[2025-11-03 15:30:47,799][200377] Fps is (10 sec: 4931.0, 60 sec: 4916.6, 300 sec: 4831.4). Total num frames: 9322496. Throughput: 0: 4873.8. Samples: 9331200. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 15:30:47,799][200377] Avg episode reward: [(0, '1480.091')]
[2025-11-03 15:30:52,925][200377] Fps is (10 sec: 4138.6, 60 sec: 4767.5, 300 sec: 4856.9). Total num frames: 9347072. Throughput: 0: 4845.0. Samples: 9345536. Policy #0 lag: (min: 14.0, avg: 17.0, max: 78.0)
[2025-11-03 15:30:52,925][200377] Avg episode reward: [(0, '1522.602')]
[2025-11-03 15:30:57,764][200377] Fps is (10 sec: 4932.3, 60 sec: 4915.3, 300 sec: 4832.0). Total num frames: 9371648. Throughput: 0: 4814.6. Samples: 9373696. Policy #0 lag: (min: 14.0, avg: 17.0, max: 78.0)
[2025-11-03 15:30:57,764][200377] Avg episode reward: [(0, '1517.906')]
[2025-11-03 15:31:03,049][200377] Fps is (10 sec: 4854.8, 60 sec: 4761.8, 300 sec: 4856.2). Total num frames: 9396224. Throughput: 0: 4843.0. Samples: 9404928. Policy #0 lag: (min: 14.0, avg: 17.0, max: 78.0)
[2025-11-03 15:31:03,049][200377] Avg episode reward: [(0, '1476.713')]
[2025-11-03 15:31:07,757][200377] Fps is (10 sec: 4918.8, 60 sec: 4918.9, 300 sec: 4834.5). Total num frames: 9420800. Throughput: 0: 4866.3. Samples: 9418752. Policy #0 lag: (min: 14.0, avg: 17.0, max: 78.0)
[2025-11-03 15:31:07,757][200377] Avg episode reward: [(0, '1468.106')]
[2025-11-03 15:31:12,756][200377] Fps is (10 sec: 4219.5, 60 sec: 4644.1, 300 sec: 4831.8). Total num frames: 9437184. Throughput: 0: 4863.2. Samples: 9447424. Policy #0 lag: (min: 14.0, avg: 17.0, max: 78.0)
[2025-11-03 15:31:12,757][200377] Avg episode reward: [(0, '1420.451')]
[2025-11-03 15:31:17,794][200377] Fps is (10 sec: 4897.0, 60 sec: 4915.8, 300 sec: 4864.1). Total num frames: 9469952. Throughput: 0: 5171.4. Samples: 9475584. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 15:31:17,794][200377] Avg episode reward: [(0, '1426.208')]
[2025-11-03 15:31:22,799][200377] Fps is (10 sec: 4894.2, 60 sec: 4644.5, 300 sec: 4831.0). Total num frames: 9486336. Throughput: 0: 4793.4. Samples: 9489920. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 15:31:22,800][200377] Avg episode reward: [(0, '1481.219')]
[2025-11-03 15:31:27,754][200377] Fps is (10 sec: 4934.8, 60 sec: 4919.1, 300 sec: 4860.1). Total num frames: 9519104. Throughput: 0: 4865.1. Samples: 9520128. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 15:31:27,754][200377] Avg episode reward: [(0, '1479.421')]
[2025-11-03 15:31:32,785][200377] Fps is (10 sec: 4922.1, 60 sec: 4646.8, 300 sec: 4832.6). Total num frames: 9535488. Throughput: 0: 4848.4. Samples: 9549312. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 15:31:32,785][200377] Avg episode reward: [(0, '1429.276')]
[2025-11-03 15:31:36,995][200377] Signal inference workers to stop experience collection... (1750 times)
[2025-11-03 15:31:36,995][200377] Signal inference workers to resume experience collection... (1750 times)
[2025-11-03 15:31:37,199][200377] InferenceWorker_p0-w0: stopping experience collection (1750 times)
[2025-11-03 15:31:37,199][200377] InferenceWorker_p0-w0: resuming experience collection (1750 times)
[2025-11-03 15:31:37,771][200377] Fps is (10 sec: 4906.7, 60 sec: 4920.1, 300 sec: 4862.6). Total num frames: 9568256. Throughput: 0: 4852.1. Samples: 9563136. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 15:31:37,772][200377] Avg episode reward: [(0, '1451.276')]
[2025-11-03 15:31:42,831][200377] Fps is (10 sec: 4893.0, 60 sec: 4657.4, 300 sec: 4830.7). Total num frames: 9584640. Throughput: 0: 4839.8. Samples: 9591808. Policy #0 lag: (min: 31.0, avg: 34.0, max: 95.0)
[2025-11-03 15:31:42,831][200377] Avg episode reward: [(0, '1449.818')]
[2025-11-03 15:31:47,781][200377] Fps is (10 sec: 4910.5, 60 sec: 4916.7, 300 sec: 4887.9). Total num frames: 9617408. Throughput: 0: 4807.3. Samples: 9619968. Policy #0 lag: (min: 31.0, avg: 34.0, max: 95.0)
[2025-11-03 15:31:47,781][200377] Avg episode reward: [(0, '1475.392')]
[2025-11-03 15:31:52,781][200377] Fps is (10 sec: 4939.6, 60 sec: 4790.1, 300 sec: 4831.4). Total num frames: 9633792. Throughput: 0: 4798.8. Samples: 9634816. Policy #0 lag: (min: 31.0, avg: 34.0, max: 95.0)
[2025-11-03 15:31:52,781][200377] Avg episode reward: [(0, '1487.532')]
[2025-11-03 15:31:57,868][200377] Fps is (10 sec: 4872.9, 60 sec: 4906.7, 300 sec: 4885.5). Total num frames: 9666560. Throughput: 0: 4800.9. Samples: 9664000. Policy #0 lag: (min: 31.0, avg: 34.0, max: 95.0)
[2025-11-03 15:31:57,868][200377] Avg episode reward: [(0, '1508.884')]
[2025-11-03 15:32:02,811][200377] Fps is (10 sec: 4900.8, 60 sec: 4797.7, 300 sec: 4831.9). Total num frames: 9682944. Throughput: 0: 4811.0. Samples: 9692160. Policy #0 lag: (min: 31.0, avg: 34.0, max: 95.0)
[2025-11-03 15:32:02,811][200377] Avg episode reward: [(0, '1507.457')]
[2025-11-03 15:32:07,771][200377] Fps is (10 sec: 4136.2, 60 sec: 4777.5, 300 sec: 4859.7). Total num frames: 9707520. Throughput: 0: 4815.9. Samples: 9706496. Policy #0 lag: (min: 33.0, avg: 36.0, max: 97.0)
[2025-11-03 15:32:07,771][200377] Avg episode reward: [(0, '1424.423')]
[2025-11-03 15:32:08,082][200377] Saving /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_lidar_policy2/checkpoint_p0/checkpoint_000037952_9715712.pth...
[2025-11-03 15:32:08,086][200377] Removing /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_lidar_policy2/checkpoint_p0/checkpoint_000033408_8552448.pth
[2025-11-03 15:32:12,829][200377] Fps is (10 sec: 4906.3, 60 sec: 4909.3, 300 sec: 4831.9). Total num frames: 9732096. Throughput: 0: 4770.8. Samples: 9735168. Policy #0 lag: (min: 33.0, avg: 36.0, max: 97.0)
[2025-11-03 15:32:12,829][200377] Avg episode reward: [(0, '1476.913')]
[2025-11-03 15:32:17,916][200377] Fps is (10 sec: 4844.8, 60 sec: 4769.0, 300 sec: 4857.2). Total num frames: 9756672. Throughput: 0: 4435.8. Samples: 9749504. Policy #0 lag: (min: 33.0, avg: 36.0, max: 97.0)
[2025-11-03 15:32:17,916][200377] Avg episode reward: [(0, '1539.520')]
[2025-11-03 15:32:22,801][200377] Fps is (10 sec: 4928.8, 60 sec: 4915.0, 300 sec: 4831.5). Total num frames: 9781248. Throughput: 0: 4821.0. Samples: 9780224. Policy #0 lag: (min: 33.0, avg: 36.0, max: 97.0)
[2025-11-03 15:32:22,802][200377] Avg episode reward: [(0, '1527.800')]
[2025-11-03 15:32:27,751][200377] Fps is (10 sec: 4164.5, 60 sec: 4642.3, 300 sec: 4832.6). Total num frames: 9797632. Throughput: 0: 4821.3. Samples: 9808384. Policy #0 lag: (min: 33.0, avg: 36.0, max: 97.0)
[2025-11-03 15:32:27,752][200377] Avg episode reward: [(0, '1504.964')]
[2025-11-03 15:32:32,828][200377] Fps is (10 sec: 4902.0, 60 sec: 4911.7, 300 sec: 4831.3). Total num frames: 9830400. Throughput: 0: 4819.1. Samples: 9837056. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 15:32:32,829][200377] Avg episode reward: [(0, '1491.999')]
[2025-11-03 15:32:34,499][200377] Signal inference workers to stop experience collection... (1800 times)
[2025-11-03 15:32:34,810][200377] InferenceWorker_p0-w0: stopping experience collection (1800 times)
[2025-11-03 15:32:34,811][200377] Signal inference workers to resume experience collection... (1800 times)
[2025-11-03 15:32:34,901][200377] InferenceWorker_p0-w0: resuming experience collection (1800 times)
[2025-11-03 15:32:37,790][200377] Fps is (10 sec: 4896.1, 60 sec: 4640.7, 300 sec: 4831.7). Total num frames: 9846784. Throughput: 0: 4811.8. Samples: 9851392. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 15:32:37,791][200377] Avg episode reward: [(0, '1542.631')]
[2025-11-03 15:32:42,759][200377] Fps is (10 sec: 4949.3, 60 sec: 4921.0, 300 sec: 4832.7). Total num frames: 9879552. Throughput: 0: 4824.4. Samples: 9880576. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 15:32:42,760][200377] Avg episode reward: [(0, '1530.411')]
[2025-11-03 15:32:47,767][200377] Fps is (10 sec: 4926.7, 60 sec: 4643.2, 300 sec: 4832.8). Total num frames: 9895936. Throughput: 0: 4863.0. Samples: 9910784. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 15:32:47,767][200377] Avg episode reward: [(0, '1494.104')]
[2025-11-03 15:32:52,828][200377] Fps is (10 sec: 4881.8, 60 sec: 4911.4, 300 sec: 4831.9). Total num frames: 9928704. Throughput: 0: 4852.2. Samples: 9925120. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 15:32:52,828][200377] Avg episode reward: [(0, '1503.184')]
[2025-11-03 15:32:57,832][200377] Fps is (10 sec: 4883.4, 60 sec: 4644.9, 300 sec: 4830.7). Total num frames: 9945088. Throughput: 0: 4869.3. Samples: 9954304. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 15:32:57,832][200377] Avg episode reward: [(0, '1508.498')]
[2025-11-03 15:33:02,798][200377] Fps is (10 sec: 4929.8, 60 sec: 4916.2, 300 sec: 4831.5). Total num frames: 9977856. Throughput: 0: 5213.3. Samples: 9983488. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 15:33:02,798][200377] Avg episode reward: [(0, '1506.114')]
[2025-11-03 15:33:07,836][200377] Fps is (10 sec: 4913.4, 60 sec: 4773.5, 300 sec: 4831.5). Total num frames: 9994240. Throughput: 0: 4831.9. Samples: 9997824. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 15:33:07,836][200377] Avg episode reward: [(0, '1532.803')]
[2025-11-03 15:33:12,773][200377] Fps is (10 sec: 4927.8, 60 sec: 4919.8, 300 sec: 4833.0). Total num frames: 10027008. Throughput: 0: 4878.8. Samples: 10028032. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 15:33:12,773][200377] Avg episode reward: [(0, '1521.167')]
[2025-11-03 15:33:17,799][200377] Fps is (10 sec: 4933.4, 60 sec: 4788.0, 300 sec: 4831.1). Total num frames: 10043392. Throughput: 0: 4884.3. Samples: 10056704. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 15:33:17,799][200377] Avg episode reward: [(0, '1513.099')]
[2025-11-03 15:33:22,808][200377] Fps is (10 sec: 4898.1, 60 sec: 4914.7, 300 sec: 4835.8). Total num frames: 10076160. Throughput: 0: 4879.2. Samples: 10071040. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 15:33:22,808][200377] Avg episode reward: [(0, '1456.039')]
[2025-11-03 15:33:27,774][200377] Fps is (10 sec: 4927.7, 60 sec: 4913.4, 300 sec: 4832.2). Total num frames: 10092544. Throughput: 0: 4868.2. Samples: 10099712. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 15:33:27,774][200377] Avg episode reward: [(0, '1444.643')]
[2025-11-03 15:33:28,717][200377] Signal inference workers to stop experience collection... (1850 times)
[2025-11-03 15:33:29,032][200377] InferenceWorker_p0-w0: stopping experience collection (1850 times)
[2025-11-03 15:33:29,032][200377] Signal inference workers to resume experience collection... (1850 times)
[2025-11-03 15:33:29,032][200377] InferenceWorker_p0-w0: resuming experience collection (1850 times)
[2025-11-03 15:33:32,807][200377] Fps is (10 sec: 4915.6, 60 sec: 4917.0, 300 sec: 4860.0). Total num frames: 10125312. Throughput: 0: 4842.7. Samples: 10128896. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 15:33:32,807][200377] Avg episode reward: [(0, '1501.422')]
[2025-11-03 15:33:37,751][200377] Fps is (10 sec: 4926.5, 60 sec: 4918.5, 300 sec: 4833.2). Total num frames: 10141696. Throughput: 0: 4843.9. Samples: 10142720. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 15:33:37,751][200377] Avg episode reward: [(0, '1525.369')]
[2025-11-03 15:33:42,769][200377] Fps is (10 sec: 4933.9, 60 sec: 4914.4, 300 sec: 4863.7). Total num frames: 10174464. Throughput: 0: 4899.3. Samples: 10174464. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 15:33:42,769][200377] Avg episode reward: [(0, '1556.863')]
[2025-11-03 15:33:47,800][200377] Fps is (10 sec: 4891.1, 60 sec: 4912.5, 300 sec: 4831.8). Total num frames: 10190848. Throughput: 0: 4880.9. Samples: 10203136. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 15:33:47,800][200377] Avg episode reward: [(0, '1563.755')]
[2025-11-03 15:33:52,764][200377] Fps is (10 sec: 4917.6, 60 sec: 4920.4, 300 sec: 4864.4). Total num frames: 10223616. Throughput: 0: 4877.5. Samples: 10216960. Policy #0 lag: (min: 8.0, avg: 11.0, max: 72.0)
[2025-11-03 15:33:52,764][200377] Avg episode reward: [(0, '1593.355')]
[2025-11-03 15:33:52,864][200377] Saving new best policy, reward=1593.355!
[2025-11-03 15:33:57,765][200377] Fps is (10 sec: 4932.3, 60 sec: 4920.7, 300 sec: 4832.9). Total num frames: 10240000. Throughput: 0: 4836.3. Samples: 10245632. Policy #0 lag: (min: 8.0, avg: 11.0, max: 72.0)
[2025-11-03 15:33:57,766][200377] Avg episode reward: [(0, '1530.336')]
[2025-11-03 15:34:02,766][200377] Fps is (10 sec: 4914.1, 60 sec: 4917.8, 300 sec: 4887.3). Total num frames: 10272768. Throughput: 0: 4827.7. Samples: 10273792. Policy #0 lag: (min: 8.0, avg: 11.0, max: 72.0)
[2025-11-03 15:34:02,766][200377] Avg episode reward: [(0, '1504.314')]
[2025-11-03 15:34:07,756][200377] Fps is (10 sec: 4919.8, 60 sec: 4921.8, 300 sec: 4831.8). Total num frames: 10289152. Throughput: 0: 4875.3. Samples: 10290176. Policy #0 lag: (min: 8.0, avg: 11.0, max: 72.0)
[2025-11-03 15:34:07,756][200377] Avg episode reward: [(0, '1561.094')]
[2025-11-03 15:34:07,857][200377] Saving /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_lidar_policy2/checkpoint_p0/checkpoint_000040192_10289152.pth...
[2025-11-03 15:34:07,861][200377] Removing /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_lidar_policy2/checkpoint_p0/checkpoint_000035648_9125888.pth
[2025-11-03 15:34:12,773][200377] Fps is (10 sec: 4911.7, 60 sec: 4915.1, 300 sec: 4887.6). Total num frames: 10321920. Throughput: 0: 4892.5. Samples: 10319872. Policy #0 lag: (min: 8.0, avg: 11.0, max: 72.0)
[2025-11-03 15:34:12,773][200377] Avg episode reward: [(0, '1551.453')]
[2025-11-03 15:34:17,833][200377] Fps is (10 sec: 4877.6, 60 sec: 4912.4, 300 sec: 4830.9). Total num frames: 10338304. Throughput: 0: 4878.2. Samples: 10348544. Policy #0 lag: (min: 8.0, avg: 11.0, max: 72.0)
[2025-11-03 15:34:17,833][200377] Avg episode reward: [(0, '1538.385')]
[2025-11-03 15:34:22,988][200377] Fps is (10 sec: 4811.7, 60 sec: 4900.4, 300 sec: 4884.8). Total num frames: 10371072. Throughput: 0: 4844.1. Samples: 10361856. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 15:34:22,988][200377] Avg episode reward: [(0, '1590.207')]
[2025-11-03 15:34:25,990][200377] Signal inference workers to stop experience collection... (1900 times)
[2025-11-03 15:34:25,990][200377] Signal inference workers to resume experience collection... (1900 times)
[2025-11-03 15:34:26,231][200377] InferenceWorker_p0-w0: stopping experience collection (1900 times)
[2025-11-03 15:34:26,231][200377] InferenceWorker_p0-w0: resuming experience collection (1900 times)
[2025-11-03 15:34:27,768][200377] Fps is (10 sec: 4947.2, 60 sec: 4915.6, 300 sec: 4832.0). Total num frames: 10387456. Throughput: 0: 4812.9. Samples: 10391040. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 15:34:27,769][200377] Avg episode reward: [(0, '1606.141')]
[2025-11-03 15:34:27,861][200377] Saving new best policy, reward=1606.141!
[2025-11-03 15:34:33,045][200377] Fps is (10 sec: 4887.4, 60 sec: 4895.7, 300 sec: 4883.8). Total num frames: 10420224. Throughput: 0: 4820.7. Samples: 10421248. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 15:34:33,045][200377] Avg episode reward: [(0, '1632.140')]
[2025-11-03 15:34:33,046][200377] Saving new best policy, reward=1632.140!
[2025-11-03 15:34:37,759][200377] Fps is (10 sec: 4919.7, 60 sec: 4914.5, 300 sec: 4832.3). Total num frames: 10436608. Throughput: 0: 4881.6. Samples: 10436608. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 15:34:37,759][200377] Avg episode reward: [(0, '1625.365')]
[2025-11-03 15:34:42,817][200377] Fps is (10 sec: 4191.6, 60 sec: 4774.8, 300 sec: 4859.6). Total num frames: 10461184. Throughput: 0: 4875.4. Samples: 10465280. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 15:34:42,817][200377] Avg episode reward: [(0, '1510.406')]
[2025-11-03 15:34:47,802][200377] Fps is (10 sec: 4894.2, 60 sec: 4915.0, 300 sec: 4831.6). Total num frames: 10485760. Throughput: 0: 4899.9. Samples: 10494464. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 15:34:47,802][200377] Avg episode reward: [(0, '1477.700')]
[2025-11-03 15:34:52,982][200377] Fps is (10 sec: 4835.6, 60 sec: 4761.4, 300 sec: 4856.1). Total num frames: 10510336. Throughput: 0: 4822.7. Samples: 10508288. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 15:34:52,982][200377] Avg episode reward: [(0, '1545.907')]
[2025-11-03 15:34:57,841][200377] Fps is (10 sec: 4895.9, 60 sec: 4909.0, 300 sec: 4831.8). Total num frames: 10534912. Throughput: 0: 4816.9. Samples: 10536960. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 15:34:57,842][200377] Avg episode reward: [(0, '1595.959')]
[2025-11-03 15:35:03,003][200377] Fps is (10 sec: 4904.9, 60 sec: 4759.9, 300 sec: 4856.3). Total num frames: 10559488. Throughput: 0: 4862.7. Samples: 10568192. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 15:35:03,003][200377] Avg episode reward: [(0, '1562.101')]
[2025-11-03 15:35:07,755][200377] Fps is (10 sec: 4958.1, 60 sec: 4915.3, 300 sec: 4832.3). Total num frames: 10584064. Throughput: 0: 4929.4. Samples: 10582528. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 15:35:07,755][200377] Avg episode reward: [(0, '1488.655')]
[2025-11-03 15:35:12,755][200377] Fps is (10 sec: 4199.9, 60 sec: 4643.5, 300 sec: 4832.7). Total num frames: 10600448. Throughput: 0: 4893.9. Samples: 10611200. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 15:35:12,755][200377] Avg episode reward: [(0, '1540.349')]
[2025-11-03 15:35:17,820][200377] Fps is (10 sec: 4883.5, 60 sec: 4916.3, 300 sec: 4832.1). Total num frames: 10633216. Throughput: 0: 4882.8. Samples: 10639872. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 15:35:17,820][200377] Avg episode reward: [(0, '1553.290')]
[2025-11-03 15:35:22,811][200377] Fps is (10 sec: 4887.9, 60 sec: 4655.9, 300 sec: 4831.7). Total num frames: 10649600. Throughput: 0: 4830.0. Samples: 10654208. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 15:35:22,811][200377] Avg episode reward: [(0, '1401.338')]
[2025-11-03 15:35:22,997][200377] Signal inference workers to stop experience collection... (1950 times)
[2025-11-03 15:35:23,310][200377] InferenceWorker_p0-w0: stopping experience collection (1950 times)
[2025-11-03 15:35:23,312][200377] Signal inference workers to resume experience collection... (1950 times)
[2025-11-03 15:35:23,400][200377] InferenceWorker_p0-w0: resuming experience collection (1950 times)
[2025-11-03 15:35:27,786][200377] Fps is (10 sec: 4932.0, 60 sec: 4913.8, 300 sec: 4832.9). Total num frames: 10682368. Throughput: 0: 4850.3. Samples: 10683392. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 15:35:27,786][200377] Avg episode reward: [(0, '1428.068')]
[2025-11-03 15:35:32,830][200377] Fps is (10 sec: 4905.9, 60 sec: 4658.8, 300 sec: 4831.9). Total num frames: 10698752. Throughput: 0: 4855.3. Samples: 10713088. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 15:35:32,830][200377] Avg episode reward: [(0, '1514.673')]
[2025-11-03 15:35:37,765][200377] Fps is (10 sec: 4925.6, 60 sec: 4914.8, 300 sec: 4836.2). Total num frames: 10731520. Throughput: 0: 4893.3. Samples: 10727424. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 15:35:37,765][200377] Avg episode reward: [(0, '1550.249')]
[2025-11-03 15:35:42,749][200377] Fps is (10 sec: 4955.6, 60 sec: 4784.1, 300 sec: 4832.7). Total num frames: 10747904. Throughput: 0: 4868.4. Samples: 10755584. Policy #0 lag: (min: 8.0, avg: 11.0, max: 72.0)
[2025-11-03 15:35:42,749][200377] Avg episode reward: [(0, '1460.605')]
[2025-11-03 15:35:47,822][200377] Fps is (10 sec: 4887.0, 60 sec: 4913.5, 300 sec: 4861.3). Total num frames: 10780672. Throughput: 0: 4832.2. Samples: 10784768. Policy #0 lag: (min: 8.0, avg: 11.0, max: 72.0)
[2025-11-03 15:35:47,822][200377] Avg episode reward: [(0, '1466.685')]
[2025-11-03 15:35:52,802][200377] Fps is (10 sec: 4889.1, 60 sec: 4793.0, 300 sec: 4831.3). Total num frames: 10797056. Throughput: 0: 4807.8. Samples: 10799104. Policy #0 lag: (min: 8.0, avg: 11.0, max: 72.0)
[2025-11-03 15:35:52,802][200377] Avg episode reward: [(0, '1501.128')]
[2025-11-03 15:35:57,825][200377] Fps is (10 sec: 4913.7, 60 sec: 4916.5, 300 sec: 4863.4). Total num frames: 10829824. Throughput: 0: 4850.8. Samples: 10829824. Policy #0 lag: (min: 8.0, avg: 11.0, max: 72.0)
[2025-11-03 15:35:57,825][200377] Avg episode reward: [(0, '1492.925')]
[2025-11-03 15:35:59,159][200377] Keyboard interrupt detected in the event loop EvtLoop [Runner_EvtLoop, process=main process 200377], exiting...
[2025-11-03 15:35:59,160][200377] Runner profile tree view:
main_loop: 2258.8797
[2025-11-03 15:35:59,160][200377] Collected {0: 10829824}, FPS: 4794.3
