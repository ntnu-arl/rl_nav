[2025-11-03 19:37:48,925][413835] Saving configuration to /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_lidar_policy4_random_envs_stable_at_goal/config.json...
[2025-11-03 19:37:48,966][413835] Using GPUs [0] for process 0 (actually maps to GPUs [0])
[2025-11-03 19:37:48,966][413835] Rollout worker 0 uses device cuda:0
[2025-11-03 19:37:48,990][413835] Using GPUs [0] for process 0 (actually maps to GPUs [0])
[2025-11-03 19:37:48,990][413835] InferenceWorker_p0-w0: min num requests: 1
[2025-11-03 19:37:48,990][413835] Using GPUs [0] for process 0 (actually maps to GPUs [0])
[2025-11-03 19:37:48,991][413835] Starting seed is not provided
[2025-11-03 19:37:48,991][413835] Using GPUs [0] for process 0 (actually maps to GPUs [0])
[2025-11-03 19:37:48,991][413835] Initializing actor-critic model on device cuda:0
[2025-11-03 19:37:48,991][413835] RunningMeanStd input shape: (337,)
[2025-11-03 19:37:48,991][413835] RunningMeanStd input shape: (1,)
[2025-11-03 19:37:48,999][413835] Created Actor Critic model with architecture:
[2025-11-03 19:37:48,999][413835] ActorCriticSharedWeights(
  (obs_normalizer): ObservationNormalizer(
    (running_mean_std): RunningMeanStdDictInPlace(
      (running_mean_std): ModuleDict(
        (observations): RunningMeanStdInPlace()
      )
    )
  )
  (returns_normalizer): RecursiveScriptModule(original_name=RunningMeanStdInPlace)
  (encoder): CustomEncoder(
    (encoders): ModuleDict(
      (obs_image): Sequential(
        (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): ELU(alpha=1.0)
        (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
        (3): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (4): ELU(alpha=1.0)
        (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
        (6): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (7): ELU(alpha=1.0)
        (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        (9): Flatten(start_dim=1, end_dim=-1)
      )
    )
    (mlp_head_custom): Sequential(
      (0): Linear(in_features=145, out_features=256, bias=True)
      (1): ELU(alpha=1.0)
      (2): Linear(in_features=256, out_features=128, bias=True)
      (3): ELU(alpha=1.0)
      (4): Linear(in_features=128, out_features=64, bias=True)
      (5): ELU(alpha=1.0)
    )
  )
  (core): ModelCoreRNN(
    (core): GRU(64, 128)
  )
  (decoder): MlpDecoder(
    (mlp): Identity()
  )
  (critic_linear): Linear(in_features=128, out_features=1, bias=True)
  (action_parameterization): ActionParameterizationDefault(
    (distribution_linear): Linear(in_features=128, out_features=8, bias=True)
  )
)
[2025-11-03 19:37:49,377][413835] Using optimizer <class 'torch.optim.adam.Adam'>
[2025-11-03 19:37:49,378][413835] No checkpoints found
[2025-11-03 19:37:49,378][413835] Did not load from checkpoint, starting from scratch!
[2025-11-03 19:37:49,378][413835] Initialized policy 0 weights for model version 0
[2025-11-03 19:37:49,378][413835] LearnerWorker_p0 finished initialization!
[2025-11-03 19:37:49,379][413835] Using GPUs [0] for process 0 (actually maps to GPUs [0])
[2025-11-03 19:37:49,384][413835] Fps is (10 sec: nan, 60 sec: nan, 300 sec: nan). Total num frames: 0. Throughput: 0: nan. Samples: 0. Policy #0 lag: (min: -1.0, avg: -1.0, max: -1.0)
[2025-11-03 19:37:49,384][413835] Inference worker 0-0 is ready!
[2025-11-03 19:37:49,384][413835] All inference workers are ready! Signal rollout workers to start!
[2025-11-03 19:37:49,384][413835] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 0.0). Total num frames: 0. Throughput: 0: 0.0. Samples: 0. Policy #0 lag: (min: -1.0, avg: -1.0, max: -1.0)
[2025-11-03 19:37:49,384][413835] EnvRunner 0-0 uses policy 0
[2025-11-03 19:38:03,223][413835] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 0.0). Total num frames: 0. Throughput: 0: 0.0. Samples: 0. Policy #0 lag: (min: -1.0, avg: -1.0, max: -1.0)
[2025-11-03 19:38:07,062][413835] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 0.0). Total num frames: 0. Throughput: 0: 0.0. Samples: 0. Policy #0 lag: (min: -1.0, avg: -1.0, max: -1.0)
[2025-11-03 19:38:07,167][413835] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 0.0). Total num frames: 0. Throughput: 0: 28.8. Samples: 512. Policy #0 lag: (min: -1.0, avg: -1.0, max: -1.0)
[2025-11-03 19:38:07,168][413835] Avg episode reward: [(0, '-100.000')]
[2025-11-03 19:38:08,228][413835] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 0.0). Total num frames: 0. Throughput: 0: 54.3. Samples: 1024. Policy #0 lag: (min: -1.0, avg: -1.0, max: -1.0)
[2025-11-03 19:38:08,228][413835] Avg episode reward: [(0, '-100.000')]
[2025-11-03 19:38:09,655][413835] Heartbeat connected on Batcher_0
[2025-11-03 19:38:09,655][413835] Heartbeat connected on LearnerWorker_p0
[2025-11-03 19:38:09,656][413835] Heartbeat connected on InferenceWorker_p0-w0
[2025-11-03 19:38:09,656][413835] Heartbeat connected on RolloutWorker_w0
[2025-11-03 19:38:11,244][413835] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 0.0). Total num frames: 0. Throughput: 0: 327.9. Samples: 7168. Policy #0 lag: (min: -1.0, avg: -1.0, max: -1.0)
[2025-11-03 19:38:11,244][413835] Avg episode reward: [(0, '-99.872')]
[2025-11-03 19:38:13,544][413835] Signal inference workers to stop experience collection...
[2025-11-03 19:38:14,764][413835] InferenceWorker_p0-w0: stopping experience collection
[2025-11-03 19:38:14,766][413835] Signal inference workers to resume experience collection...
[2025-11-03 19:38:14,921][413835] InferenceWorker_p0-w0: resuming experience collection
[2025-11-03 19:38:16,162][413835] Fps is (10 sec: 2065.0, 60 sec: 611.8, 300 sec: 611.8). Total num frames: 16384. Throughput: 0: 611.8. Samples: 16384. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[2025-11-03 19:38:16,162][413835] Avg episode reward: [(0, '-95.359')]
[2025-11-03 19:38:21,163][413835] Fps is (10 sec: 3303.5, 60 sec: 1031.1, 300 sec: 1031.1). Total num frames: 32768. Throughput: 0: 1063.3. Samples: 33792. Policy #0 lag: (min: 6.0, avg: 9.0, max: 70.0)
[2025-11-03 19:38:21,163][413835] Avg episode reward: [(0, '-88.088')]
[2025-11-03 19:38:26,106][413835] Fps is (10 sec: 3295.1, 60 sec: 1338.5, 300 sec: 1338.5). Total num frames: 49152. Throughput: 0: 1464.0. Samples: 53760. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 19:38:26,106][413835] Avg episode reward: [(0, '-7.213')]
[2025-11-03 19:38:31,138][413835] Fps is (10 sec: 3285.0, 60 sec: 1569.6, 300 sec: 1569.6). Total num frames: 65536. Throughput: 0: 1594.1. Samples: 66560. Policy #0 lag: (min: 11.0, avg: 14.0, max: 75.0)
[2025-11-03 19:38:31,138][413835] Avg episode reward: [(0, '-3.035')]
[2025-11-03 19:38:36,208][413835] Fps is (10 sec: 3243.9, 60 sec: 1749.5, 300 sec: 1749.5). Total num frames: 81920. Throughput: 0: 2669.8. Samples: 88064. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 19:38:36,208][413835] Avg episode reward: [(0, '-32.788')]
[2025-11-03 19:38:41,118][413835] Fps is (10 sec: 3283.1, 60 sec: 1900.2, 300 sec: 1900.2). Total num frames: 98304. Throughput: 0: 3247.3. Samples: 110592. Policy #0 lag: (min: 8.0, avg: 11.0, max: 72.0)
[2025-11-03 19:38:41,119][413835] Avg episode reward: [(0, '-7.727')]
[2025-11-03 19:38:46,272][413835] Fps is (10 sec: 4070.0, 60 sec: 2160.1, 300 sec: 2160.0). Total num frames: 122880. Throughput: 0: 3090.0. Samples: 121344. Policy #0 lag: (min: 11.0, avg: 14.0, max: 75.0)
[2025-11-03 19:38:46,272][413835] Avg episode reward: [(0, '2.316')]
[2025-11-03 19:38:46,647][413835] Saving new best policy, reward=2.316!
[2025-11-03 19:38:51,113][413835] Fps is (10 sec: 4918.0, 60 sec: 3079.0, 300 sec: 2388.8). Total num frames: 147456. Throughput: 0: 3330.9. Samples: 143872. Policy #0 lag: (min: 13.0, avg: 16.0, max: 77.0)
[2025-11-03 19:38:51,113][413835] Avg episode reward: [(0, '-18.675')]
[2025-11-03 19:38:56,119][413835] Fps is (10 sec: 4159.6, 60 sec: 3339.8, 300 sec: 2455.1). Total num frames: 163840. Throughput: 0: 3514.1. Samples: 164864. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 19:38:56,119][413835] Avg episode reward: [(0, '7.948')]
[2025-11-03 19:38:56,249][413835] Saving new best policy, reward=7.948!
[2025-11-03 19:39:01,162][413835] Fps is (10 sec: 3260.9, 60 sec: 3337.8, 300 sec: 2510.9). Total num frames: 180224. Throughput: 0: 3538.5. Samples: 175616. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 19:39:01,162][413835] Avg episode reward: [(0, '22.944')]
[2025-11-03 19:39:01,293][413835] Saving new best policy, reward=22.944!
[2025-11-03 19:39:06,184][413835] Fps is (10 sec: 3255.5, 60 sec: 3392.4, 300 sec: 2560.0). Total num frames: 196608. Throughput: 0: 3639.2. Samples: 197632. Policy #0 lag: (min: 4.0, avg: 7.0, max: 68.0)
[2025-11-03 19:39:06,184][413835] Avg episode reward: [(0, '9.607')]
[2025-11-03 19:39:11,166][413835] Fps is (10 sec: 3275.2, 60 sec: 3554.4, 300 sec: 2604.4). Total num frames: 212992. Throughput: 0: 3670.1. Samples: 219136. Policy #0 lag: (min: 4.0, avg: 7.0, max: 68.0)
[2025-11-03 19:39:11,167][413835] Avg episode reward: [(0, '39.483')]
[2025-11-03 19:39:11,303][413835] Saving new best policy, reward=39.483!
[2025-11-03 19:39:16,214][413835] Fps is (10 sec: 3267.0, 60 sec: 3546.8, 300 sec: 2641.7). Total num frames: 229376. Throughput: 0: 3634.7. Samples: 230400. Policy #0 lag: (min: 6.0, avg: 9.0, max: 70.0)
[2025-11-03 19:39:16,214][413835] Avg episode reward: [(0, '57.880')]
[2025-11-03 19:39:16,342][413835] Saving new best policy, reward=57.880!
[2025-11-03 19:39:21,728][413835] Fps is (10 sec: 3102.4, 60 sec: 3516.7, 300 sec: 2661.3). Total num frames: 245760. Throughput: 0: 3599.2. Samples: 251904. Policy #0 lag: (min: 1.0, avg: 4.0, max: 65.0)
[2025-11-03 19:39:21,729][413835] Avg episode reward: [(0, '71.695')]
[2025-11-03 19:39:21,855][413835] Saving new best policy, reward=71.695!
[2025-11-03 19:39:26,207][413835] Fps is (10 sec: 3279.3, 60 sec: 3543.9, 300 sec: 2707.5). Total num frames: 262144. Throughput: 0: 3611.1. Samples: 273408. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 19:39:26,207][413835] Avg episode reward: [(0, '79.215')]
[2025-11-03 19:39:26,341][413835] Saving new best policy, reward=79.215!
[2025-11-03 19:39:27,212][413835] Signal inference workers to stop experience collection... (50 times)
[2025-11-03 19:39:27,543][413835] InferenceWorker_p0-w0: stopping experience collection (50 times)
[2025-11-03 19:39:27,543][413835] Signal inference workers to resume experience collection... (50 times)
[2025-11-03 19:39:27,543][413835] InferenceWorker_p0-w0: resuming experience collection (50 times)
[2025-11-03 19:39:31,155][413835] Fps is (10 sec: 3476.1, 60 sec: 3548.8, 300 sec: 2736.8). Total num frames: 278528. Throughput: 0: 3616.1. Samples: 283648. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 19:39:31,155][413835] Avg episode reward: [(0, '94.770')]
[2025-11-03 19:39:31,284][413835] Saving /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_lidar_policy4_random_envs_stable_at_goal/checkpoint_p0/checkpoint_000001088_278528.pth...
[2025-11-03 19:39:31,289][413835] Saving new best policy, reward=94.770!
[2025-11-03 19:39:36,140][413835] Fps is (10 sec: 4123.4, 60 sec: 3690.6, 300 sec: 2839.2). Total num frames: 303104. Throughput: 0: 3615.9. Samples: 306688. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 19:39:36,140][413835] Avg episode reward: [(0, '114.008')]
[2025-11-03 19:39:36,475][413835] Saving new best policy, reward=114.008!
[2025-11-03 19:39:41,182][413835] Fps is (10 sec: 4902.0, 60 sec: 3818.9, 300 sec: 2931.0). Total num frames: 327680. Throughput: 0: 3635.8. Samples: 328704. Policy #0 lag: (min: 1.0, avg: 4.0, max: 65.0)
[2025-11-03 19:39:41,182][413835] Avg episode reward: [(0, '129.687')]
[2025-11-03 19:39:41,331][413835] Saving new best policy, reward=129.687!
[2025-11-03 19:39:46,124][413835] Fps is (10 sec: 4102.6, 60 sec: 3695.5, 300 sec: 2947.3). Total num frames: 344064. Throughput: 0: 3609.8. Samples: 337920. Policy #0 lag: (min: 11.0, avg: 14.0, max: 75.0)
[2025-11-03 19:39:46,124][413835] Avg episode reward: [(0, '143.117')]
[2025-11-03 19:39:46,124][413835] Saving new best policy, reward=143.117!
[2025-11-03 19:39:51,278][413835] Fps is (10 sec: 3245.6, 60 sec: 3540.1, 300 sec: 2957.0). Total num frames: 360448. Throughput: 0: 3531.1. Samples: 356864. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 19:39:51,279][413835] Avg episode reward: [(0, '147.990')]
[2025-11-03 19:39:51,280][413835] Saving new best policy, reward=147.990!
[2025-11-03 19:39:56,176][413835] Fps is (10 sec: 2445.0, 60 sec: 3410.1, 300 sec: 2907.4). Total num frames: 368640. Throughput: 0: 3480.9. Samples: 375808. Policy #0 lag: (min: 5.0, avg: 8.0, max: 69.0)
[2025-11-03 19:39:56,176][413835] Avg episode reward: [(0, '156.382')]
[2025-11-03 19:39:56,519][413835] Saving new best policy, reward=156.382!
[2025-11-03 19:40:01,170][413835] Fps is (10 sec: 3312.8, 60 sec: 3549.4, 300 sec: 2983.7). Total num frames: 393216. Throughput: 0: 3462.3. Samples: 386048. Policy #0 lag: (min: 9.0, avg: 12.0, max: 73.0)
[2025-11-03 19:40:01,170][413835] Avg episode reward: [(0, '159.468')]
[2025-11-03 19:40:01,299][413835] Saving new best policy, reward=159.468!
[2025-11-03 19:40:06,147][413835] Fps is (10 sec: 4107.6, 60 sec: 3552.0, 300 sec: 2994.9). Total num frames: 409600. Throughput: 0: 3527.1. Samples: 408576. Policy #0 lag: (min: 1.0, avg: 4.0, max: 65.0)
[2025-11-03 19:40:06,148][413835] Avg episode reward: [(0, '164.114')]
[2025-11-03 19:40:06,275][413835] Saving new best policy, reward=164.114!
[2025-11-03 19:40:11,158][413835] Fps is (10 sec: 3280.6, 60 sec: 3550.3, 300 sec: 3004.7). Total num frames: 425984. Throughput: 0: 3451.2. Samples: 428544. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 19:40:11,158][413835] Avg episode reward: [(0, '174.444')]
[2025-11-03 19:40:11,308][413835] Saving new best policy, reward=174.444!
[2025-11-03 19:40:16,198][413835] Fps is (10 sec: 3260.4, 60 sec: 3550.8, 300 sec: 3013.1). Total num frames: 442368. Throughput: 0: 3444.2. Samples: 438784. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 19:40:16,198][413835] Avg episode reward: [(0, '183.604')]
[2025-11-03 19:40:16,349][413835] Saving new best policy, reward=183.604!
[2025-11-03 19:40:21,119][413835] Fps is (10 sec: 3289.8, 60 sec: 3586.3, 300 sec: 3023.4). Total num frames: 458752. Throughput: 0: 3369.4. Samples: 458240. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 19:40:21,119][413835] Avg episode reward: [(0, '183.930')]
[2025-11-03 19:40:21,267][413835] Saving new best policy, reward=183.930!
[2025-11-03 19:40:26,205][413835] Fps is (10 sec: 3274.6, 60 sec: 3550.0, 300 sec: 3029.8). Total num frames: 475136. Throughput: 0: 3275.2. Samples: 476160. Policy #0 lag: (min: 1.0, avg: 4.0, max: 65.0)
[2025-11-03 19:40:26,205][413835] Avg episode reward: [(0, '188.798')]
[2025-11-03 19:40:26,354][413835] Saving new best policy, reward=188.798!
[2025-11-03 19:40:31,250][413835] Fps is (10 sec: 3234.4, 60 sec: 3544.3, 300 sec: 3036.6). Total num frames: 491520. Throughput: 0: 3290.3. Samples: 486400. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 19:40:31,250][413835] Avg episode reward: [(0, '190.372')]
[2025-11-03 19:40:31,410][413835] Saving new best policy, reward=190.372!
[2025-11-03 19:40:36,208][413835] Fps is (10 sec: 3275.7, 60 sec: 3409.5, 300 sec: 3044.5). Total num frames: 507904. Throughput: 0: 3304.7. Samples: 505344. Policy #0 lag: (min: 2.0, avg: 5.0, max: 66.0)
[2025-11-03 19:40:36,208][413835] Avg episode reward: [(0, '191.187')]
[2025-11-03 19:40:36,356][413835] Saving new best policy, reward=191.187!
[2025-11-03 19:40:41,360][413835] Fps is (10 sec: 3241.3, 60 sec: 3267.1, 300 sec: 3048.6). Total num frames: 524288. Throughput: 0: 3286.1. Samples: 524288. Policy #0 lag: (min: 14.0, avg: 17.0, max: 78.0)
[2025-11-03 19:40:41,360][413835] Avg episode reward: [(0, '194.284')]
[2025-11-03 19:40:41,362][413835] Saving new best policy, reward=194.284!
[2025-11-03 19:40:46,291][413835] Fps is (10 sec: 2437.4, 60 sec: 3131.6, 300 sec: 3009.9). Total num frames: 532480. Throughput: 0: 3256.7. Samples: 532992. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 19:40:46,291][413835] Avg episode reward: [(0, '201.834')]
[2025-11-03 19:40:46,655][413835] Saving new best policy, reward=201.834!
[2025-11-03 19:40:50,878][413835] Signal inference workers to stop experience collection... (100 times)
[2025-11-03 19:40:50,881][413835] Signal inference workers to resume experience collection... (100 times)
[2025-11-03 19:40:51,112][413835] InferenceWorker_p0-w0: stopping experience collection (100 times)
[2025-11-03 19:40:51,112][413835] InferenceWorker_p0-w0: resuming experience collection (100 times)
[2025-11-03 19:40:51,219][413835] Fps is (10 sec: 3323.6, 60 sec: 3280.0, 300 sec: 3063.5). Total num frames: 557056. Throughput: 0: 3203.4. Samples: 552960. Policy #0 lag: (min: 14.0, avg: 17.0, max: 78.0)
[2025-11-03 19:40:51,219][413835] Avg episode reward: [(0, '207.288')]
[2025-11-03 19:40:51,221][413835] Saving new best policy, reward=207.288!
[2025-11-03 19:40:56,185][413835] Fps is (10 sec: 4139.8, 60 sec: 3412.8, 300 sec: 3069.8). Total num frames: 573440. Throughput: 0: 3240.8. Samples: 574464. Policy #0 lag: (min: 6.0, avg: 9.0, max: 70.0)
[2025-11-03 19:40:56,185][413835] Avg episode reward: [(0, '212.120')]
[2025-11-03 19:40:56,306][413835] Saving new best policy, reward=212.120!
[2025-11-03 19:41:01,208][413835] Fps is (10 sec: 3280.4, 60 sec: 3274.7, 300 sec: 3074.8). Total num frames: 589824. Throughput: 0: 3264.7. Samples: 585728. Policy #0 lag: (min: 8.0, avg: 11.0, max: 72.0)
[2025-11-03 19:41:01,208][413835] Avg episode reward: [(0, '213.925')]
[2025-11-03 19:41:01,337][413835] Saving new best policy, reward=213.925!
[2025-11-03 19:41:06,183][413835] Fps is (10 sec: 3277.4, 60 sec: 3274.9, 300 sec: 3080.3). Total num frames: 606208. Throughput: 0: 3306.2. Samples: 607232. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 19:41:06,183][413835] Avg episode reward: [(0, '218.439')]
[2025-11-03 19:41:06,316][413835] Saving new best policy, reward=218.439!
[2025-11-03 19:41:11,197][413835] Fps is (10 sec: 3280.3, 60 sec: 3274.7, 300 sec: 3085.0). Total num frames: 622592. Throughput: 0: 3402.5. Samples: 629248. Policy #0 lag: (min: 9.0, avg: 12.0, max: 73.0)
[2025-11-03 19:41:11,198][413835] Avg episode reward: [(0, '218.082')]
[2025-11-03 19:41:16,213][413835] Fps is (10 sec: 3267.1, 60 sec: 3276.0, 300 sec: 3089.4). Total num frames: 638976. Throughput: 0: 3416.2. Samples: 640000. Policy #0 lag: (min: 13.0, avg: 16.0, max: 77.0)
[2025-11-03 19:41:16,213][413835] Avg episode reward: [(0, '219.997')]
[2025-11-03 19:41:16,346][413835] Saving new best policy, reward=219.997!
[2025-11-03 19:41:21,190][413835] Fps is (10 sec: 3279.4, 60 sec: 3272.9, 300 sec: 3094.2). Total num frames: 655360. Throughput: 0: 3483.0. Samples: 662016. Policy #0 lag: (min: 0.0, avg: 3.0, max: 64.0)
[2025-11-03 19:41:21,190][413835] Avg episode reward: [(0, '221.207')]
[2025-11-03 19:41:21,312][413835] Saving new best policy, reward=221.207!
[2025-11-03 19:41:26,221][413835] Fps is (10 sec: 3274.0, 60 sec: 3275.9, 300 sec: 3097.9). Total num frames: 671744. Throughput: 0: 3572.2. Samples: 684544. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 19:41:26,221][413835] Avg episode reward: [(0, '223.055')]
[2025-11-03 19:41:26,347][413835] Saving new best policy, reward=223.055!
[2025-11-03 19:41:31,220][413835] Fps is (10 sec: 3266.8, 60 sec: 3278.4, 300 sec: 3102.0). Total num frames: 688128. Throughput: 0: 3601.0. Samples: 694784. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 19:41:31,220][413835] Avg episode reward: [(0, '227.541')]
[2025-11-03 19:41:31,603][413835] Saving /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_lidar_policy4_random_envs_stable_at_goal/checkpoint_p0/checkpoint_000002720_696320.pth...
[2025-11-03 19:41:31,607][413835] Saving new best policy, reward=227.541!
[2025-11-03 19:41:36,215][413835] Fps is (10 sec: 4098.7, 60 sec: 3413.0, 300 sec: 3142.0). Total num frames: 712704. Throughput: 0: 3618.5. Samples: 715776. Policy #0 lag: (min: 13.0, avg: 16.0, max: 77.0)
[2025-11-03 19:41:36,215][413835] Avg episode reward: [(0, '229.121')]
[2025-11-03 19:41:36,562][413835] Saving new best policy, reward=229.121!
[2025-11-03 19:41:41,140][413835] Fps is (10 sec: 4955.0, 60 sec: 3562.9, 300 sec: 3181.3). Total num frames: 737280. Throughput: 0: 3633.1. Samples: 737792. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 19:41:41,140][413835] Avg episode reward: [(0, '230.485')]
[2025-11-03 19:41:41,141][413835] Saving new best policy, reward=230.485!
[2025-11-03 19:41:46,235][413835] Fps is (10 sec: 4087.7, 60 sec: 3689.8, 300 sec: 3182.0). Total num frames: 753664. Throughput: 0: 3604.6. Samples: 748032. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 19:41:46,235][413835] Avg episode reward: [(0, '229.144')]
[2025-11-03 19:41:51,150][413835] Fps is (10 sec: 3273.6, 60 sec: 3554.0, 300 sec: 3185.1). Total num frames: 770048. Throughput: 0: 3620.8. Samples: 770048. Policy #0 lag: (min: 8.0, avg: 11.0, max: 72.0)
[2025-11-03 19:41:51,150][413835] Avg episode reward: [(0, '230.789')]
[2025-11-03 19:41:51,280][413835] Saving new best policy, reward=230.789!
[2025-11-03 19:41:56,160][413835] Fps is (10 sec: 3301.6, 60 sec: 3551.3, 300 sec: 3186.8). Total num frames: 786432. Throughput: 0: 3575.6. Samples: 790016. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 19:41:56,160][413835] Avg episode reward: [(0, '234.928')]
[2025-11-03 19:41:56,296][413835] Saving new best policy, reward=234.928!
[2025-11-03 19:42:01,201][413835] Fps is (10 sec: 3260.2, 60 sec: 3550.3, 300 sec: 3188.1). Total num frames: 802816. Throughput: 0: 3596.3. Samples: 801792. Policy #0 lag: (min: 0.0, avg: 3.0, max: 64.0)
[2025-11-03 19:42:01,201][413835] Avg episode reward: [(0, '236.454')]
[2025-11-03 19:42:01,324][413835] Saving new best policy, reward=236.454!
[2025-11-03 19:42:06,149][413835] Fps is (10 sec: 3280.5, 60 sec: 3551.9, 300 sec: 3190.5). Total num frames: 819200. Throughput: 0: 3564.5. Samples: 822272. Policy #0 lag: (min: 2.0, avg: 5.0, max: 66.0)
[2025-11-03 19:42:06,149][413835] Avg episode reward: [(0, '237.287')]
[2025-11-03 19:42:06,289][413835] Saving new best policy, reward=237.287!
[2025-11-03 19:42:08,038][413835] Signal inference workers to stop experience collection... (150 times)
[2025-11-03 19:42:08,390][413835] InferenceWorker_p0-w0: stopping experience collection (150 times)
[2025-11-03 19:42:08,391][413835] Signal inference workers to resume experience collection... (150 times)
[2025-11-03 19:42:08,515][413835] InferenceWorker_p0-w0: resuming experience collection (150 times)
[2025-11-03 19:42:11,175][413835] Fps is (10 sec: 3285.4, 60 sec: 3551.2, 300 sec: 3191.8). Total num frames: 835584. Throughput: 0: 3542.2. Samples: 843776. Policy #0 lag: (min: 13.0, avg: 16.0, max: 77.0)
[2025-11-03 19:42:11,175][413835] Avg episode reward: [(0, '232.374')]
[2025-11-03 19:42:16,163][413835] Fps is (10 sec: 3272.3, 60 sec: 3552.8, 300 sec: 3193.5). Total num frames: 851968. Throughput: 0: 3543.0. Samples: 854016. Policy #0 lag: (min: 1.0, avg: 4.0, max: 65.0)
[2025-11-03 19:42:16,163][413835] Avg episode reward: [(0, '229.788')]
[2025-11-03 19:42:21,179][413835] Fps is (10 sec: 3275.3, 60 sec: 3550.5, 300 sec: 3194.9). Total num frames: 868352. Throughput: 0: 3564.0. Samples: 876032. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 19:42:21,179][413835] Avg episode reward: [(0, '226.647')]
[2025-11-03 19:42:26,116][413835] Fps is (10 sec: 3292.1, 60 sec: 3556.1, 300 sec: 3197.1). Total num frames: 884736. Throughput: 0: 3574.5. Samples: 898560. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 19:42:26,116][413835] Avg episode reward: [(0, '226.861')]
[2025-11-03 19:42:31,134][413835] Fps is (10 sec: 4114.8, 60 sec: 3691.7, 300 sec: 3227.4). Total num frames: 909312. Throughput: 0: 3580.7. Samples: 908800. Policy #0 lag: (min: 1.0, avg: 4.0, max: 65.0)
[2025-11-03 19:42:31,134][413835] Avg episode reward: [(0, '230.088')]
[2025-11-03 19:42:36,591][413835] Fps is (10 sec: 4692.5, 60 sec: 3663.4, 300 sec: 3251.6). Total num frames: 933888. Throughput: 0: 3515.4. Samples: 929792. Policy #0 lag: (min: 12.0, avg: 15.0, max: 76.0)
[2025-11-03 19:42:36,591][413835] Avg episode reward: [(0, '236.868')]
[2025-11-03 19:42:41,196][413835] Fps is (10 sec: 2442.5, 60 sec: 3273.8, 300 sec: 3200.3). Total num frames: 933888. Throughput: 0: 3467.5. Samples: 946176. Policy #0 lag: (min: 12.0, avg: 15.0, max: 76.0)
[2025-11-03 19:42:41,196][413835] Avg episode reward: [(0, '240.090')]
[2025-11-03 19:42:41,405][413835] Saving new best policy, reward=240.090!
[2025-11-03 19:42:46,237][413835] Fps is (10 sec: 1698.4, 60 sec: 3276.7, 300 sec: 3357.7). Total num frames: 950272. Throughput: 0: 3342.3. Samples: 952320. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 19:42:46,238][413835] Avg episode reward: [(0, '242.854')]
[2025-11-03 19:42:46,395][413835] Saving new best policy, reward=242.854!
[2025-11-03 19:42:51,228][413835] Fps is (10 sec: 3266.2, 60 sec: 3272.5, 300 sec: 3401.7). Total num frames: 966656. Throughput: 0: 3248.3. Samples: 968704. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 19:42:51,228][413835] Avg episode reward: [(0, '243.256')]
[2025-11-03 19:42:51,389][413835] Saving new best policy, reward=243.256!
[2025-11-03 19:42:56,255][413835] Fps is (10 sec: 3271.0, 60 sec: 3271.6, 300 sec: 3400.5). Total num frames: 983040. Throughput: 0: 3134.7. Samples: 985088. Policy #0 lag: (min: 5.0, avg: 8.0, max: 69.0)
[2025-11-03 19:42:56,256][413835] Avg episode reward: [(0, '248.205')]
[2025-11-03 19:42:56,426][413835] Saving new best policy, reward=248.205!
[2025-11-03 19:43:01,266][413835] Fps is (10 sec: 3264.5, 60 sec: 3273.3, 300 sec: 3410.6). Total num frames: 999424. Throughput: 0: 3110.4. Samples: 994304. Policy #0 lag: (min: 11.0, avg: 14.0, max: 75.0)
[2025-11-03 19:43:01,266][413835] Avg episode reward: [(0, '248.914')]
[2025-11-03 19:43:01,269][413835] Saving new best policy, reward=248.914!
[2025-11-03 19:43:06,145][413835] Fps is (10 sec: 1656.6, 60 sec: 3003.9, 300 sec: 3389.0). Total num frames: 999424. Throughput: 0: 3006.0. Samples: 1011200. Policy #0 lag: (min: 11.0, avg: 14.0, max: 75.0)
[2025-11-03 19:43:06,146][413835] Avg episode reward: [(0, '251.675')]
[2025-11-03 19:43:06,680][413835] Saving new best policy, reward=251.675!
[2025-11-03 19:43:11,191][413835] Fps is (10 sec: 1650.7, 60 sec: 3002.9, 300 sec: 3387.5). Total num frames: 1015808. Throughput: 0: 2862.5. Samples: 1027584. Policy #0 lag: (min: 9.0, avg: 12.0, max: 73.0)
[2025-11-03 19:43:11,191][413835] Avg episode reward: [(0, '250.473')]
[2025-11-03 19:43:16,122][413835] Fps is (10 sec: 3284.5, 60 sec: 3005.8, 300 sec: 3388.3). Total num frames: 1032192. Throughput: 0: 2788.3. Samples: 1034240. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 19:43:16,122][413835] Avg episode reward: [(0, '255.120')]
[2025-11-03 19:43:16,289][413835] Saving new best policy, reward=255.120!
[2025-11-03 19:43:21,147][413835] Fps is (10 sec: 3291.1, 60 sec: 3005.3, 300 sec: 3387.4). Total num frames: 1048576. Throughput: 0: 2711.9. Samples: 1050624. Policy #0 lag: (min: 10.0, avg: 13.0, max: 74.0)
[2025-11-03 19:43:21,148][413835] Avg episode reward: [(0, '255.609')]
[2025-11-03 19:43:21,318][413835] Saving new best policy, reward=255.609!
[2025-11-03 19:43:26,262][413835] Fps is (10 sec: 3231.6, 60 sec: 2996.5, 300 sec: 3386.5). Total num frames: 1064960. Throughput: 0: 2658.5. Samples: 1065984. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 19:43:26,262][413835] Avg episode reward: [(0, '259.056')]
[2025-11-03 19:43:26,425][413835] Saving new best policy, reward=259.056!
[2025-11-03 19:43:31,499][413835] Fps is (10 sec: 3165.3, 60 sec: 2849.8, 300 sec: 3384.5). Total num frames: 1081344. Throughput: 0: 2726.2. Samples: 1075712. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 19:43:31,500][413835] Avg episode reward: [(0, '263.670')]
[2025-11-03 19:43:31,503][413835] Saving /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_lidar_policy4_random_envs_stable_at_goal/checkpoint_p0/checkpoint_000004224_1081344.pth...
[2025-11-03 19:43:31,509][413835] Removing /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_lidar_policy4_random_envs_stable_at_goal/checkpoint_p0/checkpoint_000001088_278528.pth
[2025-11-03 19:43:31,509][413835] Saving new best policy, reward=263.670!
[2025-11-03 19:43:36,174][413835] Fps is (10 sec: 1652.9, 60 sec: 2474.8, 300 sec: 3331.7). Total num frames: 1081344. Throughput: 0: 2745.3. Samples: 1092096. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 19:43:36,174][413835] Avg episode reward: [(0, '268.258')]
[2025-11-03 19:43:36,348][413835] Saving new best policy, reward=268.258!
[2025-11-03 19:43:37,073][413835] Signal inference workers to stop experience collection... (200 times)
[2025-11-03 19:43:37,632][413835] InferenceWorker_p0-w0: stopping experience collection (200 times)
[2025-11-03 19:43:37,632][413835] Signal inference workers to resume experience collection... (200 times)
[2025-11-03 19:43:37,633][413835] InferenceWorker_p0-w0: resuming experience collection (200 times)
[2025-11-03 19:43:41,121][413835] Fps is (10 sec: 1702.8, 60 sec: 2734.1, 300 sec: 3306.3). Total num frames: 1097728. Throughput: 0: 2738.8. Samples: 1107968. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 19:43:41,121][413835] Avg episode reward: [(0, '270.306')]
[2025-11-03 19:43:41,299][413835] Saving new best policy, reward=270.306!
[2025-11-03 19:43:46,212][413835] Fps is (10 sec: 3264.4, 60 sec: 2731.8, 300 sec: 3275.7). Total num frames: 1114112. Throughput: 0: 2688.4. Samples: 1115136. Policy #0 lag: (min: 4.0, avg: 7.0, max: 68.0)
[2025-11-03 19:43:46,212][413835] Avg episode reward: [(0, '274.952')]
[2025-11-03 19:43:46,392][413835] Saving new best policy, reward=274.952!
[2025-11-03 19:43:51,129][413835] Fps is (10 sec: 3274.2, 60 sec: 2735.2, 300 sec: 3276.7). Total num frames: 1130496. Throughput: 0: 2674.8. Samples: 1131520. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 19:43:51,129][413835] Avg episode reward: [(0, '278.044')]
[2025-11-03 19:43:51,289][413835] Saving new best policy, reward=278.044!
[2025-11-03 19:43:56,667][413835] Fps is (10 sec: 3134.1, 60 sec: 2712.0, 300 sec: 3271.2). Total num frames: 1146880. Throughput: 0: 2634.5. Samples: 1147392. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 19:43:56,668][413835] Avg episode reward: [(0, '281.462')]
[2025-11-03 19:43:56,668][413835] Saving new best policy, reward=281.462!
[2025-11-03 19:44:01,156][413835] Fps is (10 sec: 1634.0, 60 sec: 2462.1, 300 sec: 3221.6). Total num frames: 1146880. Throughput: 0: 2649.0. Samples: 1153536. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 19:44:01,156][413835] Avg episode reward: [(0, '289.724')]
[2025-11-03 19:44:01,332][413835] Saving new best policy, reward=289.724!
[2025-11-03 19:44:06,245][413835] Fps is (10 sec: 1710.6, 60 sec: 2726.1, 300 sec: 3220.4). Total num frames: 1163264. Throughput: 0: 2622.5. Samples: 1168896. Policy #0 lag: (min: 1.0, avg: 4.0, max: 65.0)
[2025-11-03 19:44:06,246][413835] Avg episode reward: [(0, '290.666')]
[2025-11-03 19:44:06,466][413835] Saving new best policy, reward=290.666!
[2025-11-03 19:44:11,255][413835] Fps is (10 sec: 3244.5, 60 sec: 2727.7, 300 sec: 3220.8). Total num frames: 1179648. Throughput: 0: 2617.3. Samples: 1183744. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 19:44:11,256][413835] Avg episode reward: [(0, '297.951')]
[2025-11-03 19:44:11,431][413835] Saving new best policy, reward=297.951!
[2025-11-03 19:44:16,109][413835] Fps is (10 sec: 3322.0, 60 sec: 2731.2, 300 sec: 3228.0). Total num frames: 1196032. Throughput: 0: 2628.3. Samples: 1192960. Policy #0 lag: (min: 4.0, avg: 7.0, max: 68.0)
[2025-11-03 19:44:16,110][413835] Avg episode reward: [(0, '292.526')]
[2025-11-03 19:44:21,335][413835] Fps is (10 sec: 2438.1, 60 sec: 2586.0, 300 sec: 3192.1). Total num frames: 1204224. Throughput: 0: 2584.9. Samples: 1208832. Policy #0 lag: (min: 13.0, avg: 16.0, max: 77.0)
[2025-11-03 19:44:21,335][413835] Avg episode reward: [(0, '288.775')]
[2025-11-03 19:44:26,261][413835] Fps is (10 sec: 1614.0, 60 sec: 2457.6, 300 sec: 3164.6). Total num frames: 1212416. Throughput: 0: 2597.4. Samples: 1225216. Policy #0 lag: (min: 13.0, avg: 16.0, max: 77.0)
[2025-11-03 19:44:26,261][413835] Avg episode reward: [(0, '290.094')]
[2025-11-03 19:44:31,124][413835] Fps is (10 sec: 2510.5, 60 sec: 2473.1, 300 sec: 3138.1). Total num frames: 1228800. Throughput: 0: 2610.6. Samples: 1232384. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 19:44:31,125][413835] Avg episode reward: [(0, '292.390')]
[2025-11-03 19:44:36,239][413835] Fps is (10 sec: 3284.0, 60 sec: 2727.7, 300 sec: 3109.6). Total num frames: 1245184. Throughput: 0: 2655.9. Samples: 1251328. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 19:44:36,239][413835] Avg episode reward: [(0, '303.085')]
[2025-11-03 19:44:36,368][413835] Saving new best policy, reward=303.085!
[2025-11-03 19:44:41,184][413835] Fps is (10 sec: 3257.3, 60 sec: 2727.8, 300 sec: 3109.5). Total num frames: 1261568. Throughput: 0: 2817.8. Samples: 1272832. Policy #0 lag: (min: 47.0, avg: 50.0, max: 111.0)
[2025-11-03 19:44:41,184][413835] Avg episode reward: [(0, '306.078')]
[2025-11-03 19:44:41,347][413835] Saving new best policy, reward=306.078!
[2025-11-03 19:44:46,197][413835] Fps is (10 sec: 3290.7, 60 sec: 2731.4, 300 sec: 3111.0). Total num frames: 1277952. Throughput: 0: 2841.9. Samples: 1281536. Policy #0 lag: (min: 53.0, avg: 56.0, max: 117.0)
[2025-11-03 19:44:46,197][413835] Avg episode reward: [(0, '318.102')]
[2025-11-03 19:44:46,349][413835] Saving new best policy, reward=318.102!
[2025-11-03 19:44:51,106][413835] Fps is (10 sec: 3302.5, 60 sec: 2731.7, 300 sec: 3138.7). Total num frames: 1294336. Throughput: 0: 2921.7. Samples: 1299968. Policy #0 lag: (min: 22.0, avg: 25.0, max: 86.0)
[2025-11-03 19:44:51,107][413835] Avg episode reward: [(0, '318.131')]
[2025-11-03 19:44:51,252][413835] Saving new best policy, reward=318.131!
[2025-11-03 19:44:56,152][413835] Fps is (10 sec: 3291.7, 60 sec: 2754.3, 300 sec: 3110.4). Total num frames: 1310720. Throughput: 0: 3010.7. Samples: 1318912. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 19:44:56,152][413835] Avg episode reward: [(0, '314.654')]
[2025-11-03 19:45:01,164][413835] Fps is (10 sec: 3257.9, 60 sec: 3003.3, 300 sec: 3110.0). Total num frames: 1327104. Throughput: 0: 3022.8. Samples: 1329152. Policy #0 lag: (min: 34.0, avg: 37.0, max: 98.0)
[2025-11-03 19:45:01,165][413835] Avg episode reward: [(0, '306.920')]
[2025-11-03 19:45:06,168][413835] Fps is (10 sec: 3271.5, 60 sec: 3007.6, 300 sec: 3110.1). Total num frames: 1343488. Throughput: 0: 3174.8. Samples: 1351168. Policy #0 lag: (min: 34.0, avg: 37.0, max: 98.0)
[2025-11-03 19:45:06,168][413835] Avg episode reward: [(0, '303.038')]
[2025-11-03 19:45:11,219][413835] Fps is (10 sec: 3259.0, 60 sec: 3005.5, 300 sec: 3110.0). Total num frames: 1359872. Throughput: 0: 3302.6. Samples: 1373696. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 19:45:11,219][413835] Avg episode reward: [(0, '312.944')]
[2025-11-03 19:45:11,567][413835] Signal inference workers to stop experience collection... (250 times)
[2025-11-03 19:45:11,568][413835] Signal inference workers to resume experience collection... (250 times)
[2025-11-03 19:45:11,806][413835] InferenceWorker_p0-w0: stopping experience collection (250 times)
[2025-11-03 19:45:11,806][413835] InferenceWorker_p0-w0: resuming experience collection (250 times)
[2025-11-03 19:45:16,127][413835] Fps is (10 sec: 4112.8, 60 sec: 3139.3, 300 sec: 3137.9). Total num frames: 1384448. Throughput: 0: 3367.6. Samples: 1383936. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 19:45:16,127][413835] Avg episode reward: [(0, '318.159')]
[2025-11-03 19:45:16,476][413835] Saving new best policy, reward=318.159!
[2025-11-03 19:45:21,120][413835] Fps is (10 sec: 4964.5, 60 sec: 3425.6, 300 sec: 3166.6). Total num frames: 1409024. Throughput: 0: 3445.2. Samples: 1405952. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 19:45:21,120][413835] Avg episode reward: [(0, '330.593')]
[2025-11-03 19:45:21,246][413835] Saving new best policy, reward=330.593!
[2025-11-03 19:45:26,228][413835] Fps is (10 sec: 4055.0, 60 sec: 3551.8, 300 sec: 3166.0). Total num frames: 1425408. Throughput: 0: 3410.0. Samples: 1426432. Policy #0 lag: (min: 0.0, avg: 3.0, max: 64.0)
[2025-11-03 19:45:26,228][413835] Avg episode reward: [(0, '329.380')]
[2025-11-03 19:45:31,209][413835] Fps is (10 sec: 3247.7, 60 sec: 3544.8, 300 sec: 3165.7). Total num frames: 1441792. Throughput: 0: 3503.4. Samples: 1439232. Policy #0 lag: (min: 0.0, avg: 3.0, max: 64.0)
[2025-11-03 19:45:31,210][413835] Avg episode reward: [(0, '350.104')]
[2025-11-03 19:45:31,384][413835] Saving /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_lidar_policy4_random_envs_stable_at_goal/checkpoint_p0/checkpoint_000005632_1441792.pth...
[2025-11-03 19:45:31,388][413835] Removing /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_lidar_policy4_random_envs_stable_at_goal/checkpoint_p0/checkpoint_000002720_696320.pth
[2025-11-03 19:45:31,389][413835] Saving new best policy, reward=350.104!
[2025-11-03 19:45:36,173][413835] Fps is (10 sec: 3295.0, 60 sec: 3553.8, 300 sec: 3167.7). Total num frames: 1458176. Throughput: 0: 3533.3. Samples: 1459200. Policy #0 lag: (min: 3.0, avg: 6.0, max: 67.0)
[2025-11-03 19:45:36,173][413835] Avg episode reward: [(0, '356.401')]
[2025-11-03 19:45:36,313][413835] Saving new best policy, reward=356.401!
[2025-11-03 19:45:41,157][413835] Fps is (10 sec: 3294.1, 60 sec: 3551.5, 300 sec: 3194.9). Total num frames: 1474560. Throughput: 0: 3617.7. Samples: 1481728. Policy #0 lag: (min: 3.0, avg: 6.0, max: 67.0)
[2025-11-03 19:45:41,157][413835] Avg episode reward: [(0, '359.518')]
[2025-11-03 19:45:41,280][413835] Saving new best policy, reward=359.518!
[2025-11-03 19:45:46,152][413835] Fps is (10 sec: 3283.5, 60 sec: 3552.5, 300 sec: 3166.4). Total num frames: 1490944. Throughput: 0: 3619.1. Samples: 1491968. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 19:45:46,152][413835] Avg episode reward: [(0, '357.781')]
[2025-11-03 19:45:51,153][413835] Fps is (10 sec: 3277.9, 60 sec: 3547.1, 300 sec: 3166.1). Total num frames: 1507328. Throughput: 0: 3619.3. Samples: 1513984. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 19:45:51,154][413835] Avg episode reward: [(0, '355.632')]
[2025-11-03 19:45:56,137][413835] Fps is (10 sec: 3281.8, 60 sec: 3550.7, 300 sec: 3166.5). Total num frames: 1523712. Throughput: 0: 3624.7. Samples: 1536512. Policy #0 lag: (min: 12.0, avg: 15.0, max: 76.0)
[2025-11-03 19:45:56,137][413835] Avg episode reward: [(0, '361.620')]
[2025-11-03 19:45:56,266][413835] Saving new best policy, reward=361.620!
[2025-11-03 19:46:01,282][413835] Fps is (10 sec: 4043.9, 60 sec: 3679.2, 300 sec: 3192.4). Total num frames: 1548288. Throughput: 0: 3605.7. Samples: 1546752. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 19:46:01,282][413835] Avg episode reward: [(0, '370.228')]
[2025-11-03 19:46:01,626][413835] Saving new best policy, reward=370.228!
[2025-11-03 19:46:06,182][413835] Fps is (10 sec: 4893.1, 60 sec: 3822.0, 300 sec: 3221.4). Total num frames: 1572864. Throughput: 0: 3624.5. Samples: 1569280. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 19:46:06,182][413835] Avg episode reward: [(0, '373.969')]
[2025-11-03 19:46:06,183][413835] Saving new best policy, reward=373.969!
[2025-11-03 19:46:11,114][413835] Fps is (10 sec: 4166.0, 60 sec: 3829.6, 300 sec: 3222.3). Total num frames: 1589248. Throughput: 0: 3650.1. Samples: 1590272. Policy #0 lag: (min: 10.0, avg: 13.0, max: 74.0)
[2025-11-03 19:46:11,114][413835] Avg episode reward: [(0, '384.839')]
[2025-11-03 19:46:11,256][413835] Saving new best policy, reward=384.839!
[2025-11-03 19:46:16,245][413835] Fps is (10 sec: 3256.5, 60 sec: 3679.2, 300 sec: 3220.7). Total num frames: 1605632. Throughput: 0: 3603.9. Samples: 1601536. Policy #0 lag: (min: 10.0, avg: 13.0, max: 74.0)
[2025-11-03 19:46:16,245][413835] Avg episode reward: [(0, '384.285')]
[2025-11-03 19:46:21,203][413835] Fps is (10 sec: 3247.9, 60 sec: 3545.0, 300 sec: 3221.5). Total num frames: 1622016. Throughput: 0: 3638.4. Samples: 1623040. Policy #0 lag: (min: 6.0, avg: 9.0, max: 70.0)
[2025-11-03 19:46:21,203][413835] Avg episode reward: [(0, '384.570')]
[2025-11-03 19:46:26,163][413835] Fps is (10 sec: 3303.7, 60 sec: 3553.7, 300 sec: 3221.9). Total num frames: 1638400. Throughput: 0: 3606.2. Samples: 1644032. Policy #0 lag: (min: 6.0, avg: 9.0, max: 70.0)
[2025-11-03 19:46:26,164][413835] Avg episode reward: [(0, '396.436')]
[2025-11-03 19:46:26,300][413835] Saving new best policy, reward=396.436!
[2025-11-03 19:46:28,183][413835] Signal inference workers to stop experience collection... (300 times)
[2025-11-03 19:46:28,559][413835] InferenceWorker_p0-w0: stopping experience collection (300 times)
[2025-11-03 19:46:28,561][413835] Signal inference workers to resume experience collection... (300 times)
[2025-11-03 19:46:28,683][413835] InferenceWorker_p0-w0: resuming experience collection (300 times)
[2025-11-03 19:46:31,210][413835] Fps is (10 sec: 3274.6, 60 sec: 3549.8, 300 sec: 3193.5). Total num frames: 1654784. Throughput: 0: 3636.2. Samples: 1655808. Policy #0 lag: (min: 9.0, avg: 12.0, max: 73.0)
[2025-11-03 19:46:31,210][413835] Avg episode reward: [(0, '405.076')]
[2025-11-03 19:46:31,337][413835] Saving new best policy, reward=405.076!
[2025-11-03 19:46:36,179][413835] Fps is (10 sec: 3271.7, 60 sec: 3549.5, 300 sec: 3165.3). Total num frames: 1671168. Throughput: 0: 3616.1. Samples: 1676800. Policy #0 lag: (min: 9.0, avg: 12.0, max: 73.0)
[2025-11-03 19:46:36,179][413835] Avg episode reward: [(0, '422.649')]
[2025-11-03 19:46:36,313][413835] Saving new best policy, reward=422.649!
[2025-11-03 19:46:41,175][413835] Fps is (10 sec: 3288.4, 60 sec: 3548.8, 300 sec: 3166.4). Total num frames: 1687552. Throughput: 0: 3615.1. Samples: 1699328. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 19:46:41,175][413835] Avg episode reward: [(0, '425.594')]
[2025-11-03 19:46:41,301][413835] Saving new best policy, reward=425.594!
[2025-11-03 19:46:46,207][413835] Fps is (10 sec: 3267.7, 60 sec: 3546.7, 300 sec: 3165.1). Total num frames: 1703936. Throughput: 0: 3624.2. Samples: 1709568. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 19:46:46,207][413835] Avg episode reward: [(0, '425.649')]
[2025-11-03 19:46:46,574][413835] Saving new best policy, reward=425.649!
[2025-11-03 19:46:51,118][413835] Fps is (10 sec: 4119.3, 60 sec: 3688.6, 300 sec: 3193.9). Total num frames: 1728512. Throughput: 0: 3623.3. Samples: 1732096. Policy #0 lag: (min: 0.0, avg: 3.0, max: 64.0)
[2025-11-03 19:46:51,118][413835] Avg episode reward: [(0, '424.108')]
[2025-11-03 19:46:56,213][413835] Fps is (10 sec: 4911.9, 60 sec: 3818.1, 300 sec: 3221.1). Total num frames: 1753088. Throughput: 0: 3621.5. Samples: 1753600. Policy #0 lag: (min: 6.0, avg: 9.0, max: 70.0)
[2025-11-03 19:46:56,213][413835] Avg episode reward: [(0, '411.774')]
[2025-11-03 19:47:01,201][413835] Fps is (10 sec: 4062.4, 60 sec: 3691.4, 300 sec: 3220.7). Total num frames: 1769472. Throughput: 0: 3610.3. Samples: 1763840. Policy #0 lag: (min: 6.0, avg: 9.0, max: 70.0)
[2025-11-03 19:47:01,201][413835] Avg episode reward: [(0, '422.100')]
[2025-11-03 19:47:06,138][413835] Fps is (10 sec: 3301.7, 60 sec: 3552.5, 300 sec: 3221.7). Total num frames: 1785856. Throughput: 0: 3634.8. Samples: 1786368. Policy #0 lag: (min: 14.0, avg: 17.0, max: 78.0)
[2025-11-03 19:47:06,138][413835] Avg episode reward: [(0, '428.904')]
[2025-11-03 19:47:06,270][413835] Saving new best policy, reward=428.904!
[2025-11-03 19:47:11,166][413835] Fps is (10 sec: 3288.4, 60 sec: 3546.8, 300 sec: 3221.2). Total num frames: 1802240. Throughput: 0: 3618.0. Samples: 1806848. Policy #0 lag: (min: 14.0, avg: 17.0, max: 78.0)
[2025-11-03 19:47:11,166][413835] Avg episode reward: [(0, '453.354')]
[2025-11-03 19:47:11,300][413835] Saving new best policy, reward=453.354!
[2025-11-03 19:47:16,144][413835] Fps is (10 sec: 3274.9, 60 sec: 3555.8, 300 sec: 3221.6). Total num frames: 1818624. Throughput: 0: 3634.8. Samples: 1819136. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 19:47:16,144][413835] Avg episode reward: [(0, '462.340')]
[2025-11-03 19:47:16,267][413835] Saving new best policy, reward=462.340!
[2025-11-03 19:47:21,188][413835] Fps is (10 sec: 3269.3, 60 sec: 3550.7, 300 sec: 3220.5). Total num frames: 1835008. Throughput: 0: 3617.4. Samples: 1839616. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 19:47:21,189][413835] Avg episode reward: [(0, '470.788')]
[2025-11-03 19:47:21,318][413835] Saving new best policy, reward=470.788!
[2025-11-03 19:47:26,113][413835] Fps is (10 sec: 3286.9, 60 sec: 3552.8, 300 sec: 3193.7). Total num frames: 1851392. Throughput: 0: 3623.1. Samples: 1862144. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 19:47:26,113][413835] Avg episode reward: [(0, '469.158')]
[2025-11-03 19:47:31,224][413835] Fps is (10 sec: 3265.3, 60 sec: 3549.1, 300 sec: 3169.7). Total num frames: 1867776. Throughput: 0: 3605.4. Samples: 1871872. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 19:47:31,224][413835] Avg episode reward: [(0, '477.102')]
[2025-11-03 19:47:31,377][413835] Saving /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_lidar_policy4_random_envs_stable_at_goal/checkpoint_p0/checkpoint_000007296_1867776.pth...
[2025-11-03 19:47:31,381][413835] Removing /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_lidar_policy4_random_envs_stable_at_goal/checkpoint_p0/checkpoint_000004224_1081344.pth
[2025-11-03 19:47:31,382][413835] Saving new best policy, reward=477.102!
[2025-11-03 19:47:36,150][413835] Fps is (10 sec: 3264.7, 60 sec: 3551.6, 300 sec: 3221.8). Total num frames: 1884160. Throughput: 0: 3536.0. Samples: 1891328. Policy #0 lag: (min: 2.0, avg: 5.0, max: 66.0)
[2025-11-03 19:47:36,150][413835] Avg episode reward: [(0, '492.532')]
[2025-11-03 19:47:36,282][413835] Saving new best policy, reward=492.532!
[2025-11-03 19:47:41,222][413835] Fps is (10 sec: 3277.3, 60 sec: 3547.1, 300 sec: 3221.4). Total num frames: 1900544. Throughput: 0: 3537.8. Samples: 1912832. Policy #0 lag: (min: 2.0, avg: 5.0, max: 66.0)
[2025-11-03 19:47:41,222][413835] Avg episode reward: [(0, '504.595')]
[2025-11-03 19:47:41,352][413835] Saving new best policy, reward=504.595!
[2025-11-03 19:47:41,969][413835] Signal inference workers to stop experience collection... (350 times)
[2025-11-03 19:47:42,358][413835] InferenceWorker_p0-w0: stopping experience collection (350 times)
[2025-11-03 19:47:42,358][413835] Signal inference workers to resume experience collection... (350 times)
[2025-11-03 19:47:42,358][413835] InferenceWorker_p0-w0: resuming experience collection (350 times)
[2025-11-03 19:47:46,142][413835] Fps is (10 sec: 3279.6, 60 sec: 3553.7, 300 sec: 3222.2). Total num frames: 1916928. Throughput: 0: 3531.7. Samples: 1922560. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 19:47:46,142][413835] Avg episode reward: [(0, '504.278')]
[2025-11-03 19:47:51,164][413835] Fps is (10 sec: 4119.9, 60 sec: 3547.2, 300 sec: 3250.0). Total num frames: 1941504. Throughput: 0: 3513.7. Samples: 1944576. Policy #0 lag: (min: 3.0, avg: 6.0, max: 67.0)
[2025-11-03 19:47:51,164][413835] Avg episode reward: [(0, '506.355')]
[2025-11-03 19:47:51,508][413835] Saving new best policy, reward=506.355!
[2025-11-03 19:47:56,196][413835] Fps is (10 sec: 4888.7, 60 sec: 3550.9, 300 sec: 3277.6). Total num frames: 1966080. Throughput: 0: 3547.5. Samples: 1966592. Policy #0 lag: (min: 3.0, avg: 6.0, max: 67.0)
[2025-11-03 19:47:56,196][413835] Avg episode reward: [(0, '541.965')]
[2025-11-03 19:47:56,330][413835] Saving new best policy, reward=541.965!
[2025-11-03 19:48:01,132][413835] Fps is (10 sec: 4109.0, 60 sec: 3553.9, 300 sec: 3332.5). Total num frames: 1982464. Throughput: 0: 3505.3. Samples: 1976832. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 19:48:01,133][413835] Avg episode reward: [(0, '582.006')]
[2025-11-03 19:48:01,257][413835] Saving new best policy, reward=582.006!
[2025-11-03 19:48:06,174][413835] Fps is (10 sec: 3283.9, 60 sec: 3547.7, 300 sec: 3332.5). Total num frames: 1998848. Throughput: 0: 3539.6. Samples: 1998848. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 19:48:06,174][413835] Avg episode reward: [(0, '605.386')]
[2025-11-03 19:48:06,311][413835] Saving new best policy, reward=605.386!
[2025-11-03 19:48:11,119][413835] Fps is (10 sec: 3281.3, 60 sec: 3552.6, 300 sec: 3332.4). Total num frames: 2015232. Throughput: 0: 3481.2. Samples: 2018816. Policy #0 lag: (min: 6.0, avg: 9.0, max: 70.0)
[2025-11-03 19:48:11,119][413835] Avg episode reward: [(0, '602.032')]
[2025-11-03 19:48:16,164][413835] Fps is (10 sec: 3280.3, 60 sec: 3548.7, 300 sec: 3332.2). Total num frames: 2031616. Throughput: 0: 3531.8. Samples: 2030592. Policy #0 lag: (min: 6.0, avg: 9.0, max: 70.0)
[2025-11-03 19:48:16,164][413835] Avg episode reward: [(0, '590.638')]
[2025-11-03 19:48:21,209][413835] Fps is (10 sec: 3247.4, 60 sec: 3548.6, 300 sec: 3332.9). Total num frames: 2048000. Throughput: 0: 3533.8. Samples: 2050560. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 19:48:21,210][413835] Avg episode reward: [(0, '577.952')]
[2025-11-03 19:48:26,187][413835] Fps is (10 sec: 3269.0, 60 sec: 3545.5, 300 sec: 3335.9). Total num frames: 2064384. Throughput: 0: 3529.8. Samples: 2071552. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 19:48:26,188][413835] Avg episode reward: [(0, '595.468')]
[2025-11-03 19:48:31,124][413835] Fps is (10 sec: 3304.9, 60 sec: 3555.7, 300 sec: 3388.4). Total num frames: 2080768. Throughput: 0: 3539.9. Samples: 2081792. Policy #0 lag: (min: 3.0, avg: 6.0, max: 67.0)
[2025-11-03 19:48:31,125][413835] Avg episode reward: [(0, '624.307')]
[2025-11-03 19:48:31,259][413835] Saving new best policy, reward=624.307!
[2025-11-03 19:48:36,130][413835] Fps is (10 sec: 3295.6, 60 sec: 3551.0, 300 sec: 3387.8). Total num frames: 2097152. Throughput: 0: 3529.7. Samples: 2103296. Policy #0 lag: (min: 3.0, avg: 6.0, max: 67.0)
[2025-11-03 19:48:36,131][413835] Avg episode reward: [(0, '660.871')]
[2025-11-03 19:48:36,261][413835] Saving new best policy, reward=660.871!
[2025-11-03 19:48:41,197][413835] Fps is (10 sec: 3253.1, 60 sec: 3551.3, 300 sec: 3388.0). Total num frames: 2113536. Throughput: 0: 3504.3. Samples: 2124288. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 19:48:41,197][413835] Avg episode reward: [(0, '656.295')]
[2025-11-03 19:48:46,135][413835] Fps is (10 sec: 3275.2, 60 sec: 3550.2, 300 sec: 3387.8). Total num frames: 2129920. Throughput: 0: 3504.1. Samples: 2134528. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 19:48:46,135][413835] Avg episode reward: [(0, '676.436')]
[2025-11-03 19:48:46,275][413835] Saving new best policy, reward=676.436!
[2025-11-03 19:48:51,185][413835] Fps is (10 sec: 3280.9, 60 sec: 3412.2, 300 sec: 3393.4). Total num frames: 2146304. Throughput: 0: 3480.8. Samples: 2155520. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 19:48:51,185][413835] Avg episode reward: [(0, '706.431')]
[2025-11-03 19:48:51,317][413835] Saving new best policy, reward=706.431!
[2025-11-03 19:48:56,118][413835] Fps is (10 sec: 3282.3, 60 sec: 3281.0, 300 sec: 3443.9). Total num frames: 2162688. Throughput: 0: 3515.7. Samples: 2177024. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 19:48:56,119][413835] Avg episode reward: [(0, '736.574')]
[2025-11-03 19:48:56,477][413835] Saving new best policy, reward=736.574!
[2025-11-03 19:49:01,237][413835] Fps is (10 sec: 3259.8, 60 sec: 3271.1, 300 sec: 3443.5). Total num frames: 2179072. Throughput: 0: 3464.6. Samples: 2186752. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 19:49:01,237][413835] Avg episode reward: [(0, '749.360')]
[2025-11-03 19:49:01,610][413835] Saving new best policy, reward=749.360!
[2025-11-03 19:49:01,614][413835] Signal inference workers to stop experience collection... (400 times)
[2025-11-03 19:49:01,615][413835] Signal inference workers to resume experience collection... (400 times)
[2025-11-03 19:49:01,882][413835] InferenceWorker_p0-w0: stopping experience collection (400 times)
[2025-11-03 19:49:01,882][413835] InferenceWorker_p0-w0: resuming experience collection (400 times)
[2025-11-03 19:49:06,188][413835] Fps is (10 sec: 3254.3, 60 sec: 3276.1, 300 sec: 3444.2). Total num frames: 2195456. Throughput: 0: 3437.7. Samples: 2205184. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 19:49:06,188][413835] Avg episode reward: [(0, '719.331')]
[2025-11-03 19:49:11,168][413835] Fps is (10 sec: 3299.6, 60 sec: 3274.1, 300 sec: 3442.7). Total num frames: 2211840. Throughput: 0: 3392.1. Samples: 2224128. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 19:49:11,168][413835] Avg episode reward: [(0, '705.388')]
[2025-11-03 19:49:16,186][413835] Fps is (10 sec: 3277.4, 60 sec: 3275.6, 300 sec: 3472.9). Total num frames: 2228224. Throughput: 0: 3351.9. Samples: 2232832. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 19:49:16,186][413835] Avg episode reward: [(0, '706.911')]
[2025-11-03 19:49:21,250][413835] Fps is (10 sec: 3250.1, 60 sec: 3274.6, 300 sec: 3499.1). Total num frames: 2244608. Throughput: 0: 3279.5. Samples: 2251264. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 19:49:21,250][413835] Avg episode reward: [(0, '726.201')]
[2025-11-03 19:49:26,184][413835] Fps is (10 sec: 3277.4, 60 sec: 3277.0, 300 sec: 3498.2). Total num frames: 2260992. Throughput: 0: 3232.2. Samples: 2269696. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 19:49:26,184][413835] Avg episode reward: [(0, '768.286')]
[2025-11-03 19:49:26,328][413835] Saving new best policy, reward=768.286!
[2025-11-03 19:49:31,167][413835] Fps is (10 sec: 3304.3, 60 sec: 3274.5, 300 sec: 3499.8). Total num frames: 2277376. Throughput: 0: 3194.9. Samples: 2278400. Policy #0 lag: (min: 12.0, avg: 15.0, max: 76.0)
[2025-11-03 19:49:31,167][413835] Avg episode reward: [(0, '775.919')]
[2025-11-03 19:49:31,312][413835] Saving /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_lidar_policy4_random_envs_stable_at_goal/checkpoint_p0/checkpoint_000008896_2277376.pth...
[2025-11-03 19:49:31,315][413835] Removing /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_lidar_policy4_random_envs_stable_at_goal/checkpoint_p0/checkpoint_000005632_1441792.pth
[2025-11-03 19:49:31,316][413835] Saving new best policy, reward=775.919!
[2025-11-03 19:49:36,139][413835] Fps is (10 sec: 3291.8, 60 sec: 3276.4, 300 sec: 3499.5). Total num frames: 2293760. Throughput: 0: 3154.9. Samples: 2297344. Policy #0 lag: (min: 12.0, avg: 15.0, max: 76.0)
[2025-11-03 19:49:36,139][413835] Avg episode reward: [(0, '800.854')]
[2025-11-03 19:49:36,303][413835] Saving new best policy, reward=800.854!
[2025-11-03 19:49:41,157][413835] Fps is (10 sec: 3279.8, 60 sec: 3279.0, 300 sec: 3499.4). Total num frames: 2310144. Throughput: 0: 3080.7. Samples: 2315776. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 19:49:41,157][413835] Avg episode reward: [(0, '800.412')]
[2025-11-03 19:49:46,151][413835] Fps is (10 sec: 3272.6, 60 sec: 3275.9, 300 sec: 3498.4). Total num frames: 2326528. Throughput: 0: 3100.6. Samples: 2326016. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 19:49:46,152][413835] Avg episode reward: [(0, '797.850')]
[2025-11-03 19:49:51,190][413835] Fps is (10 sec: 3266.0, 60 sec: 3276.5, 300 sec: 3498.5). Total num frames: 2342912. Throughput: 0: 3083.2. Samples: 2343936. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 19:49:51,191][413835] Avg episode reward: [(0, '800.083')]
[2025-11-03 19:49:56,191][413835] Fps is (10 sec: 3263.8, 60 sec: 3272.8, 300 sec: 3498.6). Total num frames: 2359296. Throughput: 0: 3059.0. Samples: 2361856. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 19:49:56,191][413835] Avg episode reward: [(0, '828.257')]
[2025-11-03 19:49:56,352][413835] Saving new best policy, reward=828.257!
[2025-11-03 19:50:01,151][413835] Fps is (10 sec: 3289.6, 60 sec: 3281.5, 300 sec: 3499.2). Total num frames: 2375680. Throughput: 0: 3085.8. Samples: 2371584. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 19:50:01,152][413835] Avg episode reward: [(0, '869.118')]
[2025-11-03 19:50:01,311][413835] Saving new best policy, reward=869.118!
[2025-11-03 19:50:06,130][413835] Fps is (10 sec: 3297.0, 60 sec: 3280.0, 300 sec: 3500.0). Total num frames: 2392064. Throughput: 0: 3103.0. Samples: 2390528. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 19:50:06,130][413835] Avg episode reward: [(0, '893.464')]
[2025-11-03 19:50:06,288][413835] Saving new best policy, reward=893.464!
[2025-11-03 19:50:11,144][413835] Fps is (10 sec: 3279.2, 60 sec: 3278.1, 300 sec: 3471.0). Total num frames: 2408448. Throughput: 0: 3097.5. Samples: 2408960. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 19:50:11,144][413835] Avg episode reward: [(0, '896.638')]
[2025-11-03 19:50:11,146][413835] Saving new best policy, reward=896.638!
[2025-11-03 19:50:16,426][413835] Fps is (10 sec: 3182.4, 60 sec: 3263.7, 300 sec: 3439.8). Total num frames: 2424832. Throughput: 0: 3077.0. Samples: 2417664. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 19:50:16,427][413835] Avg episode reward: [(0, '888.298')]
[2025-11-03 19:50:21,362][413835] Fps is (10 sec: 2405.3, 60 sec: 3134.4, 300 sec: 3414.1). Total num frames: 2433024. Throughput: 0: 3079.5. Samples: 2436608. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 19:50:21,362][413835] Avg episode reward: [(0, '884.858')]
[2025-11-03 19:50:26,236][413835] Fps is (10 sec: 1670.2, 60 sec: 3001.2, 300 sec: 3387.6). Total num frames: 2441216. Throughput: 0: 3100.7. Samples: 2455552. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 19:50:26,236][413835] Avg episode reward: [(0, '895.459')]
[2025-11-03 19:50:31,185][413835] Fps is (10 sec: 2501.9, 60 sec: 3002.8, 300 sec: 3387.7). Total num frames: 2457600. Throughput: 0: 3069.7. Samples: 2464256. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 19:50:31,185][413835] Avg episode reward: [(0, '922.507')]
[2025-11-03 19:50:31,346][413835] Saving new best policy, reward=922.507!
[2025-11-03 19:50:31,526][413835] Signal inference workers to stop experience collection... (450 times)
[2025-11-03 19:50:31,898][413835] InferenceWorker_p0-w0: stopping experience collection (450 times)
[2025-11-03 19:50:31,900][413835] Signal inference workers to resume experience collection... (450 times)
[2025-11-03 19:50:32,058][413835] InferenceWorker_p0-w0: resuming experience collection (450 times)
[2025-11-03 19:50:36,229][413835] Fps is (10 sec: 3279.2, 60 sec: 2999.2, 300 sec: 3387.1). Total num frames: 2473984. Throughput: 0: 3080.8. Samples: 2482688. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 19:50:36,229][413835] Avg episode reward: [(0, '910.755')]
[2025-11-03 19:50:41,131][413835] Fps is (10 sec: 3294.4, 60 sec: 3005.0, 300 sec: 3388.1). Total num frames: 2490368. Throughput: 0: 3110.3. Samples: 2501632. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 19:50:41,131][413835] Avg episode reward: [(0, '908.789')]
[2025-11-03 19:50:46,114][413835] Fps is (10 sec: 3314.7, 60 sec: 3005.6, 300 sec: 3388.3). Total num frames: 2506752. Throughput: 0: 3085.9. Samples: 2510336. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 19:50:46,114][413835] Avg episode reward: [(0, '926.250')]
[2025-11-03 19:50:46,276][413835] Saving new best policy, reward=926.250!
[2025-11-03 19:50:51,213][413835] Fps is (10 sec: 3250.3, 60 sec: 3002.6, 300 sec: 3387.0). Total num frames: 2523136. Throughput: 0: 3066.3. Samples: 2528768. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 19:50:51,213][413835] Avg episode reward: [(0, '960.900')]
[2025-11-03 19:50:51,364][413835] Saving new best policy, reward=960.900!
[2025-11-03 19:50:56,146][413835] Fps is (10 sec: 3266.4, 60 sec: 3006.0, 300 sec: 3361.7). Total num frames: 2539520. Throughput: 0: 3094.6. Samples: 2548224. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 19:50:56,146][413835] Avg episode reward: [(0, '954.577')]
[2025-11-03 19:51:01,114][413835] Fps is (10 sec: 3309.4, 60 sec: 3005.6, 300 sec: 3333.1). Total num frames: 2555904. Throughput: 0: 3139.3. Samples: 2557952. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 19:51:01,114][413835] Avg episode reward: [(0, '968.846')]
[2025-11-03 19:51:01,244][413835] Saving new best policy, reward=968.846!
[2025-11-03 19:51:06,165][413835] Fps is (10 sec: 3270.6, 60 sec: 3002.0, 300 sec: 3331.8). Total num frames: 2572288. Throughput: 0: 3199.7. Samples: 2579968. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 19:51:06,165][413835] Avg episode reward: [(0, '963.325')]
[2025-11-03 19:51:11,197][413835] Fps is (10 sec: 3249.9, 60 sec: 3001.1, 300 sec: 3332.9). Total num frames: 2588672. Throughput: 0: 3234.1. Samples: 2600960. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 19:51:11,197][413835] Avg episode reward: [(0, '993.555')]
[2025-11-03 19:51:11,330][413835] Saving new best policy, reward=993.555!
[2025-11-03 19:51:16,115][413835] Fps is (10 sec: 3293.4, 60 sec: 3019.4, 300 sec: 3333.3). Total num frames: 2605056. Throughput: 0: 3270.5. Samples: 2611200. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 19:51:16,115][413835] Avg episode reward: [(0, '976.538')]
[2025-11-03 19:51:21,445][413835] Fps is (10 sec: 4796.2, 60 sec: 3408.6, 300 sec: 3384.6). Total num frames: 2637824. Throughput: 0: 3329.1. Samples: 2633216. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 19:51:21,445][413835] Avg episode reward: [(0, '989.097')]
[2025-11-03 19:51:26,192][413835] Fps is (10 sec: 4877.3, 60 sec: 3552.4, 300 sec: 3388.1). Total num frames: 2654208. Throughput: 0: 3397.3. Samples: 2654720. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 19:51:26,193][413835] Avg episode reward: [(0, '948.739')]
[2025-11-03 19:51:31,142][413835] Fps is (10 sec: 3379.0, 60 sec: 3552.4, 300 sec: 3388.3). Total num frames: 2670592. Throughput: 0: 3422.6. Samples: 2664448. Policy #0 lag: (min: 8.0, avg: 11.0, max: 72.0)
[2025-11-03 19:51:31,143][413835] Avg episode reward: [(0, '968.559')]
[2025-11-03 19:51:31,276][413835] Saving /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_lidar_policy4_random_envs_stable_at_goal/checkpoint_p0/checkpoint_000010432_2670592.pth...
[2025-11-03 19:51:31,280][413835] Removing /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_lidar_policy4_random_envs_stable_at_goal/checkpoint_p0/checkpoint_000007296_1867776.pth
[2025-11-03 19:51:36,198][413835] Fps is (10 sec: 3275.0, 60 sec: 3551.7, 300 sec: 3387.6). Total num frames: 2686976. Throughput: 0: 3494.1. Samples: 2685952. Policy #0 lag: (min: 8.0, avg: 11.0, max: 72.0)
[2025-11-03 19:51:36,198][413835] Avg episode reward: [(0, '964.755')]
[2025-11-03 19:51:41,204][413835] Fps is (10 sec: 3256.9, 60 sec: 3545.6, 300 sec: 3387.9). Total num frames: 2703360. Throughput: 0: 3499.9. Samples: 2705920. Policy #0 lag: (min: 2.0, avg: 5.0, max: 66.0)
[2025-11-03 19:51:41,204][413835] Avg episode reward: [(0, '961.875')]
[2025-11-03 19:51:46,239][413835] Fps is (10 sec: 3263.4, 60 sec: 3542.5, 300 sec: 3358.7). Total num frames: 2719744. Throughput: 0: 3540.1. Samples: 2717696. Policy #0 lag: (min: 2.0, avg: 5.0, max: 66.0)
[2025-11-03 19:51:46,239][413835] Avg episode reward: [(0, '967.187')]
[2025-11-03 19:51:49,144][413835] Signal inference workers to stop experience collection... (500 times)
[2025-11-03 19:51:49,502][413835] InferenceWorker_p0-w0: stopping experience collection (500 times)
[2025-11-03 19:51:49,503][413835] Signal inference workers to resume experience collection... (500 times)
[2025-11-03 19:51:49,503][413835] InferenceWorker_p0-w0: resuming experience collection (500 times)
[2025-11-03 19:51:51,198][413835] Fps is (10 sec: 3278.7, 60 sec: 3550.7, 300 sec: 3332.5). Total num frames: 2736128. Throughput: 0: 3490.4. Samples: 2737152. Policy #0 lag: (min: 2.0, avg: 5.0, max: 66.0)
[2025-11-03 19:51:51,198][413835] Avg episode reward: [(0, '966.984')]
[2025-11-03 19:51:56,125][413835] Fps is (10 sec: 3314.5, 60 sec: 3551.1, 300 sec: 3333.2). Total num frames: 2752512. Throughput: 0: 3510.0. Samples: 2758656. Policy #0 lag: (min: 2.0, avg: 5.0, max: 66.0)
[2025-11-03 19:51:56,125][413835] Avg episode reward: [(0, '946.616')]
[2025-11-03 19:52:01,175][413835] Fps is (10 sec: 3284.4, 60 sec: 3546.3, 300 sec: 3331.9). Total num frames: 2768896. Throughput: 0: 3488.3. Samples: 2768384. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 19:52:01,175][413835] Avg episode reward: [(0, '964.916')]
[2025-11-03 19:52:06,117][413835] Fps is (10 sec: 3279.5, 60 sec: 3552.7, 300 sec: 3332.9). Total num frames: 2785280. Throughput: 0: 3427.0. Samples: 2786304. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-03 19:52:06,117][413835] Avg episode reward: [(0, '948.799')]
[2025-11-03 19:52:11,256][413835] Fps is (10 sec: 3250.5, 60 sec: 3546.4, 300 sec: 3331.1). Total num frames: 2801664. Throughput: 0: 3329.0. Samples: 2804736. Policy #0 lag: (min: 10.0, avg: 13.0, max: 74.0)
[2025-11-03 19:52:11,256][413835] Avg episode reward: [(0, '961.798')]
[2025-11-03 19:52:16,129][413835] Fps is (10 sec: 3272.7, 60 sec: 3549.0, 300 sec: 3333.0). Total num frames: 2818048. Throughput: 0: 3334.7. Samples: 2814464. Policy #0 lag: (min: 10.0, avg: 13.0, max: 74.0)
[2025-11-03 19:52:16,129][413835] Avg episode reward: [(0, '935.841')]
[2025-11-03 19:52:21,170][413835] Fps is (10 sec: 3305.0, 60 sec: 3291.9, 300 sec: 3331.7). Total num frames: 2834432. Throughput: 0: 3290.2. Samples: 2833920. Policy #0 lag: (min: 8.0, avg: 11.0, max: 72.0)
[2025-11-03 19:52:21,171][413835] Avg episode reward: [(0, '960.030')]
[2025-11-03 19:52:26,227][413835] Fps is (10 sec: 3245.1, 60 sec: 3274.9, 300 sec: 3332.3). Total num frames: 2850816. Throughput: 0: 3263.8. Samples: 2852864. Policy #0 lag: (min: 8.0, avg: 11.0, max: 72.0)
[2025-11-03 19:52:26,227][413835] Avg episode reward: [(0, '997.451')]
[2025-11-03 19:52:26,359][413835] Saving new best policy, reward=997.451!
[2025-11-03 19:52:31,221][413835] Fps is (10 sec: 3260.3, 60 sec: 3272.5, 300 sec: 3331.5). Total num frames: 2867200. Throughput: 0: 3266.7. Samples: 2864640. Policy #0 lag: (min: 11.0, avg: 14.0, max: 75.0)
[2025-11-03 19:52:31,221][413835] Avg episode reward: [(0, '1044.339')]
[2025-11-03 19:52:31,355][413835] Saving new best policy, reward=1044.339!
[2025-11-03 19:52:36,231][413835] Fps is (10 sec: 3275.2, 60 sec: 3275.0, 300 sec: 3332.2). Total num frames: 2883584. Throughput: 0: 3274.4. Samples: 2884608. Policy #0 lag: (min: 11.0, avg: 14.0, max: 75.0)
[2025-11-03 19:52:36,232][413835] Avg episode reward: [(0, '1020.751')]
