[2025-11-09 20:17:22,060][12634] Saving configuration to /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_lidar_policy6_vel_ttc_yaw/config.json...
[2025-11-09 20:17:22,091][12634] Using GPUs [0] for process 0 (actually maps to GPUs [0])
[2025-11-09 20:17:22,091][12634] Rollout worker 0 uses device cuda:0
[2025-11-09 20:17:22,133][12634] Using GPUs [0] for process 0 (actually maps to GPUs [0])
[2025-11-09 20:17:22,133][12634] InferenceWorker_p0-w0: min num requests: 1
[2025-11-09 20:17:22,134][12634] Using GPUs [0] for process 0 (actually maps to GPUs [0])
[2025-11-09 20:17:22,134][12634] Starting seed is not provided
[2025-11-09 20:17:22,134][12634] Using GPUs [0] for process 0 (actually maps to GPUs [0])
[2025-11-09 20:17:22,134][12634] Initializing actor-critic model on device cuda:0
[2025-11-09 20:17:22,134][12634] RunningMeanStd input shape: (337,)
[2025-11-09 20:17:22,135][12634] RunningMeanStd input shape: (1,)
[2025-11-09 20:17:22,145][12634] Created Actor Critic model with architecture:
[2025-11-09 20:17:22,145][12634] ActorCriticSharedWeights(
  (obs_normalizer): ObservationNormalizer(
    (running_mean_std): RunningMeanStdDictInPlace(
      (running_mean_std): ModuleDict(
        (observations): RunningMeanStdInPlace()
      )
    )
  )
  (returns_normalizer): RecursiveScriptModule(original_name=RunningMeanStdInPlace)
  (encoder): CustomEncoder(
    (encoders): ModuleDict(
      (obs_image): Sequential(
        (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): ELU(alpha=1.0)
        (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
        (3): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (4): ELU(alpha=1.0)
        (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
        (6): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (7): ELU(alpha=1.0)
        (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        (9): Flatten(start_dim=1, end_dim=-1)
      )
    )
    (mlp_head_custom): Sequential(
      (0): Linear(in_features=145, out_features=256, bias=True)
      (1): ELU(alpha=1.0)
      (2): Linear(in_features=256, out_features=128, bias=True)
      (3): ELU(alpha=1.0)
      (4): Linear(in_features=128, out_features=64, bias=True)
      (5): ELU(alpha=1.0)
    )
  )
  (core): ModelCoreRNN(
    (core): GRU(64, 128)
  )
  (decoder): MlpDecoder(
    (mlp): Identity()
  )
  (critic_linear): Linear(in_features=128, out_features=1, bias=True)
  (action_parameterization): ActionParameterizationDefault(
    (distribution_linear): Linear(in_features=128, out_features=8, bias=True)
  )
)
[2025-11-09 20:17:22,522][12634] Using optimizer <class 'torch.optim.adam.Adam'>
[2025-11-09 20:17:22,522][12634] No checkpoints found
[2025-11-09 20:17:22,522][12634] Did not load from checkpoint, starting from scratch!
[2025-11-09 20:17:22,522][12634] Initialized policy 0 weights for model version 0
[2025-11-09 20:17:22,522][12634] LearnerWorker_p0 finished initialization!
[2025-11-09 20:17:22,523][12634] Using GPUs [0] for process 0 (actually maps to GPUs [0])
[2025-11-09 20:17:22,529][12634] Fps is (10 sec: nan, 60 sec: nan, 300 sec: nan). Total num frames: 0. Throughput: 0: nan. Samples: 0. Policy #0 lag: (min: -1.0, avg: -1.0, max: -1.0)
[2025-11-09 20:17:22,529][12634] Inference worker 0-0 is ready!
[2025-11-09 20:17:22,529][12634] All inference workers are ready! Signal rollout workers to start!
[2025-11-09 20:17:22,529][12634] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 0.0). Total num frames: 0. Throughput: 0: 0.0. Samples: 0. Policy #0 lag: (min: -1.0, avg: -1.0, max: -1.0)
[2025-11-09 20:17:22,530][12634] EnvRunner 0-0 uses policy 0
[2025-11-09 20:17:35,631][12634] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 0.0). Total num frames: 0. Throughput: 0: 0.0. Samples: 0. Policy #0 lag: (min: -1.0, avg: -1.0, max: -1.0)
[2025-11-09 20:17:39,601][12634] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 0.0). Total num frames: 0. Throughput: 0: 0.0. Samples: 0. Policy #0 lag: (min: -1.0, avg: -1.0, max: -1.0)
[2025-11-09 20:17:39,704][12634] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 0.0). Total num frames: 0. Throughput: 0: 29.8. Samples: 512. Policy #0 lag: (min: -1.0, avg: -1.0, max: -1.0)
[2025-11-09 20:17:39,704][12634] Avg episode reward: [(0, '-10.000')]
[2025-11-09 20:17:40,903][12634] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 0.0). Total num frames: 0. Throughput: 0: 55.7. Samples: 1024. Policy #0 lag: (min: -1.0, avg: -1.0, max: -1.0)
[2025-11-09 20:17:40,903][12634] Avg episode reward: [(0, '-10.000')]
[2025-11-09 20:17:42,364][12634] Heartbeat connected on Batcher_0
[2025-11-09 20:17:42,364][12634] Heartbeat connected on LearnerWorker_p0
[2025-11-09 20:17:42,364][12634] Heartbeat connected on InferenceWorker_p0-w0
[2025-11-09 20:17:42,364][12634] Heartbeat connected on RolloutWorker_w0
[2025-11-09 20:17:45,155][12634] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 0.0). Total num frames: 0. Throughput: 0: 316.8. Samples: 7168. Policy #0 lag: (min: -1.0, avg: -1.0, max: -1.0)
[2025-11-09 20:17:45,155][12634] Avg episode reward: [(0, '-11.001')]
[2025-11-09 20:17:46,688][12634] Signal inference workers to stop experience collection...
[2025-11-09 20:17:48,016][12634] InferenceWorker_p0-w0: stopping experience collection
[2025-11-09 20:17:48,018][12634] Signal inference workers to resume experience collection...
[2025-11-09 20:17:48,172][12634] InferenceWorker_p0-w0: resuming experience collection
[2025-11-09 20:17:50,058][12634] Fps is (10 sec: 1789.6, 60 sec: 595.2, 300 sec: 595.2). Total num frames: 16384. Throughput: 0: 799.7. Samples: 22016. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[2025-11-09 20:17:50,058][12634] Avg episode reward: [(0, '-12.772')]
[2025-11-09 20:17:55,119][12634] Fps is (10 sec: 3288.7, 60 sec: 1005.5, 300 sec: 1005.5). Total num frames: 32768. Throughput: 0: 989.8. Samples: 32256. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-09 20:17:55,119][12634] Avg episode reward: [(0, '-13.286')]
[2025-11-09 20:18:00,052][12634] Fps is (10 sec: 3278.6, 60 sec: 1309.9, 300 sec: 1309.9). Total num frames: 49152. Throughput: 0: 1337.2. Samples: 50176. Policy #0 lag: (min: 9.0, avg: 12.0, max: 73.0)
[2025-11-09 20:18:00,052][12634] Avg episode reward: [(0, '8.872')]
[2025-11-09 20:18:05,065][12634] Fps is (10 sec: 3294.7, 60 sec: 1540.7, 300 sec: 1540.7). Total num frames: 65536. Throughput: 0: 1588.9. Samples: 67584. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-09 20:18:05,065][12634] Avg episode reward: [(0, '11.995')]
[2025-11-09 20:18:10,190][12634] Fps is (10 sec: 3232.2, 60 sec: 1718.8, 300 sec: 1718.8). Total num frames: 81920. Throughput: 0: 2237.1. Samples: 77312. Policy #0 lag: (min: 0.0, avg: 3.0, max: 64.0)
[2025-11-09 20:18:10,190][12634] Avg episode reward: [(0, '5.611')]
[2025-11-09 20:18:15,152][12634] Fps is (10 sec: 3248.3, 60 sec: 1868.1, 300 sec: 1868.1). Total num frames: 98304. Throughput: 0: 2779.5. Samples: 98816. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-09 20:18:15,152][12634] Avg episode reward: [(0, '-1.145')]
[2025-11-09 20:18:20,128][12634] Fps is (10 sec: 3297.3, 60 sec: 1991.2, 300 sec: 1991.1). Total num frames: 114688. Throughput: 0: 2849.8. Samples: 115712. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-09 20:18:20,128][12634] Avg episode reward: [(0, '14.931')]
[2025-11-09 20:18:20,268][12634] Saving new best policy, reward=14.931!
[2025-11-09 20:18:25,143][12634] Fps is (10 sec: 3280.0, 60 sec: 2647.3, 300 sec: 2093.3). Total num frames: 131072. Throughput: 0: 2835.5. Samples: 126464. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-09 20:18:25,143][12634] Avg episode reward: [(0, '14.363')]
[2025-11-09 20:18:30,099][12634] Fps is (10 sec: 3286.3, 60 sec: 2920.0, 300 sec: 2182.3). Total num frames: 147456. Throughput: 0: 3144.2. Samples: 148480. Policy #0 lag: (min: 8.0, avg: 11.0, max: 72.0)
[2025-11-09 20:18:30,099][12634] Avg episode reward: [(0, '6.646')]
[2025-11-09 20:18:35,083][12634] Fps is (10 sec: 3296.5, 60 sec: 2958.5, 300 sec: 2258.2). Total num frames: 163840. Throughput: 0: 3240.9. Samples: 167936. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-09 20:18:35,083][12634] Avg episode reward: [(0, '22.873')]
[2025-11-09 20:18:35,242][12634] Saving new best policy, reward=22.873!
[2025-11-09 20:18:40,094][12634] Fps is (10 sec: 3278.5, 60 sec: 3044.8, 300 sec: 2323.5). Total num frames: 180224. Throughput: 0: 3233.1. Samples: 177664. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-09 20:18:40,094][12634] Avg episode reward: [(0, '27.404')]
[2025-11-09 20:18:40,255][12634] Saving new best policy, reward=27.404!
[2025-11-09 20:18:45,153][12634] Fps is (10 sec: 3253.9, 60 sec: 3276.9, 300 sec: 2379.5). Total num frames: 196608. Throughput: 0: 3246.8. Samples: 196608. Policy #0 lag: (min: 0.0, avg: 3.0, max: 64.0)
[2025-11-09 20:18:45,153][12634] Avg episode reward: [(0, '25.548')]
[2025-11-09 20:18:50,149][12634] Fps is (10 sec: 3258.7, 60 sec: 3271.8, 300 sec: 2430.8). Total num frames: 212992. Throughput: 0: 3270.6. Samples: 215040. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-09 20:18:50,150][12634] Avg episode reward: [(0, '41.098')]
[2025-11-09 20:18:50,291][12634] Saving new best policy, reward=41.098!
[2025-11-09 20:18:55,115][12634] Fps is (10 sec: 3289.5, 60 sec: 3277.0, 300 sec: 2477.4). Total num frames: 229376. Throughput: 0: 3327.9. Samples: 226816. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-09 20:18:55,115][12634] Avg episode reward: [(0, '49.415')]
[2025-11-09 20:18:55,247][12634] Saving new best policy, reward=49.415!
[2025-11-09 20:19:00,050][12634] Fps is (10 sec: 3309.5, 60 sec: 3276.9, 300 sec: 2520.1). Total num frames: 245760. Throughput: 0: 3295.6. Samples: 246784. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-09 20:19:00,051][12634] Avg episode reward: [(0, '51.942')]
[2025-11-09 20:19:00,184][12634] Saving new best policy, reward=51.942!
[2025-11-09 20:19:05,069][12634] Fps is (10 sec: 3291.6, 60 sec: 3276.5, 300 sec: 2556.5). Total num frames: 262144. Throughput: 0: 3383.6. Samples: 267776. Policy #0 lag: (min: 12.0, avg: 15.0, max: 76.0)
[2025-11-09 20:19:05,070][12634] Avg episode reward: [(0, '68.354')]
[2025-11-09 20:19:05,205][12634] Saving /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_lidar_policy6_vel_ttc_yaw/checkpoint_p0/checkpoint_000001024_262144.pth...
[2025-11-09 20:19:05,209][12634] Saving new best policy, reward=68.354!
[2025-11-09 20:19:07,802][12634] Signal inference workers to stop experience collection... (50 times)
[2025-11-09 20:19:08,155][12634] InferenceWorker_p0-w0: stopping experience collection (50 times)
[2025-11-09 20:19:08,155][12634] Signal inference workers to resume experience collection... (50 times)
[2025-11-09 20:19:08,155][12634] InferenceWorker_p0-w0: resuming experience collection (50 times)
[2025-11-09 20:19:10,121][12634] Fps is (10 sec: 3254.0, 60 sec: 3280.6, 300 sec: 2588.7). Total num frames: 278528. Throughput: 0: 3403.6. Samples: 279552. Policy #0 lag: (min: 7.0, avg: 10.0, max: 71.0)
[2025-11-09 20:19:10,121][12634] Avg episode reward: [(0, '76.299')]
[2025-11-09 20:19:10,249][12634] Saving new best policy, reward=76.299!
[2025-11-09 20:19:15,098][12634] Fps is (10 sec: 3267.4, 60 sec: 3279.8, 300 sec: 2619.8). Total num frames: 294912. Throughput: 0: 3322.4. Samples: 297984. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-09 20:19:15,098][12634] Avg episode reward: [(0, '85.284')]
[2025-11-09 20:19:15,253][12634] Saving new best policy, reward=85.284!
[2025-11-09 20:19:20,168][12634] Fps is (10 sec: 3261.3, 60 sec: 3274.6, 300 sec: 2646.2). Total num frames: 311296. Throughput: 0: 3338.7. Samples: 318464. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-09 20:19:20,168][12634] Avg episode reward: [(0, '97.118')]
[2025-11-09 20:19:20,298][12634] Saving new best policy, reward=97.118!
[2025-11-09 20:19:25,145][12634] Fps is (10 sec: 3261.6, 60 sec: 3276.7, 300 sec: 2672.4). Total num frames: 327680. Throughput: 0: 3352.7. Samples: 328704. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-09 20:19:25,145][12634] Avg episode reward: [(0, '106.299')]
[2025-11-09 20:19:25,278][12634] Saving new best policy, reward=106.299!
[2025-11-09 20:19:30,095][12634] Fps is (10 sec: 3300.8, 60 sec: 3277.0, 300 sec: 2697.1). Total num frames: 344064. Throughput: 0: 3406.3. Samples: 349696. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-09 20:19:30,096][12634] Avg episode reward: [(0, '109.532')]
[2025-11-09 20:19:30,223][12634] Saving new best policy, reward=109.532!
[2025-11-09 20:19:35,099][12634] Fps is (10 sec: 3292.0, 60 sec: 3275.9, 300 sec: 2718.9). Total num frames: 360448. Throughput: 0: 3474.1. Samples: 371200. Policy #0 lag: (min: 0.0, avg: 3.0, max: 64.0)
[2025-11-09 20:19:35,099][12634] Avg episode reward: [(0, '114.969')]
[2025-11-09 20:19:35,232][12634] Saving new best policy, reward=114.969!
[2025-11-09 20:19:40,156][12634] Fps is (10 sec: 3256.9, 60 sec: 3273.4, 300 sec: 2738.1). Total num frames: 376832. Throughput: 0: 3421.5. Samples: 380928. Policy #0 lag: (min: 9.0, avg: 12.0, max: 73.0)
[2025-11-09 20:19:40,157][12634] Avg episode reward: [(0, '121.037')]
[2025-11-09 20:19:40,315][12634] Saving new best policy, reward=121.037!
[2025-11-09 20:19:45,155][12634] Fps is (10 sec: 3258.3, 60 sec: 3276.7, 300 sec: 2757.0). Total num frames: 393216. Throughput: 0: 3405.4. Samples: 400384. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-09 20:19:45,156][12634] Avg episode reward: [(0, '126.711')]
[2025-11-09 20:19:45,309][12634] Saving new best policy, reward=126.711!
[2025-11-09 20:19:50,130][12634] Fps is (10 sec: 3285.5, 60 sec: 3277.9, 300 sec: 2775.0). Total num frames: 409600. Throughput: 0: 3351.9. Samples: 418816. Policy #0 lag: (min: 10.0, avg: 13.0, max: 74.0)
[2025-11-09 20:19:50,130][12634] Avg episode reward: [(0, '131.869')]
[2025-11-09 20:19:50,284][12634] Saving new best policy, reward=131.869!
[2025-11-09 20:19:55,055][12634] Fps is (10 sec: 3310.0, 60 sec: 3280.0, 300 sec: 2792.9). Total num frames: 425984. Throughput: 0: 3281.6. Samples: 427008. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-09 20:19:55,055][12634] Avg episode reward: [(0, '134.673')]
[2025-11-09 20:19:55,220][12634] Saving new best policy, reward=134.673!
[2025-11-09 20:20:00,136][12634] Fps is (10 sec: 3275.0, 60 sec: 3272.2, 300 sec: 2806.8). Total num frames: 442368. Throughput: 0: 3274.1. Samples: 445440. Policy #0 lag: (min: 13.0, avg: 16.0, max: 77.0)
[2025-11-09 20:20:00,136][12634] Avg episode reward: [(0, '133.134')]
[2025-11-09 20:20:05,103][12634] Fps is (10 sec: 3261.2, 60 sec: 3275.0, 300 sec: 2821.8). Total num frames: 458752. Throughput: 0: 3281.6. Samples: 465920. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-09 20:20:05,103][12634] Avg episode reward: [(0, '135.732')]
[2025-11-09 20:20:05,255][12634] Saving new best policy, reward=135.732!
[2025-11-09 20:20:10,083][12634] Fps is (10 sec: 3294.2, 60 sec: 3278.9, 300 sec: 2835.7). Total num frames: 475136. Throughput: 0: 3281.3. Samples: 476160. Policy #0 lag: (min: 11.0, avg: 14.0, max: 75.0)
[2025-11-09 20:20:10,083][12634] Avg episode reward: [(0, '138.911')]
[2025-11-09 20:20:10,213][12634] Saving new best policy, reward=138.911!
[2025-11-09 20:20:15,122][12634] Fps is (10 sec: 3270.4, 60 sec: 3275.5, 300 sec: 2847.8). Total num frames: 491520. Throughput: 0: 3252.1. Samples: 496128. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-09 20:20:15,123][12634] Avg episode reward: [(0, '144.273')]
[2025-11-09 20:20:15,255][12634] Saving new best policy, reward=144.273!
[2025-11-09 20:20:20,118][12634] Fps is (10 sec: 3265.4, 60 sec: 3279.6, 300 sec: 2860.0). Total num frames: 507904. Throughput: 0: 3264.0. Samples: 518144. Policy #0 lag: (min: 3.0, avg: 6.0, max: 67.0)
[2025-11-09 20:20:20,118][12634] Avg episode reward: [(0, '146.661')]
[2025-11-09 20:20:20,260][12634] Saving new best policy, reward=146.661!
[2025-11-09 20:20:25,089][12634] Fps is (10 sec: 3287.7, 60 sec: 3279.8, 300 sec: 2871.9). Total num frames: 524288. Throughput: 0: 3258.9. Samples: 527360. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-09 20:20:25,090][12634] Avg episode reward: [(0, '145.527')]
[2025-11-09 20:20:30,058][12634] Fps is (10 sec: 3296.5, 60 sec: 3278.9, 300 sec: 2883.1). Total num frames: 540672. Throughput: 0: 3306.7. Samples: 548864. Policy #0 lag: (min: 9.0, avg: 12.0, max: 73.0)
[2025-11-09 20:20:30,058][12634] Avg episode reward: [(0, '145.979')]
[2025-11-09 20:20:31,188][12634] Signal inference workers to stop experience collection... (100 times)
[2025-11-09 20:20:31,191][12634] Signal inference workers to resume experience collection... (100 times)
[2025-11-09 20:20:31,428][12634] InferenceWorker_p0-w0: stopping experience collection (100 times)
[2025-11-09 20:20:31,428][12634] InferenceWorker_p0-w0: resuming experience collection (100 times)
[2025-11-09 20:20:35,180][12634] Fps is (10 sec: 3247.3, 60 sec: 3272.4, 300 sec: 2891.5). Total num frames: 557056. Throughput: 0: 3364.1. Samples: 570368. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-09 20:20:35,180][12634] Avg episode reward: [(0, '151.817')]
[2025-11-09 20:20:35,184][12634] Saving new best policy, reward=151.817!
[2025-11-09 20:20:40,051][12634] Fps is (10 sec: 3279.1, 60 sec: 3282.6, 300 sec: 2903.2). Total num frames: 573440. Throughput: 0: 3413.7. Samples: 580608. Policy #0 lag: (min: 7.0, avg: 10.0, max: 71.0)
[2025-11-09 20:20:40,051][12634] Avg episode reward: [(0, '157.995')]
[2025-11-09 20:20:40,401][12634] Saving new best policy, reward=157.995!
[2025-11-09 20:20:45,298][12634] Fps is (10 sec: 4858.1, 60 sec: 3541.5, 300 sec: 2989.6). Total num frames: 606208. Throughput: 0: 3480.4. Samples: 602624. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-09 20:20:45,298][12634] Avg episode reward: [(0, '159.729')]
[2025-11-09 20:20:45,300][12634] Saving new best policy, reward=159.729!
[2025-11-09 20:20:50,168][12634] Fps is (10 sec: 4858.1, 60 sec: 3547.6, 300 sec: 2998.4). Total num frames: 622592. Throughput: 0: 3499.3. Samples: 623616. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-09 20:20:50,168][12634] Avg episode reward: [(0, '160.453')]
[2025-11-09 20:20:50,302][12634] Saving new best policy, reward=160.453!
[2025-11-09 20:20:55,121][12634] Fps is (10 sec: 3335.7, 60 sec: 3546.0, 300 sec: 3005.6). Total num frames: 638976. Throughput: 0: 3524.1. Samples: 634880. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-09 20:20:55,121][12634] Avg episode reward: [(0, '162.255')]
[2025-11-09 20:20:55,256][12634] Saving new best policy, reward=162.255!
[2025-11-09 20:21:00,056][12634] Fps is (10 sec: 3313.9, 60 sec: 3554.6, 300 sec: 3012.8). Total num frames: 655360. Throughput: 0: 3566.5. Samples: 656384. Policy #0 lag: (min: 10.0, avg: 13.0, max: 74.0)
[2025-11-09 20:21:00,056][12634] Avg episode reward: [(0, '165.162')]
[2025-11-09 20:21:00,206][12634] Saving new best policy, reward=165.162!
[2025-11-09 20:21:05,098][12634] Fps is (10 sec: 3284.3, 60 sec: 3550.1, 300 sec: 3018.1). Total num frames: 671744. Throughput: 0: 3528.6. Samples: 676864. Policy #0 lag: (min: 4.0, avg: 7.0, max: 68.0)
[2025-11-09 20:21:05,099][12634] Avg episode reward: [(0, '166.905')]
[2025-11-09 20:21:05,226][12634] Saving /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_lidar_policy6_vel_ttc_yaw/checkpoint_p0/checkpoint_000002624_671744.pth...
[2025-11-09 20:21:05,229][12634] Saving new best policy, reward=166.905!
[2025-11-09 20:21:10,079][12634] Fps is (10 sec: 3269.3, 60 sec: 3550.1, 300 sec: 3024.1). Total num frames: 688128. Throughput: 0: 3573.4. Samples: 688128. Policy #0 lag: (min: 4.0, avg: 7.0, max: 68.0)
[2025-11-09 20:21:10,080][12634] Avg episode reward: [(0, '170.438')]
[2025-11-09 20:21:10,221][12634] Saving new best policy, reward=170.438!
[2025-11-09 20:21:15,080][12634] Fps is (10 sec: 3283.0, 60 sec: 3552.4, 300 sec: 3029.5). Total num frames: 704512. Throughput: 0: 3525.4. Samples: 707584. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-09 20:21:15,080][12634] Avg episode reward: [(0, '172.229')]
[2025-11-09 20:21:15,210][12634] Saving new best policy, reward=172.229!
[2025-11-09 20:21:20,114][12634] Fps is (10 sec: 3265.5, 60 sec: 3550.1, 300 sec: 3034.3). Total num frames: 720896. Throughput: 0: 3532.3. Samples: 729088. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-09 20:21:20,114][12634] Avg episode reward: [(0, '176.312')]
[2025-11-09 20:21:20,252][12634] Saving new best policy, reward=176.312!
[2025-11-09 20:21:25,093][12634] Fps is (10 sec: 3272.5, 60 sec: 3549.7, 300 sec: 3039.5). Total num frames: 737280. Throughput: 0: 3501.1. Samples: 738304. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-09 20:21:25,093][12634] Avg episode reward: [(0, '176.356')]
[2025-11-09 20:21:25,251][12634] Saving new best policy, reward=176.356!
[2025-11-09 20:21:30,118][12634] Fps is (10 sec: 3275.6, 60 sec: 3546.3, 300 sec: 3044.0). Total num frames: 753664. Throughput: 0: 3427.1. Samples: 756224. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-09 20:21:30,118][12634] Avg episode reward: [(0, '178.802')]
[2025-11-09 20:21:30,252][12634] Saving new best policy, reward=178.802!
[2025-11-09 20:21:35,132][12634] Fps is (10 sec: 3264.0, 60 sec: 3552.7, 300 sec: 3048.5). Total num frames: 770048. Throughput: 0: 3427.5. Samples: 777728. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-09 20:21:35,132][12634] Avg episode reward: [(0, '182.855')]
[2025-11-09 20:21:35,261][12634] Saving new best policy, reward=182.855!
[2025-11-09 20:21:40,134][12634] Fps is (10 sec: 3271.5, 60 sec: 3545.0, 300 sec: 3052.9). Total num frames: 786432. Throughput: 0: 3389.6. Samples: 787456. Policy #0 lag: (min: 5.0, avg: 8.0, max: 69.0)
[2025-11-09 20:21:40,134][12634] Avg episode reward: [(0, '187.899')]
[2025-11-09 20:21:40,267][12634] Saving new best policy, reward=187.899!
[2025-11-09 20:21:45,142][12634] Fps is (10 sec: 3273.6, 60 sec: 3285.4, 300 sec: 3057.0). Total num frames: 802816. Throughput: 0: 3395.5. Samples: 809472. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-09 20:21:45,142][12634] Avg episode reward: [(0, '190.213')]
[2025-11-09 20:21:45,282][12634] Saving new best policy, reward=190.213!
[2025-11-09 20:21:50,165][12634] Fps is (10 sec: 3266.6, 60 sec: 3277.0, 300 sec: 3060.9). Total num frames: 819200. Throughput: 0: 3431.0. Samples: 831488. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-09 20:21:50,165][12634] Avg episode reward: [(0, '196.132')]
[2025-11-09 20:21:50,293][12634] Saving new best policy, reward=196.132!
[2025-11-09 20:21:50,798][12634] Signal inference workers to stop experience collection... (150 times)
[2025-11-09 20:21:51,158][12634] InferenceWorker_p0-w0: stopping experience collection (150 times)
[2025-11-09 20:21:51,160][12634] Signal inference workers to resume experience collection... (150 times)
[2025-11-09 20:21:51,298][12634] InferenceWorker_p0-w0: resuming experience collection (150 times)
[2025-11-09 20:21:55,163][12634] Fps is (10 sec: 3269.6, 60 sec: 3274.5, 300 sec: 3064.8). Total num frames: 835584. Throughput: 0: 3395.6. Samples: 841216. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-09 20:21:55,164][12634] Avg episode reward: [(0, '198.772')]
[2025-11-09 20:21:55,306][12634] Saving new best policy, reward=198.772!
[2025-11-09 20:22:00,058][12634] Fps is (10 sec: 3312.3, 60 sec: 3276.7, 300 sec: 3069.8). Total num frames: 851968. Throughput: 0: 3460.5. Samples: 863232. Policy #0 lag: (min: 11.0, avg: 14.0, max: 75.0)
[2025-11-09 20:22:00,058][12634] Avg episode reward: [(0, '206.086')]
[2025-11-09 20:22:00,412][12634] Saving new best policy, reward=206.086!
[2025-11-09 20:22:05,374][12634] Fps is (10 sec: 4814.0, 60 sec: 3533.7, 300 sec: 3128.0). Total num frames: 884736. Throughput: 0: 3439.0. Samples: 884736. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-09 20:22:05,374][12634] Avg episode reward: [(0, '211.203')]
[2025-11-09 20:22:05,375][12634] Saving new best policy, reward=211.203!
[2025-11-09 20:22:10,105][12634] Fps is (10 sec: 4892.3, 60 sec: 3548.4, 300 sec: 3133.5). Total num frames: 901120. Throughput: 0: 3480.7. Samples: 894976. Policy #0 lag: (min: 9.0, avg: 12.0, max: 73.0)
[2025-11-09 20:22:10,105][12634] Avg episode reward: [(0, '221.379')]
[2025-11-09 20:22:10,254][12634] Saving new best policy, reward=221.379!
[2025-11-09 20:22:15,133][12634] Fps is (10 sec: 3357.6, 60 sec: 3546.7, 300 sec: 3135.7). Total num frames: 917504. Throughput: 0: 3560.0. Samples: 916480. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-09 20:22:15,133][12634] Avg episode reward: [(0, '229.537')]
[2025-11-09 20:22:15,268][12634] Saving new best policy, reward=229.537!
[2025-11-09 20:22:20,169][12634] Fps is (10 sec: 3255.8, 60 sec: 3546.6, 300 sec: 3282.1). Total num frames: 933888. Throughput: 0: 3535.5. Samples: 936960. Policy #0 lag: (min: 7.0, avg: 10.0, max: 71.0)
[2025-11-09 20:22:20,170][12634] Avg episode reward: [(0, '228.448')]
[2025-11-09 20:22:25,074][12634] Fps is (10 sec: 3296.3, 60 sec: 3551.0, 300 sec: 3328.8). Total num frames: 950272. Throughput: 0: 3577.4. Samples: 948224. Policy #0 lag: (min: 9.0, avg: 12.0, max: 73.0)
[2025-11-09 20:22:25,074][12634] Avg episode reward: [(0, '225.122')]
[2025-11-09 20:22:30,058][12634] Fps is (10 sec: 3313.8, 60 sec: 3553.4, 300 sec: 3329.2). Total num frames: 966656. Throughput: 0: 3545.1. Samples: 968704. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-09 20:22:30,058][12634] Avg episode reward: [(0, '223.949')]
[2025-11-09 20:22:35,140][12634] Fps is (10 sec: 3255.4, 60 sec: 3549.4, 300 sec: 3341.0). Total num frames: 983040. Throughput: 0: 3529.1. Samples: 990208. Policy #0 lag: (min: 12.0, avg: 15.0, max: 76.0)
[2025-11-09 20:22:35,140][12634] Avg episode reward: [(0, '232.474')]
[2025-11-09 20:22:35,271][12634] Saving new best policy, reward=232.474!
[2025-11-09 20:22:40,102][12634] Fps is (10 sec: 3262.3, 60 sec: 3551.7, 300 sec: 3388.5). Total num frames: 999424. Throughput: 0: 3543.3. Samples: 1000448. Policy #0 lag: (min: 11.0, avg: 14.0, max: 75.0)
[2025-11-09 20:22:40,102][12634] Avg episode reward: [(0, '241.848')]
[2025-11-09 20:22:40,235][12634] Saving new best policy, reward=241.848!
[2025-11-09 20:22:45,124][12634] Fps is (10 sec: 3282.1, 60 sec: 3550.9, 300 sec: 3387.1). Total num frames: 1015808. Throughput: 0: 3510.6. Samples: 1021440. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-09 20:22:45,124][12634] Avg episode reward: [(0, '244.943')]
[2025-11-09 20:22:45,252][12634] Saving new best policy, reward=244.943!
[2025-11-09 20:22:50,148][12634] Fps is (10 sec: 3261.7, 60 sec: 3550.8, 300 sec: 3387.5). Total num frames: 1032192. Throughput: 0: 3544.9. Samples: 1043456. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-09 20:22:50,149][12634] Avg episode reward: [(0, '247.841')]
[2025-11-09 20:22:50,282][12634] Saving new best policy, reward=247.841!
[2025-11-09 20:22:55,102][12634] Fps is (10 sec: 3283.9, 60 sec: 3553.5, 300 sec: 3387.3). Total num frames: 1048576. Throughput: 0: 3516.0. Samples: 1053184. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-09 20:22:55,102][12634] Avg episode reward: [(0, '243.383')]
[2025-11-09 20:23:00,109][12634] Fps is (10 sec: 3289.8, 60 sec: 3546.9, 300 sec: 3387.4). Total num frames: 1064960. Throughput: 0: 3517.6. Samples: 1074688. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-09 20:23:00,109][12634] Avg episode reward: [(0, '247.498')]
[2025-11-09 20:23:05,322][12634] Signal inference workers to stop experience collection... (200 times)
[2025-11-09 20:23:05,322][12634] Fps is (10 sec: 4007.7, 60 sec: 3416.3, 300 sec: 3414.1). Total num frames: 1089536. Throughput: 0: 3537.8. Samples: 1096704. Policy #0 lag: (min: 14.0, avg: 17.0, max: 78.0)
[2025-11-09 20:23:05,322][12634] Avg episode reward: [(0, '253.850')]
[2025-11-09 20:23:05,668][12634] InferenceWorker_p0-w0: stopping experience collection (200 times)
[2025-11-09 20:23:05,669][12634] Saving /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_lidar_policy6_vel_ttc_yaw/checkpoint_p0/checkpoint_000004288_1097728.pth...
[2025-11-09 20:23:05,672][12634] Removing /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_lidar_policy6_vel_ttc_yaw/checkpoint_p0/checkpoint_000001024_262144.pth
[2025-11-09 20:23:05,673][12634] Saving new best policy, reward=253.850!
[2025-11-09 20:23:05,677][12634] Signal inference workers to resume experience collection... (200 times)
[2025-11-09 20:23:05,677][12634] InferenceWorker_p0-w0: resuming experience collection (200 times)
[2025-11-09 20:23:10,262][12634] Fps is (10 sec: 4841.2, 60 sec: 3540.6, 300 sec: 3442.1). Total num frames: 1114112. Throughput: 0: 3512.5. Samples: 1106944. Policy #0 lag: (min: 9.0, avg: 12.0, max: 73.0)
[2025-11-09 20:23:10,262][12634] Avg episode reward: [(0, '265.995')]
[2025-11-09 20:23:10,262][12634] Saving new best policy, reward=265.995!
[2025-11-09 20:23:15,092][12634] Fps is (10 sec: 4192.7, 60 sec: 3552.3, 300 sec: 3443.8). Total num frames: 1130496. Throughput: 0: 3547.2. Samples: 1128448. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-09 20:23:15,092][12634] Avg episode reward: [(0, '272.113')]
[2025-11-09 20:23:15,233][12634] Saving new best policy, reward=272.113!
[2025-11-09 20:23:20,067][12634] Fps is (10 sec: 3342.0, 60 sec: 3556.0, 300 sec: 3444.3). Total num frames: 1146880. Throughput: 0: 3510.1. Samples: 1147904. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-09 20:23:20,067][12634] Avg episode reward: [(0, '281.658')]
[2025-11-09 20:23:20,208][12634] Saving new best policy, reward=281.658!
[2025-11-09 20:23:25,150][12634] Fps is (10 sec: 3257.8, 60 sec: 3545.4, 300 sec: 3442.8). Total num frames: 1163264. Throughput: 0: 3534.7. Samples: 1159680. Policy #0 lag: (min: 31.0, avg: 34.0, max: 95.0)
[2025-11-09 20:23:25,150][12634] Avg episode reward: [(0, '286.081')]
[2025-11-09 20:23:25,288][12634] Saving new best policy, reward=286.081!
[2025-11-09 20:23:30,093][12634] Fps is (10 sec: 3268.3, 60 sec: 3547.8, 300 sec: 3443.3). Total num frames: 1179648. Throughput: 0: 3540.9. Samples: 1180672. Policy #0 lag: (min: 34.0, avg: 37.0, max: 98.0)
[2025-11-09 20:23:30,093][12634] Avg episode reward: [(0, '286.045')]
[2025-11-09 20:23:35,085][12634] Fps is (10 sec: 3298.4, 60 sec: 3553.1, 300 sec: 3443.5). Total num frames: 1196032. Throughput: 0: 3509.3. Samples: 1201152. Policy #0 lag: (min: 63.0, avg: 66.0, max: 127.0)
[2025-11-09 20:23:35,085][12634] Avg episode reward: [(0, '295.411')]
[2025-11-09 20:23:35,232][12634] Saving new best policy, reward=295.411!
[2025-11-09 20:23:40,107][12634] Fps is (10 sec: 3272.2, 60 sec: 3549.6, 300 sec: 3444.0). Total num frames: 1212416. Throughput: 0: 3549.5. Samples: 1212928. Policy #0 lag: (min: 63.0, avg: 66.0, max: 127.0)
[2025-11-09 20:23:40,107][12634] Avg episode reward: [(0, '300.866')]
[2025-11-09 20:23:40,239][12634] Saving new best policy, reward=300.866!
[2025-11-09 20:23:45,094][12634] Fps is (10 sec: 3273.8, 60 sec: 3551.6, 300 sec: 3444.1). Total num frames: 1228800. Throughput: 0: 3516.9. Samples: 1232896. Policy #0 lag: (min: 1.0, avg: 4.0, max: 65.0)
[2025-11-09 20:23:45,094][12634] Avg episode reward: [(0, '302.272')]
[2025-11-09 20:23:45,226][12634] Saving new best policy, reward=302.272!
[2025-11-09 20:23:50,089][12634] Fps is (10 sec: 3282.6, 60 sec: 3553.4, 300 sec: 3443.7). Total num frames: 1245184. Throughput: 0: 3522.6. Samples: 1254400. Policy #0 lag: (min: 41.0, avg: 44.0, max: 105.0)
[2025-11-09 20:23:50,089][12634] Avg episode reward: [(0, '308.448')]
[2025-11-09 20:23:50,239][12634] Saving new best policy, reward=308.448!
[2025-11-09 20:23:55,114][12634] Fps is (10 sec: 3270.4, 60 sec: 3549.2, 300 sec: 3442.7). Total num frames: 1261568. Throughput: 0: 3504.5. Samples: 1264128. Policy #0 lag: (min: 41.0, avg: 44.0, max: 105.0)
[2025-11-09 20:23:55,114][12634] Avg episode reward: [(0, '311.456')]
[2025-11-09 20:23:55,252][12634] Saving new best policy, reward=311.456!
[2025-11-09 20:24:00,050][12634] Fps is (10 sec: 3289.7, 60 sec: 3553.4, 300 sec: 3443.6). Total num frames: 1277952. Throughput: 0: 3496.2. Samples: 1285632. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-09 20:24:00,050][12634] Avg episode reward: [(0, '326.237')]
[2025-11-09 20:24:00,180][12634] Saving new best policy, reward=326.237!
[2025-11-09 20:24:05,155][12634] Fps is (10 sec: 3263.3, 60 sec: 3422.9, 300 sec: 3443.0). Total num frames: 1294336. Throughput: 0: 3531.6. Samples: 1307136. Policy #0 lag: (min: 47.0, avg: 50.0, max: 111.0)
[2025-11-09 20:24:05,155][12634] Avg episode reward: [(0, '338.416')]
[2025-11-09 20:24:05,299][12634] Saving new best policy, reward=338.416!
[2025-11-09 20:24:10,158][12634] Fps is (10 sec: 3241.7, 60 sec: 3282.5, 300 sec: 3442.7). Total num frames: 1310720. Throughput: 0: 3492.3. Samples: 1316864. Policy #0 lag: (min: 47.0, avg: 50.0, max: 111.0)
[2025-11-09 20:24:10,158][12634] Avg episode reward: [(0, '357.978')]
[2025-11-09 20:24:10,295][12634] Saving new best policy, reward=357.978!
[2025-11-09 20:24:15,106][12634] Fps is (10 sec: 3292.8, 60 sec: 3276.0, 300 sec: 3444.1). Total num frames: 1327104. Throughput: 0: 3491.9. Samples: 1337856. Policy #0 lag: (min: 12.0, avg: 15.0, max: 76.0)
[2025-11-09 20:24:15,106][12634] Avg episode reward: [(0, '366.497')]
[2025-11-09 20:24:15,469][12634] Saving new best policy, reward=366.497!
[2025-11-09 20:24:20,078][12634] Fps is (10 sec: 4129.2, 60 sec: 3412.7, 300 sec: 3472.0). Total num frames: 1351680. Throughput: 0: 3527.6. Samples: 1359872. Policy #0 lag: (min: 63.0, avg: 66.0, max: 127.0)
[2025-11-09 20:24:20,078][12634] Avg episode reward: [(0, '360.164')]
[2025-11-09 20:24:24,760][12634] Signal inference workers to stop experience collection... (250 times)
[2025-11-09 20:24:24,764][12634] Signal inference workers to resume experience collection... (250 times)
[2025-11-09 20:24:25,008][12634] InferenceWorker_p0-w0: stopping experience collection (250 times)
[2025-11-09 20:24:25,009][12634] InferenceWorker_p0-w0: resuming experience collection (250 times)
[2025-11-09 20:24:25,118][12634] Fps is (10 sec: 4909.2, 60 sec: 3551.7, 300 sec: 3498.7). Total num frames: 1376256. Throughput: 0: 3480.7. Samples: 1369600. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-09 20:24:25,119][12634] Avg episode reward: [(0, '368.671')]
[2025-11-09 20:24:25,120][12634] Saving new best policy, reward=368.671!
[2025-11-09 20:24:30,129][12634] Fps is (10 sec: 4075.0, 60 sec: 3547.7, 300 sec: 3498.6). Total num frames: 1392640. Throughput: 0: 3513.0. Samples: 1391104. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-09 20:24:30,130][12634] Avg episode reward: [(0, '373.707')]
[2025-11-09 20:24:30,283][12634] Saving new best policy, reward=373.707!
[2025-11-09 20:24:35,115][12634] Fps is (10 sec: 3278.0, 60 sec: 3548.1, 300 sec: 3499.5). Total num frames: 1409024. Throughput: 0: 3456.9. Samples: 1410048. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-09 20:24:35,115][12634] Avg episode reward: [(0, '392.464')]
[2025-11-09 20:24:35,255][12634] Saving new best policy, reward=392.464!
[2025-11-09 20:24:40,093][12634] Fps is (10 sec: 3288.9, 60 sec: 3550.7, 300 sec: 3499.7). Total num frames: 1425408. Throughput: 0: 3506.0. Samples: 1421824. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-09 20:24:40,093][12634] Avg episode reward: [(0, '388.787')]
[2025-11-09 20:24:45,106][12634] Fps is (10 sec: 3279.5, 60 sec: 3549.1, 300 sec: 3499.2). Total num frames: 1441792. Throughput: 0: 3488.6. Samples: 1442816. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-09 20:24:45,107][12634] Avg episode reward: [(0, '400.629')]
[2025-11-09 20:24:45,246][12634] Saving new best policy, reward=400.629!
[2025-11-09 20:24:50,131][12634] Fps is (10 sec: 3264.3, 60 sec: 3547.4, 300 sec: 3498.1). Total num frames: 1458176. Throughput: 0: 3472.1. Samples: 1463296. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-09 20:24:50,131][12634] Avg episode reward: [(0, '400.794')]
[2025-11-09 20:24:50,277][12634] Saving new best policy, reward=400.794!
[2025-11-09 20:24:55,126][12634] Fps is (10 sec: 3270.5, 60 sec: 3549.1, 300 sec: 3499.1). Total num frames: 1474560. Throughput: 0: 3506.9. Samples: 1474560. Policy #0 lag: (min: 8.0, avg: 11.0, max: 72.0)
[2025-11-09 20:24:55,126][12634] Avg episode reward: [(0, '406.050')]
[2025-11-09 20:24:55,269][12634] Saving new best policy, reward=406.050!
[2025-11-09 20:25:00,124][12634] Fps is (10 sec: 3279.0, 60 sec: 3545.5, 300 sec: 3498.7). Total num frames: 1490944. Throughput: 0: 3480.2. Samples: 1494528. Policy #0 lag: (min: 8.0, avg: 11.0, max: 72.0)
[2025-11-09 20:25:00,124][12634] Avg episode reward: [(0, '417.257')]
[2025-11-09 20:25:00,292][12634] Saving new best policy, reward=417.257!
[2025-11-09 20:25:05,143][12634] Fps is (10 sec: 3271.3, 60 sec: 3550.6, 300 sec: 3498.2). Total num frames: 1507328. Throughput: 0: 3453.9. Samples: 1515520. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-09 20:25:05,143][12634] Avg episode reward: [(0, '422.452')]
[2025-11-09 20:25:05,285][12634] Saving /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_lidar_policy6_vel_ttc_yaw/checkpoint_p0/checkpoint_000005888_1507328.pth...
[2025-11-09 20:25:05,289][12634] Removing /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_lidar_policy6_vel_ttc_yaw/checkpoint_p0/checkpoint_000002624_671744.pth
[2025-11-09 20:25:05,290][12634] Saving new best policy, reward=422.452!
[2025-11-09 20:25:10,097][12634] Fps is (10 sec: 3285.7, 60 sec: 3553.5, 300 sec: 3499.3). Total num frames: 1523712. Throughput: 0: 3449.1. Samples: 1524736. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-09 20:25:10,097][12634] Avg episode reward: [(0, '426.744')]
[2025-11-09 20:25:10,231][12634] Saving new best policy, reward=426.744!
[2025-11-09 20:25:15,168][12634] Fps is (10 sec: 3268.3, 60 sec: 3546.2, 300 sec: 3498.4). Total num frames: 1540096. Throughput: 0: 3455.8. Samples: 1546752. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-09 20:25:15,169][12634] Avg episode reward: [(0, '424.226')]
[2025-11-09 20:25:20,108][12634] Fps is (10 sec: 3273.3, 60 sec: 3411.6, 300 sec: 3498.7). Total num frames: 1556480. Throughput: 0: 3516.3. Samples: 1568256. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-09 20:25:20,108][12634] Avg episode reward: [(0, '439.294')]
[2025-11-09 20:25:20,250][12634] Saving new best policy, reward=439.294!
[2025-11-09 20:25:25,096][12634] Fps is (10 sec: 3300.7, 60 sec: 3278.0, 300 sec: 3498.5). Total num frames: 1572864. Throughput: 0: 3481.3. Samples: 1578496. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-09 20:25:25,096][12634] Avg episode reward: [(0, '444.266')]
[2025-11-09 20:25:25,254][12634] Saving new best policy, reward=444.266!
[2025-11-09 20:25:30,122][12634] Fps is (10 sec: 3272.1, 60 sec: 3277.2, 300 sec: 3499.6). Total num frames: 1589248. Throughput: 0: 3434.9. Samples: 1597440. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-09 20:25:30,122][12634] Avg episode reward: [(0, '456.352')]
[2025-11-09 20:25:30,262][12634] Saving new best policy, reward=456.352!
[2025-11-09 20:25:35,135][12634] Fps is (10 sec: 3264.3, 60 sec: 3275.7, 300 sec: 3498.0). Total num frames: 1605632. Throughput: 0: 3424.4. Samples: 1617408. Policy #0 lag: (min: 13.0, avg: 16.0, max: 77.0)
[2025-11-09 20:25:35,135][12634] Avg episode reward: [(0, '459.436')]
[2025-11-09 20:25:35,303][12634] Saving new best policy, reward=459.436!
[2025-11-09 20:25:40,129][12634] Fps is (10 sec: 3274.5, 60 sec: 3274.8, 300 sec: 3445.4). Total num frames: 1622016. Throughput: 0: 3356.2. Samples: 1625600. Policy #0 lag: (min: 52.0, avg: 55.0, max: 116.0)
[2025-11-09 20:25:40,129][12634] Avg episode reward: [(0, '466.383')]
[2025-11-09 20:25:40,290][12634] Saving new best policy, reward=466.383!
[2025-11-09 20:25:45,056][12634] Fps is (10 sec: 3302.9, 60 sec: 3279.6, 300 sec: 3444.7). Total num frames: 1638400. Throughput: 0: 3327.4. Samples: 1644032. Policy #0 lag: (min: 52.0, avg: 55.0, max: 116.0)
[2025-11-09 20:25:45,056][12634] Avg episode reward: [(0, '475.332')]
[2025-11-09 20:25:45,219][12634] Saving new best policy, reward=475.332!
[2025-11-09 20:25:46,935][12634] Signal inference workers to stop experience collection... (300 times)
[2025-11-09 20:25:47,312][12634] InferenceWorker_p0-w0: stopping experience collection (300 times)
[2025-11-09 20:25:47,314][12634] Signal inference workers to resume experience collection... (300 times)
[2025-11-09 20:25:47,447][12634] InferenceWorker_p0-w0: resuming experience collection (300 times)
[2025-11-09 20:25:50,168][12634] Fps is (10 sec: 3264.0, 60 sec: 3274.8, 300 sec: 3442.9). Total num frames: 1654784. Throughput: 0: 3297.7. Samples: 1664000. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-09 20:25:50,168][12634] Avg episode reward: [(0, '467.697')]
[2025-11-09 20:25:55,132][12634] Fps is (10 sec: 3252.1, 60 sec: 3276.5, 300 sec: 3442.5). Total num frames: 1671168. Throughput: 0: 3308.4. Samples: 1673728. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-09 20:25:55,132][12634] Avg episode reward: [(0, '480.137')]
[2025-11-09 20:25:55,268][12634] Saving new best policy, reward=480.137!
[2025-11-09 20:26:00,100][12634] Fps is (10 sec: 3299.3, 60 sec: 3278.1, 300 sec: 3443.4). Total num frames: 1687552. Throughput: 0: 3304.6. Samples: 1695232. Policy #0 lag: (min: 12.0, avg: 15.0, max: 76.0)
[2025-11-09 20:26:00,100][12634] Avg episode reward: [(0, '468.402')]
[2025-11-09 20:26:05,164][12634] Fps is (10 sec: 3266.1, 60 sec: 3275.6, 300 sec: 3442.4). Total num frames: 1703936. Throughput: 0: 3295.4. Samples: 1716736. Policy #0 lag: (min: 12.0, avg: 15.0, max: 76.0)
[2025-11-09 20:26:05,165][12634] Avg episode reward: [(0, '480.633')]
[2025-11-09 20:26:05,301][12634] Saving new best policy, reward=480.633!
[2025-11-09 20:26:10,116][12634] Fps is (10 sec: 3271.7, 60 sec: 3275.8, 300 sec: 3443.0). Total num frames: 1720320. Throughput: 0: 3286.8. Samples: 1726464. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-09 20:26:10,116][12634] Avg episode reward: [(0, '501.544')]
[2025-11-09 20:26:10,248][12634] Saving new best policy, reward=501.544!
[2025-11-09 20:26:15,156][12634] Fps is (10 sec: 3279.5, 60 sec: 3277.5, 300 sec: 3442.9). Total num frames: 1736704. Throughput: 0: 3331.2. Samples: 1747456. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-09 20:26:15,156][12634] Avg episode reward: [(0, '515.068')]
[2025-11-09 20:26:15,505][12634] Saving new best policy, reward=515.068!
[2025-11-09 20:26:20,179][12634] Fps is (10 sec: 4070.1, 60 sec: 3409.3, 300 sec: 3470.2). Total num frames: 1761280. Throughput: 0: 3364.5. Samples: 1768960. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-09 20:26:20,180][12634] Avg episode reward: [(0, '522.522')]
[2025-11-09 20:26:20,528][12634] Saving new best policy, reward=522.522!
[2025-11-09 20:26:25,217][12634] Fps is (10 sec: 4885.4, 60 sec: 3542.7, 300 sec: 3497.8). Total num frames: 1785856. Throughput: 0: 3395.3. Samples: 1778688. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-09 20:26:25,217][12634] Avg episode reward: [(0, '514.494')]
[2025-11-09 20:26:30,184][12634] Fps is (10 sec: 4094.0, 60 sec: 3546.2, 300 sec: 3498.3). Total num frames: 1802240. Throughput: 0: 3460.3. Samples: 1800192. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-09 20:26:30,184][12634] Avg episode reward: [(0, '517.868')]
[2025-11-09 20:26:35,099][12634] Fps is (10 sec: 3316.1, 60 sec: 3552.0, 300 sec: 3499.4). Total num frames: 1818624. Throughput: 0: 3464.2. Samples: 1819648. Policy #0 lag: (min: 11.0, avg: 14.0, max: 75.0)
[2025-11-09 20:26:35,099][12634] Avg episode reward: [(0, '511.527')]
[2025-11-09 20:26:40,057][12634] Fps is (10 sec: 3319.1, 60 sec: 3554.1, 300 sec: 3500.0). Total num frames: 1835008. Throughput: 0: 3521.6. Samples: 1831936. Policy #0 lag: (min: 11.0, avg: 14.0, max: 75.0)
[2025-11-09 20:26:40,057][12634] Avg episode reward: [(0, '513.031')]
[2025-11-09 20:26:45,133][12634] Fps is (10 sec: 3265.5, 60 sec: 3545.3, 300 sec: 3499.3). Total num frames: 1851392. Throughput: 0: 3490.4. Samples: 1852416. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-09 20:26:45,133][12634] Avg episode reward: [(0, '515.475')]
[2025-11-09 20:26:50,083][12634] Fps is (10 sec: 3268.4, 60 sec: 3554.9, 300 sec: 3499.9). Total num frames: 1867776. Throughput: 0: 3476.5. Samples: 1872896. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-09 20:26:50,083][12634] Avg episode reward: [(0, '509.306')]
[2025-11-09 20:26:55,085][12634] Fps is (10 sec: 3292.8, 60 sec: 3552.7, 300 sec: 3498.6). Total num frames: 1884160. Throughput: 0: 3518.2. Samples: 1884672. Policy #0 lag: (min: 14.0, avg: 17.0, max: 78.0)
[2025-11-09 20:26:55,085][12634] Avg episode reward: [(0, '521.436')]
[2025-11-09 20:27:00,160][12634] Fps is (10 sec: 3251.7, 60 sec: 3546.3, 300 sec: 3445.9). Total num frames: 1900544. Throughput: 0: 3481.3. Samples: 1904128. Policy #0 lag: (min: 14.0, avg: 17.0, max: 78.0)
[2025-11-09 20:27:00,160][12634] Avg episode reward: [(0, '532.779')]
[2025-11-09 20:27:00,300][12634] Saving new best policy, reward=532.779!
[2025-11-09 20:27:02,645][12634] Signal inference workers to stop experience collection... (350 times)
[2025-11-09 20:27:03,015][12634] InferenceWorker_p0-w0: stopping experience collection (350 times)
[2025-11-09 20:27:03,015][12634] Signal inference workers to resume experience collection... (350 times)
[2025-11-09 20:27:03,016][12634] InferenceWorker_p0-w0: resuming experience collection (350 times)
[2025-11-09 20:27:05,062][12634] Fps is (10 sec: 3284.1, 60 sec: 3555.9, 300 sec: 3443.9). Total num frames: 1916928. Throughput: 0: 3445.1. Samples: 1923584. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-09 20:27:05,062][12634] Avg episode reward: [(0, '552.423')]
[2025-11-09 20:27:05,221][12634] Saving /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_lidar_policy6_vel_ttc_yaw/checkpoint_p0/checkpoint_000007488_1916928.pth...
[2025-11-09 20:27:05,226][12634] Removing /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_lidar_policy6_vel_ttc_yaw/checkpoint_p0/checkpoint_000004288_1097728.pth
[2025-11-09 20:27:05,226][12634] Saving new best policy, reward=552.423!
[2025-11-09 20:27:10,067][12634] Fps is (10 sec: 3307.4, 60 sec: 3552.7, 300 sec: 3444.2). Total num frames: 1933312. Throughput: 0: 3447.6. Samples: 1933312. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-09 20:27:10,067][12634] Avg episode reward: [(0, '544.299')]
[2025-11-09 20:27:15,140][12634] Fps is (10 sec: 3251.7, 60 sec: 3550.8, 300 sec: 3443.8). Total num frames: 1949696. Throughput: 0: 3348.4. Samples: 1950720. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-09 20:27:15,140][12634] Avg episode reward: [(0, '542.965')]
[2025-11-09 20:27:20,067][12634] Fps is (10 sec: 3276.7, 60 sec: 3419.7, 300 sec: 3443.5). Total num frames: 1966080. Throughput: 0: 3347.4. Samples: 1970176. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-09 20:27:20,068][12634] Avg episode reward: [(0, '552.038')]
[2025-11-09 20:27:25,081][12634] Fps is (10 sec: 3296.1, 60 sec: 3284.3, 300 sec: 3443.1). Total num frames: 1982464. Throughput: 0: 3320.5. Samples: 1981440. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-09 20:27:25,081][12634] Avg episode reward: [(0, '555.347')]
[2025-11-09 20:27:25,219][12634] Saving new best policy, reward=555.347!
[2025-11-09 20:27:30,089][12634] Fps is (10 sec: 3269.7, 60 sec: 3282.0, 300 sec: 3444.0). Total num frames: 1998848. Throughput: 0: 3302.8. Samples: 2000896. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-09 20:27:30,089][12634] Avg episode reward: [(0, '557.444')]
[2025-11-09 20:27:30,232][12634] Saving new best policy, reward=557.444!
[2025-11-09 20:27:35,086][12634] Fps is (10 sec: 3275.2, 60 sec: 3277.5, 300 sec: 3443.6). Total num frames: 2015232. Throughput: 0: 3310.7. Samples: 2021888. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-09 20:27:35,086][12634] Avg episode reward: [(0, '568.453')]
[2025-11-09 20:27:35,218][12634] Saving new best policy, reward=568.453!
[2025-11-09 20:27:40,073][12634] Fps is (10 sec: 3282.0, 60 sec: 3275.9, 300 sec: 3444.0). Total num frames: 2031616. Throughput: 0: 3289.0. Samples: 2032640. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-09 20:27:40,073][12634] Avg episode reward: [(0, '586.682')]
[2025-11-09 20:27:40,209][12634] Saving new best policy, reward=586.682!
[2025-11-09 20:27:45,116][12634] Fps is (10 sec: 3266.8, 60 sec: 3277.7, 300 sec: 3443.8). Total num frames: 2048000. Throughput: 0: 3314.1. Samples: 2053120. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-09 20:27:45,117][12634] Avg episode reward: [(0, '596.094')]
[2025-11-09 20:27:45,251][12634] Saving new best policy, reward=596.094!
[2025-11-09 20:27:50,071][12634] Fps is (10 sec: 3277.6, 60 sec: 3277.4, 300 sec: 3443.8). Total num frames: 2064384. Throughput: 0: 3355.8. Samples: 2074624. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-09 20:27:50,071][12634] Avg episode reward: [(0, '600.751')]
[2025-11-09 20:27:50,223][12634] Saving new best policy, reward=600.751!
[2025-11-09 20:27:55,105][12634] Fps is (10 sec: 3280.7, 60 sec: 3275.7, 300 sec: 3443.5). Total num frames: 2080768. Throughput: 0: 3296.8. Samples: 2081792. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-09 20:27:55,105][12634] Avg episode reward: [(0, '607.125')]
[2025-11-09 20:27:55,261][12634] Saving new best policy, reward=607.125!
[2025-11-09 20:28:00,061][12634] Fps is (10 sec: 3280.2, 60 sec: 3282.2, 300 sec: 3418.7). Total num frames: 2097152. Throughput: 0: 3362.4. Samples: 2101760. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-09 20:28:00,061][12634] Avg episode reward: [(0, '598.336')]
[2025-11-09 20:28:05,114][12634] Fps is (10 sec: 3273.8, 60 sec: 3274.0, 300 sec: 3389.6). Total num frames: 2113536. Throughput: 0: 3353.0. Samples: 2121216. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-09 20:28:05,114][12634] Avg episode reward: [(0, '606.086')]
[2025-11-09 20:28:10,130][12634] Fps is (10 sec: 3254.1, 60 sec: 3273.4, 300 sec: 3387.4). Total num frames: 2129920. Throughput: 0: 3318.7. Samples: 2130944. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-09 20:28:10,131][12634] Avg episode reward: [(0, '593.664')]
[2025-11-09 20:28:15,114][12634] Fps is (10 sec: 3276.6, 60 sec: 3278.2, 300 sec: 3387.3). Total num frames: 2146304. Throughput: 0: 3343.2. Samples: 2151424. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-09 20:28:15,114][12634] Avg episode reward: [(0, '593.013')]
[2025-11-09 20:28:20,085][12634] Fps is (10 sec: 3291.7, 60 sec: 3275.8, 300 sec: 3388.6). Total num frames: 2162688. Throughput: 0: 3333.7. Samples: 2171904. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-09 20:28:20,085][12634] Avg episode reward: [(0, '596.213')]
[2025-11-09 20:28:25,146][12634] Fps is (10 sec: 3266.3, 60 sec: 3273.2, 300 sec: 3387.3). Total num frames: 2179072. Throughput: 0: 3305.6. Samples: 2181632. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-09 20:28:25,147][12634] Avg episode reward: [(0, '620.571')]
[2025-11-09 20:28:25,296][12634] Saving new best policy, reward=620.571!
[2025-11-09 20:28:26,953][12634] Signal inference workers to stop experience collection... (400 times)
[2025-11-09 20:28:26,953][12634] Signal inference workers to resume experience collection... (400 times)
[2025-11-09 20:28:27,205][12634] InferenceWorker_p0-w0: stopping experience collection (400 times)
[2025-11-09 20:28:27,206][12634] InferenceWorker_p0-w0: resuming experience collection (400 times)
[2025-11-09 20:28:30,057][12634] Fps is (10 sec: 3286.0, 60 sec: 3278.5, 300 sec: 3388.2). Total num frames: 2195456. Throughput: 0: 3303.9. Samples: 2201600. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-09 20:28:30,057][12634] Avg episode reward: [(0, '634.898')]
[2025-11-09 20:28:30,219][12634] Saving new best policy, reward=634.898!
[2025-11-09 20:28:35,086][12634] Fps is (10 sec: 3296.8, 60 sec: 3276.8, 300 sec: 3388.1). Total num frames: 2211840. Throughput: 0: 3264.4. Samples: 2221568. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-09 20:28:35,086][12634] Avg episode reward: [(0, '632.681')]
[2025-11-09 20:28:40,122][12634] Fps is (10 sec: 3255.6, 60 sec: 3274.1, 300 sec: 3387.6). Total num frames: 2228224. Throughput: 0: 3321.0. Samples: 2231296. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-09 20:28:40,123][12634] Avg episode reward: [(0, '619.864')]
[2025-11-09 20:28:45,130][12634] Fps is (10 sec: 3262.1, 60 sec: 3276.0, 300 sec: 3387.4). Total num frames: 2244608. Throughput: 0: 3317.2. Samples: 2251264. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-09 20:28:45,131][12634] Avg episode reward: [(0, '623.310')]
[2025-11-09 20:28:50,196][12634] Fps is (10 sec: 3252.9, 60 sec: 3270.0, 300 sec: 3386.9). Total num frames: 2260992. Throughput: 0: 3327.6. Samples: 2271232. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-09 20:28:50,196][12634] Avg episode reward: [(0, '615.194')]
[2025-11-09 20:28:55,144][12634] Fps is (10 sec: 3272.4, 60 sec: 3274.6, 300 sec: 3386.8). Total num frames: 2277376. Throughput: 0: 3298.6. Samples: 2279424. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-09 20:28:55,144][12634] Avg episode reward: [(0, '630.502')]
[2025-11-09 20:29:00,143][12634] Fps is (10 sec: 3294.3, 60 sec: 3272.3, 300 sec: 3388.0). Total num frames: 2293760. Throughput: 0: 3263.3. Samples: 2298368. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-09 20:29:00,143][12634] Avg episode reward: [(0, '642.057')]
[2025-11-09 20:29:00,307][12634] Saving new best policy, reward=642.057!
[2025-11-09 20:29:05,193][12634] Fps is (10 sec: 3260.8, 60 sec: 3272.5, 300 sec: 3387.5). Total num frames: 2310144. Throughput: 0: 3223.6. Samples: 2317312. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-09 20:29:05,193][12634] Avg episode reward: [(0, '665.816')]
[2025-11-09 20:29:05,348][12634] Saving /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_lidar_policy6_vel_ttc_yaw/checkpoint_p0/checkpoint_000009024_2310144.pth...
[2025-11-09 20:29:05,352][12634] Removing /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_lidar_policy6_vel_ttc_yaw/checkpoint_p0/checkpoint_000005888_1507328.pth
[2025-11-09 20:29:05,352][12634] Saving new best policy, reward=665.816!
[2025-11-09 20:29:10,079][12634] Fps is (10 sec: 3297.8, 60 sec: 3279.6, 300 sec: 3388.2). Total num frames: 2326528. Throughput: 0: 3247.5. Samples: 2327552. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-09 20:29:10,079][12634] Avg episode reward: [(0, '652.152')]
[2025-11-09 20:29:15,139][12634] Fps is (10 sec: 3294.4, 60 sec: 3275.4, 300 sec: 3359.4). Total num frames: 2342912. Throughput: 0: 3191.3. Samples: 2345472. Policy #0 lag: (min: 3.0, avg: 6.0, max: 67.0)
[2025-11-09 20:29:15,140][12634] Avg episode reward: [(0, '637.332')]
[2025-11-09 20:29:20,061][12634] Fps is (10 sec: 3282.9, 60 sec: 3278.1, 300 sec: 3333.0). Total num frames: 2359296. Throughput: 0: 3198.9. Samples: 2365440. Policy #0 lag: (min: 3.0, avg: 6.0, max: 67.0)
[2025-11-09 20:29:20,061][12634] Avg episode reward: [(0, '644.780')]
[2025-11-09 20:29:25,183][12634] Fps is (10 sec: 3262.6, 60 sec: 3274.8, 300 sec: 3331.7). Total num frames: 2375680. Throughput: 0: 3192.9. Samples: 2375168. Policy #0 lag: (min: 3.0, avg: 6.0, max: 67.0)
[2025-11-09 20:29:25,183][12634] Avg episode reward: [(0, '663.500')]
[2025-11-09 20:29:30,135][12634] Fps is (10 sec: 3252.5, 60 sec: 3272.5, 300 sec: 3332.1). Total num frames: 2392064. Throughput: 0: 3139.9. Samples: 2392576. Policy #0 lag: (min: 3.0, avg: 6.0, max: 67.0)
[2025-11-09 20:29:30,135][12634] Avg episode reward: [(0, '665.771')]
[2025-11-09 20:29:35,153][12634] Fps is (10 sec: 3286.6, 60 sec: 3273.1, 300 sec: 3331.7). Total num frames: 2408448. Throughput: 0: 3074.9. Samples: 2409472. Policy #0 lag: (min: 14.0, avg: 17.0, max: 78.0)
[2025-11-09 20:29:35,153][12634] Avg episode reward: [(0, '667.936')]
[2025-11-09 20:29:35,316][12634] Saving new best policy, reward=667.936!
[2025-11-09 20:29:40,076][12634] Fps is (10 sec: 2472.3, 60 sec: 3142.7, 300 sec: 3304.9). Total num frames: 2416640. Throughput: 0: 3099.5. Samples: 2418688. Policy #0 lag: (min: 14.0, avg: 17.0, max: 78.0)
[2025-11-09 20:29:40,076][12634] Avg episode reward: [(0, '661.177')]
[2025-11-09 20:29:45,053][12634] Fps is (10 sec: 1654.9, 60 sec: 3007.6, 300 sec: 3277.7). Total num frames: 2424832. Throughput: 0: 3066.7. Samples: 2436096. Policy #0 lag: (min: 14.0, avg: 17.0, max: 78.0)
[2025-11-09 20:29:45,054][12634] Avg episode reward: [(0, '663.933')]
[2025-11-09 20:29:50,218][12634] Fps is (10 sec: 2423.1, 60 sec: 3002.6, 300 sec: 3275.8). Total num frames: 2441216. Throughput: 0: 3024.8. Samples: 2453504. Policy #0 lag: (min: 9.0, avg: 12.0, max: 73.0)
[2025-11-09 20:29:50,218][12634] Avg episode reward: [(0, '686.464')]
[2025-11-09 20:29:50,220][12634] Saving new best policy, reward=686.464!
[2025-11-09 20:29:55,207][12634] Fps is (10 sec: 3227.1, 60 sec: 3000.6, 300 sec: 3275.9). Total num frames: 2457600. Throughput: 0: 2961.2. Samples: 2461184. Policy #0 lag: (min: 9.0, avg: 12.0, max: 73.0)
[2025-11-09 20:29:55,208][12634] Avg episode reward: [(0, '695.260')]
[2025-11-09 20:29:55,374][12634] Saving new best policy, reward=695.260!
[2025-11-09 20:29:56,839][12634] Signal inference workers to stop experience collection... (450 times)
[2025-11-09 20:29:57,242][12634] InferenceWorker_p0-w0: stopping experience collection (450 times)
[2025-11-09 20:29:57,244][12634] Signal inference workers to resume experience collection... (450 times)
[2025-11-09 20:29:57,409][12634] InferenceWorker_p0-w0: resuming experience collection (450 times)
[2025-11-09 20:30:00,070][12634] Fps is (10 sec: 3326.1, 60 sec: 3007.4, 300 sec: 3277.6). Total num frames: 2473984. Throughput: 0: 2962.8. Samples: 2478592. Policy #0 lag: (min: 11.0, avg: 14.0, max: 75.0)
[2025-11-09 20:30:00,070][12634] Avg episode reward: [(0, '685.065')]
[2025-11-09 20:30:05,180][12634] Fps is (10 sec: 3285.9, 60 sec: 3004.4, 300 sec: 3275.9). Total num frames: 2490368. Throughput: 0: 2905.0. Samples: 2496512. Policy #0 lag: (min: 11.0, avg: 14.0, max: 75.0)
[2025-11-09 20:30:05,180][12634] Avg episode reward: [(0, '687.792')]
[2025-11-09 20:30:10,104][12634] Fps is (10 sec: 3265.6, 60 sec: 3002.5, 300 sec: 3277.5). Total num frames: 2506752. Throughput: 0: 2906.4. Samples: 2505728. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-09 20:30:10,104][12634] Avg episode reward: [(0, '676.745')]
[2025-11-09 20:30:15,111][12634] Fps is (10 sec: 3299.4, 60 sec: 3005.1, 300 sec: 3276.8). Total num frames: 2523136. Throughput: 0: 2914.3. Samples: 2523648. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-09 20:30:15,111][12634] Avg episode reward: [(0, '679.590')]
[2025-11-09 20:30:20,157][12634] Fps is (10 sec: 3259.4, 60 sec: 2998.9, 300 sec: 3276.1). Total num frames: 2539520. Throughput: 0: 2912.4. Samples: 2540544. Policy #0 lag: (min: 0.0, avg: 3.0, max: 64.0)
[2025-11-09 20:30:20,158][12634] Avg episode reward: [(0, '678.699')]
[2025-11-09 20:30:25,079][12634] Fps is (10 sec: 2465.6, 60 sec: 2872.2, 300 sec: 3249.5). Total num frames: 2547712. Throughput: 0: 2912.5. Samples: 2549760. Policy #0 lag: (min: 0.0, avg: 3.0, max: 64.0)
[2025-11-09 20:30:25,079][12634] Avg episode reward: [(0, '688.070')]
[2025-11-09 20:30:30,200][12634] Fps is (10 sec: 1631.5, 60 sec: 2727.7, 300 sec: 3220.5). Total num frames: 2555904. Throughput: 0: 2903.2. Samples: 2567168. Policy #0 lag: (min: 0.0, avg: 3.0, max: 64.0)
[2025-11-09 20:30:30,200][12634] Avg episode reward: [(0, '698.887')]
[2025-11-09 20:30:30,361][12634] Saving new best policy, reward=698.887!
[2025-11-09 20:30:35,091][12634] Fps is (10 sec: 2454.8, 60 sec: 2733.5, 300 sec: 3221.7). Total num frames: 2572288. Throughput: 0: 2909.6. Samples: 2584064. Policy #0 lag: (min: 9.0, avg: 12.0, max: 73.0)
[2025-11-09 20:30:35,091][12634] Avg episode reward: [(0, '697.788')]
[2025-11-09 20:30:40,155][12634] Fps is (10 sec: 3291.5, 60 sec: 2863.4, 300 sec: 3220.2). Total num frames: 2588672. Throughput: 0: 2904.7. Samples: 2591744. Policy #0 lag: (min: 9.0, avg: 12.0, max: 73.0)
[2025-11-09 20:30:40,155][12634] Avg episode reward: [(0, '711.778')]
[2025-11-09 20:30:40,318][12634] Saving new best policy, reward=711.778!
[2025-11-09 20:30:45,198][12634] Fps is (10 sec: 3241.9, 60 sec: 2996.5, 300 sec: 3220.9). Total num frames: 2605056. Throughput: 0: 2870.4. Samples: 2608128. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-09 20:30:45,198][12634] Avg episode reward: [(0, '729.297')]
[2025-11-09 20:30:45,368][12634] Saving new best policy, reward=729.297!
[2025-11-09 20:30:50,130][12634] Fps is (10 sec: 3285.1, 60 sec: 3008.1, 300 sec: 3221.3). Total num frames: 2621440. Throughput: 0: 2847.6. Samples: 2624512. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-09 20:30:50,130][12634] Avg episode reward: [(0, '733.154')]
[2025-11-09 20:30:50,305][12634] Saving new best policy, reward=733.154!
[2025-11-09 20:30:55,067][12634] Fps is (10 sec: 3320.4, 60 sec: 3010.8, 300 sec: 3221.6). Total num frames: 2637824. Throughput: 0: 2846.8. Samples: 2633728. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-09 20:30:55,067][12634] Avg episode reward: [(0, '717.928')]
[2025-11-09 20:31:00,099][12634] Fps is (10 sec: 3287.0, 60 sec: 3002.3, 300 sec: 3222.0). Total num frames: 2654208. Throughput: 0: 2868.0. Samples: 2652672. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-09 20:31:00,099][12634] Avg episode reward: [(0, '717.129')]
[2025-11-09 20:31:05,087][12634] Fps is (10 sec: 3270.3, 60 sec: 3008.4, 300 sec: 3221.6). Total num frames: 2670592. Throughput: 0: 2917.3. Samples: 2671616. Policy #0 lag: (min: 11.0, avg: 14.0, max: 75.0)
[2025-11-09 20:31:05,087][12634] Avg episode reward: [(0, '750.510')]
[2025-11-09 20:31:05,233][12634] Saving /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_lidar_policy6_vel_ttc_yaw/checkpoint_p0/checkpoint_000010432_2670592.pth...
[2025-11-09 20:31:05,236][12634] Removing /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_lidar_policy6_vel_ttc_yaw/checkpoint_p0/checkpoint_000007488_1916928.pth
[2025-11-09 20:31:05,237][12634] Saving new best policy, reward=750.510!
[2025-11-09 20:31:10,175][12634] Fps is (10 sec: 3252.1, 60 sec: 3000.2, 300 sec: 3221.1). Total num frames: 2686976. Throughput: 0: 2929.2. Samples: 2681856. Policy #0 lag: (min: 11.0, avg: 14.0, max: 75.0)
[2025-11-09 20:31:10,175][12634] Avg episode reward: [(0, '766.157')]
[2025-11-09 20:31:10,319][12634] Saving new best policy, reward=766.157!
[2025-11-09 20:31:15,136][12634] Fps is (10 sec: 3260.5, 60 sec: 3002.5, 300 sec: 3194.0). Total num frames: 2703360. Throughput: 0: 2996.6. Samples: 2701824. Policy #0 lag: (min: 11.0, avg: 14.0, max: 75.0)
[2025-11-09 20:31:15,137][12634] Avg episode reward: [(0, '746.169')]
[2025-11-09 20:31:20,102][12634] Fps is (10 sec: 3300.9, 60 sec: 3006.5, 300 sec: 3167.0). Total num frames: 2719744. Throughput: 0: 3037.1. Samples: 2720768. Policy #0 lag: (min: 11.0, avg: 14.0, max: 75.0)
[2025-11-09 20:31:20,102][12634] Avg episode reward: [(0, '747.540')]
[2025-11-09 20:31:24,621][12634] Signal inference workers to stop experience collection... (500 times)
[2025-11-09 20:31:24,989][12634] InferenceWorker_p0-w0: stopping experience collection (500 times)
[2025-11-09 20:31:24,989][12634] Signal inference workers to resume experience collection... (500 times)
[2025-11-09 20:31:24,989][12634] InferenceWorker_p0-w0: resuming experience collection (500 times)
[2025-11-09 20:31:25,137][12634] Fps is (10 sec: 3276.6, 60 sec: 3137.2, 300 sec: 3166.2). Total num frames: 2736128. Throughput: 0: 3084.6. Samples: 2730496. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-09 20:31:25,137][12634] Avg episode reward: [(0, '719.650')]
[2025-11-09 20:31:30,151][12634] Fps is (10 sec: 3260.6, 60 sec: 3279.5, 300 sec: 3165.2). Total num frames: 2752512. Throughput: 0: 3177.7. Samples: 2750976. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-09 20:31:30,152][12634] Avg episode reward: [(0, '747.978')]
[2025-11-09 20:31:35,166][12634] Fps is (10 sec: 3267.4, 60 sec: 3272.7, 300 sec: 3164.6). Total num frames: 2768896. Throughput: 0: 3228.7. Samples: 2769920. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-09 20:31:35,166][12634] Avg episode reward: [(0, '759.627')]
[2025-11-09 20:31:40,097][12634] Fps is (10 sec: 3294.7, 60 sec: 3280.0, 300 sec: 3166.1). Total num frames: 2785280. Throughput: 0: 3274.6. Samples: 2781184. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-09 20:31:40,097][12634] Avg episode reward: [(0, '760.636')]
[2025-11-09 20:31:45,123][12634] Fps is (10 sec: 3290.8, 60 sec: 3280.9, 300 sec: 3165.3). Total num frames: 2801664. Throughput: 0: 3309.1. Samples: 2801664. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-09 20:31:45,124][12634] Avg episode reward: [(0, '762.514')]
[2025-11-09 20:31:50,067][12634] Fps is (10 sec: 3286.7, 60 sec: 3280.3, 300 sec: 3165.9). Total num frames: 2818048. Throughput: 0: 3323.8. Samples: 2821120. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-09 20:31:50,067][12634] Avg episode reward: [(0, '763.459')]
[2025-11-09 20:31:55,166][12634] Fps is (10 sec: 3263.0, 60 sec: 3271.4, 300 sec: 3165.7). Total num frames: 2834432. Throughput: 0: 3334.4. Samples: 2831872. Policy #0 lag: (min: 0.0, avg: 3.0, max: 64.0)
[2025-11-09 20:31:55,166][12634] Avg episode reward: [(0, '769.097')]
[2025-11-09 20:31:55,325][12634] Saving new best policy, reward=769.097!
[2025-11-09 20:32:00,123][12634] Fps is (10 sec: 3258.6, 60 sec: 3275.5, 300 sec: 3165.1). Total num frames: 2850816. Throughput: 0: 3334.7. Samples: 2851840. Policy #0 lag: (min: 0.0, avg: 3.0, max: 64.0)
[2025-11-09 20:32:00,123][12634] Avg episode reward: [(0, '779.809')]
[2025-11-09 20:32:00,258][12634] Saving new best policy, reward=779.809!
[2025-11-09 20:32:05,180][12634] Fps is (10 sec: 3272.2, 60 sec: 3271.7, 300 sec: 3164.5). Total num frames: 2867200. Throughput: 0: 3350.6. Samples: 2871808. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-09 20:32:05,180][12634] Avg episode reward: [(0, '824.174')]
[2025-11-09 20:32:05,331][12634] Saving new best policy, reward=824.174!
[2025-11-09 20:32:10,094][12634] Fps is (10 sec: 3286.2, 60 sec: 3281.2, 300 sec: 3166.2). Total num frames: 2883584. Throughput: 0: 3393.8. Samples: 2883072. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-09 20:32:10,094][12634] Avg episode reward: [(0, '860.300')]
[2025-11-09 20:32:10,237][12634] Saving new best policy, reward=860.300!
[2025-11-09 20:32:15,130][12634] Fps is (10 sec: 3293.2, 60 sec: 3277.2, 300 sec: 3165.1). Total num frames: 2899968. Throughput: 0: 3369.4. Samples: 2902528. Policy #0 lag: (min: 14.0, avg: 17.0, max: 78.0)
[2025-11-09 20:32:15,130][12634] Avg episode reward: [(0, '811.107')]
[2025-11-09 20:32:20,164][12634] Fps is (10 sec: 3253.9, 60 sec: 3273.4, 300 sec: 3164.8). Total num frames: 2916352. Throughput: 0: 3413.5. Samples: 2923520. Policy #0 lag: (min: 14.0, avg: 17.0, max: 78.0)
[2025-11-09 20:32:20,164][12634] Avg episode reward: [(0, '811.738')]
[2025-11-09 20:32:25,079][12634] Fps is (10 sec: 3293.4, 60 sec: 3280.0, 300 sec: 3165.8). Total num frames: 2932736. Throughput: 0: 3391.9. Samples: 2933760. Policy #0 lag: (min: 12.0, avg: 15.0, max: 76.0)
[2025-11-09 20:32:25,079][12634] Avg episode reward: [(0, '804.729')]
[2025-11-09 20:32:30,168][12634] Fps is (10 sec: 3275.5, 60 sec: 3275.9, 300 sec: 3164.8). Total num frames: 2949120. Throughput: 0: 3375.8. Samples: 2953728. Policy #0 lag: (min: 12.0, avg: 15.0, max: 76.0)
[2025-11-09 20:32:30,168][12634] Avg episode reward: [(0, '806.765')]
[2025-11-09 20:32:35,171][12634] Fps is (10 sec: 3247.0, 60 sec: 3276.5, 300 sec: 3164.7). Total num frames: 2965504. Throughput: 0: 3405.5. Samples: 2974720. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-09 20:32:35,171][12634] Avg episode reward: [(0, '824.700')]
[2025-11-09 20:32:40,183][12634] Fps is (10 sec: 3272.0, 60 sec: 3272.1, 300 sec: 3165.0). Total num frames: 2981888. Throughput: 0: 3355.1. Samples: 2982912. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-09 20:32:40,183][12634] Avg episode reward: [(0, '797.643')]
[2025-11-09 20:32:45,178][12634] Fps is (10 sec: 3274.5, 60 sec: 3273.8, 300 sec: 3164.6). Total num frames: 2998272. Throughput: 0: 3363.7. Samples: 3003392. Policy #0 lag: (min: 4.0, avg: 7.0, max: 68.0)
[2025-11-09 20:32:45,178][12634] Avg episode reward: [(0, '793.394')]
[2025-11-09 20:32:47,047][12634] Signal inference workers to stop experience collection... (550 times)
[2025-11-09 20:32:47,047][12634] Signal inference workers to resume experience collection... (550 times)
[2025-11-09 20:32:47,314][12634] InferenceWorker_p0-w0: stopping experience collection (550 times)
[2025-11-09 20:32:47,314][12634] InferenceWorker_p0-w0: resuming experience collection (550 times)
[2025-11-09 20:32:50,145][12634] Fps is (10 sec: 3289.4, 60 sec: 3272.6, 300 sec: 3165.3). Total num frames: 3014656. Throughput: 0: 3381.8. Samples: 3023872. Policy #0 lag: (min: 4.0, avg: 7.0, max: 68.0)
[2025-11-09 20:32:50,145][12634] Avg episode reward: [(0, '770.217')]
[2025-11-09 20:32:55,182][12634] Fps is (10 sec: 3275.7, 60 sec: 3275.9, 300 sec: 3164.4). Total num frames: 3031040. Throughput: 0: 3338.6. Samples: 3033600. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-09 20:32:55,182][12634] Avg episode reward: [(0, '790.188')]
[2025-11-09 20:33:00,101][12634] Fps is (10 sec: 3291.1, 60 sec: 3278.0, 300 sec: 3165.9). Total num frames: 3047424. Throughput: 0: 3358.6. Samples: 3053568. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-09 20:33:00,101][12634] Avg episode reward: [(0, '815.020')]
[2025-11-09 20:33:05,057][12634] Fps is (10 sec: 3318.0, 60 sec: 3283.5, 300 sec: 3166.5). Total num frames: 3063808. Throughput: 0: 3353.0. Samples: 3074048. Policy #0 lag: (min: 7.0, avg: 10.0, max: 71.0)
[2025-11-09 20:33:05,058][12634] Avg episode reward: [(0, '828.782')]
[2025-11-09 20:33:05,197][12634] Saving /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_lidar_policy6_vel_ttc_yaw/checkpoint_p0/checkpoint_000011968_3063808.pth...
[2025-11-09 20:33:05,201][12634] Removing /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_lidar_policy6_vel_ttc_yaw/checkpoint_p0/checkpoint_000009024_2310144.pth
[2025-11-09 20:33:10,080][12634] Fps is (10 sec: 3283.7, 60 sec: 3277.6, 300 sec: 3166.1). Total num frames: 3080192. Throughput: 0: 3322.2. Samples: 3083264. Policy #0 lag: (min: 7.0, avg: 10.0, max: 71.0)
[2025-11-09 20:33:10,080][12634] Avg episode reward: [(0, '814.824')]
[2025-11-09 20:33:15,142][12634] Fps is (10 sec: 3249.3, 60 sec: 3276.1, 300 sec: 3165.1). Total num frames: 3096576. Throughput: 0: 3335.6. Samples: 3103744. Policy #0 lag: (min: 7.0, avg: 10.0, max: 71.0)
[2025-11-09 20:33:15,142][12634] Avg episode reward: [(0, '811.075')]
[2025-11-09 20:33:20,111][12634] Fps is (10 sec: 3266.8, 60 sec: 3279.7, 300 sec: 3166.1). Total num frames: 3112960. Throughput: 0: 3349.6. Samples: 3125248. Policy #0 lag: (min: 7.0, avg: 10.0, max: 71.0)
[2025-11-09 20:33:20,111][12634] Avg episode reward: [(0, '800.642')]
[2025-11-09 20:33:25,148][12634] Fps is (10 sec: 3274.7, 60 sec: 3273.0, 300 sec: 3164.7). Total num frames: 3129344. Throughput: 0: 3381.8. Samples: 3134976. Policy #0 lag: (min: 14.0, avg: 17.0, max: 78.0)
[2025-11-09 20:33:25,149][12634] Avg episode reward: [(0, '822.398')]
[2025-11-09 20:33:30,141][12634] Fps is (10 sec: 3267.0, 60 sec: 3278.3, 300 sec: 3165.1). Total num frames: 3145728. Throughput: 0: 3370.6. Samples: 3154944. Policy #0 lag: (min: 14.0, avg: 17.0, max: 78.0)
[2025-11-09 20:33:30,141][12634] Avg episode reward: [(0, '814.541')]
[2025-11-09 20:33:35,061][12634] Fps is (10 sec: 3305.6, 60 sec: 3282.8, 300 sec: 3166.4). Total num frames: 3162112. Throughput: 0: 3362.7. Samples: 3174912. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-09 20:33:35,061][12634] Avg episode reward: [(0, '840.054')]
[2025-11-09 20:33:40,202][12634] Fps is (10 sec: 3256.7, 60 sec: 3275.7, 300 sec: 3165.0). Total num frames: 3178496. Throughput: 0: 3343.5. Samples: 3184128. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-09 20:33:40,202][12634] Avg episode reward: [(0, '847.989')]
[2025-11-09 20:33:45,155][12634] Fps is (10 sec: 3246.2, 60 sec: 3278.0, 300 sec: 3166.2). Total num frames: 3194880. Throughput: 0: 3318.3. Samples: 3203072. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-09 20:33:45,156][12634] Avg episode reward: [(0, '863.106')]
[2025-11-09 20:33:45,322][12634] Saving new best policy, reward=863.106!
[2025-11-09 20:33:50,189][12634] Fps is (10 sec: 3281.3, 60 sec: 3274.4, 300 sec: 3165.2). Total num frames: 3211264. Throughput: 0: 3255.9. Samples: 3220992. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-09 20:33:50,189][12634] Avg episode reward: [(0, '886.355')]
[2025-11-09 20:33:50,353][12634] Saving new best policy, reward=886.355!
[2025-11-09 20:33:55,068][12634] Fps is (10 sec: 3305.6, 60 sec: 3283.0, 300 sec: 3166.5). Total num frames: 3227648. Throughput: 0: 3232.1. Samples: 3228672. Policy #0 lag: (min: 5.0, avg: 8.0, max: 69.0)
[2025-11-09 20:33:55,069][12634] Avg episode reward: [(0, '892.867')]
[2025-11-09 20:33:55,226][12634] Saving new best policy, reward=892.867!
[2025-11-09 20:34:00,185][12634] Fps is (10 sec: 3278.0, 60 sec: 3272.2, 300 sec: 3165.8). Total num frames: 3244032. Throughput: 0: 3182.7. Samples: 3247104. Policy #0 lag: (min: 5.0, avg: 8.0, max: 69.0)
[2025-11-09 20:34:00,185][12634] Avg episode reward: [(0, '850.686')]
[2025-11-09 20:34:05,161][12634] Fps is (10 sec: 3246.8, 60 sec: 3271.2, 300 sec: 3164.8). Total num frames: 3260416. Throughput: 0: 3136.8. Samples: 3266560. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-09 20:34:05,161][12634] Avg episode reward: [(0, '838.347')]
[2025-11-09 20:34:10,095][12634] Fps is (10 sec: 3306.4, 60 sec: 3276.0, 300 sec: 3166.2). Total num frames: 3276800. Throughput: 0: 3155.4. Samples: 3276800. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-09 20:34:10,095][12634] Avg episode reward: [(0, '856.908')]
[2025-11-09 20:34:12,984][12634] Signal inference workers to stop experience collection... (600 times)
[2025-11-09 20:34:13,364][12634] InferenceWorker_p0-w0: stopping experience collection (600 times)
[2025-11-09 20:34:13,366][12634] Signal inference workers to resume experience collection... (600 times)
[2025-11-09 20:34:13,509][12634] InferenceWorker_p0-w0: resuming experience collection (600 times)
[2025-11-09 20:34:15,167][12634] Fps is (10 sec: 3274.8, 60 sec: 3275.4, 300 sec: 3164.6). Total num frames: 3293184. Throughput: 0: 3092.9. Samples: 3294208. Policy #0 lag: (min: 12.0, avg: 15.0, max: 76.0)
[2025-11-09 20:34:15,167][12634] Avg episode reward: [(0, '904.229')]
[2025-11-09 20:34:15,330][12634] Saving new best policy, reward=904.229!
[2025-11-09 20:34:20,151][12634] Fps is (10 sec: 3258.7, 60 sec: 3274.6, 300 sec: 3166.1). Total num frames: 3309568. Throughput: 0: 3088.6. Samples: 3314176. Policy #0 lag: (min: 12.0, avg: 15.0, max: 76.0)
[2025-11-09 20:34:20,151][12634] Avg episode reward: [(0, '914.895')]
[2025-11-09 20:34:20,293][12634] Saving new best policy, reward=914.895!
[2025-11-09 20:34:25,083][12634] Fps is (10 sec: 3304.7, 60 sec: 3280.4, 300 sec: 3166.3). Total num frames: 3325952. Throughput: 0: 3137.2. Samples: 3324928. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-09 20:34:25,083][12634] Avg episode reward: [(0, '898.236')]
[2025-11-09 20:34:30,051][12634] Fps is (10 sec: 3309.8, 60 sec: 3281.7, 300 sec: 3166.8). Total num frames: 3342336. Throughput: 0: 3124.8. Samples: 3343360. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-09 20:34:30,051][12634] Avg episode reward: [(0, '877.843')]
[2025-11-09 20:34:35,168][12634] Fps is (10 sec: 3249.1, 60 sec: 3271.0, 300 sec: 3192.5). Total num frames: 3358720. Throughput: 0: 3118.9. Samples: 3361280. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-09 20:34:35,168][12634] Avg episode reward: [(0, '893.723')]
[2025-11-09 20:34:40,101][12634] Fps is (10 sec: 3260.4, 60 sec: 3282.3, 300 sec: 3220.7). Total num frames: 3375104. Throughput: 0: 3183.4. Samples: 3372032. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-09 20:34:40,102][12634] Avg episode reward: [(0, '885.028')]
[2025-11-09 20:34:45,159][12634] Fps is (10 sec: 3279.8, 60 sec: 3276.6, 300 sec: 3221.9). Total num frames: 3391488. Throughput: 0: 3199.0. Samples: 3390976. Policy #0 lag: (min: 7.0, avg: 10.0, max: 71.0)
[2025-11-09 20:34:45,159][12634] Avg episode reward: [(0, '880.687')]
[2025-11-09 20:34:50,104][12634] Fps is (10 sec: 3275.9, 60 sec: 3281.4, 300 sec: 3222.4). Total num frames: 3407872. Throughput: 0: 3167.0. Samples: 3408896. Policy #0 lag: (min: 7.0, avg: 10.0, max: 71.0)
[2025-11-09 20:34:50,104][12634] Avg episode reward: [(0, '896.528')]
[2025-11-09 20:34:55,171][12634] Fps is (10 sec: 3273.0, 60 sec: 3271.2, 300 sec: 3220.2). Total num frames: 3424256. Throughput: 0: 3169.1. Samples: 3419648. Policy #0 lag: (min: 0.0, avg: 3.0, max: 64.0)
[2025-11-09 20:34:55,171][12634] Avg episode reward: [(0, '893.935')]
[2025-11-09 20:35:00,176][12634] Fps is (10 sec: 3253.3, 60 sec: 3277.3, 300 sec: 3221.3). Total num frames: 3440640. Throughput: 0: 3219.2. Samples: 3439104. Policy #0 lag: (min: 0.0, avg: 3.0, max: 64.0)
[2025-11-09 20:35:00,177][12634] Avg episode reward: [(0, '880.226')]
[2025-11-09 20:35:05,118][12634] Fps is (10 sec: 3294.3, 60 sec: 3279.2, 300 sec: 3221.1). Total num frames: 3457024. Throughput: 0: 3199.5. Samples: 3458048. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-09 20:35:05,118][12634] Avg episode reward: [(0, '861.960')]
[2025-11-09 20:35:05,120][12634] Saving /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_lidar_policy6_vel_ttc_yaw/checkpoint_p0/checkpoint_000013504_3457024.pth...
[2025-11-09 20:35:05,124][12634] Removing /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_lidar_policy6_vel_ttc_yaw/checkpoint_p0/checkpoint_000010432_2670592.pth
[2025-11-09 20:35:10,175][12634] Fps is (10 sec: 3277.1, 60 sec: 3272.4, 300 sec: 3220.6). Total num frames: 3473408. Throughput: 0: 3156.5. Samples: 3467264. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-09 20:35:10,176][12634] Avg episode reward: [(0, '885.996')]
[2025-11-09 20:35:15,144][12634] Fps is (10 sec: 3268.1, 60 sec: 3278.0, 300 sec: 3221.4). Total num frames: 3489792. Throughput: 0: 3201.9. Samples: 3487744. Policy #0 lag: (min: 44.0, avg: 47.0, max: 108.0)
[2025-11-09 20:35:15,145][12634] Avg episode reward: [(0, '919.428')]
[2025-11-09 20:35:15,292][12634] Saving new best policy, reward=919.428!
[2025-11-09 20:35:20,117][12634] Fps is (10 sec: 3296.2, 60 sec: 3278.7, 300 sec: 3248.6). Total num frames: 3506176. Throughput: 0: 3246.4. Samples: 3507200. Policy #0 lag: (min: 44.0, avg: 47.0, max: 108.0)
[2025-11-09 20:35:20,117][12634] Avg episode reward: [(0, '921.364')]
[2025-11-09 20:35:20,265][12634] Saving new best policy, reward=921.364!
[2025-11-09 20:35:25,173][12634] Fps is (10 sec: 3267.5, 60 sec: 3271.9, 300 sec: 3277.1). Total num frames: 3522560. Throughput: 0: 3226.2. Samples: 3517440. Policy #0 lag: (min: 44.0, avg: 47.0, max: 108.0)
[2025-11-09 20:35:25,173][12634] Avg episode reward: [(0, '919.726')]
[2025-11-09 20:35:30,125][12634] Fps is (10 sec: 3274.1, 60 sec: 3272.8, 300 sec: 3276.4). Total num frames: 3538944. Throughput: 0: 3267.9. Samples: 3537920. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-09 20:35:30,125][12634] Avg episode reward: [(0, '927.485')]
[2025-11-09 20:35:30,262][12634] Saving new best policy, reward=927.485!
[2025-11-09 20:35:34,352][12634] Signal inference workers to stop experience collection... (650 times)
[2025-11-09 20:35:34,715][12634] InferenceWorker_p0-w0: stopping experience collection (650 times)
[2025-11-09 20:35:34,715][12634] Signal inference workers to resume experience collection... (650 times)
[2025-11-09 20:35:34,716][12634] InferenceWorker_p0-w0: resuming experience collection (650 times)
[2025-11-09 20:35:35,148][12634] Fps is (10 sec: 3284.9, 60 sec: 3277.9, 300 sec: 3276.9). Total num frames: 3555328. Throughput: 0: 3273.6. Samples: 3556352. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-09 20:35:35,148][12634] Avg episode reward: [(0, '937.800')]
[2025-11-09 20:35:35,298][12634] Saving new best policy, reward=937.800!
[2025-11-09 20:35:40,101][12634] Fps is (10 sec: 3284.5, 60 sec: 3276.8, 300 sec: 3277.9). Total num frames: 3571712. Throughput: 0: 3281.9. Samples: 3567104. Policy #0 lag: (min: 39.0, avg: 42.0, max: 103.0)
[2025-11-09 20:35:40,102][12634] Avg episode reward: [(0, '939.546')]
[2025-11-09 20:35:40,242][12634] Saving new best policy, reward=939.546!
[2025-11-09 20:35:45,157][12634] Fps is (10 sec: 3274.0, 60 sec: 3276.9, 300 sec: 3276.5). Total num frames: 3588096. Throughput: 0: 3301.0. Samples: 3587584. Policy #0 lag: (min: 39.0, avg: 42.0, max: 103.0)
[2025-11-09 20:35:45,157][12634] Avg episode reward: [(0, '931.674')]
[2025-11-09 20:35:50,133][12634] Fps is (10 sec: 3266.5, 60 sec: 3275.2, 300 sec: 3276.1). Total num frames: 3604480. Throughput: 0: 3298.4. Samples: 3606528. Policy #0 lag: (min: 39.0, avg: 42.0, max: 103.0)
[2025-11-09 20:35:50,133][12634] Avg episode reward: [(0, '923.634')]
[2025-11-09 20:35:55,093][12634] Fps is (10 sec: 3297.8, 60 sec: 3281.1, 300 sec: 3276.9). Total num frames: 3620864. Throughput: 0: 3328.4. Samples: 3616768. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-09 20:35:55,093][12634] Avg episode reward: [(0, '920.487')]
[2025-11-09 20:36:00,149][12634] Fps is (10 sec: 3271.5, 60 sec: 3278.3, 300 sec: 3276.1). Total num frames: 3637248. Throughput: 0: 3299.2. Samples: 3636224. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-09 20:36:00,149][12634] Avg episode reward: [(0, '939.871')]
[2025-11-09 20:36:00,301][12634] Saving new best policy, reward=939.871!
[2025-11-09 20:36:05,082][12634] Fps is (10 sec: 2460.2, 60 sec: 3142.1, 300 sec: 3250.0). Total num frames: 3645440. Throughput: 0: 3267.9. Samples: 3654144. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-09 20:36:05,083][12634] Avg episode reward: [(0, '962.615')]
[2025-11-09 20:36:05,493][12634] Saving new best policy, reward=962.615!
[2025-11-09 20:36:10,189][12634] Fps is (10 sec: 1631.9, 60 sec: 3003.1, 300 sec: 3220.7). Total num frames: 3653632. Throughput: 0: 3207.4. Samples: 3661824. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-09 20:36:10,189][12634] Avg episode reward: [(0, '949.758')]
[2025-11-09 20:36:15,146][12634] Fps is (10 sec: 2442.0, 60 sec: 3003.6, 300 sec: 3220.8). Total num frames: 3670016. Throughput: 0: 3150.2. Samples: 3679744. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-09 20:36:15,146][12634] Avg episode reward: [(0, '974.614')]
[2025-11-09 20:36:15,298][12634] Saving new best policy, reward=974.614!
[2025-11-09 20:36:20,145][12634] Fps is (10 sec: 3291.4, 60 sec: 3002.3, 300 sec: 3221.2). Total num frames: 3686400. Throughput: 0: 3174.6. Samples: 3699200. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-09 20:36:20,145][12634] Avg episode reward: [(0, '939.840')]
[2025-11-09 20:36:25,081][12634] Fps is (10 sec: 3298.4, 60 sec: 3008.3, 300 sec: 3222.0). Total num frames: 3702784. Throughput: 0: 3130.3. Samples: 3707904. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-09 20:36:25,081][12634] Avg episode reward: [(0, '976.737')]
[2025-11-09 20:36:25,232][12634] Saving new best policy, reward=976.737!
[2025-11-09 20:36:30,103][12634] Fps is (10 sec: 3290.7, 60 sec: 3004.9, 300 sec: 3222.0). Total num frames: 3719168. Throughput: 0: 3098.5. Samples: 3726848. Policy #0 lag: (min: 31.0, avg: 34.0, max: 95.0)
[2025-11-09 20:36:30,103][12634] Avg episode reward: [(0, '935.343')]
[2025-11-09 20:36:35,128][12634] Fps is (10 sec: 3261.5, 60 sec: 3004.7, 300 sec: 3220.9). Total num frames: 3735552. Throughput: 0: 3083.7. Samples: 3745280. Policy #0 lag: (min: 31.0, avg: 34.0, max: 95.0)
[2025-11-09 20:36:35,128][12634] Avg episode reward: [(0, '952.431')]
[2025-11-09 20:36:40,198][12634] Fps is (10 sec: 3245.7, 60 sec: 2998.9, 300 sec: 3220.4). Total num frames: 3751936. Throughput: 0: 3019.4. Samples: 3752960. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-09 20:36:40,199][12634] Avg episode reward: [(0, '975.163')]
[2025-11-09 20:36:45,182][12634] Fps is (10 sec: 3259.0, 60 sec: 3002.4, 300 sec: 3220.0). Total num frames: 3768320. Throughput: 0: 3024.2. Samples: 3772416. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-09 20:36:45,183][12634] Avg episode reward: [(0, '964.913')]
[2025-11-09 20:36:50,156][12634] Fps is (10 sec: 3290.8, 60 sec: 3002.6, 300 sec: 3221.4). Total num frames: 3784704. Throughput: 0: 3032.9. Samples: 3790848. Policy #0 lag: (min: 19.0, avg: 22.0, max: 83.0)
[2025-11-09 20:36:50,156][12634] Avg episode reward: [(0, '956.549')]
[2025-11-09 20:36:55,080][12634] Fps is (10 sec: 3310.8, 60 sec: 3004.4, 300 sec: 3221.7). Total num frames: 3801088. Throughput: 0: 3102.3. Samples: 3801088. Policy #0 lag: (min: 19.0, avg: 22.0, max: 83.0)
[2025-11-09 20:36:55,080][12634] Avg episode reward: [(0, '965.896')]
[2025-11-09 20:37:00,176][12634] Fps is (10 sec: 3270.1, 60 sec: 3002.4, 300 sec: 3221.3). Total num frames: 3817472. Throughput: 0: 3081.3. Samples: 3818496. Policy #0 lag: (min: 47.0, avg: 50.0, max: 111.0)
[2025-11-09 20:37:00,177][12634] Avg episode reward: [(0, '1008.790')]
[2025-11-09 20:37:00,332][12634] Saving new best policy, reward=1008.790!
[2025-11-09 20:37:03,660][12634] Signal inference workers to stop experience collection... (700 times)
[2025-11-09 20:37:03,660][12634] Signal inference workers to resume experience collection... (700 times)
[2025-11-09 20:37:03,932][12634] InferenceWorker_p0-w0: stopping experience collection (700 times)
[2025-11-09 20:37:03,932][12634] InferenceWorker_p0-w0: resuming experience collection (700 times)
[2025-11-09 20:37:05,114][12634] Fps is (10 sec: 3265.4, 60 sec: 3138.6, 300 sec: 3221.0). Total num frames: 3833856. Throughput: 0: 3074.1. Samples: 3837440. Policy #0 lag: (min: 47.0, avg: 50.0, max: 111.0)
[2025-11-09 20:37:05,115][12634] Avg episode reward: [(0, '1006.016')]
[2025-11-09 20:37:05,267][12634] Saving /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_lidar_policy6_vel_ttc_yaw/checkpoint_p0/checkpoint_000014976_3833856.pth...
[2025-11-09 20:37:05,271][12634] Removing /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_lidar_policy6_vel_ttc_yaw/checkpoint_p0/checkpoint_000011968_3063808.pth
[2025-11-09 20:37:10,079][12634] Fps is (10 sec: 3309.0, 60 sec: 3282.8, 300 sec: 3221.8). Total num frames: 3850240. Throughput: 0: 3094.9. Samples: 3847168. Policy #0 lag: (min: 49.0, avg: 52.0, max: 113.0)
[2025-11-09 20:37:10,079][12634] Avg episode reward: [(0, '967.558')]
[2025-11-09 20:37:15,071][12634] Fps is (10 sec: 3291.2, 60 sec: 3280.9, 300 sec: 3222.3). Total num frames: 3866624. Throughput: 0: 3074.2. Samples: 3865088. Policy #0 lag: (min: 49.0, avg: 52.0, max: 113.0)
[2025-11-09 20:37:15,071][12634] Avg episode reward: [(0, '961.773')]
[2025-11-09 20:37:20,206][12634] Fps is (10 sec: 3235.8, 60 sec: 3273.5, 300 sec: 3219.9). Total num frames: 3883008. Throughput: 0: 3078.0. Samples: 3884032. Policy #0 lag: (min: 49.0, avg: 52.0, max: 113.0)
[2025-11-09 20:37:20,206][12634] Avg episode reward: [(0, '978.497')]
[2025-11-09 20:37:25,072][12634] Fps is (10 sec: 2457.3, 60 sec: 3140.7, 300 sec: 3194.5). Total num frames: 3891200. Throughput: 0: 3114.9. Samples: 3892736. Policy #0 lag: (min: 7.0, avg: 10.0, max: 71.0)
[2025-11-09 20:37:25,072][12634] Avg episode reward: [(0, '1002.440')]
[2025-11-09 20:37:30,405][12634] Fps is (10 sec: 2409.7, 60 sec: 3124.5, 300 sec: 3191.0). Total num frames: 3907584. Throughput: 0: 3079.6. Samples: 3911680. Policy #0 lag: (min: 7.0, avg: 10.0, max: 71.0)
[2025-11-09 20:37:30,405][12634] Avg episode reward: [(0, '1008.510')]
[2025-11-09 20:37:35,062][12634] Fps is (10 sec: 2460.1, 60 sec: 3007.1, 300 sec: 3167.0). Total num frames: 3915776. Throughput: 0: 3101.3. Samples: 3930112. Policy #0 lag: (min: 7.0, avg: 10.0, max: 71.0)
[2025-11-09 20:37:35,062][12634] Avg episode reward: [(0, '1027.763')]
[2025-11-09 20:37:35,222][12634] Saving new best policy, reward=1027.763!
