[2026-02-02 14:36:51,276][187009] Saving configuration to /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_accel_policy3_aggressive_magpie_refined_params_02022026_smooth_aggressive_ttc/config.json...
[2026-02-02 14:36:51,310][187009] Using GPUs [0] for process 0 (actually maps to GPUs [0])
[2026-02-02 14:36:51,310][187009] Rollout worker 0 uses device cuda:0
[2026-02-02 14:36:51,346][187009] Using GPUs [0] for process 0 (actually maps to GPUs [0])
[2026-02-02 14:36:51,346][187009] InferenceWorker_p0-w0: min num requests: 1
[2026-02-02 14:36:51,346][187009] Using GPUs [0] for process 0 (actually maps to GPUs [0])
[2026-02-02 14:36:51,347][187009] Starting seed is not provided
[2026-02-02 14:36:51,347][187009] Using GPUs [0] for process 0 (actually maps to GPUs [0])
[2026-02-02 14:36:51,347][187009] Initializing actor-critic model on device cuda:0
[2026-02-02 14:36:51,348][187009] RunningMeanStd input shape: (337,)
[2026-02-02 14:36:51,348][187009] RunningMeanStd input shape: (1,)
[2026-02-02 14:36:51,356][187009] Created Actor Critic model with architecture:
[2026-02-02 14:36:51,356][187009] ActorCriticSharedWeights(
  (obs_normalizer): ObservationNormalizer(
    (running_mean_std): RunningMeanStdDictInPlace(
      (running_mean_std): ModuleDict(
        (observations): RunningMeanStdInPlace()
      )
    )
  )
  (returns_normalizer): RecursiveScriptModule(original_name=RunningMeanStdInPlace)
  (encoder): CustomEncoder(
    (encoders): ModuleDict(
      (obs_image): Sequential(
        (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): ELU(alpha=1.0)
        (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
        (3): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (4): ELU(alpha=1.0)
        (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
        (6): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (7): ELU(alpha=1.0)
        (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        (9): Flatten(start_dim=1, end_dim=-1)
      )
    )
    (mlp_head_custom): Sequential(
      (0): Linear(in_features=145, out_features=256, bias=True)
      (1): ELU(alpha=1.0)
      (2): Linear(in_features=256, out_features=128, bias=True)
      (3): ELU(alpha=1.0)
      (4): Linear(in_features=128, out_features=64, bias=True)
      (5): ELU(alpha=1.0)
    )
  )
  (core): ModelCoreRNN(
    (core): GRU(64, 128)
  )
  (decoder): MlpDecoder(
    (mlp): Identity()
  )
  (critic_linear): Linear(in_features=128, out_features=1, bias=True)
  (action_parameterization): ActionParameterizationDefault(
    (distribution_linear): Linear(in_features=128, out_features=8, bias=True)
  )
)
[2026-02-02 14:36:51,725][187009] Using optimizer <class 'torch.optim.adam.Adam'>
[2026-02-02 14:36:51,725][187009] No checkpoints found
[2026-02-02 14:36:51,726][187009] Did not load from checkpoint, starting from scratch!
[2026-02-02 14:36:51,726][187009] Initialized policy 0 weights for model version 0
[2026-02-02 14:36:51,726][187009] LearnerWorker_p0 finished initialization!
[2026-02-02 14:36:51,726][187009] Using GPUs [0] for process 0 (actually maps to GPUs [0])
[2026-02-02 14:36:51,731][187009] Fps is (10 sec: nan, 60 sec: nan, 300 sec: nan). Total num frames: 0. Throughput: 0: nan. Samples: 0. Policy #0 lag: (min: -1.0, avg: -1.0, max: -1.0)
[2026-02-02 14:36:51,731][187009] Inference worker 0-0 is ready!
[2026-02-02 14:36:51,731][187009] All inference workers are ready! Signal rollout workers to start!
[2026-02-02 14:36:51,732][187009] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 0.0). Total num frames: 0. Throughput: 0: 0.0. Samples: 0. Policy #0 lag: (min: -1.0, avg: -1.0, max: -1.0)
[2026-02-02 14:36:51,732][187009] EnvRunner 0-0 uses policy 0
[2026-02-02 14:37:05,867][187009] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 0.0). Total num frames: 0. Throughput: 0: 0.0. Samples: 0. Policy #0 lag: (min: -1.0, avg: -1.0, max: -1.0)
[2026-02-02 14:37:10,207][187009] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 0.0). Total num frames: 0. Throughput: 0: 0.0. Samples: 0. Policy #0 lag: (min: -1.0, avg: -1.0, max: -1.0)
[2026-02-02 14:37:10,311][187009] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 0.0). Total num frames: 0. Throughput: 0: 27.6. Samples: 512. Policy #0 lag: (min: -1.0, avg: -1.0, max: -1.0)
[2026-02-02 14:37:10,312][187009] Avg episode reward: [(0, '-10.000')]
[2026-02-02 14:37:11,671][187009] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 0.0). Total num frames: 0. Throughput: 0: 51.4. Samples: 1024. Policy #0 lag: (min: -1.0, avg: -1.0, max: -1.0)
[2026-02-02 14:37:11,671][187009] Avg episode reward: [(0, '-10.000')]
[2026-02-02 14:37:11,820][187009] Heartbeat connected on Batcher_0
[2026-02-02 14:37:11,820][187009] Heartbeat connected on LearnerWorker_p0
[2026-02-02 14:37:11,820][187009] Heartbeat connected on InferenceWorker_p0-w0
[2026-02-02 14:37:11,820][187009] Heartbeat connected on RolloutWorker_w0
[2026-02-02 14:37:14,622][187009] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 0.0). Total num frames: 0. Throughput: 0: 246.0. Samples: 5632. Policy #0 lag: (min: -1.0, avg: -1.0, max: -1.0)
[2026-02-02 14:37:14,622][187009] Avg episode reward: [(0, '-10.742')]
[2026-02-02 14:37:16,293][187009] Signal inference workers to stop experience collection...
[2026-02-02 14:37:17,561][187009] InferenceWorker_p0-w0: stopping experience collection
[2026-02-02 14:37:17,563][187009] Signal inference workers to resume experience collection...
[2026-02-02 14:37:17,691][187009] InferenceWorker_p0-w0: resuming experience collection
[2026-02-02 14:37:19,632][187009] Fps is (10 sec: 2058.1, 60 sec: 587.2, 300 sec: 587.2). Total num frames: 16384. Throughput: 0: 770.7. Samples: 21504. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[2026-02-02 14:37:19,632][187009] Avg episode reward: [(0, '-23.304')]
[2026-02-02 14:37:24,558][187009] Fps is (10 sec: 3298.0, 60 sec: 998.2, 300 sec: 998.2). Total num frames: 32768. Throughput: 0: 1029.4. Samples: 33792. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 14:37:24,558][187009] Avg episode reward: [(0, '-35.920')]
[2026-02-02 14:37:29,519][187009] Fps is (10 sec: 3314.1, 60 sec: 1300.7, 300 sec: 1300.7). Total num frames: 49152. Throughput: 0: 1490.4. Samples: 56320. Policy #0 lag: (min: 11.0, avg: 14.0, max: 75.0)
[2026-02-02 14:37:29,519][187009] Avg episode reward: [(0, '-186.389')]
[2026-02-02 14:37:34,626][187009] Fps is (10 sec: 3254.5, 60 sec: 1527.8, 300 sec: 1527.8). Total num frames: 65536. Throughput: 0: 1754.6. Samples: 75264. Policy #0 lag: (min: 9.0, avg: 12.0, max: 73.0)
[2026-02-02 14:37:34,627][187009] Avg episode reward: [(0, '-200.123')]
[2026-02-02 14:37:39,610][187009] Fps is (10 sec: 3247.3, 60 sec: 1711.0, 300 sec: 1711.0). Total num frames: 81920. Throughput: 0: 2518.9. Samples: 84992. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 14:37:39,610][187009] Avg episode reward: [(0, '-136.188')]
[2026-02-02 14:37:44,833][187009] Fps is (10 sec: 3210.5, 60 sec: 1851.2, 300 sec: 1851.2). Total num frames: 98304. Throughput: 0: 3120.0. Samples: 108032. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 14:37:44,833][187009] Avg episode reward: [(0, '-145.217')]
[2026-02-02 14:37:49,779][187009] Fps is (10 sec: 4027.8, 60 sec: 2116.9, 300 sec: 2116.9). Total num frames: 122880. Throughput: 0: 3256.1. Samples: 129024. Policy #0 lag: (min: 13.0, avg: 16.0, max: 77.0)
[2026-02-02 14:37:49,779][187009] Avg episode reward: [(0, '-145.345')]
[2026-02-02 14:37:50,136][187009] Saving new best policy, reward=-145.345!
[2026-02-02 14:37:54,877][187009] Fps is (10 sec: 4893.6, 60 sec: 3008.7, 300 sec: 2335.2). Total num frames: 147456. Throughput: 0: 3187.7. Samples: 138752. Policy #0 lag: (min: 4.0, avg: 7.0, max: 68.0)
[2026-02-02 14:37:54,877][187009] Avg episode reward: [(0, '-104.644')]
[2026-02-02 14:37:54,879][187009] Saving new best policy, reward=-104.644!
[2026-02-02 14:37:59,589][187009] Fps is (10 sec: 4175.4, 60 sec: 3317.8, 300 sec: 2414.5). Total num frames: 163840. Throughput: 0: 3438.6. Samples: 160256. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 14:37:59,589][187009] Avg episode reward: [(0, '-70.590')]
[2026-02-02 14:37:59,709][187009] Saving new best policy, reward=-70.590!
[2026-02-02 14:38:04,605][187009] Fps is (10 sec: 3368.4, 60 sec: 3319.4, 300 sec: 2473.1). Total num frames: 180224. Throughput: 0: 3551.9. Samples: 181248. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 14:38:04,606][187009] Avg episode reward: [(0, '-68.040')]
[2026-02-02 14:38:04,738][187009] Saving new best policy, reward=-68.040!
[2026-02-02 14:38:09,617][187009] Fps is (10 sec: 3267.5, 60 sec: 3392.9, 300 sec: 2524.3). Total num frames: 196608. Throughput: 0: 3499.7. Samples: 191488. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 14:38:09,624][187009] Avg episode reward: [(0, '-60.928')]
[2026-02-02 14:38:09,751][187009] Saving new best policy, reward=-60.928!
[2026-02-02 14:38:14,583][187009] Fps is (10 sec: 3284.2, 60 sec: 3552.2, 300 sec: 2570.8). Total num frames: 212992. Throughput: 0: 3488.0. Samples: 213504. Policy #0 lag: (min: 1.0, avg: 4.0, max: 65.0)
[2026-02-02 14:38:14,583][187009] Avg episode reward: [(0, '-45.950')]
[2026-02-02 14:38:14,703][187009] Saving new best policy, reward=-45.950!
[2026-02-02 14:38:19,577][187009] Fps is (10 sec: 3290.2, 60 sec: 3553.1, 300 sec: 2611.1). Total num frames: 229376. Throughput: 0: 3519.6. Samples: 233472. Policy #0 lag: (min: 6.0, avg: 9.0, max: 70.0)
[2026-02-02 14:38:19,577][187009] Avg episode reward: [(0, '-43.402')]
[2026-02-02 14:38:19,707][187009] Saving new best policy, reward=-43.402!
[2026-02-02 14:38:24,528][187009] Fps is (10 sec: 3294.9, 60 sec: 3551.7, 300 sec: 2648.4). Total num frames: 245760. Throughput: 0: 3567.8. Samples: 245248. Policy #0 lag: (min: 11.0, avg: 14.0, max: 75.0)
[2026-02-02 14:38:24,528][187009] Avg episode reward: [(0, '-39.906')]
[2026-02-02 14:38:24,667][187009] Saving new best policy, reward=-39.906!
[2026-02-02 14:38:29,521][187009] Fps is (10 sec: 3295.1, 60 sec: 3549.7, 300 sec: 2680.7). Total num frames: 262144. Throughput: 0: 3517.4. Samples: 265216. Policy #0 lag: (min: 2.0, avg: 5.0, max: 66.0)
[2026-02-02 14:38:29,521][187009] Avg episode reward: [(0, '-34.224')]
[2026-02-02 14:38:29,652][187009] Saving new best policy, reward=-34.224!
[2026-02-02 14:38:31,731][187009] Signal inference workers to stop experience collection... (50 times)
[2026-02-02 14:38:32,082][187009] InferenceWorker_p0-w0: stopping experience collection (50 times)
[2026-02-02 14:38:32,083][187009] Signal inference workers to resume experience collection... (50 times)
[2026-02-02 14:38:32,083][187009] InferenceWorker_p0-w0: resuming experience collection (50 times)
[2026-02-02 14:38:34,613][187009] Fps is (10 sec: 3249.0, 60 sec: 3550.6, 300 sec: 2707.3). Total num frames: 278528. Throughput: 0: 3505.9. Samples: 286208. Policy #0 lag: (min: 0.0, avg: 3.0, max: 64.0)
[2026-02-02 14:38:34,613][187009] Avg episode reward: [(0, '-29.984')]
[2026-02-02 14:38:34,762][187009] Saving /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_accel_policy3_aggressive_magpie_refined_params_02022026_smooth_aggressive_ttc/checkpoint_p0/checkpoint_000001088_278528.pth...
[2026-02-02 14:38:34,767][187009] Saving new best policy, reward=-29.984!
[2026-02-02 14:38:39,543][187009] Fps is (10 sec: 3269.5, 60 sec: 3553.8, 300 sec: 2735.4). Total num frames: 294912. Throughput: 0: 3519.1. Samples: 295936. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 14:38:39,544][187009] Avg episode reward: [(0, '-24.643')]
[2026-02-02 14:38:39,681][187009] Saving new best policy, reward=-24.643!
[2026-02-02 14:38:44,608][187009] Fps is (10 sec: 3278.5, 60 sec: 3563.2, 300 sec: 2757.8). Total num frames: 311296. Throughput: 0: 3491.5. Samples: 317440. Policy #0 lag: (min: 11.0, avg: 14.0, max: 75.0)
[2026-02-02 14:38:44,608][187009] Avg episode reward: [(0, '-18.592')]
[2026-02-02 14:38:44,745][187009] Saving new best policy, reward=-18.592!
[2026-02-02 14:38:49,637][187009] Fps is (10 sec: 3246.3, 60 sec: 3421.4, 300 sec: 2779.2). Total num frames: 327680. Throughput: 0: 3501.9. Samples: 338944. Policy #0 lag: (min: 14.0, avg: 17.0, max: 78.0)
[2026-02-02 14:38:49,637][187009] Avg episode reward: [(0, '-13.613')]
[2026-02-02 14:38:49,775][187009] Saving new best policy, reward=-13.613!
[2026-02-02 14:38:54,595][187009] Fps is (10 sec: 3281.1, 60 sec: 3292.3, 300 sec: 2800.4). Total num frames: 344064. Throughput: 0: 3494.7. Samples: 348672. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 14:38:54,595][187009] Avg episode reward: [(0, '-8.662')]
[2026-02-02 14:38:54,739][187009] Saving new best policy, reward=-8.662!
[2026-02-02 14:38:59,600][187009] Fps is (10 sec: 3288.9, 60 sec: 3276.2, 300 sec: 2818.9). Total num frames: 360448. Throughput: 0: 3446.1. Samples: 368640. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 14:38:59,601][187009] Avg episode reward: [(0, '-0.464')]
[2026-02-02 14:38:59,732][187009] Saving new best policy, reward=-0.464!
[2026-02-02 14:39:04,535][187009] Fps is (10 sec: 3296.7, 60 sec: 3280.7, 300 sec: 2837.5). Total num frames: 376832. Throughput: 0: 3462.1. Samples: 389120. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 14:39:04,535][187009] Avg episode reward: [(0, '5.079')]
[2026-02-02 14:39:04,673][187009] Saving new best policy, reward=5.079!
[2026-02-02 14:39:09,593][187009] Fps is (10 sec: 3279.1, 60 sec: 3278.1, 300 sec: 2852.2). Total num frames: 393216. Throughput: 0: 3397.0. Samples: 398336. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 14:39:09,594][187009] Avg episode reward: [(0, '10.708')]
[2026-02-02 14:39:09,726][187009] Saving new best policy, reward=10.708!
[2026-02-02 14:39:14,632][187009] Fps is (10 sec: 3245.3, 60 sec: 3274.1, 300 sec: 2866.3). Total num frames: 409600. Throughput: 0: 3416.3. Samples: 419328. Policy #0 lag: (min: 5.0, avg: 8.0, max: 69.0)
[2026-02-02 14:39:14,632][187009] Avg episode reward: [(0, '18.461')]
[2026-02-02 14:39:15,017][187009] Saving new best policy, reward=18.461!
[2026-02-02 14:39:19,828][187009] Fps is (10 sec: 4002.1, 60 sec: 3399.1, 300 sec: 2931.7). Total num frames: 434176. Throughput: 0: 3408.4. Samples: 440320. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 14:39:19,828][187009] Avg episode reward: [(0, '24.443')]
[2026-02-02 14:39:20,208][187009] Saving new best policy, reward=24.443!
[2026-02-02 14:39:24,701][187009] Fps is (10 sec: 4068.0, 60 sec: 3403.5, 300 sec: 2945.4). Total num frames: 450560. Throughput: 0: 3401.4. Samples: 449536. Policy #0 lag: (min: 11.0, avg: 14.0, max: 75.0)
[2026-02-02 14:39:24,701][187009] Avg episode reward: [(0, '28.074')]
[2026-02-02 14:39:25,115][187009] Saving new best policy, reward=28.074!
[2026-02-02 14:39:29,623][187009] Fps is (10 sec: 3345.6, 60 sec: 3407.6, 300 sec: 2957.4). Total num frames: 466944. Throughput: 0: 3400.8. Samples: 470528. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 14:39:29,623][187009] Avg episode reward: [(0, '31.790')]
[2026-02-02 14:39:29,993][187009] Saving new best policy, reward=31.790!
[2026-02-02 14:39:34,839][187009] Fps is (10 sec: 3232.1, 60 sec: 3400.5, 300 sec: 2963.2). Total num frames: 483328. Throughput: 0: 3352.8. Samples: 490496. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 14:39:34,839][187009] Avg episode reward: [(0, '38.335')]
[2026-02-02 14:39:35,292][187009] Saving new best policy, reward=38.335!
[2026-02-02 14:39:39,533][187009] Fps is (10 sec: 2479.7, 60 sec: 3277.3, 300 sec: 2929.2). Total num frames: 491520. Throughput: 0: 3326.9. Samples: 498176. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 14:39:39,534][187009] Avg episode reward: [(0, '49.998')]
[2026-02-02 14:39:39,906][187009] Saving new best policy, reward=49.998!
[2026-02-02 14:39:44,840][187009] Fps is (10 sec: 3276.3, 60 sec: 3400.2, 300 sec: 2981.3). Total num frames: 516096. Throughput: 0: 3327.3. Samples: 519168. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 14:39:44,840][187009] Avg episode reward: [(0, '58.407')]
[2026-02-02 14:39:45,218][187009] Saving new best policy, reward=58.407!
[2026-02-02 14:39:49,705][187009] Fps is (10 sec: 4027.0, 60 sec: 3409.5, 300 sec: 2991.9). Total num frames: 532480. Throughput: 0: 3321.1. Samples: 539136. Policy #0 lag: (min: 12.0, avg: 15.0, max: 76.0)
[2026-02-02 14:39:49,705][187009] Avg episode reward: [(0, '63.513')]
[2026-02-02 14:39:50,066][187009] Saving new best policy, reward=63.513!
[2026-02-02 14:39:54,718][187009] Signal inference workers to stop experience collection... (100 times)
[2026-02-02 14:39:54,725][187009] Signal inference workers to resume experience collection... (100 times)
[2026-02-02 14:39:54,726][187009] Fps is (10 sec: 3314.5, 60 sec: 3405.9, 300 sec: 2999.3). Total num frames: 548864. Throughput: 0: 3323.9. Samples: 548352. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 14:39:54,727][187009] Avg episode reward: [(0, '67.889')]
[2026-02-02 14:39:54,998][187009] InferenceWorker_p0-w0: stopping experience collection (100 times)
[2026-02-02 14:39:54,998][187009] InferenceWorker_p0-w0: resuming experience collection (100 times)
[2026-02-02 14:39:55,112][187009] Saving new best policy, reward=67.889!
[2026-02-02 14:39:59,643][187009] Fps is (10 sec: 3297.1, 60 sec: 3410.9, 300 sec: 3008.0). Total num frames: 565248. Throughput: 0: 3310.1. Samples: 568320. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 14:39:59,643][187009] Avg episode reward: [(0, '77.903')]
[2026-02-02 14:40:00,002][187009] Saving new best policy, reward=77.903!
[2026-02-02 14:40:04,835][187009] Fps is (10 sec: 4051.9, 60 sec: 3532.2, 300 sec: 3054.4). Total num frames: 589824. Throughput: 0: 3310.4. Samples: 589312. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 14:40:04,835][187009] Avg episode reward: [(0, '87.718')]
[2026-02-02 14:40:04,837][187009] Saving new best policy, reward=87.718!
[2026-02-02 14:40:09,741][187009] Fps is (10 sec: 4056.3, 60 sec: 3541.2, 300 sec: 3061.5). Total num frames: 606208. Throughput: 0: 3308.0. Samples: 598528. Policy #0 lag: (min: 7.0, avg: 10.0, max: 71.0)
[2026-02-02 14:40:09,741][187009] Avg episode reward: [(0, '97.779')]
[2026-02-02 14:40:09,742][187009] Saving new best policy, reward=97.779!
[2026-02-02 14:40:14,712][187009] Fps is (10 sec: 3317.8, 60 sec: 3545.1, 300 sec: 3067.3). Total num frames: 622592. Throughput: 0: 3293.0. Samples: 619008. Policy #0 lag: (min: 11.0, avg: 14.0, max: 75.0)
[2026-02-02 14:40:14,712][187009] Avg episode reward: [(0, '116.157')]
[2026-02-02 14:40:14,714][187009] Saving new best policy, reward=116.157!
[2026-02-02 14:40:19,649][187009] Fps is (10 sec: 3307.3, 60 sec: 3423.6, 300 sec: 3073.2). Total num frames: 638976. Throughput: 0: 3336.4. Samples: 640000. Policy #0 lag: (min: 13.0, avg: 16.0, max: 77.0)
[2026-02-02 14:40:19,649][187009] Avg episode reward: [(0, '122.367')]
[2026-02-02 14:40:19,782][187009] Saving new best policy, reward=122.367!
[2026-02-02 14:40:24,601][187009] Fps is (10 sec: 3313.4, 60 sec: 3419.0, 300 sec: 3078.7). Total num frames: 655360. Throughput: 0: 3351.4. Samples: 649216. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 14:40:24,602][187009] Avg episode reward: [(0, '130.070')]
[2026-02-02 14:40:24,745][187009] Saving new best policy, reward=130.070!
[2026-02-02 14:40:29,591][187009] Fps is (10 sec: 3295.7, 60 sec: 3415.1, 300 sec: 3083.4). Total num frames: 671744. Throughput: 0: 3363.7. Samples: 669696. Policy #0 lag: (min: 2.0, avg: 5.0, max: 66.0)
[2026-02-02 14:40:29,592][187009] Avg episode reward: [(0, '130.697')]
[2026-02-02 14:40:29,738][187009] Saving new best policy, reward=130.697!
[2026-02-02 14:40:34,539][187009] Fps is (10 sec: 3297.5, 60 sec: 3430.5, 300 sec: 3088.4). Total num frames: 688128. Throughput: 0: 3346.1. Samples: 689152. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 14:40:34,539][187009] Avg episode reward: [(0, '137.077')]
[2026-02-02 14:40:34,672][187009] Saving /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_accel_policy3_aggressive_magpie_refined_params_02022026_smooth_aggressive_ttc/checkpoint_p0/checkpoint_000002688_688128.pth...
[2026-02-02 14:40:34,676][187009] Saving new best policy, reward=137.077!
[2026-02-02 14:40:39,643][187009] Fps is (10 sec: 3260.1, 60 sec: 3543.4, 300 sec: 3091.2). Total num frames: 704512. Throughput: 0: 3351.3. Samples: 698880. Policy #0 lag: (min: 11.0, avg: 14.0, max: 75.0)
[2026-02-02 14:40:39,643][187009] Avg episode reward: [(0, '147.844')]
[2026-02-02 14:40:39,794][187009] Saving new best policy, reward=147.844!
[2026-02-02 14:40:44,624][187009] Fps is (10 sec: 3249.1, 60 sec: 3425.7, 300 sec: 3095.4). Total num frames: 720896. Throughput: 0: 3380.7. Samples: 720384. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 14:40:44,624][187009] Avg episode reward: [(0, '165.919')]
[2026-02-02 14:40:44,759][187009] Saving new best policy, reward=165.919!
[2026-02-02 14:40:49,604][187009] Fps is (10 sec: 3289.6, 60 sec: 3419.1, 300 sec: 3099.5). Total num frames: 737280. Throughput: 0: 3362.4. Samples: 739840. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 14:40:49,604][187009] Avg episode reward: [(0, '177.879')]
[2026-02-02 14:40:49,747][187009] Saving new best policy, reward=177.879!
[2026-02-02 14:40:54,536][187009] Fps is (10 sec: 3305.7, 60 sec: 3424.2, 300 sec: 3104.0). Total num frames: 753664. Throughput: 0: 3417.5. Samples: 751616. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 14:40:54,537][187009] Avg episode reward: [(0, '178.508')]
[2026-02-02 14:40:54,670][187009] Saving new best policy, reward=178.508!
[2026-02-02 14:40:59,625][187009] Fps is (10 sec: 3269.7, 60 sec: 3414.4, 300 sec: 3106.4). Total num frames: 770048. Throughput: 0: 3385.7. Samples: 771072. Policy #0 lag: (min: 7.0, avg: 10.0, max: 71.0)
[2026-02-02 14:40:59,626][187009] Avg episode reward: [(0, '174.883')]
[2026-02-02 14:41:04,540][187009] Fps is (10 sec: 3275.4, 60 sec: 3293.0, 300 sec: 3110.8). Total num frames: 786432. Throughput: 0: 3375.9. Samples: 791552. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 14:41:04,541][187009] Avg episode reward: [(0, '181.887')]
[2026-02-02 14:41:04,675][187009] Saving new best policy, reward=181.887!
[2026-02-02 14:41:09,590][187009] Fps is (10 sec: 3288.3, 60 sec: 3285.1, 300 sec: 3113.4). Total num frames: 802816. Throughput: 0: 3402.8. Samples: 802304. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 14:41:09,590][187009] Avg episode reward: [(0, '195.074')]
[2026-02-02 14:41:09,723][187009] Saving new best policy, reward=195.074!
[2026-02-02 14:41:14,534][187009] Fps is (10 sec: 3279.1, 60 sec: 3286.6, 300 sec: 3117.2). Total num frames: 819200. Throughput: 0: 3394.9. Samples: 822272. Policy #0 lag: (min: 11.0, avg: 14.0, max: 75.0)
[2026-02-02 14:41:14,534][187009] Avg episode reward: [(0, '197.075')]
[2026-02-02 14:41:14,670][187009] Saving new best policy, reward=197.075!
[2026-02-02 14:41:16,357][187009] Signal inference workers to stop experience collection... (150 times)
[2026-02-02 14:41:16,709][187009] InferenceWorker_p0-w0: stopping experience collection (150 times)
[2026-02-02 14:41:16,711][187009] Signal inference workers to resume experience collection... (150 times)
[2026-02-02 14:41:16,852][187009] InferenceWorker_p0-w0: resuming experience collection (150 times)
[2026-02-02 14:41:19,578][187009] Fps is (10 sec: 3281.0, 60 sec: 3280.7, 300 sec: 3119.6). Total num frames: 835584. Throughput: 0: 3433.1. Samples: 843776. Policy #0 lag: (min: 1.0, avg: 4.0, max: 65.0)
[2026-02-02 14:41:19,578][187009] Avg episode reward: [(0, '192.887')]
[2026-02-02 14:41:24,610][187009] Fps is (10 sec: 3252.1, 60 sec: 3276.4, 300 sec: 3122.2). Total num frames: 851968. Throughput: 0: 3427.2. Samples: 852992. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 14:41:24,610][187009] Avg episode reward: [(0, '193.813')]
[2026-02-02 14:41:29,573][187009] Fps is (10 sec: 3278.4, 60 sec: 3277.8, 300 sec: 3125.4). Total num frames: 868352. Throughput: 0: 3440.0. Samples: 875008. Policy #0 lag: (min: 10.0, avg: 13.0, max: 74.0)
[2026-02-02 14:41:29,573][187009] Avg episode reward: [(0, '199.368')]
[2026-02-02 14:41:29,721][187009] Saving new best policy, reward=199.368!
[2026-02-02 14:41:34,644][187009] Fps is (10 sec: 3265.6, 60 sec: 3271.1, 300 sec: 3127.2). Total num frames: 884736. Throughput: 0: 3433.0. Samples: 894464. Policy #0 lag: (min: 12.0, avg: 15.0, max: 76.0)
[2026-02-02 14:41:34,644][187009] Avg episode reward: [(0, '210.262')]
[2026-02-02 14:41:34,783][187009] Saving new best policy, reward=210.262!
[2026-02-02 14:41:39,526][187009] Fps is (10 sec: 3292.1, 60 sec: 3283.2, 300 sec: 3131.1). Total num frames: 901120. Throughput: 0: 3380.0. Samples: 903680. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 14:41:39,526][187009] Avg episode reward: [(0, '210.141')]
[2026-02-02 14:41:44,646][187009] Fps is (10 sec: 3276.0, 60 sec: 3275.6, 300 sec: 3132.3). Total num frames: 917504. Throughput: 0: 3423.1. Samples: 925184. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 14:41:44,646][187009] Avg episode reward: [(0, '212.170')]
[2026-02-02 14:41:44,777][187009] Saving new best policy, reward=212.170!
[2026-02-02 14:41:49,531][187009] Fps is (10 sec: 3275.1, 60 sec: 3280.8, 300 sec: 3292.2). Total num frames: 933888. Throughput: 0: 3448.2. Samples: 946688. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 14:41:49,531][187009] Avg episode reward: [(0, '215.743')]
[2026-02-02 14:41:49,666][187009] Saving new best policy, reward=215.743!
[2026-02-02 14:41:54,719][187009] Fps is (10 sec: 4066.4, 60 sec: 3403.0, 300 sec: 3368.8). Total num frames: 958464. Throughput: 0: 3426.3. Samples: 956928. Policy #0 lag: (min: 12.0, avg: 15.0, max: 76.0)
[2026-02-02 14:41:54,719][187009] Avg episode reward: [(0, '220.669')]
[2026-02-02 14:41:55,070][187009] Saving new best policy, reward=220.669!
[2026-02-02 14:41:59,656][187009] Fps is (10 sec: 4854.5, 60 sec: 3548.0, 300 sec: 3397.5). Total num frames: 983040. Throughput: 0: 3472.1. Samples: 978944. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 14:41:59,656][187009] Avg episode reward: [(0, '225.801')]
[2026-02-02 14:41:59,657][187009] Saving new best policy, reward=225.801!
[2026-02-02 14:42:04,591][187009] Fps is (10 sec: 4149.3, 60 sec: 3546.9, 300 sec: 3411.9). Total num frames: 999424. Throughput: 0: 3480.6. Samples: 1000448. Policy #0 lag: (min: 3.0, avg: 6.0, max: 67.0)
[2026-02-02 14:42:04,591][187009] Avg episode reward: [(0, '226.795')]
[2026-02-02 14:42:04,732][187009] Saving new best policy, reward=226.795!
[2026-02-02 14:42:09,553][187009] Fps is (10 sec: 3310.9, 60 sec: 3552.1, 300 sec: 3444.2). Total num frames: 1015808. Throughput: 0: 3520.1. Samples: 1011200. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 14:42:09,553][187009] Avg episode reward: [(0, '224.167')]
[2026-02-02 14:42:14,576][187009] Fps is (10 sec: 3281.6, 60 sec: 3547.4, 300 sec: 3444.1). Total num frames: 1032192. Throughput: 0: 3515.5. Samples: 1033216. Policy #0 lag: (min: 4.0, avg: 7.0, max: 68.0)
[2026-02-02 14:42:14,576][187009] Avg episode reward: [(0, '227.775')]
[2026-02-02 14:42:14,717][187009] Saving new best policy, reward=227.775!
[2026-02-02 14:42:19,547][187009] Fps is (10 sec: 3278.8, 60 sec: 3551.7, 300 sec: 3443.5). Total num frames: 1048576. Throughput: 0: 3523.3. Samples: 1052672. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 14:42:19,548][187009] Avg episode reward: [(0, '227.770')]
[2026-02-02 14:42:24,517][187009] Fps is (10 sec: 3296.1, 60 sec: 3555.3, 300 sec: 3443.4). Total num frames: 1064960. Throughput: 0: 3561.9. Samples: 1063936. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 14:42:24,517][187009] Avg episode reward: [(0, '236.271')]
[2026-02-02 14:42:24,650][187009] Saving new best policy, reward=236.271!
[2026-02-02 14:42:29,630][187009] Fps is (10 sec: 3250.0, 60 sec: 3546.5, 300 sec: 3443.4). Total num frames: 1081344. Throughput: 0: 3528.4. Samples: 1083904. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 14:42:29,630][187009] Avg episode reward: [(0, '243.546')]
[2026-02-02 14:42:29,768][187009] Saving new best policy, reward=243.546!
[2026-02-02 14:42:31,875][187009] Signal inference workers to stop experience collection... (200 times)
[2026-02-02 14:42:32,231][187009] InferenceWorker_p0-w0: stopping experience collection (200 times)
[2026-02-02 14:42:32,232][187009] Signal inference workers to resume experience collection... (200 times)
[2026-02-02 14:42:32,232][187009] InferenceWorker_p0-w0: resuming experience collection (200 times)
[2026-02-02 14:42:34,551][187009] Fps is (10 sec: 3265.9, 60 sec: 3555.4, 300 sec: 3444.1). Total num frames: 1097728. Throughput: 0: 3525.6. Samples: 1105408. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 14:42:34,551][187009] Avg episode reward: [(0, '250.342')]
[2026-02-02 14:42:34,688][187009] Saving /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_accel_policy3_aggressive_magpie_refined_params_02022026_smooth_aggressive_ttc/checkpoint_p0/checkpoint_000004288_1097728.pth...
[2026-02-02 14:42:34,692][187009] Removing /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_accel_policy3_aggressive_magpie_refined_params_02022026_smooth_aggressive_ttc/checkpoint_p0/checkpoint_000001088_278528.pth
[2026-02-02 14:42:34,693][187009] Saving new best policy, reward=250.342!
[2026-02-02 14:42:39,633][187009] Fps is (10 sec: 3275.6, 60 sec: 3543.5, 300 sec: 3445.7). Total num frames: 1114112. Throughput: 0: 3522.4. Samples: 1115136. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 14:42:39,634][187009] Avg episode reward: [(0, '254.800')]
[2026-02-02 14:42:39,769][187009] Saving new best policy, reward=254.800!
[2026-02-02 14:42:44,596][187009] Fps is (10 sec: 3261.9, 60 sec: 3552.8, 300 sec: 3417.8). Total num frames: 1130496. Throughput: 0: 3486.2. Samples: 1135616. Policy #0 lag: (min: 2.0, avg: 5.0, max: 66.0)
[2026-02-02 14:42:44,597][187009] Avg episode reward: [(0, '251.389')]
[2026-02-02 14:42:49,567][187009] Fps is (10 sec: 3298.5, 60 sec: 3547.7, 300 sec: 3391.4). Total num frames: 1146880. Throughput: 0: 3460.6. Samples: 1156096. Policy #0 lag: (min: 7.0, avg: 10.0, max: 71.0)
[2026-02-02 14:42:49,568][187009] Avg episode reward: [(0, '254.230')]
[2026-02-02 14:42:54,554][187009] Fps is (10 sec: 3290.9, 60 sec: 3422.8, 300 sec: 3388.3). Total num frames: 1163264. Throughput: 0: 3436.1. Samples: 1165824. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 14:42:54,554][187009] Avg episode reward: [(0, '249.904')]
[2026-02-02 14:42:59,550][187009] Fps is (10 sec: 3282.7, 60 sec: 3282.6, 300 sec: 3388.5). Total num frames: 1179648. Throughput: 0: 3403.9. Samples: 1186304. Policy #0 lag: (min: 13.0, avg: 16.0, max: 77.0)
[2026-02-02 14:42:59,550][187009] Avg episode reward: [(0, '253.265')]
[2026-02-02 14:43:04,638][187009] Fps is (10 sec: 3249.5, 60 sec: 3274.2, 300 sec: 3387.6). Total num frames: 1196032. Throughput: 0: 3429.2. Samples: 1207296. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 14:43:04,638][187009] Avg episode reward: [(0, '264.019')]
[2026-02-02 14:43:04,773][187009] Saving new best policy, reward=264.019!
[2026-02-02 14:43:09,532][187009] Fps is (10 sec: 3282.6, 60 sec: 3278.0, 300 sec: 3388.5). Total num frames: 1212416. Throughput: 0: 3400.8. Samples: 1217024. Policy #0 lag: (min: 31.0, avg: 34.0, max: 95.0)
[2026-02-02 14:43:09,532][187009] Avg episode reward: [(0, '271.520')]
[2026-02-02 14:43:09,671][187009] Saving new best policy, reward=271.520!
[2026-02-02 14:43:14,548][187009] Fps is (10 sec: 3306.3, 60 sec: 3278.3, 300 sec: 3388.2). Total num frames: 1228800. Throughput: 0: 3419.5. Samples: 1237504. Policy #0 lag: (min: 47.0, avg: 50.0, max: 111.0)
[2026-02-02 14:43:14,549][187009] Avg episode reward: [(0, '278.654')]
[2026-02-02 14:43:14,683][187009] Saving new best policy, reward=278.654!
[2026-02-02 14:43:19,623][187009] Fps is (10 sec: 3247.3, 60 sec: 3272.7, 300 sec: 3386.8). Total num frames: 1245184. Throughput: 0: 3396.5. Samples: 1258496. Policy #0 lag: (min: 61.0, avg: 64.0, max: 125.0)
[2026-02-02 14:43:19,623][187009] Avg episode reward: [(0, '283.919')]
[2026-02-02 14:43:19,760][187009] Saving new best policy, reward=283.919!
[2026-02-02 14:43:24,545][187009] Fps is (10 sec: 3277.9, 60 sec: 3275.3, 300 sec: 3387.6). Total num frames: 1261568. Throughput: 0: 3397.2. Samples: 1267712. Policy #0 lag: (min: 61.0, avg: 64.0, max: 125.0)
[2026-02-02 14:43:24,545][187009] Avg episode reward: [(0, '287.518')]
[2026-02-02 14:43:24,925][187009] Saving new best policy, reward=287.518!
[2026-02-02 14:43:29,839][187009] Fps is (10 sec: 4009.2, 60 sec: 3401.5, 300 sec: 3413.0). Total num frames: 1286144. Throughput: 0: 3383.7. Samples: 1288704. Policy #0 lag: (min: 30.0, avg: 33.0, max: 94.0)
[2026-02-02 14:43:29,839][187009] Avg episode reward: [(0, '293.809')]
[2026-02-02 14:43:30,225][187009] Saving new best policy, reward=293.809!
[2026-02-02 14:43:34,787][187009] Fps is (10 sec: 3999.4, 60 sec: 3400.0, 300 sec: 3412.8). Total num frames: 1302528. Throughput: 0: 3385.5. Samples: 1309184. Policy #0 lag: (min: 30.0, avg: 33.0, max: 94.0)
[2026-02-02 14:43:34,787][187009] Avg episode reward: [(0, '291.028')]
[2026-02-02 14:43:39,630][187009] Fps is (10 sec: 3346.9, 60 sec: 3413.5, 300 sec: 3415.4). Total num frames: 1318912. Throughput: 0: 3384.9. Samples: 1318400. Policy #0 lag: (min: 33.0, avg: 36.0, max: 97.0)
[2026-02-02 14:43:39,630][187009] Avg episode reward: [(0, '293.946')]
[2026-02-02 14:43:40,008][187009] Saving new best policy, reward=293.946!
[2026-02-02 14:43:44,800][187009] Fps is (10 sec: 4090.4, 60 sec: 3537.8, 300 sec: 3441.5). Total num frames: 1343488. Throughput: 0: 3383.1. Samples: 1339392. Policy #0 lag: (min: 8.0, avg: 11.0, max: 72.0)
[2026-02-02 14:43:44,801][187009] Avg episode reward: [(0, '296.351')]
[2026-02-02 14:43:44,802][187009] Saving new best policy, reward=296.351!
[2026-02-02 14:43:49,564][187009] Fps is (10 sec: 4123.2, 60 sec: 3550.1, 300 sec: 3443.8). Total num frames: 1359872. Throughput: 0: 3407.6. Samples: 1360384. Policy #0 lag: (min: 57.0, avg: 60.0, max: 121.0)
[2026-02-02 14:43:49,564][187009] Avg episode reward: [(0, '303.066')]
[2026-02-02 14:43:49,694][187009] Saving new best policy, reward=303.066!
[2026-02-02 14:43:53,667][187009] Signal inference workers to stop experience collection... (250 times)
[2026-02-02 14:43:53,667][187009] Signal inference workers to resume experience collection... (250 times)
[2026-02-02 14:43:53,908][187009] InferenceWorker_p0-w0: stopping experience collection (250 times)
[2026-02-02 14:43:53,909][187009] InferenceWorker_p0-w0: resuming experience collection (250 times)
[2026-02-02 14:43:54,569][187009] Fps is (10 sec: 3354.6, 60 sec: 3549.0, 300 sec: 3443.8). Total num frames: 1376256. Throughput: 0: 3410.6. Samples: 1370624. Policy #0 lag: (min: 57.0, avg: 60.0, max: 121.0)
[2026-02-02 14:43:54,569][187009] Avg episode reward: [(0, '305.037')]
[2026-02-02 14:43:54,697][187009] Saving new best policy, reward=305.037!
[2026-02-02 14:43:59,608][187009] Fps is (10 sec: 3262.2, 60 sec: 3546.4, 300 sec: 3442.6). Total num frames: 1392640. Throughput: 0: 3442.9. Samples: 1392640. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 14:43:59,609][187009] Avg episode reward: [(0, '304.117')]
[2026-02-02 14:44:04,579][187009] Fps is (10 sec: 3273.3, 60 sec: 3553.3, 300 sec: 3443.6). Total num frames: 1409024. Throughput: 0: 3405.3. Samples: 1411584. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 14:44:04,579][187009] Avg episode reward: [(0, '315.314')]
[2026-02-02 14:44:04,723][187009] Saving new best policy, reward=315.314!
[2026-02-02 14:44:09,640][187009] Fps is (10 sec: 3266.5, 60 sec: 3543.5, 300 sec: 3443.3). Total num frames: 1425408. Throughput: 0: 3451.6. Samples: 1423360. Policy #0 lag: (min: 10.0, avg: 13.0, max: 74.0)
[2026-02-02 14:44:09,640][187009] Avg episode reward: [(0, '322.323')]
[2026-02-02 14:44:09,769][187009] Saving new best policy, reward=322.323!
[2026-02-02 14:44:14,539][187009] Fps is (10 sec: 3289.9, 60 sec: 3550.4, 300 sec: 3419.0). Total num frames: 1441792. Throughput: 0: 3447.7. Samples: 1442816. Policy #0 lag: (min: 10.0, avg: 13.0, max: 74.0)
[2026-02-02 14:44:14,540][187009] Avg episode reward: [(0, '328.509')]
[2026-02-02 14:44:14,681][187009] Saving new best policy, reward=328.509!
[2026-02-02 14:44:19,608][187009] Fps is (10 sec: 3287.1, 60 sec: 3550.7, 300 sec: 3416.7). Total num frames: 1458176. Throughput: 0: 3449.8. Samples: 1463808. Policy #0 lag: (min: 0.0, avg: 3.0, max: 64.0)
[2026-02-02 14:44:19,609][187009] Avg episode reward: [(0, '330.223')]
[2026-02-02 14:44:19,747][187009] Saving new best policy, reward=330.223!
[2026-02-02 14:44:24,614][187009] Fps is (10 sec: 3252.4, 60 sec: 3545.8, 300 sec: 3415.7). Total num frames: 1474560. Throughput: 0: 3482.8. Samples: 1475072. Policy #0 lag: (min: 0.0, avg: 3.0, max: 64.0)
[2026-02-02 14:44:24,614][187009] Avg episode reward: [(0, '336.215')]
[2026-02-02 14:44:24,743][187009] Saving new best policy, reward=336.215!
[2026-02-02 14:44:29,630][187009] Fps is (10 sec: 3269.8, 60 sec: 3425.3, 300 sec: 3418.1). Total num frames: 1490944. Throughput: 0: 3472.0. Samples: 1495040. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 14:44:29,630][187009] Avg episode reward: [(0, '339.536')]
[2026-02-02 14:44:29,763][187009] Saving new best policy, reward=339.536!
[2026-02-02 14:44:34,602][187009] Fps is (10 sec: 3280.8, 60 sec: 3423.9, 300 sec: 3442.6). Total num frames: 1507328. Throughput: 0: 3455.9. Samples: 1516032. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 14:44:34,602][187009] Avg episode reward: [(0, '348.085')]
[2026-02-02 14:44:34,738][187009] Saving /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_accel_policy3_aggressive_magpie_refined_params_02022026_smooth_aggressive_ttc/checkpoint_p0/checkpoint_000005888_1507328.pth...
[2026-02-02 14:44:34,742][187009] Removing /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_accel_policy3_aggressive_magpie_refined_params_02022026_smooth_aggressive_ttc/checkpoint_p0/checkpoint_000002688_688128.pth
[2026-02-02 14:44:34,743][187009] Saving new best policy, reward=348.085!
[2026-02-02 14:44:39,597][187009] Fps is (10 sec: 3287.7, 60 sec: 3415.2, 300 sec: 3418.5). Total num frames: 1523712. Throughput: 0: 3445.3. Samples: 1525760. Policy #0 lag: (min: 6.0, avg: 9.0, max: 70.0)
[2026-02-02 14:44:39,597][187009] Avg episode reward: [(0, '347.557')]
[2026-02-02 14:44:44,553][187009] Fps is (10 sec: 3293.1, 60 sec: 3290.4, 300 sec: 3417.4). Total num frames: 1540096. Throughput: 0: 3440.3. Samples: 1547264. Policy #0 lag: (min: 6.0, avg: 9.0, max: 70.0)
[2026-02-02 14:44:44,553][187009] Avg episode reward: [(0, '354.577')]
[2026-02-02 14:44:44,689][187009] Saving new best policy, reward=354.577!
[2026-02-02 14:44:49,524][187009] Fps is (10 sec: 3300.8, 60 sec: 3279.0, 300 sec: 3418.0). Total num frames: 1556480. Throughput: 0: 3485.9. Samples: 1568256. Policy #0 lag: (min: 9.0, avg: 12.0, max: 73.0)
[2026-02-02 14:44:49,524][187009] Avg episode reward: [(0, '344.961')]
[2026-02-02 14:44:54,536][187009] Fps is (10 sec: 3282.2, 60 sec: 3278.6, 300 sec: 3416.9). Total num frames: 1572864. Throughput: 0: 3455.4. Samples: 1578496. Policy #0 lag: (min: 9.0, avg: 12.0, max: 73.0)
[2026-02-02 14:44:54,536][187009] Avg episode reward: [(0, '342.691')]
[2026-02-02 14:44:59,722][187009] Fps is (10 sec: 4016.4, 60 sec: 3406.9, 300 sec: 3417.0). Total num frames: 1597440. Throughput: 0: 3478.8. Samples: 1600000. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 14:44:59,722][187009] Avg episode reward: [(0, '342.046')]
[2026-02-02 14:45:04,682][187009] Fps is (10 sec: 4844.4, 60 sec: 3543.8, 300 sec: 3444.1). Total num frames: 1622016. Throughput: 0: 3510.0. Samples: 1622016. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 14:45:04,682][187009] Avg episode reward: [(0, '351.077')]
[2026-02-02 14:45:09,630][187009] Fps is (10 sec: 4134.2, 60 sec: 3550.4, 300 sec: 3444.4). Total num frames: 1638400. Throughput: 0: 3480.4. Samples: 1631744. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 14:45:09,630][187009] Avg episode reward: [(0, '368.921')]
[2026-02-02 14:45:09,761][187009] Saving new best policy, reward=368.921!
[2026-02-02 14:45:13,290][187009] Signal inference workers to stop experience collection... (300 times)
[2026-02-02 14:45:13,646][187009] InferenceWorker_p0-w0: stopping experience collection (300 times)
[2026-02-02 14:45:13,648][187009] Signal inference workers to resume experience collection... (300 times)
[2026-02-02 14:45:13,781][187009] InferenceWorker_p0-w0: resuming experience collection (300 times)
[2026-02-02 14:45:14,563][187009] Fps is (10 sec: 3316.2, 60 sec: 3548.4, 300 sec: 3444.4). Total num frames: 1654784. Throughput: 0: 3520.9. Samples: 1653248. Policy #0 lag: (min: 14.0, avg: 17.0, max: 78.0)
[2026-02-02 14:45:14,564][187009] Avg episode reward: [(0, '388.205')]
[2026-02-02 14:45:14,705][187009] Saving new best policy, reward=388.205!
[2026-02-02 14:45:19,625][187009] Fps is (10 sec: 3278.4, 60 sec: 3548.9, 300 sec: 3443.1). Total num frames: 1671168. Throughput: 0: 3491.2. Samples: 1673216. Policy #0 lag: (min: 14.0, avg: 17.0, max: 78.0)
[2026-02-02 14:45:19,625][187009] Avg episode reward: [(0, '398.172')]
[2026-02-02 14:45:19,760][187009] Saving new best policy, reward=398.172!
[2026-02-02 14:45:24,566][187009] Fps is (10 sec: 3275.9, 60 sec: 3552.7, 300 sec: 3443.7). Total num frames: 1687552. Throughput: 0: 3540.9. Samples: 1684992. Policy #0 lag: (min: 7.0, avg: 10.0, max: 71.0)
[2026-02-02 14:45:24,566][187009] Avg episode reward: [(0, '397.487')]
[2026-02-02 14:45:29,528][187009] Fps is (10 sec: 3308.7, 60 sec: 3555.9, 300 sec: 3443.5). Total num frames: 1703936. Throughput: 0: 3506.2. Samples: 1704960. Policy #0 lag: (min: 7.0, avg: 10.0, max: 71.0)
[2026-02-02 14:45:29,529][187009] Avg episode reward: [(0, '387.218')]
[2026-02-02 14:45:34,535][187009] Fps is (10 sec: 3287.1, 60 sec: 3553.8, 300 sec: 3444.7). Total num frames: 1720320. Throughput: 0: 3514.9. Samples: 1726464. Policy #0 lag: (min: 9.0, avg: 12.0, max: 73.0)
[2026-02-02 14:45:34,535][187009] Avg episode reward: [(0, '374.762')]
[2026-02-02 14:45:39,615][187009] Fps is (10 sec: 3248.5, 60 sec: 3548.8, 300 sec: 3443.5). Total num frames: 1736704. Throughput: 0: 3532.3. Samples: 1737728. Policy #0 lag: (min: 9.0, avg: 12.0, max: 73.0)
[2026-02-02 14:45:39,616][187009] Avg episode reward: [(0, '376.316')]
[2026-02-02 14:45:44,546][187009] Fps is (10 sec: 3273.2, 60 sec: 3550.3, 300 sec: 3444.1). Total num frames: 1753088. Throughput: 0: 3506.7. Samples: 1757184. Policy #0 lag: (min: 3.0, avg: 6.0, max: 67.0)
[2026-02-02 14:45:44,546][187009] Avg episode reward: [(0, '387.041')]
[2026-02-02 14:45:49,524][187009] Fps is (10 sec: 3307.0, 60 sec: 3549.9, 300 sec: 3443.6). Total num frames: 1769472. Throughput: 0: 3505.3. Samples: 1779200. Policy #0 lag: (min: 3.0, avg: 6.0, max: 67.0)
[2026-02-02 14:45:49,524][187009] Avg episode reward: [(0, '396.541')]
[2026-02-02 14:45:54,615][187009] Fps is (10 sec: 3254.4, 60 sec: 3545.2, 300 sec: 3443.5). Total num frames: 1785856. Throughput: 0: 3494.2. Samples: 1788928. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 14:45:54,615][187009] Avg episode reward: [(0, '401.385')]
[2026-02-02 14:45:54,753][187009] Saving new best policy, reward=401.385!
[2026-02-02 14:45:59,600][187009] Fps is (10 sec: 3252.0, 60 sec: 3420.3, 300 sec: 3442.7). Total num frames: 1802240. Throughput: 0: 3478.7. Samples: 1809920. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 14:45:59,601][187009] Avg episode reward: [(0, '392.685')]
[2026-02-02 14:46:04,654][187009] Fps is (10 sec: 3263.9, 60 sec: 3278.3, 300 sec: 3442.7). Total num frames: 1818624. Throughput: 0: 3513.5. Samples: 1831424. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 14:46:04,654][187009] Avg episode reward: [(0, '393.389')]
[2026-02-02 14:46:09,817][187009] Fps is (10 sec: 4009.1, 60 sec: 3402.7, 300 sec: 3467.9). Total num frames: 1843200. Throughput: 0: 3462.3. Samples: 1841664. Policy #0 lag: (min: 14.0, avg: 17.0, max: 78.0)
[2026-02-02 14:46:09,817][187009] Avg episode reward: [(0, '390.318')]
[2026-02-02 14:46:14,522][187009] Fps is (10 sec: 4150.7, 60 sec: 3415.7, 300 sec: 3471.8). Total num frames: 1859584. Throughput: 0: 3516.2. Samples: 1863168. Policy #0 lag: (min: 14.0, avg: 17.0, max: 78.0)
[2026-02-02 14:46:14,522][187009] Avg episode reward: [(0, '408.824')]
[2026-02-02 14:46:14,888][187009] Saving new best policy, reward=408.824!
[2026-02-02 14:46:19,645][187009] Fps is (10 sec: 4167.6, 60 sec: 3548.7, 300 sec: 3498.5). Total num frames: 1884160. Throughput: 0: 3495.8. Samples: 1884160. Policy #0 lag: (min: 10.0, avg: 13.0, max: 74.0)
[2026-02-02 14:46:19,646][187009] Avg episode reward: [(0, '412.628')]
[2026-02-02 14:46:19,646][187009] Saving new best policy, reward=412.628!
[2026-02-02 14:46:24,548][187009] Fps is (10 sec: 4085.6, 60 sec: 3550.9, 300 sec: 3499.3). Total num frames: 1900544. Throughput: 0: 3475.4. Samples: 1893888. Policy #0 lag: (min: 10.0, avg: 13.0, max: 74.0)
[2026-02-02 14:46:24,548][187009] Avg episode reward: [(0, '426.305')]
[2026-02-02 14:46:24,694][187009] Saving new best policy, reward=426.305!
[2026-02-02 14:46:28,631][187009] Signal inference workers to stop experience collection... (350 times)
[2026-02-02 14:46:28,993][187009] InferenceWorker_p0-w0: stopping experience collection (350 times)
[2026-02-02 14:46:28,993][187009] Signal inference workers to resume experience collection... (350 times)
[2026-02-02 14:46:28,993][187009] InferenceWorker_p0-w0: resuming experience collection (350 times)
[2026-02-02 14:46:29,528][187009] Fps is (10 sec: 3315.6, 60 sec: 3549.9, 300 sec: 3500.3). Total num frames: 1916928. Throughput: 0: 3528.5. Samples: 1915904. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 14:46:29,529][187009] Avg episode reward: [(0, '426.149')]
[2026-02-02 14:46:34,587][187009] Fps is (10 sec: 3264.0, 60 sec: 3546.8, 300 sec: 3498.2). Total num frames: 1933312. Throughput: 0: 3442.7. Samples: 1934336. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 14:46:34,587][187009] Avg episode reward: [(0, '439.151')]
[2026-02-02 14:46:34,728][187009] Saving /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_accel_policy3_aggressive_magpie_refined_params_02022026_smooth_aggressive_ttc/checkpoint_p0/checkpoint_000007552_1933312.pth...
[2026-02-02 14:46:34,732][187009] Removing /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_accel_policy3_aggressive_magpie_refined_params_02022026_smooth_aggressive_ttc/checkpoint_p0/checkpoint_000004288_1097728.pth
[2026-02-02 14:46:34,732][187009] Saving new best policy, reward=439.151!
[2026-02-02 14:46:39,583][187009] Fps is (10 sec: 3259.0, 60 sec: 3551.8, 300 sec: 3499.7). Total num frames: 1949696. Throughput: 0: 3484.0. Samples: 1945600. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 14:46:39,583][187009] Avg episode reward: [(0, '438.646')]
[2026-02-02 14:46:44,568][187009] Fps is (10 sec: 3282.9, 60 sec: 3548.5, 300 sec: 3498.5). Total num frames: 1966080. Throughput: 0: 3472.7. Samples: 1966080. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 14:46:44,569][187009] Avg episode reward: [(0, '429.073')]
[2026-02-02 14:46:49,542][187009] Fps is (10 sec: 3290.4, 60 sec: 3548.8, 300 sec: 3473.3). Total num frames: 1982464. Throughput: 0: 3421.9. Samples: 1985024. Policy #0 lag: (min: 7.0, avg: 10.0, max: 71.0)
[2026-02-02 14:46:49,542][187009] Avg episode reward: [(0, '428.002')]
[2026-02-02 14:46:54,544][187009] Fps is (10 sec: 3284.8, 60 sec: 3554.0, 300 sec: 3444.7). Total num frames: 1998848. Throughput: 0: 3434.2. Samples: 1995264. Policy #0 lag: (min: 7.0, avg: 10.0, max: 71.0)
[2026-02-02 14:46:54,544][187009] Avg episode reward: [(0, '420.689')]
[2026-02-02 14:46:59,532][187009] Fps is (10 sec: 3280.1, 60 sec: 3553.9, 300 sec: 3444.1). Total num frames: 2015232. Throughput: 0: 3378.5. Samples: 2015232. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 14:46:59,532][187009] Avg episode reward: [(0, '426.256')]
[2026-02-02 14:47:04,620][187009] Fps is (10 sec: 3252.1, 60 sec: 3551.9, 300 sec: 3442.6). Total num frames: 2031616. Throughput: 0: 3335.6. Samples: 2034176. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 14:47:04,620][187009] Avg episode reward: [(0, '427.988')]
[2026-02-02 14:47:09,618][187009] Fps is (10 sec: 3248.8, 60 sec: 3424.7, 300 sec: 3442.9). Total num frames: 2048000. Throughput: 0: 3362.6. Samples: 2045440. Policy #0 lag: (min: 4.0, avg: 7.0, max: 68.0)
[2026-02-02 14:47:09,618][187009] Avg episode reward: [(0, '445.560')]
[2026-02-02 14:47:09,775][187009] Saving new best policy, reward=445.560!
[2026-02-02 14:47:14,626][187009] Fps is (10 sec: 3274.9, 60 sec: 3407.4, 300 sec: 3442.5). Total num frames: 2064384. Throughput: 0: 3315.1. Samples: 2065408. Policy #0 lag: (min: 4.0, avg: 7.0, max: 68.0)
[2026-02-02 14:47:14,626][187009] Avg episode reward: [(0, '460.402')]
[2026-02-02 14:47:14,762][187009] Saving new best policy, reward=460.402!
[2026-02-02 14:47:19,639][187009] Fps is (10 sec: 3269.9, 60 sec: 3277.1, 300 sec: 3442.0). Total num frames: 2080768. Throughput: 0: 3363.9. Samples: 2085888. Policy #0 lag: (min: 2.0, avg: 5.0, max: 66.0)
[2026-02-02 14:47:19,639][187009] Avg episode reward: [(0, '452.019')]
[2026-02-02 14:47:24,622][187009] Fps is (10 sec: 3277.9, 60 sec: 3272.7, 300 sec: 3443.5). Total num frames: 2097152. Throughput: 0: 3364.9. Samples: 2097152. Policy #0 lag: (min: 2.0, avg: 5.0, max: 66.0)
[2026-02-02 14:47:24,623][187009] Avg episode reward: [(0, '452.375')]
[2026-02-02 14:47:29,609][187009] Fps is (10 sec: 3286.5, 60 sec: 3272.4, 300 sec: 3442.7). Total num frames: 2113536. Throughput: 0: 3330.6. Samples: 2116096. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 14:47:29,610][187009] Avg episode reward: [(0, '432.561')]
[2026-02-02 14:47:34,526][187009] Fps is (10 sec: 3308.7, 60 sec: 3280.1, 300 sec: 3444.7). Total num frames: 2129920. Throughput: 0: 3369.0. Samples: 2136576. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 14:47:34,526][187009] Avg episode reward: [(0, '462.421')]
[2026-02-02 14:47:34,660][187009] Saving new best policy, reward=462.421!
[2026-02-02 14:47:39,605][187009] Fps is (10 sec: 3278.2, 60 sec: 3275.6, 300 sec: 3443.3). Total num frames: 2146304. Throughput: 0: 3374.6. Samples: 2147328. Policy #0 lag: (min: 2.0, avg: 5.0, max: 66.0)
[2026-02-02 14:47:39,605][187009] Avg episode reward: [(0, '460.925')]
[2026-02-02 14:47:44,540][187009] Fps is (10 sec: 3272.2, 60 sec: 3278.4, 300 sec: 3443.7). Total num frames: 2162688. Throughput: 0: 3367.2. Samples: 2166784. Policy #0 lag: (min: 2.0, avg: 5.0, max: 66.0)
[2026-02-02 14:47:44,540][187009] Avg episode reward: [(0, '470.680')]
[2026-02-02 14:47:44,695][187009] Saving new best policy, reward=470.680!
[2026-02-02 14:47:49,626][187009] Fps is (10 sec: 3269.9, 60 sec: 3272.2, 300 sec: 3442.6). Total num frames: 2179072. Throughput: 0: 3424.2. Samples: 2188288. Policy #0 lag: (min: 7.0, avg: 10.0, max: 71.0)
[2026-02-02 14:47:49,627][187009] Avg episode reward: [(0, '466.154')]
[2026-02-02 14:47:51,181][187009] Signal inference workers to stop experience collection... (400 times)
[2026-02-02 14:47:51,181][187009] Signal inference workers to resume experience collection... (400 times)
[2026-02-02 14:47:51,424][187009] InferenceWorker_p0-w0: stopping experience collection (400 times)
[2026-02-02 14:47:51,424][187009] InferenceWorker_p0-w0: resuming experience collection (400 times)
[2026-02-02 14:47:54,636][187009] Fps is (10 sec: 3245.5, 60 sec: 3271.8, 300 sec: 3442.4). Total num frames: 2195456. Throughput: 0: 3389.2. Samples: 2198016. Policy #0 lag: (min: 7.0, avg: 10.0, max: 71.0)
[2026-02-02 14:47:54,637][187009] Avg episode reward: [(0, '474.032')]
[2026-02-02 14:47:54,787][187009] Saving new best policy, reward=474.032!
[2026-02-02 14:47:59,559][187009] Fps is (10 sec: 3299.0, 60 sec: 3275.3, 300 sec: 3444.3). Total num frames: 2211840. Throughput: 0: 3418.4. Samples: 2219008. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 14:47:59,559][187009] Avg episode reward: [(0, '479.283')]
[2026-02-02 14:47:59,697][187009] Saving new best policy, reward=479.283!
[2026-02-02 14:48:04,619][187009] Fps is (10 sec: 3282.6, 60 sec: 3276.9, 300 sec: 3442.4). Total num frames: 2228224. Throughput: 0: 3426.3. Samples: 2240000. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 14:48:04,619][187009] Avg episode reward: [(0, '489.222')]
[2026-02-02 14:48:04,755][187009] Saving new best policy, reward=489.222!
[2026-02-02 14:48:09,638][187009] Fps is (10 sec: 3251.1, 60 sec: 3275.7, 300 sec: 3442.4). Total num frames: 2244608. Throughput: 0: 3389.4. Samples: 2249728. Policy #0 lag: (min: 12.0, avg: 15.0, max: 76.0)
[2026-02-02 14:48:09,638][187009] Avg episode reward: [(0, '508.360')]
[2026-02-02 14:48:09,640][187009] Saving new best policy, reward=508.360!
[2026-02-02 14:48:14,602][187009] Fps is (10 sec: 3282.3, 60 sec: 3278.1, 300 sec: 3443.7). Total num frames: 2260992. Throughput: 0: 3425.3. Samples: 2270208. Policy #0 lag: (min: 12.0, avg: 15.0, max: 76.0)
[2026-02-02 14:48:14,602][187009] Avg episode reward: [(0, '515.556')]
[2026-02-02 14:48:14,742][187009] Saving new best policy, reward=515.556!
[2026-02-02 14:48:19,583][187009] Fps is (10 sec: 3294.9, 60 sec: 3279.9, 300 sec: 3443.0). Total num frames: 2277376. Throughput: 0: 3409.0. Samples: 2290176. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 14:48:19,583][187009] Avg episode reward: [(0, '497.105')]
[2026-02-02 14:48:24,537][187009] Fps is (10 sec: 3298.2, 60 sec: 3281.5, 300 sec: 3419.1). Total num frames: 2293760. Throughput: 0: 3395.7. Samples: 2299904. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 14:48:24,537][187009] Avg episode reward: [(0, '469.930')]
[2026-02-02 14:48:29,806][187009] Fps is (10 sec: 4006.7, 60 sec: 3402.2, 300 sec: 3443.2). Total num frames: 2318336. Throughput: 0: 3404.6. Samples: 2320896. Policy #0 lag: (min: 8.0, avg: 11.0, max: 72.0)
[2026-02-02 14:48:29,806][187009] Avg episode reward: [(0, '479.235')]
[2026-02-02 14:48:34,595][187009] Fps is (10 sec: 4072.4, 60 sec: 3409.4, 300 sec: 3443.8). Total num frames: 2334720. Throughput: 0: 3415.7. Samples: 2341888. Policy #0 lag: (min: 8.0, avg: 11.0, max: 72.0)
[2026-02-02 14:48:34,595][187009] Avg episode reward: [(0, '491.357')]
[2026-02-02 14:48:34,955][187009] Saving /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_accel_policy3_aggressive_magpie_refined_params_02022026_smooth_aggressive_ttc/checkpoint_p0/checkpoint_000009152_2342912.pth...
[2026-02-02 14:48:34,959][187009] Removing /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_accel_policy3_aggressive_magpie_refined_params_02022026_smooth_aggressive_ttc/checkpoint_p0/checkpoint_000005888_1507328.pth
[2026-02-02 14:48:39,740][187009] Fps is (10 sec: 4123.4, 60 sec: 3541.9, 300 sec: 3444.1). Total num frames: 2359296. Throughput: 0: 3405.5. Samples: 2351616. Policy #0 lag: (min: 8.0, avg: 11.0, max: 72.0)
[2026-02-02 14:48:39,740][187009] Avg episode reward: [(0, '508.483')]
[2026-02-02 14:48:44,562][187009] Fps is (10 sec: 4109.4, 60 sec: 3548.5, 300 sec: 3443.4). Total num frames: 2375680. Throughput: 0: 3413.1. Samples: 2372608. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 14:48:44,563][187009] Avg episode reward: [(0, '494.266')]
[2026-02-02 14:48:49,520][187009] Fps is (10 sec: 3350.4, 60 sec: 3556.2, 300 sec: 3444.0). Total num frames: 2392064. Throughput: 0: 3409.4. Samples: 2393088. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 14:48:49,520][187009] Avg episode reward: [(0, '503.018')]
[2026-02-02 14:48:54,602][187009] Fps is (10 sec: 3264.0, 60 sec: 3551.9, 300 sec: 3443.5). Total num frames: 2408448. Throughput: 0: 3416.1. Samples: 2403328. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 14:48:54,602][187009] Avg episode reward: [(0, '503.978')]
[2026-02-02 14:48:59,641][187009] Fps is (10 sec: 3237.5, 60 sec: 3545.0, 300 sec: 3442.7). Total num frames: 2424832. Throughput: 0: 3387.6. Samples: 2422784. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 14:48:59,641][187009] Avg episode reward: [(0, '512.310')]
[2026-02-02 14:49:04,562][187009] Fps is (10 sec: 3289.9, 60 sec: 3553.2, 300 sec: 3444.3). Total num frames: 2441216. Throughput: 0: 3380.8. Samples: 2442240. Policy #0 lag: (min: 9.0, avg: 12.0, max: 73.0)
[2026-02-02 14:49:04,562][187009] Avg episode reward: [(0, '529.676')]
[2026-02-02 14:49:04,703][187009] Saving new best policy, reward=529.676!
[2026-02-02 14:49:09,639][187009] Fps is (10 sec: 3277.3, 60 sec: 3549.8, 300 sec: 3442.2). Total num frames: 2457600. Throughput: 0: 3405.6. Samples: 2453504. Policy #0 lag: (min: 9.0, avg: 12.0, max: 73.0)
[2026-02-02 14:49:09,640][187009] Avg episode reward: [(0, '546.534')]
[2026-02-02 14:49:09,775][187009] Saving new best policy, reward=546.534!
[2026-02-02 14:49:12,895][187009] Signal inference workers to stop experience collection... (450 times)
[2026-02-02 14:49:13,269][187009] InferenceWorker_p0-w0: stopping experience collection (450 times)
[2026-02-02 14:49:13,270][187009] Signal inference workers to resume experience collection... (450 times)
[2026-02-02 14:49:13,407][187009] InferenceWorker_p0-w0: resuming experience collection (450 times)
[2026-02-02 14:49:14,584][187009] Fps is (10 sec: 3269.6, 60 sec: 3550.9, 300 sec: 3443.7). Total num frames: 2473984. Throughput: 0: 3418.8. Samples: 2473984. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 14:49:14,584][187009] Avg episode reward: [(0, '548.867')]
[2026-02-02 14:49:14,725][187009] Saving new best policy, reward=548.867!
[2026-02-02 14:49:19,565][187009] Fps is (10 sec: 3301.4, 60 sec: 3550.9, 300 sec: 3444.0). Total num frames: 2490368. Throughput: 0: 3358.7. Samples: 2492928. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 14:49:19,565][187009] Avg episode reward: [(0, '566.791')]
[2026-02-02 14:49:19,700][187009] Saving new best policy, reward=566.791!
[2026-02-02 14:49:24,544][187009] Fps is (10 sec: 3289.9, 60 sec: 3549.5, 300 sec: 3444.4). Total num frames: 2506752. Throughput: 0: 3405.4. Samples: 2504192. Policy #0 lag: (min: 13.0, avg: 16.0, max: 77.0)
[2026-02-02 14:49:24,544][187009] Avg episode reward: [(0, '564.574')]
[2026-02-02 14:49:29,645][187009] Fps is (10 sec: 3250.8, 60 sec: 3422.5, 300 sec: 3442.9). Total num frames: 2523136. Throughput: 0: 3361.7. Samples: 2524160. Policy #0 lag: (min: 13.0, avg: 16.0, max: 77.0)
[2026-02-02 14:49:29,645][187009] Avg episode reward: [(0, '573.094')]
[2026-02-02 14:49:29,778][187009] Saving new best policy, reward=573.094!
[2026-02-02 14:49:34,620][187009] Fps is (10 sec: 3252.1, 60 sec: 3411.9, 300 sec: 3443.1). Total num frames: 2539520. Throughput: 0: 3349.0. Samples: 2544128. Policy #0 lag: (min: 2.0, avg: 5.0, max: 66.0)
[2026-02-02 14:49:34,620][187009] Avg episode reward: [(0, '567.355')]
[2026-02-02 14:49:39,520][187009] Fps is (10 sec: 3318.2, 60 sec: 3288.8, 300 sec: 3443.8). Total num frames: 2555904. Throughput: 0: 3396.7. Samples: 2555904. Policy #0 lag: (min: 2.0, avg: 5.0, max: 66.0)
[2026-02-02 14:49:39,520][187009] Avg episode reward: [(0, '585.606')]
[2026-02-02 14:49:39,660][187009] Saving new best policy, reward=585.606!
[2026-02-02 14:49:44,544][187009] Fps is (10 sec: 3301.8, 60 sec: 3277.8, 300 sec: 3443.2). Total num frames: 2572288. Throughput: 0: 3397.9. Samples: 2575360. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 14:49:44,544][187009] Avg episode reward: [(0, '583.144')]
[2026-02-02 14:49:49,576][187009] Fps is (10 sec: 3258.6, 60 sec: 3273.7, 300 sec: 3443.0). Total num frames: 2588672. Throughput: 0: 3423.6. Samples: 2596352. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 14:49:49,576][187009] Avg episode reward: [(0, '604.372')]
[2026-02-02 14:49:49,713][187009] Saving new best policy, reward=604.372!
[2026-02-02 14:49:54,567][187009] Fps is (10 sec: 3269.2, 60 sec: 3278.7, 300 sec: 3417.4). Total num frames: 2605056. Throughput: 0: 3396.0. Samples: 2606080. Policy #0 lag: (min: 12.0, avg: 15.0, max: 76.0)
[2026-02-02 14:49:54,568][187009] Avg episode reward: [(0, '599.296')]
[2026-02-02 14:49:59,624][187009] Fps is (10 sec: 3261.0, 60 sec: 3277.7, 300 sec: 3388.5). Total num frames: 2621440. Throughput: 0: 3410.3. Samples: 2627584. Policy #0 lag: (min: 12.0, avg: 15.0, max: 76.0)
[2026-02-02 14:49:59,625][187009] Avg episode reward: [(0, '611.834')]
[2026-02-02 14:49:59,763][187009] Saving new best policy, reward=611.834!
[2026-02-02 14:50:04,616][187009] Fps is (10 sec: 3260.9, 60 sec: 3273.8, 300 sec: 3388.0). Total num frames: 2637824. Throughput: 0: 3454.9. Samples: 2648576. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 14:50:04,617][187009] Avg episode reward: [(0, '627.349')]
[2026-02-02 14:50:04,755][187009] Saving new best policy, reward=627.349!
[2026-02-02 14:50:09,558][187009] Fps is (10 sec: 3298.8, 60 sec: 3281.3, 300 sec: 3387.9). Total num frames: 2654208. Throughput: 0: 3423.7. Samples: 2658304. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 14:50:09,558][187009] Avg episode reward: [(0, '648.161')]
[2026-02-02 14:50:09,699][187009] Saving new best policy, reward=648.161!
[2026-02-02 14:50:14,655][187009] Fps is (10 sec: 3264.1, 60 sec: 3272.9, 300 sec: 3387.5). Total num frames: 2670592. Throughput: 0: 3435.3. Samples: 2678784. Policy #0 lag: (min: 9.0, avg: 12.0, max: 73.0)
[2026-02-02 14:50:14,655][187009] Avg episode reward: [(0, '671.728')]
[2026-02-02 14:50:14,814][187009] Saving new best policy, reward=671.728!
[2026-02-02 14:50:19,579][187009] Fps is (10 sec: 3269.9, 60 sec: 3276.0, 300 sec: 3387.7). Total num frames: 2686976. Throughput: 0: 3416.5. Samples: 2697728. Policy #0 lag: (min: 9.0, avg: 12.0, max: 73.0)
[2026-02-02 14:50:19,579][187009] Avg episode reward: [(0, '643.792')]
[2026-02-02 14:50:24,571][187009] Fps is (10 sec: 3304.5, 60 sec: 3275.3, 300 sec: 3387.4). Total num frames: 2703360. Throughput: 0: 3364.0. Samples: 2707456. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 14:50:24,571][187009] Avg episode reward: [(0, '651.033')]
[2026-02-02 14:50:29,621][187009] Fps is (10 sec: 3262.9, 60 sec: 3278.1, 300 sec: 3386.9). Total num frames: 2719744. Throughput: 0: 3384.8. Samples: 2727936. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 14:50:29,622][187009] Avg episode reward: [(0, '651.688')]
[2026-02-02 14:50:30,520][187009] Signal inference workers to stop experience collection... (500 times)
[2026-02-02 14:50:30,906][187009] InferenceWorker_p0-w0: stopping experience collection (500 times)
[2026-02-02 14:50:30,906][187009] Signal inference workers to resume experience collection... (500 times)
[2026-02-02 14:50:30,907][187009] InferenceWorker_p0-w0: resuming experience collection (500 times)
[2026-02-02 14:50:34,529][187009] Fps is (10 sec: 3290.6, 60 sec: 3281.8, 300 sec: 3388.9). Total num frames: 2736128. Throughput: 0: 3382.7. Samples: 2748416. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 14:50:34,530][187009] Avg episode reward: [(0, '687.149')]
[2026-02-02 14:50:34,675][187009] Saving /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_accel_policy3_aggressive_magpie_refined_params_02022026_smooth_aggressive_ttc/checkpoint_p0/checkpoint_000010688_2736128.pth...
[2026-02-02 14:50:34,679][187009] Removing /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_accel_policy3_aggressive_magpie_refined_params_02022026_smooth_aggressive_ttc/checkpoint_p0/checkpoint_000007552_1933312.pth
[2026-02-02 14:50:34,679][187009] Saving new best policy, reward=687.149!
[2026-02-02 14:50:39,568][187009] Fps is (10 sec: 3294.6, 60 sec: 3274.2, 300 sec: 3387.6). Total num frames: 2752512. Throughput: 0: 3379.2. Samples: 2758144. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 14:50:39,568][187009] Avg episode reward: [(0, '693.470')]
[2026-02-02 14:50:39,719][187009] Saving new best policy, reward=693.470!
[2026-02-02 14:50:44,797][187009] Fps is (10 sec: 3989.1, 60 sec: 3399.0, 300 sec: 3412.5). Total num frames: 2777088. Throughput: 0: 3366.3. Samples: 2779648. Policy #0 lag: (min: 1.0, avg: 4.0, max: 65.0)
[2026-02-02 14:50:44,797][187009] Avg episode reward: [(0, '721.834')]
[2026-02-02 14:50:45,151][187009] Saving new best policy, reward=721.834!
[2026-02-02 14:50:49,541][187009] Fps is (10 sec: 4106.8, 60 sec: 3415.3, 300 sec: 3416.5). Total num frames: 2793472. Throughput: 0: 3384.8. Samples: 2800640. Policy #0 lag: (min: 13.0, avg: 16.0, max: 77.0)
[2026-02-02 14:50:49,542][187009] Avg episode reward: [(0, '708.926')]
[2026-02-02 14:50:54,640][187009] Fps is (10 sec: 4161.5, 60 sec: 3545.6, 300 sec: 3443.0). Total num frames: 2818048. Throughput: 0: 3384.4. Samples: 2810880. Policy #0 lag: (min: 13.0, avg: 16.0, max: 77.0)
[2026-02-02 14:50:54,640][187009] Avg episode reward: [(0, '700.045')]
[2026-02-02 14:50:59,578][187009] Fps is (10 sec: 4081.1, 60 sec: 3552.6, 300 sec: 3444.3). Total num frames: 2834432. Throughput: 0: 3396.4. Samples: 2831360. Policy #0 lag: (min: 5.0, avg: 8.0, max: 69.0)
[2026-02-02 14:50:59,578][187009] Avg episode reward: [(0, '706.719')]
[2026-02-02 14:51:04,617][187009] Fps is (10 sec: 3284.4, 60 sec: 3549.8, 300 sec: 3418.0). Total num frames: 2850816. Throughput: 0: 3410.5. Samples: 2851328. Policy #0 lag: (min: 5.0, avg: 8.0, max: 69.0)
[2026-02-02 14:51:04,617][187009] Avg episode reward: [(0, '713.562')]
[2026-02-02 14:51:09,568][187009] Fps is (10 sec: 3280.2, 60 sec: 3549.3, 300 sec: 3415.1). Total num frames: 2867200. Throughput: 0: 3413.6. Samples: 2861056. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 14:51:09,568][187009] Avg episode reward: [(0, '709.671')]
[2026-02-02 14:51:14,532][187009] Fps is (10 sec: 3304.9, 60 sec: 3557.2, 300 sec: 3389.2). Total num frames: 2883584. Throughput: 0: 3443.0. Samples: 2882560. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 14:51:14,532][187009] Avg episode reward: [(0, '698.072')]
[2026-02-02 14:51:19,573][187009] Fps is (10 sec: 3275.1, 60 sec: 3550.2, 300 sec: 3387.6). Total num frames: 2899968. Throughput: 0: 3421.4. Samples: 2902528. Policy #0 lag: (min: 3.0, avg: 6.0, max: 67.0)
[2026-02-02 14:51:19,573][187009] Avg episode reward: [(0, '694.210')]
[2026-02-02 14:51:24,533][187009] Fps is (10 sec: 3276.4, 60 sec: 3552.1, 300 sec: 3387.8). Total num frames: 2916352. Throughput: 0: 3472.9. Samples: 2914304. Policy #0 lag: (min: 3.0, avg: 6.0, max: 67.0)
[2026-02-02 14:51:24,533][187009] Avg episode reward: [(0, '712.521')]
[2026-02-02 14:51:29,523][187009] Fps is (10 sec: 3293.3, 60 sec: 3555.7, 300 sec: 3388.6). Total num frames: 2932736. Throughput: 0: 3445.7. Samples: 2933760. Policy #0 lag: (min: 10.0, avg: 13.0, max: 74.0)
[2026-02-02 14:51:29,523][187009] Avg episode reward: [(0, '755.980')]
[2026-02-02 14:51:29,655][187009] Saving new best policy, reward=755.980!
[2026-02-02 14:51:34,569][187009] Fps is (10 sec: 3265.0, 60 sec: 3547.5, 300 sec: 3388.0). Total num frames: 2949120. Throughput: 0: 3434.0. Samples: 2955264. Policy #0 lag: (min: 10.0, avg: 13.0, max: 74.0)
[2026-02-02 14:51:34,569][187009] Avg episode reward: [(0, '782.040')]
[2026-02-02 14:51:34,710][187009] Saving new best policy, reward=782.040!
[2026-02-02 14:51:39,535][187009] Fps is (10 sec: 3272.9, 60 sec: 3551.8, 300 sec: 3388.3). Total num frames: 2965504. Throughput: 0: 3466.9. Samples: 2966528. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 14:51:39,535][187009] Avg episode reward: [(0, '783.480')]
[2026-02-02 14:51:39,672][187009] Saving new best policy, reward=783.480!
[2026-02-02 14:51:44,636][187009] Fps is (10 sec: 3255.0, 60 sec: 3422.5, 300 sec: 3386.8). Total num frames: 2981888. Throughput: 0: 3443.0. Samples: 2986496. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 14:51:44,636][187009] Avg episode reward: [(0, '759.422')]
[2026-02-02 14:51:49,599][187009] Fps is (10 sec: 3255.9, 60 sec: 3410.1, 300 sec: 3387.3). Total num frames: 2998272. Throughput: 0: 3483.0. Samples: 3008000. Policy #0 lag: (min: 12.0, avg: 15.0, max: 76.0)
[2026-02-02 14:51:49,599][187009] Avg episode reward: [(0, '767.144')]
[2026-02-02 14:51:51,018][187009] Signal inference workers to stop experience collection... (550 times)
[2026-02-02 14:51:51,018][187009] Signal inference workers to resume experience collection... (550 times)
[2026-02-02 14:51:51,268][187009] InferenceWorker_p0-w0: stopping experience collection (550 times)
[2026-02-02 14:51:51,269][187009] InferenceWorker_p0-w0: resuming experience collection (550 times)
[2026-02-02 14:51:54,625][187009] Fps is (10 sec: 3280.3, 60 sec: 3277.6, 300 sec: 3386.8). Total num frames: 3014656. Throughput: 0: 3477.2. Samples: 3017728. Policy #0 lag: (min: 12.0, avg: 15.0, max: 76.0)
[2026-02-02 14:51:54,625][187009] Avg episode reward: [(0, '775.432')]
[2026-02-02 14:51:59,597][187009] Fps is (10 sec: 3277.3, 60 sec: 3275.7, 300 sec: 3388.1). Total num frames: 3031040. Throughput: 0: 3476.5. Samples: 3039232. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 14:51:59,597][187009] Avg episode reward: [(0, '801.393')]
[2026-02-02 14:51:59,729][187009] Saving new best policy, reward=801.393!
[2026-02-02 14:52:04,608][187009] Fps is (10 sec: 3282.6, 60 sec: 3277.3, 300 sec: 3388.0). Total num frames: 3047424. Throughput: 0: 3524.4. Samples: 3061248. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 14:52:04,608][187009] Avg episode reward: [(0, '815.580')]
[2026-02-02 14:52:04,969][187009] Saving new best policy, reward=815.580!
[2026-02-02 14:52:09,619][187009] Fps is (10 sec: 4087.0, 60 sec: 3410.4, 300 sec: 3415.7). Total num frames: 3072000. Throughput: 0: 3474.9. Samples: 3070976. Policy #0 lag: (min: 6.0, avg: 9.0, max: 70.0)
[2026-02-02 14:52:09,619][187009] Avg episode reward: [(0, '826.341')]
[2026-02-02 14:52:09,974][187009] Saving new best policy, reward=826.341!
[2026-02-02 14:52:14,632][187009] Fps is (10 sec: 4903.2, 60 sec: 3543.9, 300 sec: 3443.5). Total num frames: 3096576. Throughput: 0: 3518.6. Samples: 3092480. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 14:52:14,632][187009] Avg episode reward: [(0, '818.286')]
[2026-02-02 14:52:19,581][187009] Fps is (10 sec: 4111.8, 60 sec: 3549.4, 300 sec: 3443.9). Total num frames: 3112960. Throughput: 0: 3526.2. Samples: 3113984. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 14:52:19,581][187009] Avg episode reward: [(0, '806.537')]
[2026-02-02 14:52:24,648][187009] Fps is (10 sec: 3271.7, 60 sec: 3543.1, 300 sec: 3443.0). Total num frames: 3129344. Throughput: 0: 3506.9. Samples: 3124736. Policy #0 lag: (min: 14.0, avg: 17.0, max: 78.0)
[2026-02-02 14:52:24,648][187009] Avg episode reward: [(0, '790.749')]
[2026-02-02 14:52:29,554][187009] Fps is (10 sec: 3285.7, 60 sec: 3548.0, 300 sec: 3443.1). Total num frames: 3145728. Throughput: 0: 3556.4. Samples: 3146240. Policy #0 lag: (min: 14.0, avg: 17.0, max: 78.0)
[2026-02-02 14:52:29,554][187009] Avg episode reward: [(0, '764.721')]
[2026-02-02 14:52:34,524][187009] Fps is (10 sec: 3317.7, 60 sec: 3552.5, 300 sec: 3444.4). Total num frames: 3162112. Throughput: 0: 3521.6. Samples: 3166208. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 14:52:34,525][187009] Avg episode reward: [(0, '777.873')]
[2026-02-02 14:52:34,660][187009] Saving /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_accel_policy3_aggressive_magpie_refined_params_02022026_smooth_aggressive_ttc/checkpoint_p0/checkpoint_000012352_3162112.pth...
[2026-02-02 14:52:34,664][187009] Removing /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_accel_policy3_aggressive_magpie_refined_params_02022026_smooth_aggressive_ttc/checkpoint_p0/checkpoint_000009152_2342912.pth
[2026-02-02 14:52:39,528][187009] Fps is (10 sec: 3285.4, 60 sec: 3550.3, 300 sec: 3443.6). Total num frames: 3178496. Throughput: 0: 3569.0. Samples: 3177984. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 14:52:39,528][187009] Avg episode reward: [(0, '731.826')]
[2026-02-02 14:52:44,565][187009] Fps is (10 sec: 3263.6, 60 sec: 3554.1, 300 sec: 3444.1). Total num frames: 3194880. Throughput: 0: 3541.0. Samples: 3198464. Policy #0 lag: (min: 22.0, avg: 25.0, max: 86.0)
[2026-02-02 14:52:44,565][187009] Avg episode reward: [(0, '771.980')]
[2026-02-02 14:52:49,578][187009] Fps is (10 sec: 3260.4, 60 sec: 3551.1, 300 sec: 3444.1). Total num frames: 3211264. Throughput: 0: 3529.4. Samples: 3219968. Policy #0 lag: (min: 22.0, avg: 25.0, max: 86.0)
[2026-02-02 14:52:49,578][187009] Avg episode reward: [(0, '819.031')]
[2026-02-02 14:52:54,596][187009] Fps is (10 sec: 3266.5, 60 sec: 3551.6, 300 sec: 3443.0). Total num frames: 3227648. Throughput: 0: 3528.9. Samples: 3229696. Policy #0 lag: (min: 47.0, avg: 50.0, max: 111.0)
[2026-02-02 14:52:54,597][187009] Avg episode reward: [(0, '837.085')]
[2026-02-02 14:52:54,728][187009] Saving new best policy, reward=837.085!
[2026-02-02 14:52:59,602][187009] Fps is (10 sec: 3268.8, 60 sec: 3549.6, 300 sec: 3443.6). Total num frames: 3244032. Throughput: 0: 3540.8. Samples: 3251712. Policy #0 lag: (min: 47.0, avg: 50.0, max: 111.0)
[2026-02-02 14:52:59,603][187009] Avg episode reward: [(0, '839.872')]
[2026-02-02 14:52:59,743][187009] Saving new best policy, reward=839.872!
[2026-02-02 14:53:04,601][187009] Fps is (10 sec: 3275.3, 60 sec: 3550.2, 300 sec: 3443.8). Total num frames: 3260416. Throughput: 0: 3548.3. Samples: 3273728. Policy #0 lag: (min: 47.0, avg: 50.0, max: 111.0)
[2026-02-02 14:53:04,601][187009] Avg episode reward: [(0, '850.697')]
[2026-02-02 14:53:04,739][187009] Saving new best policy, reward=850.697!
[2026-02-02 14:53:09,390][187009] Signal inference workers to stop experience collection... (600 times)
[2026-02-02 14:53:09,742][187009] InferenceWorker_p0-w0: stopping experience collection (600 times)
[2026-02-02 14:53:09,744][187009] Signal inference workers to resume experience collection... (600 times)
[2026-02-02 14:53:09,745][187009] Fps is (10 sec: 4038.6, 60 sec: 3542.5, 300 sec: 3469.5). Total num frames: 3284992. Throughput: 0: 3530.9. Samples: 3283968. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 14:53:09,745][187009] Avg episode reward: [(0, '866.377')]
[2026-02-02 14:53:09,872][187009] InferenceWorker_p0-w0: resuming experience collection (600 times)
[2026-02-02 14:53:10,107][187009] Saving new best policy, reward=866.377!
[2026-02-02 14:53:14,715][187009] Fps is (10 sec: 4860.1, 60 sec: 3545.0, 300 sec: 3497.4). Total num frames: 3309568. Throughput: 0: 3525.9. Samples: 3305472. Policy #0 lag: (min: 32.0, avg: 35.0, max: 96.0)
[2026-02-02 14:53:14,715][187009] Avg episode reward: [(0, '864.873')]
[2026-02-02 14:53:19,605][187009] Fps is (10 sec: 4154.2, 60 sec: 3548.5, 300 sec: 3498.2). Total num frames: 3325952. Throughput: 0: 3566.3. Samples: 3326976. Policy #0 lag: (min: 32.0, avg: 35.0, max: 96.0)
[2026-02-02 14:53:19,605][187009] Avg episode reward: [(0, '870.815')]
[2026-02-02 14:53:19,750][187009] Saving new best policy, reward=870.815!
[2026-02-02 14:53:24,521][187009] Fps is (10 sec: 3341.5, 60 sec: 3557.4, 300 sec: 3474.5). Total num frames: 3342336. Throughput: 0: 3550.4. Samples: 3337728. Policy #0 lag: (min: 32.0, avg: 35.0, max: 96.0)
[2026-02-02 14:53:24,522][187009] Avg episode reward: [(0, '882.772')]
[2026-02-02 14:53:24,658][187009] Saving new best policy, reward=882.772!
[2026-02-02 14:53:29,526][187009] Fps is (10 sec: 3302.8, 60 sec: 3551.5, 300 sec: 3472.0). Total num frames: 3358720. Throughput: 0: 3575.7. Samples: 3359232. Policy #0 lag: (min: 9.0, avg: 12.0, max: 73.0)
[2026-02-02 14:53:29,526][187009] Avg episode reward: [(0, '893.170')]
[2026-02-02 14:53:29,665][187009] Saving new best policy, reward=893.170!
[2026-02-02 14:53:34,625][187009] Fps is (10 sec: 3242.9, 60 sec: 3543.9, 300 sec: 3444.7). Total num frames: 3375104. Throughput: 0: 3534.8. Samples: 3379200. Policy #0 lag: (min: 9.0, avg: 12.0, max: 73.0)
[2026-02-02 14:53:34,626][187009] Avg episode reward: [(0, '871.921')]
[2026-02-02 14:53:39,575][187009] Fps is (10 sec: 3260.9, 60 sec: 3547.1, 300 sec: 3443.3). Total num frames: 3391488. Throughput: 0: 3585.7. Samples: 3390976. Policy #0 lag: (min: 9.0, avg: 12.0, max: 73.0)
[2026-02-02 14:53:39,575][187009] Avg episode reward: [(0, '877.472')]
[2026-02-02 14:53:44,608][187009] Fps is (10 sec: 3282.5, 60 sec: 3547.3, 300 sec: 3442.4). Total num frames: 3407872. Throughput: 0: 3538.0. Samples: 3410944. Policy #0 lag: (min: 6.0, avg: 9.0, max: 70.0)
[2026-02-02 14:53:44,608][187009] Avg episode reward: [(0, '862.830')]
[2026-02-02 14:53:49,619][187009] Fps is (10 sec: 3262.3, 60 sec: 3547.4, 300 sec: 3443.2). Total num frames: 3424256. Throughput: 0: 3537.1. Samples: 3432960. Policy #0 lag: (min: 6.0, avg: 9.0, max: 70.0)
[2026-02-02 14:53:49,619][187009] Avg episode reward: [(0, '861.218')]
[2026-02-02 14:53:54,536][187009] Fps is (10 sec: 3300.7, 60 sec: 3553.5, 300 sec: 3444.6). Total num frames: 3440640. Throughput: 0: 3555.0. Samples: 3443200. Policy #0 lag: (min: 6.0, avg: 9.0, max: 70.0)
[2026-02-02 14:53:54,536][187009] Avg episode reward: [(0, '843.776')]
[2026-02-02 14:53:59,537][187009] Fps is (10 sec: 3304.0, 60 sec: 3553.8, 300 sec: 3443.7). Total num frames: 3457024. Throughput: 0: 3564.0. Samples: 3465216. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 14:53:59,537][187009] Avg episode reward: [(0, '889.798')]
[2026-02-02 14:54:04,536][187009] Fps is (10 sec: 3276.7, 60 sec: 3553.7, 300 sec: 3444.6). Total num frames: 3473408. Throughput: 0: 3555.3. Samples: 3486720. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 14:54:04,536][187009] Avg episode reward: [(0, '948.146')]
[2026-02-02 14:54:04,668][187009] Saving new best policy, reward=948.146!
[2026-02-02 14:54:09,739][187009] Fps is (10 sec: 4014.8, 60 sec: 3550.2, 300 sec: 3469.4). Total num frames: 3497984. Throughput: 0: 3521.4. Samples: 3496960. Policy #0 lag: (min: 3.0, avg: 6.0, max: 67.0)
[2026-02-02 14:54:09,739][187009] Avg episode reward: [(0, '959.385')]
[2026-02-02 14:54:10,093][187009] Saving new best policy, reward=959.385!
[2026-02-02 14:54:14,655][187009] Fps is (10 sec: 4047.6, 60 sec: 3416.7, 300 sec: 3470.1). Total num frames: 3514368. Throughput: 0: 3517.0. Samples: 3517952. Policy #0 lag: (min: 3.0, avg: 6.0, max: 67.0)
[2026-02-02 14:54:14,656][187009] Avg episode reward: [(0, '977.898')]
[2026-02-02 14:54:15,070][187009] Saving new best policy, reward=977.898!
[2026-02-02 14:54:19,627][187009] Fps is (10 sec: 3313.8, 60 sec: 3412.0, 300 sec: 3470.2). Total num frames: 3530752. Throughput: 0: 3527.0. Samples: 3537920. Policy #0 lag: (min: 3.0, avg: 6.0, max: 67.0)
[2026-02-02 14:54:19,627][187009] Avg episode reward: [(0, '962.902')]
[2026-02-02 14:54:24,486][187009] Signal inference workers to stop experience collection... (650 times)
[2026-02-02 14:54:24,842][187009] InferenceWorker_p0-w0: stopping experience collection (650 times)
[2026-02-02 14:54:24,842][187009] Signal inference workers to resume experience collection... (650 times)
[2026-02-02 14:54:24,842][187009] Fps is (10 sec: 4021.0, 60 sec: 3531.0, 300 sec: 3496.6). Total num frames: 3555328. Throughput: 0: 3449.7. Samples: 3547136. Policy #0 lag: (min: 47.0, avg: 50.0, max: 111.0)
[2026-02-02 14:54:24,842][187009] Avg episode reward: [(0, '959.866')]
[2026-02-02 14:54:24,844][187009] InferenceWorker_p0-w0: resuming experience collection (650 times)
[2026-02-02 14:54:29,547][187009] Fps is (10 sec: 4129.1, 60 sec: 3548.6, 300 sec: 3499.8). Total num frames: 3571712. Throughput: 0: 3497.7. Samples: 3568128. Policy #0 lag: (min: 47.0, avg: 50.0, max: 111.0)
[2026-02-02 14:54:29,547][187009] Avg episode reward: [(0, '953.221')]
[2026-02-02 14:54:34,618][187009] Fps is (10 sec: 3351.9, 60 sec: 3550.3, 300 sec: 3497.8). Total num frames: 3588096. Throughput: 0: 3470.3. Samples: 3589120. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 14:54:34,618][187009] Avg episode reward: [(0, '981.591')]
[2026-02-02 14:54:34,771][187009] Saving /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_accel_policy3_aggressive_magpie_refined_params_02022026_smooth_aggressive_ttc/checkpoint_p0/checkpoint_000014016_3588096.pth...
[2026-02-02 14:54:34,774][187009] Removing /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_accel_policy3_aggressive_magpie_refined_params_02022026_smooth_aggressive_ttc/checkpoint_p0/checkpoint_000010688_2736128.pth
[2026-02-02 14:54:34,775][187009] Saving new best policy, reward=981.591!
[2026-02-02 14:54:39,587][187009] Fps is (10 sec: 3263.6, 60 sec: 3549.1, 300 sec: 3498.4). Total num frames: 3604480. Throughput: 0: 3466.2. Samples: 3599360. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 14:54:39,588][187009] Avg episode reward: [(0, '996.952')]
[2026-02-02 14:54:39,721][187009] Saving new best policy, reward=996.952!
[2026-02-02 14:54:44,547][187009] Fps is (10 sec: 3300.4, 60 sec: 3553.5, 300 sec: 3499.3). Total num frames: 3620864. Throughput: 0: 3446.7. Samples: 3620352. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 14:54:44,547][187009] Avg episode reward: [(0, '1029.083')]
[2026-02-02 14:54:44,688][187009] Saving new best policy, reward=1029.083!
[2026-02-02 14:54:49,603][187009] Fps is (10 sec: 3271.6, 60 sec: 3550.8, 300 sec: 3498.5). Total num frames: 3637248. Throughput: 0: 3396.9. Samples: 3639808. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 14:54:49,604][187009] Avg episode reward: [(0, '1019.234')]
[2026-02-02 14:54:54,617][187009] Fps is (10 sec: 3253.7, 60 sec: 3545.0, 300 sec: 3499.0). Total num frames: 3653632. Throughput: 0: 3434.0. Samples: 3651072. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 14:54:54,618][187009] Avg episode reward: [(0, '1007.637')]
[2026-02-02 14:54:59,605][187009] Fps is (10 sec: 3276.3, 60 sec: 3545.8, 300 sec: 3499.1). Total num frames: 3670016. Throughput: 0: 3405.8. Samples: 3671040. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 14:54:59,605][187009] Avg episode reward: [(0, '977.009')]
[2026-02-02 14:55:04,595][187009] Fps is (10 sec: 3284.3, 60 sec: 3546.4, 300 sec: 3498.5). Total num frames: 3686400. Throughput: 0: 3427.2. Samples: 3692032. Policy #0 lag: (min: 1.0, avg: 4.0, max: 65.0)
[2026-02-02 14:55:04,595][187009] Avg episode reward: [(0, '998.538')]
[2026-02-02 14:55:09,520][187009] Fps is (10 sec: 3304.9, 60 sec: 3425.8, 300 sec: 3500.6). Total num frames: 3702784. Throughput: 0: 3506.7. Samples: 3703808. Policy #0 lag: (min: 1.0, avg: 4.0, max: 65.0)
[2026-02-02 14:55:09,520][187009] Avg episode reward: [(0, '1003.297')]
[2026-02-02 14:55:14,530][187009] Fps is (10 sec: 3298.2, 60 sec: 3420.5, 300 sec: 3499.5). Total num frames: 3719168. Throughput: 0: 3448.8. Samples: 3723264. Policy #0 lag: (min: 1.0, avg: 4.0, max: 65.0)
[2026-02-02 14:55:14,530][187009] Avg episode reward: [(0, '1010.949')]
[2026-02-02 14:55:19,581][187009] Fps is (10 sec: 3257.1, 60 sec: 3416.0, 300 sec: 3498.8). Total num frames: 3735552. Throughput: 0: 3450.3. Samples: 3744256. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 14:55:19,581][187009] Avg episode reward: [(0, '1010.007')]
[2026-02-02 14:55:24,588][187009] Fps is (10 sec: 3258.0, 60 sec: 3290.8, 300 sec: 3499.4). Total num frames: 3751936. Throughput: 0: 3436.1. Samples: 3753984. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 14:55:24,588][187009] Avg episode reward: [(0, '963.196')]
[2026-02-02 14:55:29,652][187009] Fps is (10 sec: 3253.5, 60 sec: 3271.1, 300 sec: 3497.5). Total num frames: 3768320. Throughput: 0: 3428.0. Samples: 3774976. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 14:55:29,652][187009] Avg episode reward: [(0, '965.939')]
[2026-02-02 14:55:34,584][187009] Fps is (10 sec: 3277.9, 60 sec: 3278.6, 300 sec: 3498.8). Total num frames: 3784704. Throughput: 0: 3471.7. Samples: 3795968. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 14:55:34,584][187009] Avg episode reward: [(0, '959.956')]
[2026-02-02 14:55:39,536][187009] Fps is (10 sec: 3315.2, 60 sec: 3279.6, 300 sec: 3474.3). Total num frames: 3801088. Throughput: 0: 3442.3. Samples: 3805696. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 14:55:39,536][187009] Avg episode reward: [(0, '997.118')]
[2026-02-02 14:55:44,573][187009] Fps is (10 sec: 3280.4, 60 sec: 3275.3, 300 sec: 3470.8). Total num frames: 3817472. Throughput: 0: 3472.7. Samples: 3827200. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 14:55:44,573][187009] Avg episode reward: [(0, '985.435')]
[2026-02-02 14:55:45,096][187009] Signal inference workers to stop experience collection... (700 times)
[2026-02-02 14:55:45,099][187009] Signal inference workers to resume experience collection... (700 times)
[2026-02-02 14:55:45,348][187009] InferenceWorker_p0-w0: stopping experience collection (700 times)
[2026-02-02 14:55:45,349][187009] InferenceWorker_p0-w0: resuming experience collection (700 times)
[2026-02-02 14:55:49,821][187009] Fps is (10 sec: 3982.5, 60 sec: 3401.0, 300 sec: 3469.1). Total num frames: 3842048. Throughput: 0: 3452.8. Samples: 3848192. Policy #0 lag: (min: 3.0, avg: 6.0, max: 67.0)
[2026-02-02 14:55:49,821][187009] Avg episode reward: [(0, '972.382')]
[2026-02-02 14:55:54,611][187009] Fps is (10 sec: 4080.7, 60 sec: 3413.7, 300 sec: 3470.8). Total num frames: 3858432. Throughput: 0: 3417.8. Samples: 3857920. Policy #0 lag: (min: 3.0, avg: 6.0, max: 67.0)
[2026-02-02 14:55:54,611][187009] Avg episode reward: [(0, '958.013')]
[2026-02-02 14:55:59,769][187009] Fps is (10 sec: 4117.3, 60 sec: 3540.2, 300 sec: 3497.1). Total num frames: 3883008. Throughput: 0: 3440.5. Samples: 3878912. Policy #0 lag: (min: 11.0, avg: 14.0, max: 75.0)
[2026-02-02 14:55:59,770][187009] Avg episode reward: [(0, '995.444')]
[2026-02-02 14:56:04,602][187009] Fps is (10 sec: 4099.5, 60 sec: 3549.4, 300 sec: 3498.5). Total num frames: 3899392. Throughput: 0: 3457.2. Samples: 3899904. Policy #0 lag: (min: 11.0, avg: 14.0, max: 75.0)
[2026-02-02 14:56:04,602][187009] Avg episode reward: [(0, '1038.378')]
[2026-02-02 14:56:04,738][187009] Saving new best policy, reward=1038.378!
[2026-02-02 14:56:09,539][187009] Fps is (10 sec: 3354.2, 60 sec: 3548.8, 300 sec: 3498.9). Total num frames: 3915776. Throughput: 0: 3462.6. Samples: 3909632. Policy #0 lag: (min: 11.0, avg: 14.0, max: 75.0)
[2026-02-02 14:56:09,539][187009] Avg episode reward: [(0, '1083.088')]
[2026-02-02 14:56:09,687][187009] Saving new best policy, reward=1083.088!
[2026-02-02 14:56:14,640][187009] Fps is (10 sec: 3264.6, 60 sec: 3543.4, 300 sec: 3498.2). Total num frames: 3932160. Throughput: 0: 3459.8. Samples: 3930624. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 14:56:14,640][187009] Avg episode reward: [(0, '1096.550')]
[2026-02-02 14:56:14,643][187009] Saving new best policy, reward=1096.550!
[2026-02-02 14:56:19,634][187009] Fps is (10 sec: 3245.8, 60 sec: 3546.7, 300 sec: 3497.8). Total num frames: 3948544. Throughput: 0: 3432.3. Samples: 3950592. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 14:56:19,634][187009] Avg episode reward: [(0, '1119.192')]
[2026-02-02 14:56:19,763][187009] Saving new best policy, reward=1119.192!
[2026-02-02 14:56:24,607][187009] Fps is (10 sec: 3287.6, 60 sec: 3548.7, 300 sec: 3498.0). Total num frames: 3964928. Throughput: 0: 3464.8. Samples: 3961856. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 14:56:24,607][187009] Avg episode reward: [(0, '1084.209')]
[2026-02-02 14:56:29,635][187009] Fps is (10 sec: 3276.7, 60 sec: 3550.9, 300 sec: 3498.2). Total num frames: 3981312. Throughput: 0: 3442.8. Samples: 3982336. Policy #0 lag: (min: 13.0, avg: 16.0, max: 77.0)
[2026-02-02 14:56:29,635][187009] Avg episode reward: [(0, '1054.279')]
[2026-02-02 14:56:34,594][187009] Fps is (10 sec: 3281.1, 60 sec: 3549.3, 300 sec: 3498.3). Total num frames: 3997696. Throughput: 0: 3453.5. Samples: 4002816. Policy #0 lag: (min: 13.0, avg: 16.0, max: 77.0)
[2026-02-02 14:56:34,594][187009] Avg episode reward: [(0, '1011.815')]
[2026-02-02 14:56:34,736][187009] Saving /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_accel_policy3_aggressive_magpie_refined_params_02022026_smooth_aggressive_ttc/checkpoint_p0/checkpoint_000015616_3997696.pth...
[2026-02-02 14:56:34,740][187009] Removing /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_accel_policy3_aggressive_magpie_refined_params_02022026_smooth_aggressive_ttc/checkpoint_p0/checkpoint_000012352_3162112.pth
[2026-02-02 14:56:39,616][187009] Fps is (10 sec: 3282.9, 60 sec: 3545.1, 300 sec: 3499.2). Total num frames: 4014080. Throughput: 0: 3469.8. Samples: 4014080. Policy #0 lag: (min: 13.0, avg: 16.0, max: 77.0)
[2026-02-02 14:56:39,616][187009] Avg episode reward: [(0, '1006.652')]
[2026-02-02 14:56:44,630][187009] Fps is (10 sec: 3265.0, 60 sec: 3546.5, 300 sec: 3498.6). Total num frames: 4030464. Throughput: 0: 3446.8. Samples: 4033536. Policy #0 lag: (min: 3.0, avg: 6.0, max: 67.0)
[2026-02-02 14:56:44,630][187009] Avg episode reward: [(0, '1021.776')]
[2026-02-02 14:56:49,579][187009] Fps is (10 sec: 3289.1, 60 sec: 3427.2, 300 sec: 3499.5). Total num frames: 4046848. Throughput: 0: 3437.9. Samples: 4054528. Policy #0 lag: (min: 3.0, avg: 6.0, max: 67.0)
[2026-02-02 14:56:49,579][187009] Avg episode reward: [(0, '1049.004')]
[2026-02-02 14:56:54,604][187009] Fps is (10 sec: 3285.2, 60 sec: 3413.7, 300 sec: 3498.9). Total num frames: 4063232. Throughput: 0: 3431.1. Samples: 4064256. Policy #0 lag: (min: 3.0, avg: 6.0, max: 67.0)
[2026-02-02 14:56:54,604][187009] Avg episode reward: [(0, '1037.701')]
[2026-02-02 14:56:59,639][187009] Fps is (10 sec: 3257.1, 60 sec: 3283.9, 300 sec: 3498.6). Total num frames: 4079616. Throughput: 0: 3436.1. Samples: 4085248. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 14:56:59,639][187009] Avg episode reward: [(0, '1039.038')]
[2026-02-02 14:57:04,531][187009] Fps is (10 sec: 3301.1, 60 sec: 3280.7, 300 sec: 3472.2). Total num frames: 4096000. Throughput: 0: 3478.2. Samples: 4106752. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 14:57:04,531][187009] Avg episode reward: [(0, '1025.639')]
[2026-02-02 14:57:05,469][187009] Signal inference workers to stop experience collection... (750 times)
[2026-02-02 14:57:05,868][187009] InferenceWorker_p0-w0: stopping experience collection (750 times)
[2026-02-02 14:57:05,870][187009] Signal inference workers to resume experience collection... (750 times)
[2026-02-02 14:57:06,007][187009] InferenceWorker_p0-w0: resuming experience collection (750 times)
[2026-02-02 14:57:09,632][187009] Fps is (10 sec: 3279.2, 60 sec: 3271.7, 300 sec: 3443.4). Total num frames: 4112384. Throughput: 0: 3422.8. Samples: 4115968. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 14:57:09,632][187009] Avg episode reward: [(0, '1059.053')]
[2026-02-02 14:57:14,564][187009] Fps is (10 sec: 3266.0, 60 sec: 3281.0, 300 sec: 3443.6). Total num frames: 4128768. Throughput: 0: 3452.9. Samples: 4137472. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 14:57:14,564][187009] Avg episode reward: [(0, '1065.290')]
[2026-02-02 14:57:19,542][187009] Fps is (10 sec: 3306.5, 60 sec: 3281.8, 300 sec: 3444.7). Total num frames: 4145152. Throughput: 0: 3462.8. Samples: 4158464. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 14:57:19,542][187009] Avg episode reward: [(0, '1058.923')]
[2026-02-02 14:57:24,577][187009] Fps is (10 sec: 3272.4, 60 sec: 3278.4, 300 sec: 3443.1). Total num frames: 4161536. Throughput: 0: 3404.9. Samples: 4167168. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 14:57:24,577][187009] Avg episode reward: [(0, '1086.460')]
[2026-02-02 14:57:29,873][187009] Fps is (10 sec: 3171.9, 60 sec: 3263.8, 300 sec: 3439.4). Total num frames: 4177920. Throughput: 0: 3429.0. Samples: 4188672. Policy #0 lag: (min: 4.0, avg: 7.0, max: 68.0)
[2026-02-02 14:57:29,873][187009] Avg episode reward: [(0, '1112.123')]
[2026-02-02 14:57:34,636][187009] Fps is (10 sec: 4071.9, 60 sec: 3410.9, 300 sec: 3469.9). Total num frames: 4202496. Throughput: 0: 3431.7. Samples: 4209152. Policy #0 lag: (min: 4.0, avg: 7.0, max: 68.0)
[2026-02-02 14:57:34,636][187009] Avg episode reward: [(0, '1157.149')]
[2026-02-02 14:57:34,993][187009] Saving new best policy, reward=1157.149!
[2026-02-02 14:57:39,798][187009] Fps is (10 sec: 4952.3, 60 sec: 3539.2, 300 sec: 3496.2). Total num frames: 4227072. Throughput: 0: 3421.4. Samples: 4218880. Policy #0 lag: (min: 12.0, avg: 15.0, max: 76.0)
[2026-02-02 14:57:39,798][187009] Avg episode reward: [(0, '1144.122')]
[2026-02-02 14:57:44,592][187009] Fps is (10 sec: 4114.3, 60 sec: 3552.1, 300 sec: 3498.8). Total num frames: 4243456. Throughput: 0: 3439.7. Samples: 4239872. Policy #0 lag: (min: 12.0, avg: 15.0, max: 76.0)
[2026-02-02 14:57:44,592][187009] Avg episode reward: [(0, '1117.986')]
[2026-02-02 14:57:49,605][187009] Fps is (10 sec: 3341.2, 60 sec: 3548.3, 300 sec: 3498.9). Total num frames: 4259840. Throughput: 0: 3407.7. Samples: 4260352. Policy #0 lag: (min: 12.0, avg: 15.0, max: 76.0)
[2026-02-02 14:57:49,605][187009] Avg episode reward: [(0, '1107.865')]
[2026-02-02 14:57:54,522][187009] Fps is (10 sec: 3299.9, 60 sec: 3554.7, 300 sec: 3499.9). Total num frames: 4276224. Throughput: 0: 3444.5. Samples: 4270592. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 14:57:54,522][187009] Avg episode reward: [(0, '1104.925')]
[2026-02-02 14:57:59,606][187009] Fps is (10 sec: 3276.6, 60 sec: 3551.8, 300 sec: 3498.9). Total num frames: 4292608. Throughput: 0: 3432.9. Samples: 4292096. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 14:57:59,606][187009] Avg episode reward: [(0, '1107.349')]
[2026-02-02 14:58:04,600][187009] Fps is (10 sec: 3251.4, 60 sec: 3545.8, 300 sec: 3472.9). Total num frames: 4308992. Throughput: 0: 3397.6. Samples: 4311552. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 14:58:04,600][187009] Avg episode reward: [(0, '1123.476')]
[2026-02-02 14:58:09,625][187009] Fps is (10 sec: 3270.6, 60 sec: 3550.3, 300 sec: 3444.5). Total num frames: 4325376. Throughput: 0: 3455.2. Samples: 4322816. Policy #0 lag: (min: 14.0, avg: 17.0, max: 78.0)
[2026-02-02 14:58:09,625][187009] Avg episode reward: [(0, '1107.540')]
[2026-02-02 14:58:14,523][187009] Fps is (10 sec: 3302.1, 60 sec: 3552.3, 300 sec: 3444.4). Total num frames: 4341760. Throughput: 0: 3451.5. Samples: 4342784. Policy #0 lag: (min: 14.0, avg: 17.0, max: 78.0)
[2026-02-02 14:58:14,523][187009] Avg episode reward: [(0, '1134.612')]
[2026-02-02 14:58:19,616][187009] Fps is (10 sec: 3279.8, 60 sec: 3545.5, 300 sec: 3442.3). Total num frames: 4358144. Throughput: 0: 3426.3. Samples: 4363264. Policy #0 lag: (min: 14.0, avg: 17.0, max: 78.0)
[2026-02-02 14:58:19,616][187009] Avg episode reward: [(0, '1093.744')]
[2026-02-02 14:58:22,272][187009] Signal inference workers to stop experience collection... (800 times)
[2026-02-02 14:58:22,617][187009] InferenceWorker_p0-w0: stopping experience collection (800 times)
[2026-02-02 14:58:22,617][187009] Signal inference workers to resume experience collection... (800 times)
[2026-02-02 14:58:22,618][187009] InferenceWorker_p0-w0: resuming experience collection (800 times)
[2026-02-02 14:58:24,597][187009] Fps is (10 sec: 3252.7, 60 sec: 3548.7, 300 sec: 3442.6). Total num frames: 4374528. Throughput: 0: 3474.3. Samples: 4374528. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 14:58:24,599][187009] Avg episode reward: [(0, '1113.650')]
[2026-02-02 14:58:29,622][187009] Fps is (10 sec: 3274.8, 60 sec: 3564.8, 300 sec: 3443.5). Total num frames: 4390912. Throughput: 0: 3422.4. Samples: 4393984. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 14:58:29,622][187009] Avg episode reward: [(0, '1155.840')]
[2026-02-02 14:58:34,577][187009] Fps is (10 sec: 3283.5, 60 sec: 3416.7, 300 sec: 3443.4). Total num frames: 4407296. Throughput: 0: 3449.6. Samples: 4415488. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 14:58:34,577][187009] Avg episode reward: [(0, '1168.302')]
[2026-02-02 14:58:34,712][187009] Saving /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_accel_policy3_aggressive_magpie_refined_params_02022026_smooth_aggressive_ttc/checkpoint_p0/checkpoint_000017216_4407296.pth...
[2026-02-02 14:58:34,716][187009] Removing /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_accel_policy3_aggressive_magpie_refined_params_02022026_smooth_aggressive_ttc/checkpoint_p0/checkpoint_000014016_3588096.pth
[2026-02-02 14:58:34,716][187009] Saving new best policy, reward=1168.302!
[2026-02-02 14:58:39,529][187009] Fps is (10 sec: 3307.5, 60 sec: 3291.5, 300 sec: 3444.3). Total num frames: 4423680. Throughput: 0: 3424.2. Samples: 4424704. Policy #0 lag: (min: 9.0, avg: 12.0, max: 73.0)
[2026-02-02 14:58:39,529][187009] Avg episode reward: [(0, '1190.774')]
[2026-02-02 14:58:39,666][187009] Saving new best policy, reward=1190.774!
[2026-02-02 14:58:44,612][187009] Fps is (10 sec: 3265.3, 60 sec: 3275.7, 300 sec: 3443.5). Total num frames: 4440064. Throughput: 0: 3424.2. Samples: 4446208. Policy #0 lag: (min: 9.0, avg: 12.0, max: 73.0)
[2026-02-02 14:58:44,612][187009] Avg episode reward: [(0, '1154.810')]
[2026-02-02 14:58:49,592][187009] Fps is (10 sec: 3256.3, 60 sec: 3277.5, 300 sec: 3442.8). Total num frames: 4456448. Throughput: 0: 3470.8. Samples: 4467712. Policy #0 lag: (min: 9.0, avg: 12.0, max: 73.0)
[2026-02-02 14:58:49,592][187009] Avg episode reward: [(0, '1121.265')]
[2026-02-02 14:58:54,531][187009] Fps is (10 sec: 3303.4, 60 sec: 3276.3, 300 sec: 3443.5). Total num frames: 4472832. Throughput: 0: 3443.3. Samples: 4477440. Policy #0 lag: (min: 11.0, avg: 14.0, max: 75.0)
[2026-02-02 14:58:54,531][187009] Avg episode reward: [(0, '1149.511')]
[2026-02-02 14:58:59,605][187009] Fps is (10 sec: 3272.6, 60 sec: 3276.9, 300 sec: 3442.6). Total num frames: 4489216. Throughput: 0: 3452.6. Samples: 4498432. Policy #0 lag: (min: 11.0, avg: 14.0, max: 75.0)
[2026-02-02 14:58:59,605][187009] Avg episode reward: [(0, '1207.436')]
[2026-02-02 14:58:59,748][187009] Saving new best policy, reward=1207.436!
[2026-02-02 14:59:04,854][187009] Fps is (10 sec: 3968.0, 60 sec: 3398.9, 300 sec: 3442.1). Total num frames: 4513792. Throughput: 0: 3463.3. Samples: 4519936. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 14:59:04,854][187009] Avg episode reward: [(0, '1191.766')]
[2026-02-02 14:59:09,823][187009] Fps is (10 sec: 4810.1, 60 sec: 3538.2, 300 sec: 3469.2). Total num frames: 4538368. Throughput: 0: 3441.6. Samples: 4530176. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 14:59:09,823][187009] Avg episode reward: [(0, '1152.763')]
[2026-02-02 14:59:14,604][187009] Fps is (10 sec: 4201.1, 60 sec: 3545.1, 300 sec: 3471.5). Total num frames: 4554752. Throughput: 0: 3494.4. Samples: 4551168. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 14:59:14,604][187009] Avg episode reward: [(0, '1127.614')]
[2026-02-02 14:59:19,618][187009] Fps is (10 sec: 3345.6, 60 sec: 3549.8, 300 sec: 3446.0). Total num frames: 4571136. Throughput: 0: 3478.4. Samples: 4572160. Policy #0 lag: (min: 6.0, avg: 9.0, max: 70.0)
[2026-02-02 14:59:19,618][187009] Avg episode reward: [(0, '1162.815')]
[2026-02-02 14:59:24,591][187009] Fps is (10 sec: 3280.8, 60 sec: 3550.2, 300 sec: 3442.9). Total num frames: 4587520. Throughput: 0: 3488.1. Samples: 4581888. Policy #0 lag: (min: 6.0, avg: 9.0, max: 70.0)
[2026-02-02 14:59:24,592][187009] Avg episode reward: [(0, '1193.211')]
[2026-02-02 14:59:29,527][187009] Fps is (10 sec: 3306.7, 60 sec: 3555.5, 300 sec: 3444.5). Total num frames: 4603904. Throughput: 0: 3476.8. Samples: 4602368. Policy #0 lag: (min: 6.0, avg: 9.0, max: 70.0)
[2026-02-02 14:59:29,527][187009] Avg episode reward: [(0, '1194.449')]
[2026-02-02 14:59:34,551][187009] Fps is (10 sec: 3290.1, 60 sec: 3551.4, 300 sec: 3443.8). Total num frames: 4620288. Throughput: 0: 3416.4. Samples: 4621312. Policy #0 lag: (min: 1.0, avg: 4.0, max: 65.0)
[2026-02-02 14:59:34,551][187009] Avg episode reward: [(0, '1186.665')]
[2026-02-02 14:59:39,605][187009] Fps is (10 sec: 3251.4, 60 sec: 3545.4, 300 sec: 3442.7). Total num frames: 4636672. Throughput: 0: 3453.2. Samples: 4633088. Policy #0 lag: (min: 1.0, avg: 4.0, max: 65.0)
[2026-02-02 14:59:39,605][187009] Avg episode reward: [(0, '1166.067')]
[2026-02-02 14:59:42,993][187009] Signal inference workers to stop experience collection... (850 times)
[2026-02-02 14:59:42,993][187009] Signal inference workers to resume experience collection... (850 times)
[2026-02-02 14:59:43,247][187009] InferenceWorker_p0-w0: stopping experience collection (850 times)
[2026-02-02 14:59:43,247][187009] InferenceWorker_p0-w0: resuming experience collection (850 times)
[2026-02-02 14:59:44,591][187009] Fps is (10 sec: 3263.9, 60 sec: 3551.1, 300 sec: 3443.6). Total num frames: 4653056. Throughput: 0: 3459.9. Samples: 4654080. Policy #0 lag: (min: 1.0, avg: 4.0, max: 65.0)
[2026-02-02 14:59:44,591][187009] Avg episode reward: [(0, '1162.382')]
[2026-02-02 14:59:49,614][187009] Fps is (10 sec: 3273.8, 60 sec: 3548.5, 300 sec: 3443.5). Total num frames: 4669440. Throughput: 0: 3431.6. Samples: 4673536. Policy #0 lag: (min: 9.0, avg: 12.0, max: 73.0)
[2026-02-02 14:59:49,614][187009] Avg episode reward: [(0, '1175.550')]
[2026-02-02 14:59:54,580][187009] Fps is (10 sec: 3280.3, 60 sec: 3547.0, 300 sec: 3443.7). Total num frames: 4685824. Throughput: 0: 3454.8. Samples: 4684800. Policy #0 lag: (min: 9.0, avg: 12.0, max: 73.0)
[2026-02-02 14:59:54,580][187009] Avg episode reward: [(0, '1227.184')]
[2026-02-02 14:59:54,720][187009] Saving new best policy, reward=1227.184!
[2026-02-02 14:59:59,593][187009] Fps is (10 sec: 3283.6, 60 sec: 3550.5, 300 sec: 3443.4). Total num frames: 4702208. Throughput: 0: 3402.7. Samples: 4704256. Policy #0 lag: (min: 9.0, avg: 12.0, max: 73.0)
[2026-02-02 14:59:59,594][187009] Avg episode reward: [(0, '1283.949')]
[2026-02-02 14:59:59,735][187009] Saving new best policy, reward=1283.949!
[2026-02-02 15:00:04,610][187009] Fps is (10 sec: 3267.0, 60 sec: 3427.3, 300 sec: 3442.4). Total num frames: 4718592. Throughput: 0: 3402.6. Samples: 4725248. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:00:04,610][187009] Avg episode reward: [(0, '1294.301')]
[2026-02-02 15:00:04,746][187009] Saving new best policy, reward=1294.301!
[2026-02-02 15:00:09,565][187009] Fps is (10 sec: 3286.1, 60 sec: 3291.0, 300 sec: 3443.0). Total num frames: 4734976. Throughput: 0: 3426.7. Samples: 4736000. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:00:09,565][187009] Avg episode reward: [(0, '1251.871')]
[2026-02-02 15:00:14,550][187009] Fps is (10 sec: 3296.4, 60 sec: 3279.7, 300 sec: 3443.8). Total num frames: 4751360. Throughput: 0: 3411.6. Samples: 4755968. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:00:14,550][187009] Avg episode reward: [(0, '1226.864')]
[2026-02-02 15:00:19,629][187009] Fps is (10 sec: 3256.0, 60 sec: 3276.2, 300 sec: 3442.9). Total num frames: 4767744. Throughput: 0: 3452.8. Samples: 4776960. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:00:19,629][187009] Avg episode reward: [(0, '1241.691')]
[2026-02-02 15:00:24,587][187009] Fps is (10 sec: 3264.8, 60 sec: 3277.0, 300 sec: 3444.2). Total num frames: 4784128. Throughput: 0: 3414.7. Samples: 4786688. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:00:24,587][187009] Avg episode reward: [(0, '1233.424')]
[2026-02-02 15:00:29,625][187009] Fps is (10 sec: 3278.2, 60 sec: 3271.5, 300 sec: 3442.9). Total num frames: 4800512. Throughput: 0: 3410.7. Samples: 4807680. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:00:29,625][187009] Avg episode reward: [(0, '1201.375')]
[2026-02-02 15:00:34,577][187009] Fps is (10 sec: 3280.1, 60 sec: 3275.4, 300 sec: 3442.9). Total num frames: 4816896. Throughput: 0: 3461.7. Samples: 4829184. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:00:34,577][187009] Avg episode reward: [(0, '1198.344')]
[2026-02-02 15:00:34,715][187009] Saving /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_accel_policy3_aggressive_magpie_refined_params_02022026_smooth_aggressive_ttc/checkpoint_p0/checkpoint_000018816_4816896.pth...
[2026-02-02 15:00:34,719][187009] Removing /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_accel_policy3_aggressive_magpie_refined_params_02022026_smooth_aggressive_ttc/checkpoint_p0/checkpoint_000015616_3997696.pth
[2026-02-02 15:00:39,584][187009] Fps is (10 sec: 3290.3, 60 sec: 3278.0, 300 sec: 3443.3). Total num frames: 4833280. Throughput: 0: 3424.4. Samples: 4838912. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:00:39,584][187009] Avg episode reward: [(0, '1209.086')]
[2026-02-02 15:00:44,571][187009] Fps is (10 sec: 3278.5, 60 sec: 3277.8, 300 sec: 3418.5). Total num frames: 4849664. Throughput: 0: 3460.5. Samples: 4859904. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:00:44,572][187009] Avg episode reward: [(0, '1260.439')]
[2026-02-02 15:00:49,690][187009] Fps is (10 sec: 4052.9, 60 sec: 3409.0, 300 sec: 3442.5). Total num frames: 4874240. Throughput: 0: 3452.7. Samples: 4880896. Policy #0 lag: (min: 11.0, avg: 14.0, max: 75.0)
[2026-02-02 15:00:49,690][187009] Avg episode reward: [(0, '1260.816')]
[2026-02-02 15:00:54,806][187009] Fps is (10 sec: 4802.3, 60 sec: 3536.5, 300 sec: 3443.0). Total num frames: 4898816. Throughput: 0: 3417.8. Samples: 4890624. Policy #0 lag: (min: 11.0, avg: 14.0, max: 75.0)
[2026-02-02 15:00:54,807][187009] Avg episode reward: [(0, '1257.372')]
[2026-02-02 15:00:59,598][187009] Fps is (10 sec: 4134.0, 60 sec: 3549.6, 300 sec: 3443.5). Total num frames: 4915200. Throughput: 0: 3455.1. Samples: 4911616. Policy #0 lag: (min: 10.0, avg: 13.0, max: 74.0)
[2026-02-02 15:00:59,599][187009] Avg episode reward: [(0, '1254.392')]
[2026-02-02 15:01:03,563][187009] Signal inference workers to stop experience collection... (900 times)
[2026-02-02 15:01:03,926][187009] InferenceWorker_p0-w0: stopping experience collection (900 times)
[2026-02-02 15:01:03,927][187009] Signal inference workers to resume experience collection... (900 times)
[2026-02-02 15:01:04,064][187009] InferenceWorker_p0-w0: resuming experience collection (900 times)
[2026-02-02 15:01:04,567][187009] Fps is (10 sec: 3357.1, 60 sec: 3552.4, 300 sec: 3443.1). Total num frames: 4931584. Throughput: 0: 3463.6. Samples: 4932608. Policy #0 lag: (min: 10.0, avg: 13.0, max: 74.0)
[2026-02-02 15:01:04,567][187009] Avg episode reward: [(0, '1245.497')]
[2026-02-02 15:01:09,638][187009] Fps is (10 sec: 3263.9, 60 sec: 3545.6, 300 sec: 3443.4). Total num frames: 4947968. Throughput: 0: 3454.9. Samples: 4942336. Policy #0 lag: (min: 10.0, avg: 13.0, max: 74.0)
[2026-02-02 15:01:09,638][187009] Avg episode reward: [(0, '1234.661')]
[2026-02-02 15:01:14,588][187009] Fps is (10 sec: 3270.1, 60 sec: 3547.6, 300 sec: 3444.0). Total num frames: 4964352. Throughput: 0: 3473.1. Samples: 4963840. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:01:14,588][187009] Avg episode reward: [(0, '1213.307')]
[2026-02-02 15:01:19,521][187009] Fps is (10 sec: 3315.5, 60 sec: 3556.3, 300 sec: 3444.4). Total num frames: 4980736. Throughput: 0: 3440.3. Samples: 4983808. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:01:19,521][187009] Avg episode reward: [(0, '1208.382')]
[2026-02-02 15:01:24,556][187009] Fps is (10 sec: 3287.3, 60 sec: 3551.7, 300 sec: 3444.3). Total num frames: 4997120. Throughput: 0: 3472.4. Samples: 4995072. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:01:24,556][187009] Avg episode reward: [(0, '1246.555')]
[2026-02-02 15:01:29,537][187009] Fps is (10 sec: 3271.7, 60 sec: 3555.1, 300 sec: 3444.1). Total num frames: 5013504. Throughput: 0: 3438.8. Samples: 5014528. Policy #0 lag: (min: 3.0, avg: 6.0, max: 67.0)
[2026-02-02 15:01:29,537][187009] Avg episode reward: [(0, '1230.614')]
[2026-02-02 15:01:34,553][187009] Fps is (10 sec: 3277.9, 60 sec: 3551.3, 300 sec: 3444.2). Total num frames: 5029888. Throughput: 0: 3446.6. Samples: 5035520. Policy #0 lag: (min: 3.0, avg: 6.0, max: 67.0)
[2026-02-02 15:01:34,553][187009] Avg episode reward: [(0, '1245.688')]
[2026-02-02 15:01:39,607][187009] Fps is (10 sec: 3253.8, 60 sec: 3548.5, 300 sec: 3443.7). Total num frames: 5046272. Throughput: 0: 3497.1. Samples: 5047296. Policy #0 lag: (min: 3.0, avg: 6.0, max: 67.0)
[2026-02-02 15:01:39,608][187009] Avg episode reward: [(0, '1193.514')]
[2026-02-02 15:01:44,554][187009] Fps is (10 sec: 3276.4, 60 sec: 3550.9, 300 sec: 3443.7). Total num frames: 5062656. Throughput: 0: 3462.3. Samples: 5067264. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:01:44,554][187009] Avg episode reward: [(0, '1246.242')]
[2026-02-02 15:01:49,607][187009] Fps is (10 sec: 3276.9, 60 sec: 3418.1, 300 sec: 3443.4). Total num frames: 5079040. Throughput: 0: 3467.2. Samples: 5088768. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:01:49,607][187009] Avg episode reward: [(0, '1269.072')]
[2026-02-02 15:01:54,572][187009] Fps is (10 sec: 3270.8, 60 sec: 3289.7, 300 sec: 3444.2). Total num frames: 5095424. Throughput: 0: 3475.3. Samples: 5098496. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:01:54,572][187009] Avg episode reward: [(0, '1301.643')]
[2026-02-02 15:01:54,704][187009] Saving new best policy, reward=1301.643!
[2026-02-02 15:01:59,527][187009] Fps is (10 sec: 3303.2, 60 sec: 3280.7, 300 sec: 3443.5). Total num frames: 5111808. Throughput: 0: 3474.9. Samples: 5120000. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:01:59,527][187009] Avg episode reward: [(0, '1305.620')]
[2026-02-02 15:01:59,659][187009] Saving new best policy, reward=1305.620!
[2026-02-02 15:02:04,640][187009] Fps is (10 sec: 3254.8, 60 sec: 3272.9, 300 sec: 3443.3). Total num frames: 5128192. Throughput: 0: 3495.1. Samples: 5141504. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:02:04,640][187009] Avg episode reward: [(0, '1271.086')]
[2026-02-02 15:02:09,827][187009] Fps is (10 sec: 3976.5, 60 sec: 3402.6, 300 sec: 3468.1). Total num frames: 5152768. Throughput: 0: 3449.4. Samples: 5151232. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:02:09,828][187009] Avg episode reward: [(0, '1303.580')]
[2026-02-02 15:02:14,854][187009] Fps is (10 sec: 4811.8, 60 sec: 3534.2, 300 sec: 3495.3). Total num frames: 5177344. Throughput: 0: 3491.1. Samples: 5172736. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:02:14,855][187009] Avg episode reward: [(0, '1329.270')]
[2026-02-02 15:02:14,856][187009] Saving new best policy, reward=1329.270!
[2026-02-02 15:02:19,135][187009] Signal inference workers to stop experience collection... (950 times)
[2026-02-02 15:02:19,481][187009] InferenceWorker_p0-w0: stopping experience collection (950 times)
[2026-02-02 15:02:19,481][187009] Signal inference workers to resume experience collection... (950 times)
[2026-02-02 15:02:19,482][187009] InferenceWorker_p0-w0: resuming experience collection (950 times)
[2026-02-02 15:02:19,607][187009] Fps is (10 sec: 4188.4, 60 sec: 3544.8, 300 sec: 3498.6). Total num frames: 5193728. Throughput: 0: 3522.9. Samples: 5194240. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:02:19,607][187009] Avg episode reward: [(0, '1356.689')]
[2026-02-02 15:02:19,747][187009] Saving new best policy, reward=1356.689!
[2026-02-02 15:02:24,641][187009] Fps is (10 sec: 3348.2, 60 sec: 3544.8, 300 sec: 3501.7). Total num frames: 5210112. Throughput: 0: 3490.4. Samples: 5204480. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:02:24,641][187009] Avg episode reward: [(0, '1297.184')]
[2026-02-02 15:02:29,542][187009] Fps is (10 sec: 3298.2, 60 sec: 3549.6, 300 sec: 3472.3). Total num frames: 5226496. Throughput: 0: 3528.0. Samples: 5225984. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:02:29,578][187009] Avg episode reward: [(0, '1283.974')]
[2026-02-02 15:02:34,611][187009] Fps is (10 sec: 3286.6, 60 sec: 3546.4, 300 sec: 3445.6). Total num frames: 5242880. Throughput: 0: 3492.6. Samples: 5245952. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:02:34,611][187009] Avg episode reward: [(0, '1282.958')]
[2026-02-02 15:02:34,759][187009] Saving /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_accel_policy3_aggressive_magpie_refined_params_02022026_smooth_aggressive_ttc/checkpoint_p0/checkpoint_000020480_5242880.pth...
[2026-02-02 15:02:34,763][187009] Removing /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_accel_policy3_aggressive_magpie_refined_params_02022026_smooth_aggressive_ttc/checkpoint_p0/checkpoint_000017216_4407296.pth
[2026-02-02 15:02:39,569][187009] Fps is (10 sec: 3268.0, 60 sec: 3552.1, 300 sec: 3443.7). Total num frames: 5259264. Throughput: 0: 3527.4. Samples: 5257216. Policy #0 lag: (min: 6.0, avg: 9.0, max: 70.0)
[2026-02-02 15:02:39,569][187009] Avg episode reward: [(0, '1279.748')]
[2026-02-02 15:02:44,640][187009] Fps is (10 sec: 3267.4, 60 sec: 3544.8, 300 sec: 3443.0). Total num frames: 5275648. Throughput: 0: 3472.9. Samples: 5276672. Policy #0 lag: (min: 6.0, avg: 9.0, max: 70.0)
[2026-02-02 15:02:44,640][187009] Avg episode reward: [(0, '1276.321')]
[2026-02-02 15:02:49,533][187009] Fps is (10 sec: 3288.5, 60 sec: 3554.2, 300 sec: 3443.3). Total num frames: 5292032. Throughput: 0: 3501.2. Samples: 5298688. Policy #0 lag: (min: 6.0, avg: 9.0, max: 70.0)
[2026-02-02 15:02:49,533][187009] Avg episode reward: [(0, '1292.768')]
[2026-02-02 15:02:54,583][187009] Fps is (10 sec: 3295.4, 60 sec: 3549.2, 300 sec: 3443.7). Total num frames: 5308416. Throughput: 0: 3534.9. Samples: 5309440. Policy #0 lag: (min: 31.0, avg: 34.0, max: 95.0)
[2026-02-02 15:02:54,584][187009] Avg episode reward: [(0, '1344.260')]
[2026-02-02 15:02:59,648][187009] Fps is (10 sec: 3239.6, 60 sec: 3542.7, 300 sec: 3442.9). Total num frames: 5324800. Throughput: 0: 3520.5. Samples: 5330432. Policy #0 lag: (min: 31.0, avg: 34.0, max: 95.0)
[2026-02-02 15:02:59,648][187009] Avg episode reward: [(0, '1382.617')]
[2026-02-02 15:02:59,780][187009] Saving new best policy, reward=1382.617!
[2026-02-02 15:03:04,629][187009] Fps is (10 sec: 3262.0, 60 sec: 3550.5, 300 sec: 3443.4). Total num frames: 5341184. Throughput: 0: 3502.6. Samples: 5351936. Policy #0 lag: (min: 31.0, avg: 34.0, max: 95.0)
[2026-02-02 15:03:04,629][187009] Avg episode reward: [(0, '1336.654')]
[2026-02-02 15:03:09,623][187009] Fps is (10 sec: 3285.1, 60 sec: 3425.0, 300 sec: 3442.3). Total num frames: 5357568. Throughput: 0: 3494.4. Samples: 5361664. Policy #0 lag: (min: 47.0, avg: 50.0, max: 111.0)
[2026-02-02 15:03:09,623][187009] Avg episode reward: [(0, '1321.358')]
[2026-02-02 15:03:14,574][187009] Fps is (10 sec: 3295.0, 60 sec: 3292.2, 300 sec: 3443.9). Total num frames: 5373952. Throughput: 0: 3501.9. Samples: 5383680. Policy #0 lag: (min: 47.0, avg: 50.0, max: 111.0)
[2026-02-02 15:03:14,574][187009] Avg episode reward: [(0, '1317.544')]
[2026-02-02 15:03:19,829][187009] Fps is (10 sec: 4013.1, 60 sec: 3400.7, 300 sec: 3468.5). Total num frames: 5398528. Throughput: 0: 3510.1. Samples: 5404672. Policy #0 lag: (min: 47.0, avg: 50.0, max: 111.0)
[2026-02-02 15:03:19,830][187009] Avg episode reward: [(0, '1361.719')]
[2026-02-02 15:03:24,840][187009] Fps is (10 sec: 4787.6, 60 sec: 3538.1, 300 sec: 3496.4). Total num frames: 5423104. Throughput: 0: 3472.0. Samples: 5414400. Policy #0 lag: (min: 7.0, avg: 10.0, max: 71.0)
[2026-02-02 15:03:24,840][187009] Avg episode reward: [(0, '1374.060')]
[2026-02-02 15:03:29,622][187009] Fps is (10 sec: 4182.6, 60 sec: 3545.1, 300 sec: 3498.4). Total num frames: 5439488. Throughput: 0: 3539.9. Samples: 5435904. Policy #0 lag: (min: 7.0, avg: 10.0, max: 71.0)
[2026-02-02 15:03:29,623][187009] Avg episode reward: [(0, '1355.025')]
[2026-02-02 15:03:34,606][187009] Fps is (10 sec: 3355.3, 60 sec: 3550.2, 300 sec: 3498.0). Total num frames: 5455872. Throughput: 0: 3510.0. Samples: 5456896. Policy #0 lag: (min: 7.0, avg: 10.0, max: 71.0)
[2026-02-02 15:03:34,606][187009] Avg episode reward: [(0, '1312.416')]
[2026-02-02 15:03:38,534][187009] Signal inference workers to stop experience collection... (1000 times)
[2026-02-02 15:03:38,534][187009] Signal inference workers to resume experience collection... (1000 times)
[2026-02-02 15:03:38,766][187009] InferenceWorker_p0-w0: stopping experience collection (1000 times)
[2026-02-02 15:03:38,766][187009] InferenceWorker_p0-w0: resuming experience collection (1000 times)
[2026-02-02 15:03:39,528][187009] Fps is (10 sec: 3307.9, 60 sec: 3552.3, 300 sec: 3499.9). Total num frames: 5472256. Throughput: 0: 3520.1. Samples: 5467648. Policy #0 lag: (min: 63.0, avg: 66.0, max: 127.0)
[2026-02-02 15:03:39,528][187009] Avg episode reward: [(0, '1263.999')]
[2026-02-02 15:03:44,562][187009] Fps is (10 sec: 3291.3, 60 sec: 3554.5, 300 sec: 3499.3). Total num frames: 5488640. Throughput: 0: 3533.9. Samples: 5489152. Policy #0 lag: (min: 63.0, avg: 66.0, max: 127.0)
[2026-02-02 15:03:44,562][187009] Avg episode reward: [(0, '1285.762')]
[2026-02-02 15:03:49,602][187009] Fps is (10 sec: 3252.8, 60 sec: 3545.8, 300 sec: 3498.1). Total num frames: 5505024. Throughput: 0: 3495.1. Samples: 5509120. Policy #0 lag: (min: 63.0, avg: 66.0, max: 127.0)
[2026-02-02 15:03:49,602][187009] Avg episode reward: [(0, '1328.714')]
[2026-02-02 15:03:54,553][187009] Fps is (10 sec: 3279.9, 60 sec: 3551.7, 300 sec: 3499.6). Total num frames: 5521408. Throughput: 0: 3544.0. Samples: 5520896. Policy #0 lag: (min: 63.0, avg: 66.0, max: 127.0)
[2026-02-02 15:03:54,553][187009] Avg episode reward: [(0, '1366.091')]
[2026-02-02 15:03:59,597][187009] Fps is (10 sec: 3278.5, 60 sec: 3552.9, 300 sec: 3474.2). Total num frames: 5537792. Throughput: 0: 3479.8. Samples: 5540352. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:03:59,597][187009] Avg episode reward: [(0, '1370.250')]
[2026-02-02 15:04:04,576][187009] Fps is (10 sec: 3269.1, 60 sec: 3553.0, 300 sec: 3446.3). Total num frames: 5554176. Throughput: 0: 3512.7. Samples: 5561856. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:04:04,576][187009] Avg episode reward: [(0, '1261.707')]
[2026-02-02 15:04:09,529][187009] Fps is (10 sec: 3299.2, 60 sec: 3555.4, 300 sec: 3444.3). Total num frames: 5570560. Throughput: 0: 3517.3. Samples: 5571584. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:04:09,529][187009] Avg episode reward: [(0, '1226.168')]
[2026-02-02 15:04:14,580][187009] Fps is (10 sec: 3275.5, 60 sec: 3549.5, 300 sec: 3443.9). Total num frames: 5586944. Throughput: 0: 3496.3. Samples: 5593088. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:04:14,580][187009] Avg episode reward: [(0, '1204.451')]
[2026-02-02 15:04:19,549][187009] Fps is (10 sec: 3270.3, 60 sec: 3429.4, 300 sec: 3443.9). Total num frames: 5603328. Throughput: 0: 3508.8. Samples: 5614592. Policy #0 lag: (min: 14.0, avg: 17.0, max: 78.0)
[2026-02-02 15:04:19,549][187009] Avg episode reward: [(0, '1299.704')]
[2026-02-02 15:04:24,553][187009] Fps is (10 sec: 3285.8, 60 sec: 3292.6, 300 sec: 3443.1). Total num frames: 5619712. Throughput: 0: 3491.1. Samples: 5624832. Policy #0 lag: (min: 14.0, avg: 17.0, max: 78.0)
[2026-02-02 15:04:24,553][187009] Avg episode reward: [(0, '1331.848')]
[2026-02-02 15:04:29,614][187009] Fps is (10 sec: 3255.6, 60 sec: 3277.3, 300 sec: 3442.7). Total num frames: 5636096. Throughput: 0: 3477.6. Samples: 5645824. Policy #0 lag: (min: 14.0, avg: 17.0, max: 78.0)
[2026-02-02 15:04:29,614][187009] Avg episode reward: [(0, '1348.278')]
[2026-02-02 15:04:34,646][187009] Fps is (10 sec: 4058.3, 60 sec: 3411.1, 300 sec: 3470.7). Total num frames: 5660672. Throughput: 0: 3512.3. Samples: 5667328. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:04:34,646][187009] Avg episode reward: [(0, '1372.258')]
[2026-02-02 15:04:35,000][187009] Saving /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_accel_policy3_aggressive_magpie_refined_params_02022026_smooth_aggressive_ttc/checkpoint_p0/checkpoint_000022144_5668864.pth...
[2026-02-02 15:04:35,004][187009] Removing /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_accel_policy3_aggressive_magpie_refined_params_02022026_smooth_aggressive_ttc/checkpoint_p0/checkpoint_000018816_4816896.pth
[2026-02-02 15:04:39,674][187009] Fps is (10 sec: 4885.8, 60 sec: 3541.3, 300 sec: 3498.0). Total num frames: 5685248. Throughput: 0: 3460.9. Samples: 5677056. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:04:39,674][187009] Avg episode reward: [(0, '1352.602')]
[2026-02-02 15:04:44,622][187009] Fps is (10 sec: 4105.9, 60 sec: 3546.4, 300 sec: 3498.9). Total num frames: 5701632. Throughput: 0: 3513.8. Samples: 5698560. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:04:44,622][187009] Avg episode reward: [(0, '1415.007')]
[2026-02-02 15:04:44,757][187009] Saving new best policy, reward=1415.007!
[2026-02-02 15:04:49,557][187009] Fps is (10 sec: 3315.4, 60 sec: 3552.5, 300 sec: 3499.2). Total num frames: 5718016. Throughput: 0: 3494.4. Samples: 5719040. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:04:49,558][187009] Avg episode reward: [(0, '1380.074')]
[2026-02-02 15:04:54,598][187009] Fps is (10 sec: 3284.5, 60 sec: 3547.2, 300 sec: 3498.9). Total num frames: 5734400. Throughput: 0: 3521.7. Samples: 5730304. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:04:54,598][187009] Avg episode reward: [(0, '1445.632')]
[2026-02-02 15:04:54,737][187009] Saving new best policy, reward=1445.632!
[2026-02-02 15:04:57,693][187009] Signal inference workers to stop experience collection... (1050 times)
[2026-02-02 15:04:58,060][187009] InferenceWorker_p0-w0: stopping experience collection (1050 times)
[2026-02-02 15:04:58,062][187009] Signal inference workers to resume experience collection... (1050 times)
[2026-02-02 15:04:58,194][187009] InferenceWorker_p0-w0: resuming experience collection (1050 times)
[2026-02-02 15:04:59,609][187009] Fps is (10 sec: 3260.1, 60 sec: 3549.2, 300 sec: 3499.0). Total num frames: 5750784. Throughput: 0: 3524.9. Samples: 5751808. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:04:59,609][187009] Avg episode reward: [(0, '1424.504')]
[2026-02-02 15:05:04,532][187009] Fps is (10 sec: 3298.6, 60 sec: 3552.5, 300 sec: 3499.4). Total num frames: 5767168. Throughput: 0: 3471.5. Samples: 5770752. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:05:04,532][187009] Avg episode reward: [(0, '1444.669')]
[2026-02-02 15:05:09,550][187009] Fps is (10 sec: 3296.0, 60 sec: 3548.6, 300 sec: 3499.0). Total num frames: 5783552. Throughput: 0: 3504.5. Samples: 5782528. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:05:09,551][187009] Avg episode reward: [(0, '1391.642')]
[2026-02-02 15:05:14,608][187009] Fps is (10 sec: 3252.0, 60 sec: 3548.2, 300 sec: 3499.2). Total num frames: 5799936. Throughput: 0: 3470.6. Samples: 5801984. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:05:14,608][187009] Avg episode reward: [(0, '1395.377')]
[2026-02-02 15:05:19,606][187009] Fps is (10 sec: 3258.8, 60 sec: 3546.5, 300 sec: 3498.7). Total num frames: 5816320. Throughput: 0: 3461.9. Samples: 5822976. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:05:19,606][187009] Avg episode reward: [(0, '1302.128')]
[2026-02-02 15:05:24,526][187009] Fps is (10 sec: 3304.1, 60 sec: 3551.5, 300 sec: 3500.1). Total num frames: 5832704. Throughput: 0: 3493.1. Samples: 5833728. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:05:24,526][187009] Avg episode reward: [(0, '1301.194')]
[2026-02-02 15:05:29,599][187009] Fps is (10 sec: 3278.9, 60 sec: 3550.7, 300 sec: 3498.7). Total num frames: 5849088. Throughput: 0: 3449.2. Samples: 5853696. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:05:29,607][187009] Avg episode reward: [(0, '1313.517')]
[2026-02-02 15:05:34,586][187009] Fps is (10 sec: 3257.2, 60 sec: 3416.7, 300 sec: 3498.9). Total num frames: 5865472. Throughput: 0: 3445.3. Samples: 5874176. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:05:34,586][187009] Avg episode reward: [(0, '1372.655')]
[2026-02-02 15:05:39,530][187009] Fps is (10 sec: 3299.7, 60 sec: 3284.7, 300 sec: 3499.5). Total num frames: 5881856. Throughput: 0: 3418.5. Samples: 5883904. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:05:39,530][187009] Avg episode reward: [(0, '1413.835')]
[2026-02-02 15:05:44,602][187009] Fps is (10 sec: 3271.6, 60 sec: 3277.9, 300 sec: 3472.2). Total num frames: 5898240. Throughput: 0: 3402.5. Samples: 5904896. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:05:44,602][187009] Avg episode reward: [(0, '1419.017')]
[2026-02-02 15:05:49,560][187009] Fps is (10 sec: 3266.8, 60 sec: 3276.6, 300 sec: 3446.3). Total num frames: 5914624. Throughput: 0: 3445.3. Samples: 5925888. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:05:49,561][187009] Avg episode reward: [(0, '1374.736')]
[2026-02-02 15:05:54,562][187009] Fps is (10 sec: 3290.0, 60 sec: 3278.8, 300 sec: 3443.8). Total num frames: 5931008. Throughput: 0: 3401.1. Samples: 5935616. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:05:54,562][187009] Avg episode reward: [(0, '1386.041')]
[2026-02-02 15:05:59,616][187009] Fps is (10 sec: 3258.6, 60 sec: 3276.4, 300 sec: 3442.8). Total num frames: 5947392. Throughput: 0: 3446.9. Samples: 5957120. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:05:59,616][187009] Avg episode reward: [(0, '1339.656')]
[2026-02-02 15:06:04,525][187009] Fps is (10 sec: 3288.8, 60 sec: 3277.2, 300 sec: 3444.7). Total num frames: 5963776. Throughput: 0: 3453.6. Samples: 5978112. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:06:04,526][187009] Avg episode reward: [(0, '1337.250')]
[2026-02-02 15:06:09,603][187009] Fps is (10 sec: 4101.4, 60 sec: 3410.3, 300 sec: 3471.0). Total num frames: 5988352. Throughput: 0: 3418.8. Samples: 5987840. Policy #0 lag: (min: 9.0, avg: 12.0, max: 73.0)
[2026-02-02 15:06:09,608][187009] Avg episode reward: [(0, '1344.517')]
[2026-02-02 15:06:14,423][187009] Signal inference workers to stop experience collection... (1100 times)
[2026-02-02 15:06:14,786][187009] InferenceWorker_p0-w0: stopping experience collection (1100 times)
[2026-02-02 15:06:14,786][187009] Signal inference workers to resume experience collection... (1100 times)
[2026-02-02 15:06:14,786][187009] Fps is (10 sec: 4790.2, 60 sec: 3539.4, 300 sec: 3495.8). Total num frames: 6012928. Throughput: 0: 3433.2. Samples: 6008832. Policy #0 lag: (min: 9.0, avg: 12.0, max: 73.0)
[2026-02-02 15:06:14,786][187009] Avg episode reward: [(0, '1426.126')]
[2026-02-02 15:06:14,788][187009] InferenceWorker_p0-w0: resuming experience collection (1100 times)
[2026-02-02 15:06:19,564][187009] Fps is (10 sec: 4112.1, 60 sec: 3552.3, 300 sec: 3498.9). Total num frames: 6029312. Throughput: 0: 3460.5. Samples: 6029824. Policy #0 lag: (min: 9.0, avg: 12.0, max: 73.0)
[2026-02-02 15:06:19,564][187009] Avg episode reward: [(0, '1444.110')]
[2026-02-02 15:06:24,596][187009] Fps is (10 sec: 3340.4, 60 sec: 3545.7, 300 sec: 3498.3). Total num frames: 6045696. Throughput: 0: 3453.8. Samples: 6039552. Policy #0 lag: (min: 9.0, avg: 12.0, max: 73.0)
[2026-02-02 15:06:24,596][187009] Avg episode reward: [(0, '1407.958')]
[2026-02-02 15:06:29,570][187009] Fps is (10 sec: 3275.0, 60 sec: 3551.6, 300 sec: 3498.8). Total num frames: 6062080. Throughput: 0: 3449.9. Samples: 6060032. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:06:29,570][187009] Avg episode reward: [(0, '1393.766')]
[2026-02-02 15:06:34,663][187009] Fps is (10 sec: 3254.8, 60 sec: 3545.3, 300 sec: 3498.3). Total num frames: 6078464. Throughput: 0: 3405.5. Samples: 6079488. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:06:34,664][187009] Avg episode reward: [(0, '1427.332')]
[2026-02-02 15:06:34,829][187009] Saving /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_accel_policy3_aggressive_magpie_refined_params_02022026_smooth_aggressive_ttc/checkpoint_p0/checkpoint_000023744_6078464.pth...
[2026-02-02 15:06:34,833][187009] Removing /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_accel_policy3_aggressive_magpie_refined_params_02022026_smooth_aggressive_ttc/checkpoint_p0/checkpoint_000020480_5242880.pth
[2026-02-02 15:06:39,672][187009] Fps is (10 sec: 3243.7, 60 sec: 3541.5, 300 sec: 3497.6). Total num frames: 6094848. Throughput: 0: 3416.4. Samples: 6089728. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:06:39,672][187009] Avg episode reward: [(0, '1440.039')]
[2026-02-02 15:06:44,859][187009] Fps is (10 sec: 3213.9, 60 sec: 3534.7, 300 sec: 3496.0). Total num frames: 6111232. Throughput: 0: 3327.1. Samples: 6107648. Policy #0 lag: (min: 32.0, avg: 35.0, max: 96.0)
[2026-02-02 15:06:44,859][187009] Avg episode reward: [(0, '1422.992')]
[2026-02-02 15:06:49,638][187009] Fps is (10 sec: 1644.0, 60 sec: 3272.6, 300 sec: 3442.7). Total num frames: 6111232. Throughput: 0: 3268.6. Samples: 6125568. Policy #0 lag: (min: 32.0, avg: 35.0, max: 96.0)
[2026-02-02 15:06:49,638][187009] Avg episode reward: [(0, '1424.991')]
[2026-02-02 15:06:54,588][187009] Fps is (10 sec: 1684.1, 60 sec: 3275.4, 300 sec: 3442.7). Total num frames: 6127616. Throughput: 0: 3243.8. Samples: 6133760. Policy #0 lag: (min: 32.0, avg: 35.0, max: 96.0)
[2026-02-02 15:06:54,588][187009] Avg episode reward: [(0, '1386.965')]
[2026-02-02 15:06:59,594][187009] Fps is (10 sec: 3291.1, 60 sec: 3278.0, 300 sec: 3443.9). Total num frames: 6144000. Throughput: 0: 3188.0. Samples: 6151680. Policy #0 lag: (min: 32.0, avg: 35.0, max: 96.0)
[2026-02-02 15:06:59,594][187009] Avg episode reward: [(0, '1417.833')]
[2026-02-02 15:07:04,572][187009] Fps is (10 sec: 3282.0, 60 sec: 3274.2, 300 sec: 3418.6). Total num frames: 6160384. Throughput: 0: 3105.6. Samples: 6169600. Policy #0 lag: (min: 12.0, avg: 15.0, max: 76.0)
[2026-02-02 15:07:04,572][187009] Avg episode reward: [(0, '1371.699')]
[2026-02-02 15:07:09,572][187009] Fps is (10 sec: 3284.0, 60 sec: 3141.9, 300 sec: 3391.1). Total num frames: 6176768. Throughput: 0: 3073.6. Samples: 6177792. Policy #0 lag: (min: 12.0, avg: 15.0, max: 76.0)
[2026-02-02 15:07:09,573][187009] Avg episode reward: [(0, '1454.106')]
[2026-02-02 15:07:09,733][187009] Saving new best policy, reward=1454.106!
[2026-02-02 15:07:14,557][187009] Fps is (10 sec: 3281.6, 60 sec: 3015.2, 300 sec: 3388.4). Total num frames: 6193152. Throughput: 0: 3027.3. Samples: 6196224. Policy #0 lag: (min: 12.0, avg: 15.0, max: 76.0)
[2026-02-02 15:07:14,558][187009] Avg episode reward: [(0, '1451.604')]
[2026-02-02 15:07:19,653][187009] Fps is (10 sec: 3250.5, 60 sec: 2999.3, 300 sec: 3387.7). Total num frames: 6209536. Throughput: 0: 3004.4. Samples: 6214656. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:07:19,654][187009] Avg episode reward: [(0, '1462.046')]
[2026-02-02 15:07:19,814][187009] Saving new best policy, reward=1462.046!
[2026-02-02 15:07:24,664][187009] Fps is (10 sec: 3242.2, 60 sec: 3000.3, 300 sec: 3386.5). Total num frames: 6225920. Throughput: 0: 2992.9. Samples: 6224384. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:07:24,664][187009] Avg episode reward: [(0, '1471.435')]
[2026-02-02 15:07:24,822][187009] Saving new best policy, reward=1471.435!
[2026-02-02 15:07:29,611][187009] Fps is (10 sec: 3290.8, 60 sec: 3001.7, 300 sec: 3387.9). Total num frames: 6242304. Throughput: 0: 3009.0. Samples: 6242304. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:07:29,611][187009] Avg episode reward: [(0, '1494.007')]
[2026-02-02 15:07:29,760][187009] Saving new best policy, reward=1494.007!
[2026-02-02 15:07:34,523][187009] Fps is (10 sec: 3323.6, 60 sec: 3010.8, 300 sec: 3388.4). Total num frames: 6258688. Throughput: 0: 2988.6. Samples: 6259712. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:07:34,524][187009] Avg episode reward: [(0, '1544.160')]
[2026-02-02 15:07:34,690][187009] Saving new best policy, reward=1544.160!
[2026-02-02 15:07:39,541][187009] Fps is (10 sec: 3299.8, 60 sec: 3010.3, 300 sec: 3389.0). Total num frames: 6275072. Throughput: 0: 3006.9. Samples: 6268928. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:07:39,541][187009] Avg episode reward: [(0, '1506.186')]
[2026-02-02 15:07:44,560][187009] Signal inference workers to stop experience collection... (1150 times)
[2026-02-02 15:07:44,560][187009] Signal inference workers to resume experience collection... (1150 times)
[2026-02-02 15:07:44,560][187009] Fps is (10 sec: 2448.6, 60 sec: 2881.6, 300 sec: 3359.8). Total num frames: 6283264. Throughput: 0: 3017.4. Samples: 6287360. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:07:44,560][187009] Avg episode reward: [(0, '1508.886')]
[2026-02-02 15:07:44,834][187009] InferenceWorker_p0-w0: stopping experience collection (1150 times)
[2026-02-02 15:07:44,834][187009] InferenceWorker_p0-w0: resuming experience collection (1150 times)
[2026-02-02 15:07:49,525][187009] Fps is (10 sec: 1641.0, 60 sec: 3009.4, 300 sec: 3333.0). Total num frames: 6291456. Throughput: 0: 2995.5. Samples: 6304256. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:07:49,525][187009] Avg episode reward: [(0, '1452.197')]
[2026-02-02 15:07:54,556][187009] Fps is (10 sec: 2458.5, 60 sec: 3005.3, 300 sec: 3333.4). Total num frames: 6307840. Throughput: 0: 3004.8. Samples: 6312960. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:07:54,557][187009] Avg episode reward: [(0, '1470.906')]
[2026-02-02 15:07:59,560][187009] Fps is (10 sec: 3265.6, 60 sec: 3005.5, 300 sec: 3333.1). Total num frames: 6324224. Throughput: 0: 2992.2. Samples: 6330880. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:07:59,560][187009] Avg episode reward: [(0, '1451.199')]
[2026-02-02 15:08:04,522][187009] Fps is (10 sec: 3288.0, 60 sec: 3006.2, 300 sec: 3333.5). Total num frames: 6340608. Throughput: 0: 2978.3. Samples: 6348288. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:08:04,522][187009] Avg episode reward: [(0, '1433.284')]
[2026-02-02 15:08:09,559][187009] Fps is (10 sec: 3276.9, 60 sec: 3004.4, 300 sec: 3332.5). Total num frames: 6356992. Throughput: 0: 2976.5. Samples: 6358016. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:08:09,560][187009] Avg episode reward: [(0, '1359.151')]
[2026-02-02 15:08:14,653][187009] Fps is (10 sec: 3234.5, 60 sec: 2998.9, 300 sec: 3306.5). Total num frames: 6373376. Throughput: 0: 2932.7. Samples: 6374400. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:08:14,653][187009] Avg episode reward: [(0, '1375.921')]
[2026-02-02 15:08:19,653][187009] Fps is (10 sec: 3246.5, 60 sec: 3003.8, 300 sec: 3278.9). Total num frames: 6389760. Throughput: 0: 2961.1. Samples: 6393344. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:08:19,653][187009] Avg episode reward: [(0, '1443.699')]
[2026-02-02 15:08:24,669][187009] Fps is (10 sec: 3271.6, 60 sec: 3003.5, 300 sec: 3276.3). Total num frames: 6406144. Throughput: 0: 2972.5. Samples: 6403072. Policy #0 lag: (min: 35.0, avg: 38.0, max: 99.0)
[2026-02-02 15:08:24,669][187009] Avg episode reward: [(0, '1531.819')]
[2026-02-02 15:08:29,667][187009] Fps is (10 sec: 3272.1, 60 sec: 3000.9, 300 sec: 3276.1). Total num frames: 6422528. Throughput: 0: 2962.6. Samples: 6420992. Policy #0 lag: (min: 35.0, avg: 38.0, max: 99.0)
[2026-02-02 15:08:29,667][187009] Avg episode reward: [(0, '1539.751')]
[2026-02-02 15:08:34,645][187009] Fps is (10 sec: 3284.5, 60 sec: 2997.6, 300 sec: 3275.5). Total num frames: 6438912. Throughput: 0: 2984.4. Samples: 6438912. Policy #0 lag: (min: 35.0, avg: 38.0, max: 99.0)
[2026-02-02 15:08:34,646][187009] Avg episode reward: [(0, '1520.023')]
[2026-02-02 15:08:34,647][187009] Saving /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_accel_policy3_aggressive_magpie_refined_params_02022026_smooth_aggressive_ttc/checkpoint_p0/checkpoint_000025152_6438912.pth...
[2026-02-02 15:08:34,651][187009] Removing /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_accel_policy3_aggressive_magpie_refined_params_02022026_smooth_aggressive_ttc/checkpoint_p0/checkpoint_000022144_5668864.pth
[2026-02-02 15:08:39,714][187009] Fps is (10 sec: 2446.2, 60 sec: 2859.0, 300 sec: 3247.4). Total num frames: 6447104. Throughput: 0: 2981.9. Samples: 6447616. Policy #0 lag: (min: 35.0, avg: 38.0, max: 99.0)
[2026-02-02 15:08:39,714][187009] Avg episode reward: [(0, '1463.764')]
[2026-02-02 15:08:44,553][187009] Fps is (10 sec: 1653.6, 60 sec: 2867.5, 300 sec: 3221.8). Total num frames: 6455296. Throughput: 0: 2992.8. Samples: 6465536. Policy #0 lag: (min: 35.0, avg: 38.0, max: 99.0)
[2026-02-02 15:08:44,554][187009] Avg episode reward: [(0, '1477.975')]
[2026-02-02 15:08:49,592][187009] Fps is (10 sec: 2487.8, 60 sec: 3000.4, 300 sec: 3220.8). Total num frames: 6471680. Throughput: 0: 3033.2. Samples: 6484992. Policy #0 lag: (min: 7.0, avg: 10.0, max: 71.0)
[2026-02-02 15:08:49,592][187009] Avg episode reward: [(0, '1479.410')]
[2026-02-02 15:08:54,757][187009] Fps is (10 sec: 4014.2, 60 sec: 3129.8, 300 sec: 3247.3). Total num frames: 6496256. Throughput: 0: 3024.6. Samples: 6494720. Policy #0 lag: (min: 7.0, avg: 10.0, max: 71.0)
[2026-02-02 15:08:54,757][187009] Avg episode reward: [(0, '1423.939')]
[2026-02-02 15:08:59,795][187009] Fps is (10 sec: 4817.3, 60 sec: 3264.0, 300 sec: 3274.4). Total num frames: 6520832. Throughput: 0: 3141.7. Samples: 6516224. Policy #0 lag: (min: 7.0, avg: 10.0, max: 71.0)
[2026-02-02 15:08:59,796][187009] Avg episode reward: [(0, '1415.426')]
[2026-02-02 15:09:04,515][187009] Fps is (10 sec: 4197.7, 60 sec: 3277.2, 300 sec: 3277.0). Total num frames: 6537216. Throughput: 0: 3218.4. Samples: 6537728. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:09:04,515][187009] Avg episode reward: [(0, '1435.803')]
[2026-02-02 15:09:09,647][187009] Fps is (10 sec: 3326.1, 60 sec: 3272.0, 300 sec: 3276.1). Total num frames: 6553600. Throughput: 0: 3210.1. Samples: 6547456. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:09:09,648][187009] Avg episode reward: [(0, '1448.983')]
[2026-02-02 15:09:13,266][187009] Signal inference workers to stop experience collection... (1200 times)
[2026-02-02 15:09:13,629][187009] InferenceWorker_p0-w0: stopping experience collection (1200 times)
[2026-02-02 15:09:13,631][187009] Signal inference workers to resume experience collection... (1200 times)
[2026-02-02 15:09:13,764][187009] InferenceWorker_p0-w0: resuming experience collection (1200 times)
[2026-02-02 15:09:14,548][187009] Fps is (10 sec: 3265.9, 60 sec: 3282.5, 300 sec: 3276.8). Total num frames: 6569984. Throughput: 0: 3296.9. Samples: 6568960. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:09:14,549][187009] Avg episode reward: [(0, '1451.914')]
[2026-02-02 15:09:19,597][187009] Fps is (10 sec: 3293.3, 60 sec: 3279.8, 300 sec: 3276.3). Total num frames: 6586368. Throughput: 0: 3303.1. Samples: 6587392. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:09:19,597][187009] Avg episode reward: [(0, '1438.657')]
[2026-02-02 15:09:24,591][187009] Fps is (10 sec: 3263.0, 60 sec: 3281.1, 300 sec: 3277.1). Total num frames: 6602752. Throughput: 0: 3377.0. Samples: 6599168. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:09:24,591][187009] Avg episode reward: [(0, '1411.190')]
[2026-02-02 15:09:29,612][187009] Fps is (10 sec: 3271.8, 60 sec: 3279.8, 300 sec: 3249.4). Total num frames: 6619136. Throughput: 0: 3431.6. Samples: 6620160. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:09:29,613][187009] Avg episode reward: [(0, '1400.537')]
[2026-02-02 15:09:34,597][187009] Fps is (10 sec: 3274.9, 60 sec: 3279.5, 300 sec: 3222.1). Total num frames: 6635520. Throughput: 0: 3435.8. Samples: 6639616. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:09:34,597][187009] Avg episode reward: [(0, '1418.500')]
[2026-02-02 15:09:39,649][187009] Fps is (10 sec: 3264.7, 60 sec: 3417.0, 300 sec: 3221.0). Total num frames: 6651904. Throughput: 0: 3478.6. Samples: 6650880. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:09:39,650][187009] Avg episode reward: [(0, '1448.348')]
[2026-02-02 15:09:44,620][187009] Fps is (10 sec: 3269.0, 60 sec: 3545.9, 300 sec: 3220.6). Total num frames: 6668288. Throughput: 0: 3438.1. Samples: 6670336. Policy #0 lag: (min: 12.0, avg: 15.0, max: 76.0)
[2026-02-02 15:09:44,621][187009] Avg episode reward: [(0, '1456.215')]
[2026-02-02 15:09:49,587][187009] Fps is (10 sec: 3297.4, 60 sec: 3550.2, 300 sec: 3221.4). Total num frames: 6684672. Throughput: 0: 3396.5. Samples: 6690816. Policy #0 lag: (min: 12.0, avg: 15.0, max: 76.0)
[2026-02-02 15:09:49,587][187009] Avg episode reward: [(0, '1474.594')]
[2026-02-02 15:09:54,643][187009] Fps is (10 sec: 3269.3, 60 sec: 3419.8, 300 sec: 3220.9). Total num frames: 6701056. Throughput: 0: 3436.4. Samples: 6702080. Policy #0 lag: (min: 12.0, avg: 15.0, max: 76.0)
[2026-02-02 15:09:54,644][187009] Avg episode reward: [(0, '1461.452')]
[2026-02-02 15:09:59,524][187009] Fps is (10 sec: 3297.6, 60 sec: 3291.7, 300 sec: 3221.3). Total num frames: 6717440. Throughput: 0: 3392.4. Samples: 6721536. Policy #0 lag: (min: 12.0, avg: 15.0, max: 76.0)
[2026-02-02 15:09:59,524][187009] Avg episode reward: [(0, '1454.430')]
[2026-02-02 15:10:04,592][187009] Fps is (10 sec: 3293.9, 60 sec: 3272.6, 300 sec: 3220.8). Total num frames: 6733824. Throughput: 0: 3447.9. Samples: 6742528. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:10:04,592][187009] Avg episode reward: [(0, '1418.197')]
[2026-02-02 15:10:09,558][187009] Fps is (10 sec: 3265.5, 60 sec: 3281.7, 300 sec: 3221.8). Total num frames: 6750208. Throughput: 0: 3404.4. Samples: 6752256. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:10:09,559][187009] Avg episode reward: [(0, '1437.301')]
[2026-02-02 15:10:14,645][187009] Fps is (10 sec: 3259.5, 60 sec: 3271.5, 300 sec: 3220.8). Total num frames: 6766592. Throughput: 0: 3388.1. Samples: 6772736. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:10:14,645][187009] Avg episode reward: [(0, '1415.836')]
[2026-02-02 15:10:19,653][187009] Fps is (10 sec: 3246.1, 60 sec: 3273.8, 300 sec: 3219.9). Total num frames: 6782976. Throughput: 0: 3420.4. Samples: 6793728. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:10:19,653][187009] Avg episode reward: [(0, '1468.539')]
[2026-02-02 15:10:24,651][187009] Fps is (10 sec: 3274.7, 60 sec: 3273.5, 300 sec: 3220.7). Total num frames: 6799360. Throughput: 0: 3390.4. Samples: 6803456. Policy #0 lag: (min: 8.0, avg: 11.0, max: 72.0)
[2026-02-02 15:10:24,651][187009] Avg episode reward: [(0, '1517.508')]
[2026-02-02 15:10:29,525][187009] Fps is (10 sec: 3319.4, 60 sec: 3281.6, 300 sec: 3221.9). Total num frames: 6815744. Throughput: 0: 3432.0. Samples: 6824448. Policy #0 lag: (min: 8.0, avg: 11.0, max: 72.0)
[2026-02-02 15:10:29,525][187009] Avg episode reward: [(0, '1503.522')]
[2026-02-02 15:10:30,281][187009] Signal inference workers to stop experience collection... (1250 times)
[2026-02-02 15:10:30,632][187009] InferenceWorker_p0-w0: stopping experience collection (1250 times)
[2026-02-02 15:10:30,633][187009] Signal inference workers to resume experience collection... (1250 times)
[2026-02-02 15:10:30,633][187009] InferenceWorker_p0-w0: resuming experience collection (1250 times)
[2026-02-02 15:10:34,562][187009] Fps is (10 sec: 3306.4, 60 sec: 3278.7, 300 sec: 3220.9). Total num frames: 6832128. Throughput: 0: 3438.0. Samples: 6845440. Policy #0 lag: (min: 8.0, avg: 11.0, max: 72.0)
[2026-02-02 15:10:34,562][187009] Avg episode reward: [(0, '1487.367')]
[2026-02-02 15:10:34,699][187009] Saving /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_accel_policy3_aggressive_magpie_refined_params_02022026_smooth_aggressive_ttc/checkpoint_p0/checkpoint_000026688_6832128.pth...
[2026-02-02 15:10:34,703][187009] Removing /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_accel_policy3_aggressive_magpie_refined_params_02022026_smooth_aggressive_ttc/checkpoint_p0/checkpoint_000023744_6078464.pth
[2026-02-02 15:10:39,540][187009] Fps is (10 sec: 3271.8, 60 sec: 3282.8, 300 sec: 3221.9). Total num frames: 6848512. Throughput: 0: 3409.8. Samples: 6855168. Policy #0 lag: (min: 8.0, avg: 11.0, max: 72.0)
[2026-02-02 15:10:39,540][187009] Avg episode reward: [(0, '1488.060')]
[2026-02-02 15:10:44,644][187009] Fps is (10 sec: 4062.7, 60 sec: 3412.0, 300 sec: 3248.1). Total num frames: 6873088. Throughput: 0: 3427.0. Samples: 6876160. Policy #0 lag: (min: 1.0, avg: 4.0, max: 65.0)
[2026-02-02 15:10:44,644][187009] Avg episode reward: [(0, '1543.146')]
[2026-02-02 15:10:49,851][187009] Fps is (10 sec: 4766.8, 60 sec: 3534.3, 300 sec: 3273.6). Total num frames: 6897664. Throughput: 0: 3416.4. Samples: 6897152. Policy #0 lag: (min: 1.0, avg: 4.0, max: 65.0)
[2026-02-02 15:10:49,852][187009] Avg episode reward: [(0, '1556.604')]
[2026-02-02 15:10:49,852][187009] Saving new best policy, reward=1556.604!
[2026-02-02 15:10:54,692][187009] Fps is (10 sec: 4076.3, 60 sec: 3547.0, 300 sec: 3276.0). Total num frames: 6914048. Throughput: 0: 3414.6. Samples: 6906368. Policy #0 lag: (min: 1.0, avg: 4.0, max: 65.0)
[2026-02-02 15:10:54,692][187009] Avg episode reward: [(0, '1569.928')]
[2026-02-02 15:10:54,694][187009] Saving new best policy, reward=1569.928!
[2026-02-02 15:10:59,637][187009] Fps is (10 sec: 3348.5, 60 sec: 3543.2, 300 sec: 3275.6). Total num frames: 6930432. Throughput: 0: 3436.7. Samples: 6927360. Policy #0 lag: (min: 2.0, avg: 5.0, max: 66.0)
[2026-02-02 15:10:59,637][187009] Avg episode reward: [(0, '1573.318')]
[2026-02-02 15:10:59,776][187009] Saving new best policy, reward=1573.318!
[2026-02-02 15:11:04,590][187009] Fps is (10 sec: 3310.5, 60 sec: 3550.0, 300 sec: 3249.2). Total num frames: 6946816. Throughput: 0: 3429.5. Samples: 6947840. Policy #0 lag: (min: 2.0, avg: 5.0, max: 66.0)
[2026-02-02 15:11:04,590][187009] Avg episode reward: [(0, '1574.343')]
[2026-02-02 15:11:04,743][187009] Saving new best policy, reward=1574.343!
[2026-02-02 15:11:09,525][187009] Fps is (10 sec: 3314.1, 60 sec: 3551.9, 300 sec: 3224.1). Total num frames: 6963200. Throughput: 0: 3434.4. Samples: 6957568. Policy #0 lag: (min: 2.0, avg: 5.0, max: 66.0)
[2026-02-02 15:11:09,525][187009] Avg episode reward: [(0, '1513.875')]
[2026-02-02 15:11:14,542][187009] Fps is (10 sec: 3292.7, 60 sec: 3556.0, 300 sec: 3221.5). Total num frames: 6979584. Throughput: 0: 3423.4. Samples: 6978560. Policy #0 lag: (min: 2.0, avg: 5.0, max: 66.0)
[2026-02-02 15:11:14,542][187009] Avg episode reward: [(0, '1528.805')]
[2026-02-02 15:11:19,537][187009] Fps is (10 sec: 3272.7, 60 sec: 3556.7, 300 sec: 3221.9). Total num frames: 6995968. Throughput: 0: 3392.4. Samples: 6998016. Policy #0 lag: (min: 5.0, avg: 8.0, max: 69.0)
[2026-02-02 15:11:19,537][187009] Avg episode reward: [(0, '1502.881')]
[2026-02-02 15:11:24,638][187009] Fps is (10 sec: 3245.7, 60 sec: 3550.7, 300 sec: 3220.5). Total num frames: 7012352. Throughput: 0: 3417.3. Samples: 7009280. Policy #0 lag: (min: 5.0, avg: 8.0, max: 69.0)
[2026-02-02 15:11:24,638][187009] Avg episode reward: [(0, '1502.814')]
[2026-02-02 15:11:29,543][187009] Fps is (10 sec: 3274.8, 60 sec: 3548.8, 300 sec: 3222.6). Total num frames: 7028736. Throughput: 0: 3421.0. Samples: 7029760. Policy #0 lag: (min: 5.0, avg: 8.0, max: 69.0)
[2026-02-02 15:11:29,543][187009] Avg episode reward: [(0, '1509.052')]
[2026-02-02 15:11:34,577][187009] Fps is (10 sec: 3296.8, 60 sec: 3549.0, 300 sec: 3222.3). Total num frames: 7045120. Throughput: 0: 3388.5. Samples: 7048704. Policy #0 lag: (min: 5.0, avg: 8.0, max: 69.0)
[2026-02-02 15:11:34,577][187009] Avg episode reward: [(0, '1468.483')]
[2026-02-02 15:11:39,552][187009] Fps is (10 sec: 3274.0, 60 sec: 3549.2, 300 sec: 3224.6). Total num frames: 7061504. Throughput: 0: 3424.0. Samples: 7059968. Policy #0 lag: (min: 7.0, avg: 10.0, max: 71.0)
[2026-02-02 15:11:39,552][187009] Avg episode reward: [(0, '1470.468')]
[2026-02-02 15:11:44,573][187009] Fps is (10 sec: 3278.0, 60 sec: 3417.3, 300 sec: 3277.5). Total num frames: 7077888. Throughput: 0: 3372.6. Samples: 7078912. Policy #0 lag: (min: 7.0, avg: 10.0, max: 71.0)
[2026-02-02 15:11:44,573][187009] Avg episode reward: [(0, '1488.851')]
[2026-02-02 15:11:49,630][187009] Fps is (10 sec: 3251.4, 60 sec: 3288.9, 300 sec: 3276.3). Total num frames: 7094272. Throughput: 0: 3376.2. Samples: 7099904. Policy #0 lag: (min: 7.0, avg: 10.0, max: 71.0)
[2026-02-02 15:11:49,630][187009] Avg episode reward: [(0, '1496.984')]
[2026-02-02 15:11:52,166][187009] Signal inference workers to stop experience collection... (1300 times)
[2026-02-02 15:11:52,166][187009] Signal inference workers to resume experience collection... (1300 times)
[2026-02-02 15:11:52,424][187009] InferenceWorker_p0-w0: stopping experience collection (1300 times)
[2026-02-02 15:11:52,424][187009] InferenceWorker_p0-w0: resuming experience collection (1300 times)
[2026-02-02 15:11:54,600][187009] Fps is (10 sec: 3267.9, 60 sec: 3281.8, 300 sec: 3276.7). Total num frames: 7110656. Throughput: 0: 3407.6. Samples: 7111168. Policy #0 lag: (min: 7.0, avg: 10.0, max: 71.0)
[2026-02-02 15:11:54,601][187009] Avg episode reward: [(0, '1448.902')]
[2026-02-02 15:11:59,579][187009] Fps is (10 sec: 3293.5, 60 sec: 3280.0, 300 sec: 3276.7). Total num frames: 7127040. Throughput: 0: 3365.0. Samples: 7130112. Policy #0 lag: (min: 9.0, avg: 12.0, max: 73.0)
[2026-02-02 15:11:59,579][187009] Avg episode reward: [(0, '1487.100')]
[2026-02-02 15:12:04,579][187009] Fps is (10 sec: 3283.7, 60 sec: 3277.4, 300 sec: 3276.7). Total num frames: 7143424. Throughput: 0: 3398.8. Samples: 7151104. Policy #0 lag: (min: 9.0, avg: 12.0, max: 73.0)
[2026-02-02 15:12:04,580][187009] Avg episode reward: [(0, '1465.671')]
[2026-02-02 15:12:09,526][187009] Fps is (10 sec: 3294.2, 60 sec: 3276.7, 300 sec: 3277.1). Total num frames: 7159808. Throughput: 0: 3376.2. Samples: 7160832. Policy #0 lag: (min: 9.0, avg: 12.0, max: 73.0)
[2026-02-02 15:12:09,526][187009] Avg episode reward: [(0, '1451.417')]
[2026-02-02 15:12:14,645][187009] Fps is (10 sec: 3255.4, 60 sec: 3271.2, 300 sec: 3276.9). Total num frames: 7176192. Throughput: 0: 3360.2. Samples: 7181312. Policy #0 lag: (min: 9.0, avg: 12.0, max: 73.0)
[2026-02-02 15:12:14,645][187009] Avg episode reward: [(0, '1446.882')]
[2026-02-02 15:12:19,578][187009] Fps is (10 sec: 3259.9, 60 sec: 3274.6, 300 sec: 3277.8). Total num frames: 7192576. Throughput: 0: 3413.2. Samples: 7202304. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:12:19,578][187009] Avg episode reward: [(0, '1450.851')]
[2026-02-02 15:12:24,616][187009] Fps is (10 sec: 3286.2, 60 sec: 3278.0, 300 sec: 3276.7). Total num frames: 7208960. Throughput: 0: 3374.3. Samples: 7212032. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:12:24,617][187009] Avg episode reward: [(0, '1446.024')]
[2026-02-02 15:12:29,607][187009] Fps is (10 sec: 3267.4, 60 sec: 3273.3, 300 sec: 3275.9). Total num frames: 7225344. Throughput: 0: 3422.1. Samples: 7233024. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:12:29,607][187009] Avg episode reward: [(0, '1455.145')]
[2026-02-02 15:12:34,560][187009] Fps is (10 sec: 3295.5, 60 sec: 3277.7, 300 sec: 3276.6). Total num frames: 7241728. Throughput: 0: 3441.4. Samples: 7254528. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:12:34,560][187009] Avg episode reward: [(0, '1501.432')]
[2026-02-02 15:12:34,698][187009] Saving /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_accel_policy3_aggressive_magpie_refined_params_02022026_smooth_aggressive_ttc/checkpoint_p0/checkpoint_000028288_7241728.pth...
[2026-02-02 15:12:34,702][187009] Removing /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_accel_policy3_aggressive_magpie_refined_params_02022026_smooth_aggressive_ttc/checkpoint_p0/checkpoint_000025152_6438912.pth
[2026-02-02 15:12:39,871][187009] Fps is (10 sec: 3990.8, 60 sec: 3395.3, 300 sec: 3328.8). Total num frames: 7266304. Throughput: 0: 3393.0. Samples: 7264768. Policy #0 lag: (min: 12.0, avg: 15.0, max: 76.0)
[2026-02-02 15:12:39,871][187009] Avg episode reward: [(0, '1537.279')]
[2026-02-02 15:12:44,632][187009] Fps is (10 sec: 4066.6, 60 sec: 3410.0, 300 sec: 3358.9). Total num frames: 7282688. Throughput: 0: 3454.8. Samples: 7285760. Policy #0 lag: (min: 12.0, avg: 15.0, max: 76.0)
[2026-02-02 15:12:44,632][187009] Avg episode reward: [(0, '1570.638')]
[2026-02-02 15:12:49,681][187009] Fps is (10 sec: 4175.1, 60 sec: 3546.8, 300 sec: 3386.4). Total num frames: 7307264. Throughput: 0: 3462.4. Samples: 7307264. Policy #0 lag: (min: 12.0, avg: 15.0, max: 76.0)
[2026-02-02 15:12:49,681][187009] Avg episode reward: [(0, '1548.467')]
[2026-02-02 15:12:54,631][187009] Fps is (10 sec: 4096.6, 60 sec: 3548.1, 300 sec: 3387.1). Total num frames: 7323648. Throughput: 0: 3462.2. Samples: 7316992. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:12:54,631][187009] Avg episode reward: [(0, '1490.208')]
[2026-02-02 15:12:59,555][187009] Fps is (10 sec: 3318.5, 60 sec: 3551.3, 300 sec: 3387.5). Total num frames: 7340032. Throughput: 0: 3499.9. Samples: 7338496. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:12:59,556][187009] Avg episode reward: [(0, '1478.906')]
[2026-02-02 15:13:04,531][187009] Fps is (10 sec: 3310.0, 60 sec: 3552.8, 300 sec: 3388.2). Total num frames: 7356416. Throughput: 0: 3451.1. Samples: 7357440. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:13:04,531][187009] Avg episode reward: [(0, '1493.272')]
[2026-02-02 15:13:09,524][187009] Fps is (10 sec: 3287.0, 60 sec: 3550.0, 300 sec: 3389.4). Total num frames: 7372800. Throughput: 0: 3511.5. Samples: 7369728. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:13:09,525][187009] Avg episode reward: [(0, '1497.807')]
[2026-02-02 15:13:12,494][187009] Signal inference workers to stop experience collection... (1350 times)
[2026-02-02 15:13:12,857][187009] InferenceWorker_p0-w0: stopping experience collection (1350 times)
[2026-02-02 15:13:12,858][187009] Signal inference workers to resume experience collection... (1350 times)
[2026-02-02 15:13:12,997][187009] InferenceWorker_p0-w0: resuming experience collection (1350 times)
[2026-02-02 15:13:14,604][187009] Fps is (10 sec: 3252.8, 60 sec: 3552.3, 300 sec: 3388.4). Total num frames: 7389184. Throughput: 0: 3493.2. Samples: 7390208. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:13:14,605][187009] Avg episode reward: [(0, '1441.778')]
[2026-02-02 15:13:19,599][187009] Fps is (10 sec: 3252.5, 60 sec: 3548.6, 300 sec: 3388.7). Total num frames: 7405568. Throughput: 0: 3455.8. Samples: 7410176. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:13:19,599][187009] Avg episode reward: [(0, '1413.587')]
[2026-02-02 15:13:24,576][187009] Fps is (10 sec: 3286.3, 60 sec: 3552.3, 300 sec: 3388.9). Total num frames: 7421952. Throughput: 0: 3504.6. Samples: 7421440. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:13:24,576][187009] Avg episode reward: [(0, '1463.732')]
[2026-02-02 15:13:29,651][187009] Fps is (10 sec: 3260.0, 60 sec: 3547.3, 300 sec: 3387.8). Total num frames: 7438336. Throughput: 0: 3457.4. Samples: 7441408. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:13:29,651][187009] Avg episode reward: [(0, '1509.121')]
[2026-02-02 15:13:34,582][187009] Fps is (10 sec: 3274.8, 60 sec: 3548.6, 300 sec: 3417.2). Total num frames: 7454720. Throughput: 0: 3455.1. Samples: 7462400. Policy #0 lag: (min: 23.0, avg: 26.0, max: 87.0)
[2026-02-02 15:13:34,582][187009] Avg episode reward: [(0, '1560.376')]
[2026-02-02 15:13:39,521][187009] Fps is (10 sec: 3319.9, 60 sec: 3433.3, 300 sec: 3443.8). Total num frames: 7471104. Throughput: 0: 3455.9. Samples: 7472128. Policy #0 lag: (min: 23.0, avg: 26.0, max: 87.0)
[2026-02-02 15:13:39,521][187009] Avg episode reward: [(0, '1559.817')]
[2026-02-02 15:13:44,652][187009] Fps is (10 sec: 3254.1, 60 sec: 3412.2, 300 sec: 3442.7). Total num frames: 7487488. Throughput: 0: 3417.4. Samples: 7492608. Policy #0 lag: (min: 23.0, avg: 26.0, max: 87.0)
[2026-02-02 15:13:44,652][187009] Avg episode reward: [(0, '1513.087')]
[2026-02-02 15:13:49,624][187009] Fps is (10 sec: 3243.2, 60 sec: 3279.9, 300 sec: 3417.2). Total num frames: 7503872. Throughput: 0: 3474.4. Samples: 7514112. Policy #0 lag: (min: 23.0, avg: 26.0, max: 87.0)
[2026-02-02 15:13:49,625][187009] Avg episode reward: [(0, '1448.901')]
[2026-02-02 15:13:54,603][187009] Fps is (10 sec: 3292.8, 60 sec: 3278.3, 300 sec: 3390.1). Total num frames: 7520256. Throughput: 0: 3418.8. Samples: 7523840. Policy #0 lag: (min: 6.0, avg: 9.0, max: 70.0)
[2026-02-02 15:13:54,603][187009] Avg episode reward: [(0, '1425.064')]
[2026-02-02 15:13:59,588][187009] Fps is (10 sec: 3288.9, 60 sec: 3275.0, 300 sec: 3387.0). Total num frames: 7536640. Throughput: 0: 3448.8. Samples: 7545344. Policy #0 lag: (min: 6.0, avg: 9.0, max: 70.0)
[2026-02-02 15:13:59,588][187009] Avg episode reward: [(0, '1454.086')]
[2026-02-02 15:14:04,575][187009] Fps is (10 sec: 3286.1, 60 sec: 3274.4, 300 sec: 3388.7). Total num frames: 7553024. Throughput: 0: 3472.1. Samples: 7566336. Policy #0 lag: (min: 6.0, avg: 9.0, max: 70.0)
[2026-02-02 15:14:04,575][187009] Avg episode reward: [(0, '1472.862')]
[2026-02-02 15:14:09,783][187009] Fps is (10 sec: 4017.7, 60 sec: 3398.7, 300 sec: 3412.9). Total num frames: 7577600. Throughput: 0: 3420.4. Samples: 7576064. Policy #0 lag: (min: 6.0, avg: 9.0, max: 70.0)
[2026-02-02 15:14:09,783][187009] Avg episode reward: [(0, '1485.122')]
[2026-02-02 15:14:14,523][187009] Fps is (10 sec: 4117.2, 60 sec: 3418.0, 300 sec: 3416.5). Total num frames: 7593984. Throughput: 0: 3480.1. Samples: 7597568. Policy #0 lag: (min: 60.0, avg: 63.0, max: 124.0)
[2026-02-02 15:14:14,523][187009] Avg episode reward: [(0, '1479.502')]
[2026-02-02 15:14:19,616][187009] Fps is (10 sec: 4165.4, 60 sec: 3548.9, 300 sec: 3443.1). Total num frames: 7618560. Throughput: 0: 3467.6. Samples: 7618560. Policy #0 lag: (min: 60.0, avg: 63.0, max: 124.0)
[2026-02-02 15:14:19,616][187009] Avg episode reward: [(0, '1510.865')]
[2026-02-02 15:14:24,567][187009] Fps is (10 sec: 4078.2, 60 sec: 3550.4, 300 sec: 3444.0). Total num frames: 7634944. Throughput: 0: 3466.7. Samples: 7628288. Policy #0 lag: (min: 60.0, avg: 63.0, max: 124.0)
[2026-02-02 15:14:24,567][187009] Avg episode reward: [(0, '1531.245')]
[2026-02-02 15:14:28,584][187009] Signal inference workers to stop experience collection... (1400 times)
[2026-02-02 15:14:28,939][187009] InferenceWorker_p0-w0: stopping experience collection (1400 times)
[2026-02-02 15:14:28,939][187009] Signal inference workers to resume experience collection... (1400 times)
[2026-02-02 15:14:28,940][187009] InferenceWorker_p0-w0: resuming experience collection (1400 times)
[2026-02-02 15:14:29,584][187009] Fps is (10 sec: 3287.4, 60 sec: 3553.8, 300 sec: 3443.6). Total num frames: 7651328. Throughput: 0: 3509.6. Samples: 7650304. Policy #0 lag: (min: 60.0, avg: 63.0, max: 124.0)
[2026-02-02 15:14:29,584][187009] Avg episode reward: [(0, '1510.479')]
[2026-02-02 15:14:34,599][187009] Fps is (10 sec: 3266.3, 60 sec: 3548.9, 300 sec: 3444.0). Total num frames: 7667712. Throughput: 0: 3460.8. Samples: 7669760. Policy #0 lag: (min: 4.0, avg: 7.0, max: 68.0)
[2026-02-02 15:14:34,599][187009] Avg episode reward: [(0, '1450.906')]
[2026-02-02 15:14:34,739][187009] Saving /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_accel_policy3_aggressive_magpie_refined_params_02022026_smooth_aggressive_ttc/checkpoint_p0/checkpoint_000029952_7667712.pth...
[2026-02-02 15:14:34,743][187009] Removing /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_accel_policy3_aggressive_magpie_refined_params_02022026_smooth_aggressive_ttc/checkpoint_p0/checkpoint_000026688_6832128.pth
[2026-02-02 15:14:39,593][187009] Fps is (10 sec: 3273.8, 60 sec: 3545.6, 300 sec: 3443.7). Total num frames: 7684096. Throughput: 0: 3493.8. Samples: 7681024. Policy #0 lag: (min: 4.0, avg: 7.0, max: 68.0)
[2026-02-02 15:14:39,593][187009] Avg episode reward: [(0, '1446.719')]
[2026-02-02 15:14:44,645][187009] Fps is (10 sec: 3261.8, 60 sec: 3550.3, 300 sec: 3442.7). Total num frames: 7700480. Throughput: 0: 3465.8. Samples: 7701504. Policy #0 lag: (min: 4.0, avg: 7.0, max: 68.0)
[2026-02-02 15:14:44,645][187009] Avg episode reward: [(0, '1464.185')]
[2026-02-02 15:14:49,617][187009] Fps is (10 sec: 3268.8, 60 sec: 3550.3, 300 sec: 3443.7). Total num frames: 7716864. Throughput: 0: 3466.9. Samples: 7722496. Policy #0 lag: (min: 4.0, avg: 7.0, max: 68.0)
[2026-02-02 15:14:49,618][187009] Avg episode reward: [(0, '1498.316')]
[2026-02-02 15:14:54,594][187009] Fps is (10 sec: 3293.6, 60 sec: 3550.4, 300 sec: 3442.6). Total num frames: 7733248. Throughput: 0: 3519.1. Samples: 7733760. Policy #0 lag: (min: 4.0, avg: 7.0, max: 68.0)
[2026-02-02 15:14:54,594][187009] Avg episode reward: [(0, '1494.740')]
[2026-02-02 15:14:59,626][187009] Fps is (10 sec: 3273.8, 60 sec: 3547.6, 300 sec: 3443.0). Total num frames: 7749632. Throughput: 0: 3462.3. Samples: 7753728. Policy #0 lag: (min: 9.0, avg: 12.0, max: 73.0)
[2026-02-02 15:14:59,627][187009] Avg episode reward: [(0, '1519.017')]
[2026-02-02 15:15:04,612][187009] Fps is (10 sec: 3270.8, 60 sec: 3547.7, 300 sec: 3442.8). Total num frames: 7766016. Throughput: 0: 3481.9. Samples: 7775232. Policy #0 lag: (min: 9.0, avg: 12.0, max: 73.0)
[2026-02-02 15:15:04,612][187009] Avg episode reward: [(0, '1505.065')]
[2026-02-02 15:15:09,645][187009] Fps is (10 sec: 3270.6, 60 sec: 3421.2, 300 sec: 3443.4). Total num frames: 7782400. Throughput: 0: 3475.5. Samples: 7784960. Policy #0 lag: (min: 9.0, avg: 12.0, max: 73.0)
[2026-02-02 15:15:09,646][187009] Avg episode reward: [(0, '1535.048')]
[2026-02-02 15:15:14,611][187009] Fps is (10 sec: 3277.0, 60 sec: 3408.3, 300 sec: 3443.9). Total num frames: 7798784. Throughput: 0: 3456.7. Samples: 7805952. Policy #0 lag: (min: 9.0, avg: 12.0, max: 73.0)
[2026-02-02 15:15:14,612][187009] Avg episode reward: [(0, '1493.241')]
[2026-02-02 15:15:19,559][187009] Fps is (10 sec: 3305.3, 60 sec: 3279.9, 300 sec: 3444.5). Total num frames: 7815168. Throughput: 0: 3507.4. Samples: 7827456. Policy #0 lag: (min: 9.0, avg: 12.0, max: 73.0)
[2026-02-02 15:15:19,559][187009] Avg episode reward: [(0, '1525.354')]
[2026-02-02 15:15:24,543][187009] Fps is (10 sec: 3299.4, 60 sec: 3278.1, 300 sec: 3443.2). Total num frames: 7831552. Throughput: 0: 3474.1. Samples: 7837184. Policy #0 lag: (min: 5.0, avg: 8.0, max: 69.0)
[2026-02-02 15:15:24,543][187009] Avg episode reward: [(0, '1495.524')]
[2026-02-02 15:15:29,780][187009] Fps is (10 sec: 4007.4, 60 sec: 3402.2, 300 sec: 3468.6). Total num frames: 7856128. Throughput: 0: 3482.5. Samples: 7858688. Policy #0 lag: (min: 5.0, avg: 8.0, max: 69.0)
[2026-02-02 15:15:29,781][187009] Avg episode reward: [(0, '1499.193')]
[2026-02-02 15:15:34,832][187009] Fps is (10 sec: 4777.3, 60 sec: 3536.1, 300 sec: 3495.5). Total num frames: 7880704. Throughput: 0: 3487.8. Samples: 7880192. Policy #0 lag: (min: 5.0, avg: 8.0, max: 69.0)
[2026-02-02 15:15:34,832][187009] Avg episode reward: [(0, '1441.592')]
[2026-02-02 15:15:39,602][187009] Fps is (10 sec: 4170.5, 60 sec: 3549.3, 300 sec: 3471.7). Total num frames: 7897088. Throughput: 0: 3469.6. Samples: 7889920. Policy #0 lag: (min: 5.0, avg: 8.0, max: 69.0)
[2026-02-02 15:15:39,602][187009] Avg episode reward: [(0, '1442.548')]
[2026-02-02 15:15:44,603][187009] Fps is (10 sec: 3353.6, 60 sec: 3552.4, 300 sec: 3446.3). Total num frames: 7913472. Throughput: 0: 3494.8. Samples: 7910912. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:15:44,603][187009] Avg episode reward: [(0, '1455.110')]
[2026-02-02 15:15:49,508][187009] Signal inference workers to stop experience collection... (1450 times)
[2026-02-02 15:15:49,508][187009] Signal inference workers to resume experience collection... (1450 times)
[2026-02-02 15:15:49,771][187009] InferenceWorker_p0-w0: stopping experience collection (1450 times)
[2026-02-02 15:15:49,771][187009] InferenceWorker_p0-w0: resuming experience collection (1450 times)
[2026-02-02 15:15:49,882][187009] Fps is (10 sec: 3187.6, 60 sec: 3534.3, 300 sec: 3441.2). Total num frames: 7929856. Throughput: 0: 3404.3. Samples: 7929344. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:15:49,882][187009] Avg episode reward: [(0, '1472.406')]
[2026-02-02 15:15:54,574][187009] Fps is (10 sec: 1643.2, 60 sec: 3277.9, 300 sec: 3388.6). Total num frames: 7929856. Throughput: 0: 3396.0. Samples: 7937536. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:15:54,574][187009] Avg episode reward: [(0, '1518.946')]
[2026-02-02 15:15:59,564][187009] Fps is (10 sec: 1692.2, 60 sec: 3280.2, 300 sec: 3388.2). Total num frames: 7946240. Throughput: 0: 3337.2. Samples: 7955968. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:15:59,564][187009] Avg episode reward: [(0, '1512.142')]
[2026-02-02 15:16:04,600][187009] Fps is (10 sec: 3268.1, 60 sec: 3277.4, 300 sec: 3387.0). Total num frames: 7962624. Throughput: 0: 3251.1. Samples: 7973888. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:16:04,600][187009] Avg episode reward: [(0, '1605.099')]
[2026-02-02 15:16:04,755][187009] Saving new best policy, reward=1605.099!
[2026-02-02 15:16:09,547][187009] Fps is (10 sec: 3282.2, 60 sec: 3282.2, 300 sec: 3387.8). Total num frames: 7979008. Throughput: 0: 3219.6. Samples: 7982080. Policy #0 lag: (min: 5.0, avg: 8.0, max: 69.0)
[2026-02-02 15:16:09,548][187009] Avg episode reward: [(0, '1551.122')]
[2026-02-02 15:16:14,550][187009] Fps is (10 sec: 3293.4, 60 sec: 3280.2, 300 sec: 3387.7). Total num frames: 7995392. Throughput: 0: 3167.9. Samples: 8000512. Policy #0 lag: (min: 5.0, avg: 8.0, max: 69.0)
[2026-02-02 15:16:14,550][187009] Avg episode reward: [(0, '1555.570')]
[2026-02-02 15:16:19,540][187009] Fps is (10 sec: 3279.0, 60 sec: 3277.8, 300 sec: 3389.0). Total num frames: 8011776. Throughput: 0: 3092.0. Samples: 8018432. Policy #0 lag: (min: 5.0, avg: 8.0, max: 69.0)
[2026-02-02 15:16:19,541][187009] Avg episode reward: [(0, '1528.308')]
[2026-02-02 15:16:24,571][187009] Fps is (10 sec: 3270.0, 60 sec: 3275.3, 300 sec: 3387.6). Total num frames: 8028160. Throughput: 0: 3074.1. Samples: 8028160. Policy #0 lag: (min: 5.0, avg: 8.0, max: 69.0)
[2026-02-02 15:16:24,571][187009] Avg episode reward: [(0, '1539.271')]
[2026-02-02 15:16:29,619][187009] Fps is (10 sec: 3251.2, 60 sec: 3148.7, 300 sec: 3387.4). Total num frames: 8044544. Throughput: 0: 2991.3. Samples: 8045568. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:16:29,619][187009] Avg episode reward: [(0, '1576.895')]
[2026-02-02 15:16:34,652][187009] Fps is (10 sec: 3250.3, 60 sec: 3012.7, 300 sec: 3386.7). Total num frames: 8060928. Throughput: 0: 2984.8. Samples: 8062976. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:16:34,652][187009] Avg episode reward: [(0, '1518.477')]
[2026-02-02 15:16:34,820][187009] Saving /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_accel_policy3_aggressive_magpie_refined_params_02022026_smooth_aggressive_ttc/checkpoint_p0/checkpoint_000031488_8060928.pth...
[2026-02-02 15:16:34,824][187009] Removing /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_accel_policy3_aggressive_magpie_refined_params_02022026_smooth_aggressive_ttc/checkpoint_p0/checkpoint_000028288_7241728.pth
[2026-02-02 15:16:39,554][187009] Fps is (10 sec: 3298.2, 60 sec: 3006.1, 300 sec: 3388.1). Total num frames: 8077312. Throughput: 0: 2993.6. Samples: 8072192. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:16:39,554][187009] Avg episode reward: [(0, '1560.555')]
[2026-02-02 15:16:44,810][187009] Fps is (10 sec: 3225.7, 60 sec: 2993.4, 300 sec: 3385.8). Total num frames: 8093696. Throughput: 0: 2964.7. Samples: 8090112. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:16:44,811][187009] Avg episode reward: [(0, '1517.414')]
[2026-02-02 15:16:49,554][187009] Fps is (10 sec: 1638.5, 60 sec: 2745.7, 300 sec: 3332.9). Total num frames: 8093696. Throughput: 0: 2984.1. Samples: 8108032. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:16:49,554][187009] Avg episode reward: [(0, '1486.832')]
[2026-02-02 15:16:54,678][187009] Fps is (10 sec: 1660.4, 60 sec: 2998.5, 300 sec: 3331.2). Total num frames: 8110080. Throughput: 0: 2972.4. Samples: 8116224. Policy #0 lag: (min: 11.0, avg: 14.0, max: 75.0)
[2026-02-02 15:16:54,678][187009] Avg episode reward: [(0, '1438.875')]
[2026-02-02 15:16:59,591][187009] Fps is (10 sec: 3264.6, 60 sec: 3002.4, 300 sec: 3332.2). Total num frames: 8126464. Throughput: 0: 2966.9. Samples: 8134144. Policy #0 lag: (min: 11.0, avg: 14.0, max: 75.0)
[2026-02-02 15:16:59,591][187009] Avg episode reward: [(0, '1454.406')]
[2026-02-02 15:17:04,552][187009] Fps is (10 sec: 3318.4, 60 sec: 3006.1, 300 sec: 3332.0). Total num frames: 8142848. Throughput: 0: 2957.4. Samples: 8151552. Policy #0 lag: (min: 11.0, avg: 14.0, max: 75.0)
[2026-02-02 15:17:04,553][187009] Avg episode reward: [(0, '1509.591')]
[2026-02-02 15:17:09,617][187009] Fps is (10 sec: 3268.4, 60 sec: 3000.3, 300 sec: 3332.7). Total num frames: 8159232. Throughput: 0: 2932.5. Samples: 8160256. Policy #0 lag: (min: 11.0, avg: 14.0, max: 75.0)
[2026-02-02 15:17:09,617][187009] Avg episode reward: [(0, '1534.556')]
[2026-02-02 15:17:14,610][187009] Fps is (10 sec: 3258.1, 60 sec: 3000.7, 300 sec: 3332.0). Total num frames: 8175616. Throughput: 0: 2901.9. Samples: 8176128. Policy #0 lag: (min: 11.0, avg: 14.0, max: 75.0)
[2026-02-02 15:17:14,610][187009] Avg episode reward: [(0, '1592.655')]
[2026-02-02 15:17:19,576][187009] Fps is (10 sec: 3290.2, 60 sec: 3001.9, 300 sec: 3332.8). Total num frames: 8192000. Throughput: 0: 2883.4. Samples: 8192512. Policy #0 lag: (min: 11.0, avg: 14.0, max: 75.0)
[2026-02-02 15:17:19,576][187009] Avg episode reward: [(0, '1591.320')]
[2026-02-02 15:17:24,546][187009] Signal inference workers to stop experience collection... (1500 times)
[2026-02-02 15:17:24,546][187009] Fps is (10 sec: 1648.9, 60 sec: 2731.8, 300 sec: 3277.5). Total num frames: 8192000. Throughput: 0: 2844.9. Samples: 8200192. Policy #0 lag: (min: 11.0, avg: 14.0, max: 75.0)
[2026-02-02 15:17:24,546][187009] Avg episode reward: [(0, '1532.368')]
[2026-02-02 15:17:24,945][187009] InferenceWorker_p0-w0: stopping experience collection (1500 times)
[2026-02-02 15:17:24,947][187009] Signal inference workers to resume experience collection... (1500 times)
[2026-02-02 15:17:25,099][187009] InferenceWorker_p0-w0: resuming experience collection (1500 times)
[2026-02-02 15:17:29,625][187009] Fps is (10 sec: 1630.4, 60 sec: 2730.4, 300 sec: 3276.1). Total num frames: 8208384. Throughput: 0: 2856.2. Samples: 8218112. Policy #0 lag: (min: 11.0, avg: 14.0, max: 75.0)
[2026-02-02 15:17:29,625][187009] Avg episode reward: [(0, '1530.872')]
[2026-02-02 15:17:34,601][187009] Fps is (10 sec: 3259.1, 60 sec: 2733.0, 300 sec: 3252.0). Total num frames: 8224768. Throughput: 0: 2830.1. Samples: 8235520. Policy #0 lag: (min: 11.0, avg: 14.0, max: 75.0)
[2026-02-02 15:17:34,601][187009] Avg episode reward: [(0, '1503.273')]
[2026-02-02 15:17:39,672][187009] Fps is (10 sec: 3261.3, 60 sec: 2725.3, 300 sec: 3248.6). Total num frames: 8241152. Throughput: 0: 2833.4. Samples: 8243712. Policy #0 lag: (min: 11.0, avg: 14.0, max: 75.0)
[2026-02-02 15:17:39,673][187009] Avg episode reward: [(0, '1494.113')]
[2026-02-02 15:17:44,600][187009] Fps is (10 sec: 3277.1, 60 sec: 2740.3, 300 sec: 3222.1). Total num frames: 8257536. Throughput: 0: 2832.5. Samples: 8261632. Policy #0 lag: (min: 11.0, avg: 14.0, max: 75.0)
[2026-02-02 15:17:44,600][187009] Avg episode reward: [(0, '1530.602')]
[2026-02-02 15:17:49,639][187009] Fps is (10 sec: 3287.7, 60 sec: 2999.5, 300 sec: 3221.2). Total num frames: 8273920. Throughput: 0: 2827.6. Samples: 8279040. Policy #0 lag: (min: 11.0, avg: 14.0, max: 75.0)
[2026-02-02 15:17:49,640][187009] Avg episode reward: [(0, '1523.197')]
[2026-02-02 15:17:54,559][187009] Fps is (10 sec: 3290.2, 60 sec: 3009.7, 300 sec: 3221.2). Total num frames: 8290304. Throughput: 0: 2859.5. Samples: 8288768. Policy #0 lag: (min: 11.0, avg: 14.0, max: 75.0)
[2026-02-02 15:17:54,559][187009] Avg episode reward: [(0, '1494.302')]
[2026-02-02 15:17:59,530][187009] Fps is (10 sec: 3312.9, 60 sec: 3006.8, 300 sec: 3221.3). Total num frames: 8306688. Throughput: 0: 2895.1. Samples: 8306176. Policy #0 lag: (min: 9.0, avg: 12.0, max: 73.0)
[2026-02-02 15:17:59,531][187009] Avg episode reward: [(0, '1508.139')]
[2026-02-02 15:18:04,629][187009] Fps is (10 sec: 3254.0, 60 sec: 2999.9, 300 sec: 3220.1). Total num frames: 8323072. Throughput: 0: 2920.6. Samples: 8324096. Policy #0 lag: (min: 9.0, avg: 12.0, max: 73.0)
[2026-02-02 15:18:04,630][187009] Avg episode reward: [(0, '1494.197')]
[2026-02-02 15:18:09,731][187009] Fps is (10 sec: 2409.3, 60 sec: 2861.8, 300 sec: 3192.1). Total num frames: 8331264. Throughput: 0: 2912.1. Samples: 8331776. Policy #0 lag: (min: 9.0, avg: 12.0, max: 73.0)
[2026-02-02 15:18:09,731][187009] Avg episode reward: [(0, '1478.763')]
[2026-02-02 15:18:14,665][187009] Fps is (10 sec: 1632.6, 60 sec: 2728.2, 300 sec: 3165.0). Total num frames: 8339456. Throughput: 0: 2910.1. Samples: 8349184. Policy #0 lag: (min: 9.0, avg: 12.0, max: 73.0)
[2026-02-02 15:18:14,665][187009] Avg episode reward: [(0, '1531.549')]
[2026-02-02 15:18:19,608][187009] Fps is (10 sec: 2488.2, 60 sec: 2729.2, 300 sec: 3165.4). Total num frames: 8355840. Throughput: 0: 2923.6. Samples: 8367104. Policy #0 lag: (min: 9.0, avg: 12.0, max: 73.0)
[2026-02-02 15:18:19,608][187009] Avg episode reward: [(0, '1526.277')]
[2026-02-02 15:18:24,584][187009] Fps is (10 sec: 3303.4, 60 sec: 3001.8, 300 sec: 3166.4). Total num frames: 8372224. Throughput: 0: 2929.8. Samples: 8375296. Policy #0 lag: (min: 12.0, avg: 15.0, max: 76.0)
[2026-02-02 15:18:24,585][187009] Avg episode reward: [(0, '1466.656')]
[2026-02-02 15:18:29,568][187009] Fps is (10 sec: 3289.9, 60 sec: 3006.6, 300 sec: 3165.9). Total num frames: 8388608. Throughput: 0: 2926.2. Samples: 8393216. Policy #0 lag: (min: 12.0, avg: 15.0, max: 76.0)
[2026-02-02 15:18:29,568][187009] Avg episode reward: [(0, '1435.152')]
[2026-02-02 15:18:34,585][187009] Fps is (10 sec: 3276.6, 60 sec: 3004.5, 300 sec: 3165.0). Total num frames: 8404992. Throughput: 0: 2984.6. Samples: 8413184. Policy #0 lag: (min: 12.0, avg: 15.0, max: 76.0)
[2026-02-02 15:18:34,585][187009] Avg episode reward: [(0, '1429.134')]
[2026-02-02 15:18:34,723][187009] Saving /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_accel_policy3_aggressive_magpie_refined_params_02022026_smooth_aggressive_ttc/checkpoint_p0/checkpoint_000032832_8404992.pth...
[2026-02-02 15:18:34,727][187009] Removing /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_accel_policy3_aggressive_magpie_refined_params_02022026_smooth_aggressive_ttc/checkpoint_p0/checkpoint_000029952_7667712.pth
[2026-02-02 15:18:39,543][187009] Fps is (10 sec: 3284.9, 60 sec: 3010.2, 300 sec: 3166.9). Total num frames: 8421376. Throughput: 0: 2970.7. Samples: 8422400. Policy #0 lag: (min: 12.0, avg: 15.0, max: 76.0)
[2026-02-02 15:18:39,543][187009] Avg episode reward: [(0, '1427.289')]
[2026-02-02 15:18:44,582][187009] Fps is (10 sec: 3277.7, 60 sec: 3004.6, 300 sec: 3166.2). Total num frames: 8437760. Throughput: 0: 3045.7. Samples: 8443392. Policy #0 lag: (min: 12.0, avg: 15.0, max: 76.0)
[2026-02-02 15:18:44,582][187009] Avg episode reward: [(0, '1427.673')]
[2026-02-02 15:18:49,534][187009] Fps is (10 sec: 3279.7, 60 sec: 3009.0, 300 sec: 3166.5). Total num frames: 8454144. Throughput: 0: 3124.1. Samples: 8464384. Policy #0 lag: (min: 4.0, avg: 7.0, max: 68.0)
[2026-02-02 15:18:49,535][187009] Avg episode reward: [(0, '1516.023')]
[2026-02-02 15:18:50,971][187009] Signal inference workers to stop experience collection... (1550 times)
[2026-02-02 15:18:51,328][187009] InferenceWorker_p0-w0: stopping experience collection (1550 times)
[2026-02-02 15:18:51,328][187009] Signal inference workers to resume experience collection... (1550 times)
[2026-02-02 15:18:51,328][187009] InferenceWorker_p0-w0: resuming experience collection (1550 times)
[2026-02-02 15:18:54,585][187009] Fps is (10 sec: 3275.9, 60 sec: 3002.4, 300 sec: 3165.8). Total num frames: 8470528. Throughput: 0: 3161.9. Samples: 8473600. Policy #0 lag: (min: 4.0, avg: 7.0, max: 68.0)
[2026-02-02 15:18:54,585][187009] Avg episode reward: [(0, '1589.534')]
[2026-02-02 15:18:59,581][187009] Fps is (10 sec: 3261.6, 60 sec: 3001.2, 300 sec: 3165.7). Total num frames: 8486912. Throughput: 0: 3248.7. Samples: 8495104. Policy #0 lag: (min: 4.0, avg: 7.0, max: 68.0)
[2026-02-02 15:18:59,581][187009] Avg episode reward: [(0, '1634.904')]
[2026-02-02 15:18:59,717][187009] Saving new best policy, reward=1634.904!
[2026-02-02 15:19:04,653][187009] Fps is (10 sec: 3254.5, 60 sec: 3002.5, 300 sec: 3139.3). Total num frames: 8503296. Throughput: 0: 3307.6. Samples: 8516096. Policy #0 lag: (min: 4.0, avg: 7.0, max: 68.0)
[2026-02-02 15:19:04,654][187009] Avg episode reward: [(0, '1600.586')]
[2026-02-02 15:19:09,584][187009] Fps is (10 sec: 3275.7, 60 sec: 3148.0, 300 sec: 3137.3). Total num frames: 8519680. Throughput: 0: 3333.7. Samples: 8525312. Policy #0 lag: (min: 4.0, avg: 7.0, max: 68.0)
[2026-02-02 15:19:09,584][187009] Avg episode reward: [(0, '1585.667')]
[2026-02-02 15:19:14,815][187009] Fps is (10 sec: 4030.8, 60 sec: 3404.8, 300 sec: 3135.8). Total num frames: 8544256. Throughput: 0: 3383.4. Samples: 8546304. Policy #0 lag: (min: 13.0, avg: 16.0, max: 77.0)
[2026-02-02 15:19:14,816][187009] Avg episode reward: [(0, '1549.570')]
[2026-02-02 15:19:19,661][187009] Fps is (10 sec: 4064.8, 60 sec: 3410.3, 300 sec: 3136.9). Total num frames: 8560640. Throughput: 0: 3418.9. Samples: 8567296. Policy #0 lag: (min: 13.0, avg: 16.0, max: 77.0)
[2026-02-02 15:19:19,661][187009] Avg episode reward: [(0, '1534.329')]
[2026-02-02 15:19:24,737][187009] Fps is (10 sec: 4128.2, 60 sec: 3540.8, 300 sec: 3164.1). Total num frames: 8585216. Throughput: 0: 3421.3. Samples: 8577024. Policy #0 lag: (min: 13.0, avg: 16.0, max: 77.0)
[2026-02-02 15:19:24,738][187009] Avg episode reward: [(0, '1571.178')]
[2026-02-02 15:19:29,614][187009] Fps is (10 sec: 4115.4, 60 sec: 3547.2, 300 sec: 3165.6). Total num frames: 8601600. Throughput: 0: 3445.0. Samples: 8598528. Policy #0 lag: (min: 13.0, avg: 16.0, max: 77.0)
[2026-02-02 15:19:29,614][187009] Avg episode reward: [(0, '1536.235')]
[2026-02-02 15:19:34,655][187009] Fps is (10 sec: 3304.0, 60 sec: 3545.7, 300 sec: 3165.1). Total num frames: 8617984. Throughput: 0: 3426.9. Samples: 8619008. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:19:34,655][187009] Avg episode reward: [(0, '1528.636')]
[2026-02-02 15:19:39,538][187009] Fps is (10 sec: 3301.9, 60 sec: 3550.2, 300 sec: 3166.9). Total num frames: 8634368. Throughput: 0: 3451.1. Samples: 8628736. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:19:39,538][187009] Avg episode reward: [(0, '1491.019')]
[2026-02-02 15:19:44,584][187009] Fps is (10 sec: 3300.1, 60 sec: 3549.7, 300 sec: 3166.1). Total num frames: 8650752. Throughput: 0: 3435.8. Samples: 8649728. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:19:44,585][187009] Avg episode reward: [(0, '1539.344')]
[2026-02-02 15:19:49,596][187009] Fps is (10 sec: 3258.0, 60 sec: 3546.2, 300 sec: 3165.7). Total num frames: 8667136. Throughput: 0: 3406.3. Samples: 8669184. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:19:49,596][187009] Avg episode reward: [(0, '1550.768')]
[2026-02-02 15:19:54,640][187009] Fps is (10 sec: 3258.5, 60 sec: 3546.6, 300 sec: 3165.6). Total num frames: 8683520. Throughput: 0: 3443.2. Samples: 8680448. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:19:54,641][187009] Avg episode reward: [(0, '1556.023')]
[2026-02-02 15:19:59,658][187009] Fps is (10 sec: 3256.4, 60 sec: 3545.3, 300 sec: 3165.2). Total num frames: 8699904. Throughput: 0: 3448.1. Samples: 8700928. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:19:59,658][187009] Avg episode reward: [(0, '1534.667')]
[2026-02-02 15:20:04,632][187009] Fps is (10 sec: 3279.6, 60 sec: 3551.2, 300 sec: 3165.9). Total num frames: 8716288. Throughput: 0: 3415.6. Samples: 8720896. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:20:04,632][187009] Avg episode reward: [(0, '1516.203')]
[2026-02-02 15:20:09,517][187009] Fps is (10 sec: 3323.7, 60 sec: 3553.8, 300 sec: 3166.7). Total num frames: 8732672. Throughput: 0: 3464.4. Samples: 8732160. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:20:09,517][187009] Avg episode reward: [(0, '1565.162')]
[2026-02-02 15:20:12,177][187009] Signal inference workers to stop experience collection... (1600 times)
[2026-02-02 15:20:12,178][187009] Signal inference workers to resume experience collection... (1600 times)
[2026-02-02 15:20:12,425][187009] InferenceWorker_p0-w0: stopping experience collection (1600 times)
[2026-02-02 15:20:12,425][187009] InferenceWorker_p0-w0: resuming experience collection (1600 times)
[2026-02-02 15:20:14,583][187009] Fps is (10 sec: 3292.9, 60 sec: 3426.6, 300 sec: 3165.5). Total num frames: 8749056. Throughput: 0: 3404.3. Samples: 8751616. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:20:14,583][187009] Avg episode reward: [(0, '1571.385')]
[2026-02-02 15:20:19,593][187009] Fps is (10 sec: 3252.0, 60 sec: 3417.2, 300 sec: 3165.2). Total num frames: 8765440. Throughput: 0: 3418.0. Samples: 8772608. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:20:19,594][187009] Avg episode reward: [(0, '1604.052')]
[2026-02-02 15:20:24,624][187009] Fps is (10 sec: 3263.6, 60 sec: 3283.0, 300 sec: 3139.6). Total num frames: 8781824. Throughput: 0: 3418.2. Samples: 8782848. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:20:24,624][187009] Avg episode reward: [(0, '1544.329')]
[2026-02-02 15:20:29,636][187009] Fps is (10 sec: 3262.8, 60 sec: 3275.6, 300 sec: 3112.2). Total num frames: 8798208. Throughput: 0: 3409.4. Samples: 8803328. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:20:29,637][187009] Avg episode reward: [(0, '1584.055')]
[2026-02-02 15:20:34,600][187009] Fps is (10 sec: 3284.5, 60 sec: 3279.8, 300 sec: 3110.2). Total num frames: 8814592. Throughput: 0: 3458.5. Samples: 8824832. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:20:34,600][187009] Avg episode reward: [(0, '1602.910')]
[2026-02-02 15:20:34,746][187009] Saving /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_accel_policy3_aggressive_magpie_refined_params_02022026_smooth_aggressive_ttc/checkpoint_p0/checkpoint_000034432_8814592.pth...
[2026-02-02 15:20:34,750][187009] Removing /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_accel_policy3_aggressive_magpie_refined_params_02022026_smooth_aggressive_ttc/checkpoint_p0/checkpoint_000031488_8060928.pth
[2026-02-02 15:20:39,600][187009] Fps is (10 sec: 3288.7, 60 sec: 3273.4, 300 sec: 3110.2). Total num frames: 8830976. Throughput: 0: 3427.8. Samples: 8834560. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:20:39,600][187009] Avg episode reward: [(0, '1615.130')]
[2026-02-02 15:20:44,582][187009] Fps is (10 sec: 3282.7, 60 sec: 3276.9, 300 sec: 3113.3). Total num frames: 8847360. Throughput: 0: 3441.9. Samples: 8855552. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:20:44,582][187009] Avg episode reward: [(0, '1620.587')]
[2026-02-02 15:20:49,533][187009] Fps is (10 sec: 3298.9, 60 sec: 3280.2, 300 sec: 3166.2). Total num frames: 8863744. Throughput: 0: 3466.4. Samples: 8876544. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:20:49,533][187009] Avg episode reward: [(0, '1561.489')]
[2026-02-02 15:20:54,571][187009] Fps is (10 sec: 3280.6, 60 sec: 3280.6, 300 sec: 3165.6). Total num frames: 8880128. Throughput: 0: 3409.3. Samples: 8885760. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:20:54,571][187009] Avg episode reward: [(0, '1584.761')]
[2026-02-02 15:20:59,862][187009] Fps is (10 sec: 3965.5, 60 sec: 3401.8, 300 sec: 3190.7). Total num frames: 8904704. Throughput: 0: 3426.2. Samples: 8906752. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:20:59,862][187009] Avg episode reward: [(0, '1561.179')]
[2026-02-02 15:21:04,611][187009] Fps is (10 sec: 4079.5, 60 sec: 3414.5, 300 sec: 3192.8). Total num frames: 8921088. Throughput: 0: 3457.5. Samples: 8928256. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:21:04,611][187009] Avg episode reward: [(0, '1581.480')]
[2026-02-02 15:21:09,630][187009] Fps is (10 sec: 4193.5, 60 sec: 3543.2, 300 sec: 3220.4). Total num frames: 8945664. Throughput: 0: 3447.0. Samples: 8937984. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:21:09,630][187009] Avg episode reward: [(0, '1535.440')]
[2026-02-02 15:21:14,629][187009] Fps is (10 sec: 4088.7, 60 sec: 3547.1, 300 sec: 3220.3). Total num frames: 8962048. Throughput: 0: 3470.8. Samples: 8959488. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:21:14,629][187009] Avg episode reward: [(0, '1584.955')]
[2026-02-02 15:21:19,587][187009] Fps is (10 sec: 3291.0, 60 sec: 3550.3, 300 sec: 3221.1). Total num frames: 8978432. Throughput: 0: 3437.1. Samples: 8979456. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:21:19,587][187009] Avg episode reward: [(0, '1622.024')]
[2026-02-02 15:21:24,579][187009] Fps is (10 sec: 3293.2, 60 sec: 3552.5, 300 sec: 3221.7). Total num frames: 8994816. Throughput: 0: 3449.1. Samples: 8989696. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:21:24,579][187009] Avg episode reward: [(0, '1662.145')]
[2026-02-02 15:21:24,707][187009] Saving new best policy, reward=1662.145!
[2026-02-02 15:21:29,570][187009] Fps is (10 sec: 3282.2, 60 sec: 3553.8, 300 sec: 3222.2). Total num frames: 9011200. Throughput: 0: 3459.8. Samples: 9011200. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:21:29,570][187009] Avg episode reward: [(0, '1628.435')]
[2026-02-02 15:21:32,696][187009] Signal inference workers to stop experience collection... (1650 times)
[2026-02-02 15:21:33,078][187009] InferenceWorker_p0-w0: stopping experience collection (1650 times)
[2026-02-02 15:21:33,081][187009] Signal inference workers to resume experience collection... (1650 times)
[2026-02-02 15:21:33,220][187009] InferenceWorker_p0-w0: resuming experience collection (1650 times)
[2026-02-02 15:21:34,544][187009] Fps is (10 sec: 3288.4, 60 sec: 3553.2, 300 sec: 3221.4). Total num frames: 9027584. Throughput: 0: 3423.9. Samples: 9030656. Policy #0 lag: (min: 13.0, avg: 16.0, max: 77.0)
[2026-02-02 15:21:34,544][187009] Avg episode reward: [(0, '1609.477')]
[2026-02-02 15:21:39,628][187009] Fps is (10 sec: 3257.9, 60 sec: 3548.2, 300 sec: 3223.2). Total num frames: 9043968. Throughput: 0: 3465.8. Samples: 9041920. Policy #0 lag: (min: 13.0, avg: 16.0, max: 77.0)
[2026-02-02 15:21:39,629][187009] Avg episode reward: [(0, '1579.150')]
[2026-02-02 15:21:44,644][187009] Fps is (10 sec: 3244.2, 60 sec: 3546.2, 300 sec: 3275.8). Total num frames: 9060352. Throughput: 0: 3452.8. Samples: 9061376. Policy #0 lag: (min: 13.0, avg: 16.0, max: 77.0)
[2026-02-02 15:21:44,644][187009] Avg episode reward: [(0, '1547.363')]
[2026-02-02 15:21:49,645][187009] Fps is (10 sec: 3271.4, 60 sec: 3543.3, 300 sec: 3277.2). Total num frames: 9076736. Throughput: 0: 3433.5. Samples: 9082880. Policy #0 lag: (min: 13.0, avg: 16.0, max: 77.0)
[2026-02-02 15:21:49,645][187009] Avg episode reward: [(0, '1530.649')]
[2026-02-02 15:21:54,523][187009] Fps is (10 sec: 3317.2, 60 sec: 3552.7, 300 sec: 3277.6). Total num frames: 9093120. Throughput: 0: 3478.5. Samples: 9094144. Policy #0 lag: (min: 13.0, avg: 16.0, max: 77.0)
[2026-02-02 15:21:54,523][187009] Avg episode reward: [(0, '1554.907')]
[2026-02-02 15:21:59,600][187009] Fps is (10 sec: 3291.6, 60 sec: 3428.3, 300 sec: 3276.3). Total num frames: 9109504. Throughput: 0: 3426.9. Samples: 9113600. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:21:59,600][187009] Avg episode reward: [(0, '1547.281')]
[2026-02-02 15:22:04,614][187009] Fps is (10 sec: 3247.2, 60 sec: 3413.2, 300 sec: 3276.8). Total num frames: 9125888. Throughput: 0: 3445.4. Samples: 9134592. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:22:04,614][187009] Avg episode reward: [(0, '1569.769')]
[2026-02-02 15:22:09,636][187009] Fps is (10 sec: 3265.1, 60 sec: 3276.5, 300 sec: 3276.5). Total num frames: 9142272. Throughput: 0: 3431.8. Samples: 9144320. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:22:09,636][187009] Avg episode reward: [(0, '1563.387')]
[2026-02-02 15:22:14,594][187009] Fps is (10 sec: 3283.2, 60 sec: 3278.7, 300 sec: 3276.6). Total num frames: 9158656. Throughput: 0: 3422.9. Samples: 9165312. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:22:14,594][187009] Avg episode reward: [(0, '1641.993')]
[2026-02-02 15:22:19,628][187009] Fps is (10 sec: 3279.2, 60 sec: 3274.5, 300 sec: 3331.4). Total num frames: 9175040. Throughput: 0: 3452.4. Samples: 9186304. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:22:19,629][187009] Avg episode reward: [(0, '1615.981')]
[2026-02-02 15:22:24,566][187009] Fps is (10 sec: 3286.0, 60 sec: 3277.5, 300 sec: 3333.0). Total num frames: 9191424. Throughput: 0: 3429.5. Samples: 9196032. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:22:24,566][187009] Avg episode reward: [(0, '1652.396')]
[2026-02-02 15:22:29,608][187009] Fps is (10 sec: 3283.5, 60 sec: 3274.7, 300 sec: 3332.3). Total num frames: 9207808. Throughput: 0: 3461.6. Samples: 9217024. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:22:29,608][187009] Avg episode reward: [(0, '1659.564')]
[2026-02-02 15:22:34,598][187009] Fps is (10 sec: 3266.3, 60 sec: 3273.8, 300 sec: 3333.2). Total num frames: 9224192. Throughput: 0: 3451.0. Samples: 9238016. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:22:34,598][187009] Avg episode reward: [(0, '1665.889')]
[2026-02-02 15:22:34,965][187009] Saving /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_accel_policy3_aggressive_magpie_refined_params_02022026_smooth_aggressive_ttc/checkpoint_p0/checkpoint_000036064_9232384.pth...
[2026-02-02 15:22:34,970][187009] Removing /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_accel_policy3_aggressive_magpie_refined_params_02022026_smooth_aggressive_ttc/checkpoint_p0/checkpoint_000032832_8404992.pth
[2026-02-02 15:22:34,970][187009] Saving new best policy, reward=1665.889!
[2026-02-02 15:22:39,711][187009] Fps is (10 sec: 4054.3, 60 sec: 3408.7, 300 sec: 3358.8). Total num frames: 9248768. Throughput: 0: 3399.1. Samples: 9247744. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:22:39,711][187009] Avg episode reward: [(0, '1636.178')]
[2026-02-02 15:22:44,813][187009] Fps is (10 sec: 4811.8, 60 sec: 3539.9, 300 sec: 3385.9). Total num frames: 9273344. Throughput: 0: 3431.2. Samples: 9268736. Policy #0 lag: (min: 9.0, avg: 12.0, max: 73.0)
[2026-02-02 15:22:44,813][187009] Avg episode reward: [(0, '1637.699')]
[2026-02-02 15:22:49,173][187009] Signal inference workers to stop experience collection... (1700 times)
[2026-02-02 15:22:49,520][187009] InferenceWorker_p0-w0: stopping experience collection (1700 times)
[2026-02-02 15:22:49,520][187009] Signal inference workers to resume experience collection... (1700 times)
[2026-02-02 15:22:49,521][187009] Fps is (10 sec: 4175.4, 60 sec: 3557.2, 300 sec: 3388.3). Total num frames: 9289728. Throughput: 0: 3466.0. Samples: 9290240. Policy #0 lag: (min: 9.0, avg: 12.0, max: 73.0)
[2026-02-02 15:22:49,521][187009] Avg episode reward: [(0, '1615.051')]
[2026-02-02 15:22:49,521][187009] InferenceWorker_p0-w0: resuming experience collection (1700 times)
[2026-02-02 15:22:54,579][187009] Fps is (10 sec: 3355.3, 60 sec: 3546.5, 300 sec: 3387.3). Total num frames: 9306112. Throughput: 0: 3463.2. Samples: 9299968. Policy #0 lag: (min: 9.0, avg: 12.0, max: 73.0)
[2026-02-02 15:22:54,579][187009] Avg episode reward: [(0, '1629.085')]
[2026-02-02 15:22:59,525][187009] Fps is (10 sec: 3275.2, 60 sec: 3554.3, 300 sec: 3389.1). Total num frames: 9322496. Throughput: 0: 3464.1. Samples: 9320960. Policy #0 lag: (min: 9.0, avg: 12.0, max: 73.0)
[2026-02-02 15:22:59,526][187009] Avg episode reward: [(0, '1647.399')]
[2026-02-02 15:23:04,580][187009] Fps is (10 sec: 3276.5, 60 sec: 3551.8, 300 sec: 3417.4). Total num frames: 9338880. Throughput: 0: 3417.0. Samples: 9339904. Policy #0 lag: (min: 9.0, avg: 12.0, max: 73.0)
[2026-02-02 15:23:04,580][187009] Avg episode reward: [(0, '1597.926')]
[2026-02-02 15:23:09,540][187009] Fps is (10 sec: 3272.0, 60 sec: 3555.5, 300 sec: 3444.9). Total num frames: 9355264. Throughput: 0: 3449.4. Samples: 9351168. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:23:09,540][187009] Avg episode reward: [(0, '1554.612')]
[2026-02-02 15:23:14,573][187009] Fps is (10 sec: 3279.3, 60 sec: 3551.1, 300 sec: 3443.8). Total num frames: 9371648. Throughput: 0: 3450.2. Samples: 9372160. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:23:14,573][187009] Avg episode reward: [(0, '1522.845')]
[2026-02-02 15:23:19,524][187009] Fps is (10 sec: 3282.2, 60 sec: 3556.1, 300 sec: 3444.1). Total num frames: 9388032. Throughput: 0: 3430.4. Samples: 9392128. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:23:19,524][187009] Avg episode reward: [(0, '1578.541')]
[2026-02-02 15:23:24,570][187009] Fps is (10 sec: 3277.6, 60 sec: 3549.6, 300 sec: 3443.4). Total num frames: 9404416. Throughput: 0: 3458.3. Samples: 9402880. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:23:24,571][187009] Avg episode reward: [(0, '1634.472')]
[2026-02-02 15:23:29,558][187009] Fps is (10 sec: 3265.6, 60 sec: 3552.8, 300 sec: 3443.7). Total num frames: 9420800. Throughput: 0: 3444.2. Samples: 9422848. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:23:29,558][187009] Avg episode reward: [(0, '1556.045')]
[2026-02-02 15:23:34,612][187009] Fps is (10 sec: 3263.0, 60 sec: 3549.0, 300 sec: 3442.6). Total num frames: 9437184. Throughput: 0: 3406.4. Samples: 9443840. Policy #0 lag: (min: 6.0, avg: 9.0, max: 70.0)
[2026-02-02 15:23:34,613][187009] Avg episode reward: [(0, '1551.324')]
[2026-02-02 15:23:39,519][187009] Fps is (10 sec: 3289.8, 60 sec: 3424.3, 300 sec: 3444.2). Total num frames: 9453568. Throughput: 0: 3440.7. Samples: 9454592. Policy #0 lag: (min: 6.0, avg: 9.0, max: 70.0)
[2026-02-02 15:23:39,519][187009] Avg episode reward: [(0, '1486.200')]
[2026-02-02 15:23:44,566][187009] Fps is (10 sec: 3292.2, 60 sec: 3290.4, 300 sec: 3443.0). Total num frames: 9469952. Throughput: 0: 3410.3. Samples: 9474560. Policy #0 lag: (min: 6.0, avg: 9.0, max: 70.0)
[2026-02-02 15:23:44,566][187009] Avg episode reward: [(0, '1535.695')]
[2026-02-02 15:23:49,601][187009] Fps is (10 sec: 3249.9, 60 sec: 3272.4, 300 sec: 3443.2). Total num frames: 9486336. Throughput: 0: 3457.2. Samples: 9495552. Policy #0 lag: (min: 6.0, avg: 9.0, max: 70.0)
[2026-02-02 15:23:49,602][187009] Avg episode reward: [(0, '1571.877')]
[2026-02-02 15:23:54,634][187009] Fps is (10 sec: 3254.7, 60 sec: 3273.8, 300 sec: 3442.8). Total num frames: 9502720. Throughput: 0: 3417.6. Samples: 9505280. Policy #0 lag: (min: 6.0, avg: 9.0, max: 70.0)
[2026-02-02 15:23:54,634][187009] Avg episode reward: [(0, '1595.541')]
[2026-02-02 15:23:59,540][187009] Fps is (10 sec: 3296.9, 60 sec: 3276.0, 300 sec: 3444.7). Total num frames: 9519104. Throughput: 0: 3427.2. Samples: 9526272. Policy #0 lag: (min: 4.0, avg: 7.0, max: 68.0)
[2026-02-02 15:23:59,541][187009] Avg episode reward: [(0, '1591.762')]
[2026-02-02 15:24:04,545][187009] Fps is (10 sec: 3306.3, 60 sec: 3278.7, 300 sec: 3443.9). Total num frames: 9535488. Throughput: 0: 3445.9. Samples: 9547264. Policy #0 lag: (min: 4.0, avg: 7.0, max: 68.0)
[2026-02-02 15:24:04,545][187009] Avg episode reward: [(0, '1529.882')]
[2026-02-02 15:24:09,598][187009] Fps is (10 sec: 3258.0, 60 sec: 3273.6, 300 sec: 3418.2). Total num frames: 9551872. Throughput: 0: 3411.2. Samples: 9556480. Policy #0 lag: (min: 4.0, avg: 7.0, max: 68.0)
[2026-02-02 15:24:09,598][187009] Avg episode reward: [(0, '1534.261')]
[2026-02-02 15:24:10,367][187009] Signal inference workers to stop experience collection... (1750 times)
[2026-02-02 15:24:10,367][187009] Signal inference workers to resume experience collection... (1750 times)
[2026-02-02 15:24:10,621][187009] InferenceWorker_p0-w0: stopping experience collection (1750 times)
[2026-02-02 15:24:10,621][187009] InferenceWorker_p0-w0: resuming experience collection (1750 times)
[2026-02-02 15:24:14,539][187009] Fps is (10 sec: 3278.7, 60 sec: 3278.6, 300 sec: 3417.1). Total num frames: 9568256. Throughput: 0: 3448.9. Samples: 9577984. Policy #0 lag: (min: 4.0, avg: 7.0, max: 68.0)
[2026-02-02 15:24:14,539][187009] Avg episode reward: [(0, '1563.631')]
[2026-02-02 15:24:19,581][187009] Fps is (10 sec: 3282.5, 60 sec: 3273.7, 300 sec: 3389.7). Total num frames: 9584640. Throughput: 0: 3415.7. Samples: 9597440. Policy #0 lag: (min: 4.0, avg: 7.0, max: 68.0)
[2026-02-02 15:24:19,581][187009] Avg episode reward: [(0, '1620.370')]
[2026-02-02 15:24:24,523][187009] Fps is (10 sec: 3281.9, 60 sec: 3279.4, 300 sec: 3388.9). Total num frames: 9601024. Throughput: 0: 3390.2. Samples: 9607168. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:24:24,524][187009] Avg episode reward: [(0, '1630.683')]
[2026-02-02 15:24:29,674][187009] Fps is (10 sec: 4058.3, 60 sec: 3406.8, 300 sec: 3415.4). Total num frames: 9625600. Throughput: 0: 3405.2. Samples: 9628160. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:24:29,674][187009] Avg episode reward: [(0, '1644.454')]
[2026-02-02 15:24:34,779][187009] Fps is (10 sec: 4792.6, 60 sec: 3540.0, 300 sec: 3440.6). Total num frames: 9650176. Throughput: 0: 3411.2. Samples: 9649664. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:24:34,780][187009] Avg episode reward: [(0, '1627.094')]
[2026-02-02 15:24:34,782][187009] Saving /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_accel_policy3_aggressive_magpie_refined_params_02022026_smooth_aggressive_ttc/checkpoint_p0/checkpoint_000037696_9650176.pth...
[2026-02-02 15:24:34,786][187009] Removing /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_accel_policy3_aggressive_magpie_refined_params_02022026_smooth_aggressive_ttc/checkpoint_p0/checkpoint_000034432_8814592.pth
[2026-02-02 15:24:39,552][187009] Fps is (10 sec: 4146.4, 60 sec: 3547.9, 300 sec: 3443.8). Total num frames: 9666560. Throughput: 0: 3430.9. Samples: 9659392. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:24:39,553][187009] Avg episode reward: [(0, '1603.617')]
[2026-02-02 15:24:44,569][187009] Fps is (10 sec: 3347.3, 60 sec: 3549.7, 300 sec: 3443.7). Total num frames: 9682944. Throughput: 0: 3422.6. Samples: 9680384. Policy #0 lag: (min: 42.0, avg: 45.0, max: 106.0)
[2026-02-02 15:24:44,569][187009] Avg episode reward: [(0, '1571.314')]
[2026-02-02 15:24:49,623][187009] Fps is (10 sec: 3253.7, 60 sec: 3548.6, 300 sec: 3443.6). Total num frames: 9699328. Throughput: 0: 3396.0. Samples: 9700352. Policy #0 lag: (min: 42.0, avg: 45.0, max: 106.0)
[2026-02-02 15:24:49,624][187009] Avg episode reward: [(0, '1561.382')]
[2026-02-02 15:24:54,622][187009] Fps is (10 sec: 3259.4, 60 sec: 3550.6, 300 sec: 3443.8). Total num frames: 9715712. Throughput: 0: 3434.3. Samples: 9711104. Policy #0 lag: (min: 42.0, avg: 45.0, max: 106.0)
[2026-02-02 15:24:54,622][187009] Avg episode reward: [(0, '1578.929')]
[2026-02-02 15:24:59,622][187009] Fps is (10 sec: 3277.4, 60 sec: 3545.1, 300 sec: 3443.5). Total num frames: 9732096. Throughput: 0: 3429.8. Samples: 9732608. Policy #0 lag: (min: 42.0, avg: 45.0, max: 106.0)
[2026-02-02 15:24:59,622][187009] Avg episode reward: [(0, '1644.607')]
[2026-02-02 15:25:04,520][187009] Fps is (10 sec: 3310.6, 60 sec: 3551.3, 300 sec: 3443.4). Total num frames: 9748480. Throughput: 0: 3418.0. Samples: 9751040. Policy #0 lag: (min: 42.0, avg: 45.0, max: 106.0)
[2026-02-02 15:25:04,520][187009] Avg episode reward: [(0, '1675.949')]
[2026-02-02 15:25:04,674][187009] Saving new best policy, reward=1675.949!
[2026-02-02 15:25:09,610][187009] Fps is (10 sec: 3280.5, 60 sec: 3549.1, 300 sec: 3443.1). Total num frames: 9764864. Throughput: 0: 3418.1. Samples: 9761280. Policy #0 lag: (min: 45.0, avg: 48.0, max: 109.0)
[2026-02-02 15:25:09,611][187009] Avg episode reward: [(0, '1696.067')]
[2026-02-02 15:25:09,758][187009] Saving new best policy, reward=1696.067!
[2026-02-02 15:25:14,541][187009] Fps is (10 sec: 3269.9, 60 sec: 3549.7, 300 sec: 3444.0). Total num frames: 9781248. Throughput: 0: 3412.0. Samples: 9781248. Policy #0 lag: (min: 45.0, avg: 48.0, max: 109.0)
[2026-02-02 15:25:14,541][187009] Avg episode reward: [(0, '1672.119')]
[2026-02-02 15:25:19,578][187009] Fps is (10 sec: 3287.4, 60 sec: 3550.0, 300 sec: 3443.9). Total num frames: 9797632. Throughput: 0: 3360.1. Samples: 9800192. Policy #0 lag: (min: 45.0, avg: 48.0, max: 109.0)
[2026-02-02 15:25:19,578][187009] Avg episode reward: [(0, '1673.446')]
[2026-02-02 15:25:24,639][187009] Fps is (10 sec: 3245.0, 60 sec: 3543.0, 300 sec: 3443.4). Total num frames: 9814016. Throughput: 0: 3372.7. Samples: 9811456. Policy #0 lag: (min: 45.0, avg: 48.0, max: 109.0)
[2026-02-02 15:25:24,639][187009] Avg episode reward: [(0, '1626.308')]
[2026-02-02 15:25:29,631][187009] Fps is (10 sec: 3259.6, 60 sec: 3415.8, 300 sec: 3443.1). Total num frames: 9830400. Throughput: 0: 3351.8. Samples: 9831424. Policy #0 lag: (min: 45.0, avg: 48.0, max: 109.0)
[2026-02-02 15:25:29,631][187009] Avg episode reward: [(0, '1623.741')]
[2026-02-02 15:25:32,198][187009] Signal inference workers to stop experience collection... (1800 times)
[2026-02-02 15:25:32,575][187009] InferenceWorker_p0-w0: stopping experience collection (1800 times)
[2026-02-02 15:25:32,578][187009] Signal inference workers to resume experience collection... (1800 times)
[2026-02-02 15:25:32,719][187009] InferenceWorker_p0-w0: resuming experience collection (1800 times)
[2026-02-02 15:25:34,605][187009] Fps is (10 sec: 3287.9, 60 sec: 3286.3, 300 sec: 3443.4). Total num frames: 9846784. Throughput: 0: 3357.8. Samples: 9851392. Policy #0 lag: (min: 45.0, avg: 48.0, max: 109.0)
[2026-02-02 15:25:34,606][187009] Avg episode reward: [(0, '1630.589')]
[2026-02-02 15:25:39,553][187009] Fps is (10 sec: 3302.5, 60 sec: 3276.8, 300 sec: 3443.8). Total num frames: 9863168. Throughput: 0: 3373.0. Samples: 9862656. Policy #0 lag: (min: 8.0, avg: 11.0, max: 72.0)
[2026-02-02 15:25:39,553][187009] Avg episode reward: [(0, '1644.903')]
[2026-02-02 15:25:44,587][187009] Fps is (10 sec: 3282.8, 60 sec: 3275.8, 300 sec: 3442.8). Total num frames: 9879552. Throughput: 0: 3324.9. Samples: 9882112. Policy #0 lag: (min: 8.0, avg: 11.0, max: 72.0)
[2026-02-02 15:25:44,587][187009] Avg episode reward: [(0, '1613.985')]
[2026-02-02 15:25:49,627][187009] Fps is (10 sec: 3252.7, 60 sec: 3276.6, 300 sec: 3442.8). Total num frames: 9895936. Throughput: 0: 3371.2. Samples: 9903104. Policy #0 lag: (min: 8.0, avg: 11.0, max: 72.0)
[2026-02-02 15:25:49,627][187009] Avg episode reward: [(0, '1629.334')]
[2026-02-02 15:25:54,542][187009] Fps is (10 sec: 3291.8, 60 sec: 3281.2, 300 sec: 3419.4). Total num frames: 9912320. Throughput: 0: 3384.4. Samples: 9913344. Policy #0 lag: (min: 8.0, avg: 11.0, max: 72.0)
[2026-02-02 15:25:54,542][187009] Avg episode reward: [(0, '1647.742')]
[2026-02-02 15:25:59,587][187009] Fps is (10 sec: 3290.2, 60 sec: 3278.7, 300 sec: 3415.9). Total num frames: 9928704. Throughput: 0: 3387.1. Samples: 9933824. Policy #0 lag: (min: 8.0, avg: 11.0, max: 72.0)
[2026-02-02 15:25:59,587][187009] Avg episode reward: [(0, '1602.464')]
[2026-02-02 15:26:04,584][187009] Fps is (10 sec: 3263.1, 60 sec: 3273.3, 300 sec: 3388.4). Total num frames: 9945088. Throughput: 0: 3424.3. Samples: 9954304. Policy #0 lag: (min: 8.0, avg: 11.0, max: 72.0)
[2026-02-02 15:26:04,584][187009] Avg episode reward: [(0, '1567.710')]
[2026-02-02 15:26:09,616][187009] Fps is (10 sec: 3267.1, 60 sec: 3276.5, 300 sec: 3388.0). Total num frames: 9961472. Throughput: 0: 3392.3. Samples: 9964032. Policy #0 lag: (min: 0.0, avg: 3.0, max: 64.0)
[2026-02-02 15:26:09,617][187009] Avg episode reward: [(0, '1540.662')]
[2026-02-02 15:26:14,517][187009] Fps is (10 sec: 3298.7, 60 sec: 3278.1, 300 sec: 3388.7). Total num frames: 9977856. Throughput: 0: 3422.0. Samples: 9985024. Policy #0 lag: (min: 0.0, avg: 3.0, max: 64.0)
[2026-02-02 15:26:14,517][187009] Avg episode reward: [(0, '1564.994')]
[2026-02-02 15:26:19,618][187009] Fps is (10 sec: 3276.2, 60 sec: 3274.6, 300 sec: 3387.4). Total num frames: 9994240. Throughput: 0: 3435.1. Samples: 10006016. Policy #0 lag: (min: 0.0, avg: 3.0, max: 64.0)
[2026-02-02 15:26:19,618][187009] Avg episode reward: [(0, '1554.430')]
[2026-02-02 15:26:24,636][187009] Fps is (10 sec: 3238.3, 60 sec: 3277.0, 300 sec: 3387.1). Total num frames: 10010624. Throughput: 0: 3395.7. Samples: 10015744. Policy #0 lag: (min: 0.0, avg: 3.0, max: 64.0)
[2026-02-02 15:26:24,636][187009] Avg episode reward: [(0, '1584.319')]
[2026-02-02 15:26:29,614][187009] Fps is (10 sec: 3278.2, 60 sec: 3277.7, 300 sec: 3387.1). Total num frames: 10027008. Throughput: 0: 3434.0. Samples: 10036736. Policy #0 lag: (min: 0.0, avg: 3.0, max: 64.0)
[2026-02-02 15:26:29,614][187009] Avg episode reward: [(0, '1653.977')]
[2026-02-02 15:26:34,614][187009] Fps is (10 sec: 3284.0, 60 sec: 3276.3, 300 sec: 3388.0). Total num frames: 10043392. Throughput: 0: 3425.7. Samples: 10057216. Policy #0 lag: (min: 0.0, avg: 3.0, max: 64.0)
[2026-02-02 15:26:34,614][187009] Avg episode reward: [(0, '1673.769')]
[2026-02-02 15:26:34,984][187009] Saving /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_accel_policy3_aggressive_magpie_refined_params_02022026_smooth_aggressive_ttc/checkpoint_p0/checkpoint_000039264_10051584.pth...
[2026-02-02 15:26:34,988][187009] Removing /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_accel_policy3_aggressive_magpie_refined_params_02022026_smooth_aggressive_ttc/checkpoint_p0/checkpoint_000036064_9232384.pth
[2026-02-02 15:26:39,872][187009] Fps is (10 sec: 3194.5, 60 sec: 3259.5, 300 sec: 3385.3). Total num frames: 10059776. Throughput: 0: 3377.2. Samples: 10066432. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:26:39,872][187009] Avg episode reward: [(0, '1674.468')]
[2026-02-02 15:26:44,620][187009] Fps is (10 sec: 4093.4, 60 sec: 3411.4, 300 sec: 3415.9). Total num frames: 10084352. Throughput: 0: 3410.8. Samples: 10087424. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:26:44,621][187009] Avg episode reward: [(0, '1692.602')]
[2026-02-02 15:26:49,571][187009] Signal inference workers to stop experience collection... (1850 times)
[2026-02-02 15:26:49,571][187009] Fps is (10 sec: 4222.8, 60 sec: 3416.5, 300 sec: 3415.1). Total num frames: 10100736. Throughput: 0: 3414.3. Samples: 10107904. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:26:49,571][187009] Avg episode reward: [(0, '1681.013')]
[2026-02-02 15:26:49,945][187009] InferenceWorker_p0-w0: stopping experience collection (1850 times)
[2026-02-02 15:26:49,946][187009] Signal inference workers to resume experience collection... (1850 times)
[2026-02-02 15:26:49,946][187009] InferenceWorker_p0-w0: resuming experience collection (1850 times)
[2026-02-02 15:26:54,866][187009] Fps is (10 sec: 3997.7, 60 sec: 3530.8, 300 sec: 3440.3). Total num frames: 10125312. Throughput: 0: 3394.5. Samples: 10117632. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:26:54,866][187009] Avg episode reward: [(0, '1672.524')]
[2026-02-02 15:26:59,588][187009] Fps is (10 sec: 4089.4, 60 sec: 3549.8, 300 sec: 3443.7). Total num frames: 10141696. Throughput: 0: 3396.6. Samples: 10138112. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:26:59,588][187009] Avg episode reward: [(0, '1642.142')]
[2026-02-02 15:27:04,520][187009] Fps is (10 sec: 3394.2, 60 sec: 3553.6, 300 sec: 3444.8). Total num frames: 10158080. Throughput: 0: 3409.4. Samples: 10159104. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:27:04,521][187009] Avg episode reward: [(0, '1649.914')]
[2026-02-02 15:27:09,547][187009] Fps is (10 sec: 3290.1, 60 sec: 3554.0, 300 sec: 3444.0). Total num frames: 10174464. Throughput: 0: 3397.3. Samples: 10168320. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:27:09,547][187009] Avg episode reward: [(0, '1629.327')]
[2026-02-02 15:27:14,525][187009] Fps is (10 sec: 3275.3, 60 sec: 3549.4, 300 sec: 3444.6). Total num frames: 10190848. Throughput: 0: 3385.9. Samples: 10188800. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:27:14,525][187009] Avg episode reward: [(0, '1624.399')]
[2026-02-02 15:27:19,608][187009] Fps is (10 sec: 3256.9, 60 sec: 3550.5, 300 sec: 3442.9). Total num frames: 10207232. Throughput: 0: 3356.9. Samples: 10208256. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:27:19,609][187009] Avg episode reward: [(0, '1642.518')]
[2026-02-02 15:27:24,618][187009] Fps is (10 sec: 3246.6, 60 sec: 3550.9, 300 sec: 3443.3). Total num frames: 10223616. Throughput: 0: 3421.2. Samples: 10219520. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:27:24,618][187009] Avg episode reward: [(0, '1601.653')]
[2026-02-02 15:27:29,643][187009] Fps is (10 sec: 3265.4, 60 sec: 3548.1, 300 sec: 3442.9). Total num frames: 10240000. Throughput: 0: 3411.6. Samples: 10241024. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:27:29,644][187009] Avg episode reward: [(0, '1564.941')]
[2026-02-02 15:27:34,575][187009] Fps is (10 sec: 3291.1, 60 sec: 3552.2, 300 sec: 3417.2). Total num frames: 10256384. Throughput: 0: 3390.3. Samples: 10260480. Policy #0 lag: (min: 1.0, avg: 4.0, max: 65.0)
[2026-02-02 15:27:34,575][187009] Avg episode reward: [(0, '1506.451')]
[2026-02-02 15:27:39,612][187009] Fps is (10 sec: 3287.1, 60 sec: 3565.3, 300 sec: 3390.2). Total num frames: 10272768. Throughput: 0: 3455.6. Samples: 10272256. Policy #0 lag: (min: 1.0, avg: 4.0, max: 65.0)
[2026-02-02 15:27:39,612][187009] Avg episode reward: [(0, '1559.439')]
[2026-02-02 15:27:44,639][187009] Fps is (10 sec: 3255.8, 60 sec: 3412.3, 300 sec: 3386.5). Total num frames: 10289152. Throughput: 0: 3398.0. Samples: 10291200. Policy #0 lag: (min: 1.0, avg: 4.0, max: 65.0)
[2026-02-02 15:27:44,640][187009] Avg episode reward: [(0, '1535.994')]
[2026-02-02 15:27:49,563][187009] Fps is (10 sec: 3292.9, 60 sec: 3413.8, 300 sec: 3388.1). Total num frames: 10305536. Throughput: 0: 3398.7. Samples: 10312192. Policy #0 lag: (min: 1.0, avg: 4.0, max: 65.0)
[2026-02-02 15:27:49,563][187009] Avg episode reward: [(0, '1569.494')]
[2026-02-02 15:27:54,642][187009] Fps is (10 sec: 3276.0, 60 sec: 3289.1, 300 sec: 3386.5). Total num frames: 10321920. Throughput: 0: 3428.9. Samples: 10322944. Policy #0 lag: (min: 1.0, avg: 4.0, max: 65.0)
[2026-02-02 15:27:54,642][187009] Avg episode reward: [(0, '1597.336')]
[2026-02-02 15:27:59,579][187009] Fps is (10 sec: 3271.8, 60 sec: 3277.3, 300 sec: 3387.9). Total num frames: 10338304. Throughput: 0: 3420.6. Samples: 10342912. Policy #0 lag: (min: 1.0, avg: 4.0, max: 65.0)
[2026-02-02 15:27:59,579][187009] Avg episode reward: [(0, '1640.403')]
[2026-02-02 15:28:04,525][187009] Fps is (10 sec: 3315.5, 60 sec: 3276.5, 300 sec: 3388.1). Total num frames: 10354688. Throughput: 0: 3465.3. Samples: 10363904. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:28:04,525][187009] Avg episode reward: [(0, '1643.673')]
[2026-02-02 15:28:09,568][187009] Fps is (10 sec: 3280.4, 60 sec: 3275.7, 300 sec: 3387.9). Total num frames: 10371072. Throughput: 0: 3417.2. Samples: 10373120. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:28:09,568][187009] Avg episode reward: [(0, '1641.849')]
[2026-02-02 15:28:10,998][187009] Signal inference workers to stop experience collection... (1900 times)
[2026-02-02 15:28:10,998][187009] Signal inference workers to resume experience collection... (1900 times)
[2026-02-02 15:28:11,241][187009] InferenceWorker_p0-w0: stopping experience collection (1900 times)
[2026-02-02 15:28:11,242][187009] InferenceWorker_p0-w0: resuming experience collection (1900 times)
[2026-02-02 15:28:14,641][187009] Fps is (10 sec: 3239.2, 60 sec: 3270.5, 300 sec: 3386.5). Total num frames: 10387456. Throughput: 0: 3413.5. Samples: 10394624. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:28:14,641][187009] Avg episode reward: [(0, '1653.073')]
[2026-02-02 15:28:19,655][187009] Fps is (10 sec: 3248.3, 60 sec: 3274.2, 300 sec: 3386.9). Total num frames: 10403840. Throughput: 0: 3441.3. Samples: 10415616. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:28:19,656][187009] Avg episode reward: [(0, '1633.799')]
[2026-02-02 15:28:24,640][187009] Fps is (10 sec: 3277.2, 60 sec: 3275.6, 300 sec: 3386.9). Total num frames: 10420224. Throughput: 0: 3388.5. Samples: 10424832. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:28:24,640][187009] Avg episode reward: [(0, '1622.119')]
[2026-02-02 15:28:29,613][187009] Fps is (10 sec: 3290.7, 60 sec: 3278.4, 300 sec: 3387.9). Total num frames: 10436608. Throughput: 0: 3438.1. Samples: 10445824. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:28:29,613][187009] Avg episode reward: [(0, '1647.791')]
[2026-02-02 15:28:34,574][187009] Fps is (10 sec: 3298.6, 60 sec: 3276.9, 300 sec: 3387.2). Total num frames: 10452992. Throughput: 0: 3435.3. Samples: 10466816. Policy #0 lag: (min: 5.0, avg: 8.0, max: 69.0)
[2026-02-02 15:28:34,574][187009] Avg episode reward: [(0, '1670.170')]
[2026-02-02 15:28:34,945][187009] Saving /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_accel_policy3_aggressive_magpie_refined_params_02022026_smooth_aggressive_ttc/checkpoint_p0/checkpoint_000040864_10461184.pth...
[2026-02-02 15:28:34,949][187009] Removing /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_accel_policy3_aggressive_magpie_refined_params_02022026_smooth_aggressive_ttc/checkpoint_p0/checkpoint_000037696_9650176.pth
[2026-02-02 15:28:39,761][187009] Fps is (10 sec: 4036.3, 60 sec: 3404.9, 300 sec: 3413.4). Total num frames: 10477568. Throughput: 0: 3404.3. Samples: 10476544. Policy #0 lag: (min: 5.0, avg: 8.0, max: 69.0)
[2026-02-02 15:28:39,761][187009] Avg episode reward: [(0, '1686.641')]
[2026-02-02 15:28:44,635][187009] Fps is (10 sec: 4070.9, 60 sec: 3413.6, 300 sec: 3415.3). Total num frames: 10493952. Throughput: 0: 3420.4. Samples: 10497024. Policy #0 lag: (min: 5.0, avg: 8.0, max: 69.0)
[2026-02-02 15:28:44,636][187009] Avg episode reward: [(0, '1656.266')]
[2026-02-02 15:28:49,870][187009] Fps is (10 sec: 4052.0, 60 sec: 3531.8, 300 sec: 3440.7). Total num frames: 10518528. Throughput: 0: 3398.7. Samples: 10518016. Policy #0 lag: (min: 5.0, avg: 8.0, max: 69.0)
[2026-02-02 15:28:49,870][187009] Avg episode reward: [(0, '1643.159')]
[2026-02-02 15:28:54,603][187009] Fps is (10 sec: 4109.3, 60 sec: 3552.2, 300 sec: 3442.7). Total num frames: 10534912. Throughput: 0: 3422.0. Samples: 10527232. Policy #0 lag: (min: 5.0, avg: 8.0, max: 69.0)
[2026-02-02 15:28:54,603][187009] Avg episode reward: [(0, '1638.453')]
[2026-02-02 15:28:59,596][187009] Fps is (10 sec: 3369.0, 60 sec: 3548.8, 300 sec: 3442.8). Total num frames: 10551296. Throughput: 0: 3416.8. Samples: 10548224. Policy #0 lag: (min: 2.0, avg: 5.0, max: 66.0)
[2026-02-02 15:28:59,596][187009] Avg episode reward: [(0, '1677.348')]
[2026-02-02 15:29:04,640][187009] Fps is (10 sec: 3264.6, 60 sec: 3543.1, 300 sec: 3442.9). Total num frames: 10567680. Throughput: 0: 3403.1. Samples: 10568704. Policy #0 lag: (min: 2.0, avg: 5.0, max: 66.0)
[2026-02-02 15:29:04,641][187009] Avg episode reward: [(0, '1678.312')]
[2026-02-02 15:29:09,613][187009] Fps is (10 sec: 3271.3, 60 sec: 3547.2, 300 sec: 3442.6). Total num frames: 10584064. Throughput: 0: 3426.8. Samples: 10578944. Policy #0 lag: (min: 2.0, avg: 5.0, max: 66.0)
[2026-02-02 15:29:09,613][187009] Avg episode reward: [(0, '1653.500')]
[2026-02-02 15:29:14,546][187009] Fps is (10 sec: 3308.1, 60 sec: 3555.5, 300 sec: 3443.8). Total num frames: 10600448. Throughput: 0: 3441.2. Samples: 10600448. Policy #0 lag: (min: 2.0, avg: 5.0, max: 66.0)
[2026-02-02 15:29:14,546][187009] Avg episode reward: [(0, '1667.214')]
[2026-02-02 15:29:19,563][187009] Fps is (10 sec: 3293.3, 60 sec: 3555.3, 300 sec: 3443.0). Total num frames: 10616832. Throughput: 0: 3380.0. Samples: 10618880. Policy #0 lag: (min: 2.0, avg: 5.0, max: 66.0)
[2026-02-02 15:29:19,563][187009] Avg episode reward: [(0, '1656.807')]
[2026-02-02 15:29:24,615][187009] Fps is (10 sec: 3254.3, 60 sec: 3551.3, 300 sec: 3416.3). Total num frames: 10633216. Throughput: 0: 3424.5. Samples: 10630144. Policy #0 lag: (min: 2.0, avg: 5.0, max: 66.0)
[2026-02-02 15:29:24,615][187009] Avg episode reward: [(0, '1674.398')]
[2026-02-02 15:29:29,588][187009] Fps is (10 sec: 3268.6, 60 sec: 3551.4, 300 sec: 3390.1). Total num frames: 10649600. Throughput: 0: 3416.9. Samples: 10650624. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:29:29,588][187009] Avg episode reward: [(0, '1618.760')]
[2026-02-02 15:29:32,461][187009] Signal inference workers to stop experience collection... (1950 times)
[2026-02-02 15:29:32,828][187009] InferenceWorker_p0-w0: stopping experience collection (1950 times)
[2026-02-02 15:29:32,830][187009] Signal inference workers to resume experience collection... (1950 times)
[2026-02-02 15:29:32,967][187009] InferenceWorker_p0-w0: resuming experience collection (1950 times)
[2026-02-02 15:29:34,578][187009] Fps is (10 sec: 3288.8, 60 sec: 3549.6, 300 sec: 3387.6). Total num frames: 10665984. Throughput: 0: 3389.8. Samples: 10669568. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:29:34,579][187009] Avg episode reward: [(0, '1654.602')]
[2026-02-02 15:29:39,560][187009] Fps is (10 sec: 3286.0, 60 sec: 3424.8, 300 sec: 3388.0). Total num frames: 10682368. Throughput: 0: 3416.6. Samples: 10680832. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:29:39,560][187009] Avg episode reward: [(0, '1605.045')]
[2026-02-02 15:29:44,580][187009] Fps is (10 sec: 3276.2, 60 sec: 3416.5, 300 sec: 3388.4). Total num frames: 10698752. Throughput: 0: 3391.8. Samples: 10700800. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:29:44,580][187009] Avg episode reward: [(0, '1660.722')]
[2026-02-02 15:29:49,639][187009] Fps is (10 sec: 3251.0, 60 sec: 3289.4, 300 sec: 3387.7). Total num frames: 10715136. Throughput: 0: 3402.1. Samples: 10721792. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:29:49,639][187009] Avg episode reward: [(0, '1655.540')]
[2026-02-02 15:29:54,534][187009] Fps is (10 sec: 3292.1, 60 sec: 3280.6, 300 sec: 3388.9). Total num frames: 10731520. Throughput: 0: 3419.4. Samples: 10732544. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:29:54,534][187009] Avg episode reward: [(0, '1678.447')]
[2026-02-02 15:29:59,545][187009] Fps is (10 sec: 3307.8, 60 sec: 3279.6, 300 sec: 3387.6). Total num frames: 10747904. Throughput: 0: 3379.2. Samples: 10752512. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:29:59,545][187009] Avg episode reward: [(0, '1629.239')]
[2026-02-02 15:30:04,572][187009] Fps is (10 sec: 3264.3, 60 sec: 3280.5, 300 sec: 3388.3). Total num frames: 10764288. Throughput: 0: 3435.4. Samples: 10773504. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:30:04,572][187009] Avg episode reward: [(0, '1626.164')]
[2026-02-02 15:30:09,645][187009] Fps is (10 sec: 3244.4, 60 sec: 3275.0, 300 sec: 3386.7). Total num frames: 10780672. Throughput: 0: 3399.7. Samples: 10783232. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:30:09,645][187009] Avg episode reward: [(0, '1609.754')]
[2026-02-02 15:30:14,545][187009] Fps is (10 sec: 3285.6, 60 sec: 3276.8, 300 sec: 3388.3). Total num frames: 10797056. Throughput: 0: 3416.6. Samples: 10804224. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:30:14,545][187009] Avg episode reward: [(0, '1667.706')]
[2026-02-02 15:30:19,589][187009] Fps is (10 sec: 3295.3, 60 sec: 3275.4, 300 sec: 3388.5). Total num frames: 10813440. Throughput: 0: 3458.0. Samples: 10825216. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:30:19,589][187009] Avg episode reward: [(0, '1633.953')]
[2026-02-02 15:30:24,584][187009] Fps is (10 sec: 3264.1, 60 sec: 3278.5, 300 sec: 3388.4). Total num frames: 10829824. Throughput: 0: 3422.9. Samples: 10834944. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:30:24,584][187009] Avg episode reward: [(0, '1699.654')]
[2026-02-02 15:30:24,721][187009] Saving new best policy, reward=1699.654!
[2026-02-02 15:30:29,533][187009] Fps is (10 sec: 3295.3, 60 sec: 3279.8, 300 sec: 3388.7). Total num frames: 10846208. Throughput: 0: 3451.1. Samples: 10855936. Policy #0 lag: (min: 2.0, avg: 5.0, max: 66.0)
[2026-02-02 15:30:29,533][187009] Avg episode reward: [(0, '1733.473')]
[2026-02-02 15:30:29,678][187009] Saving new best policy, reward=1733.473!
[2026-02-02 15:30:34,575][187009] Fps is (10 sec: 3279.8, 60 sec: 3277.0, 300 sec: 3387.6). Total num frames: 10862592. Throughput: 0: 3441.0. Samples: 10876416. Policy #0 lag: (min: 2.0, avg: 5.0, max: 66.0)
[2026-02-02 15:30:34,575][187009] Avg episode reward: [(0, '1699.154')]
[2026-02-02 15:30:34,963][187009] Saving /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_accel_policy3_aggressive_magpie_refined_params_02022026_smooth_aggressive_ttc/checkpoint_p0/checkpoint_000042464_10870784.pth...
[2026-02-02 15:30:34,967][187009] Removing /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_accel_policy3_aggressive_magpie_refined_params_02022026_smooth_aggressive_ttc/checkpoint_p0/checkpoint_000039264_10051584.pth
[2026-02-02 15:30:39,771][187009] Fps is (10 sec: 4000.6, 60 sec: 3401.4, 300 sec: 3413.5). Total num frames: 10887168. Throughput: 0: 3395.4. Samples: 10886144. Policy #0 lag: (min: 2.0, avg: 5.0, max: 66.0)
[2026-02-02 15:30:39,771][187009] Avg episode reward: [(0, '1625.683')]
[2026-02-02 15:30:44,525][187009] Fps is (10 sec: 4116.5, 60 sec: 3416.5, 300 sec: 3416.8). Total num frames: 10903552. Throughput: 0: 3437.6. Samples: 10907136. Policy #0 lag: (min: 2.0, avg: 5.0, max: 66.0)
[2026-02-02 15:30:44,525][187009] Avg episode reward: [(0, '1569.044')]
[2026-02-02 15:30:49,281][187009] Signal inference workers to stop experience collection... (2000 times)
[2026-02-02 15:30:49,637][187009] InferenceWorker_p0-w0: stopping experience collection (2000 times)
[2026-02-02 15:30:49,638][187009] Signal inference workers to resume experience collection... (2000 times)
[2026-02-02 15:30:49,638][187009] Fps is (10 sec: 4151.3, 60 sec: 3549.9, 300 sec: 3442.3). Total num frames: 10928128. Throughput: 0: 3431.1. Samples: 10928128. Policy #0 lag: (min: 2.0, avg: 5.0, max: 66.0)
[2026-02-02 15:30:49,638][187009] Avg episode reward: [(0, '1626.071')]
[2026-02-02 15:30:49,638][187009] InferenceWorker_p0-w0: resuming experience collection (2000 times)
[2026-02-02 15:30:54,635][187009] Fps is (10 sec: 4051.6, 60 sec: 3543.9, 300 sec: 3442.9). Total num frames: 10944512. Throughput: 0: 3436.9. Samples: 10937856. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:30:54,635][187009] Avg episode reward: [(0, '1698.679')]
[2026-02-02 15:30:59,563][187009] Fps is (10 sec: 3301.5, 60 sec: 3548.8, 300 sec: 3443.7). Total num frames: 10960896. Throughput: 0: 3446.1. Samples: 10959360. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:30:59,563][187009] Avg episode reward: [(0, '1708.283')]
[2026-02-02 15:31:04,593][187009] Fps is (10 sec: 3290.5, 60 sec: 3548.6, 300 sec: 3443.7). Total num frames: 10977280. Throughput: 0: 3401.6. Samples: 10978304. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:31:04,593][187009] Avg episode reward: [(0, '1703.380')]
[2026-02-02 15:31:09,619][187009] Fps is (10 sec: 3258.6, 60 sec: 3551.4, 300 sec: 3442.2). Total num frames: 10993664. Throughput: 0: 3444.8. Samples: 10990080. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:31:09,619][187009] Avg episode reward: [(0, '1653.829')]
[2026-02-02 15:31:14,539][187009] Fps is (10 sec: 3294.5, 60 sec: 3550.2, 300 sec: 3444.3). Total num frames: 11010048. Throughput: 0: 3447.0. Samples: 11011072. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:31:14,539][187009] Avg episode reward: [(0, '1654.593')]
[2026-02-02 15:31:19,559][187009] Fps is (10 sec: 3296.7, 60 sec: 3551.6, 300 sec: 3444.3). Total num frames: 11026432. Throughput: 0: 3448.7. Samples: 11031552. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:31:19,559][187009] Avg episode reward: [(0, '1650.517')]
[2026-02-02 15:31:24,624][187009] Fps is (10 sec: 3249.3, 60 sec: 3547.5, 300 sec: 3443.3). Total num frames: 11042816. Throughput: 0: 3493.0. Samples: 11042816. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:31:24,624][187009] Avg episode reward: [(0, '1665.127')]
[2026-02-02 15:31:29,550][187009] Fps is (10 sec: 3279.7, 60 sec: 3548.8, 300 sec: 3444.2). Total num frames: 11059200. Throughput: 0: 3434.2. Samples: 11061760. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:31:29,550][187009] Avg episode reward: [(0, '1685.988')]
[2026-02-02 15:31:34,563][187009] Fps is (10 sec: 3296.9, 60 sec: 3550.6, 300 sec: 3447.0). Total num frames: 11075584. Throughput: 0: 3441.8. Samples: 11082752. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:31:34,563][187009] Avg episode reward: [(0, '1630.493')]
[2026-02-02 15:31:39,528][187009] Fps is (10 sec: 3284.1, 60 sec: 3427.2, 300 sec: 3416.7). Total num frames: 11091968. Throughput: 0: 3455.7. Samples: 11092992. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:31:39,528][187009] Avg episode reward: [(0, '1578.608')]
[2026-02-02 15:31:44,576][187009] Fps is (10 sec: 3272.4, 60 sec: 3410.4, 300 sec: 3415.6). Total num frames: 11108352. Throughput: 0: 3423.7. Samples: 11113472. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:31:44,577][187009] Avg episode reward: [(0, '1506.255')]
[2026-02-02 15:31:49,607][187009] Fps is (10 sec: 3250.9, 60 sec: 3278.5, 300 sec: 3390.9). Total num frames: 11124736. Throughput: 0: 3469.1. Samples: 11134464. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:31:49,608][187009] Avg episode reward: [(0, '1565.010')]
[2026-02-02 15:31:54,596][187009] Fps is (10 sec: 3270.3, 60 sec: 3278.9, 300 sec: 3387.8). Total num frames: 11141120. Throughput: 0: 3415.1. Samples: 11143680. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:31:54,597][187009] Avg episode reward: [(0, '1625.950')]
[2026-02-02 15:31:59,549][187009] Fps is (10 sec: 3295.9, 60 sec: 3277.6, 300 sec: 3387.5). Total num frames: 11157504. Throughput: 0: 3412.6. Samples: 11164672. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:31:59,550][187009] Avg episode reward: [(0, '1682.884')]
[2026-02-02 15:32:04,608][187009] Fps is (10 sec: 3273.1, 60 sec: 3276.0, 300 sec: 3387.2). Total num frames: 11173888. Throughput: 0: 3421.0. Samples: 11185664. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:32:04,608][187009] Avg episode reward: [(0, '1657.460')]
[2026-02-02 15:32:09,642][187009] Fps is (10 sec: 3246.7, 60 sec: 3275.5, 300 sec: 3386.5). Total num frames: 11190272. Throughput: 0: 3389.2. Samples: 11195392. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:32:09,642][187009] Avg episode reward: [(0, '1618.170')]
[2026-02-02 15:32:10,263][187009] Signal inference workers to stop experience collection... (2050 times)
[2026-02-02 15:32:10,263][187009] Signal inference workers to resume experience collection... (2050 times)
[2026-02-02 15:32:10,517][187009] InferenceWorker_p0-w0: stopping experience collection (2050 times)
[2026-02-02 15:32:10,517][187009] InferenceWorker_p0-w0: resuming experience collection (2050 times)
[2026-02-02 15:32:14,565][187009] Fps is (10 sec: 3290.6, 60 sec: 3275.4, 300 sec: 3388.4). Total num frames: 11206656. Throughput: 0: 3434.9. Samples: 11216384. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:32:14,566][187009] Avg episode reward: [(0, '1640.928')]
[2026-02-02 15:32:19,801][187009] Fps is (10 sec: 4031.8, 60 sec: 3399.6, 300 sec: 3413.5). Total num frames: 11231232. Throughput: 0: 3418.0. Samples: 11237376. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:32:19,802][187009] Avg episode reward: [(0, '1646.180')]
[2026-02-02 15:32:24,649][187009] Fps is (10 sec: 4062.0, 60 sec: 3411.9, 300 sec: 3415.6). Total num frames: 11247616. Throughput: 0: 3415.5. Samples: 11247104. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:32:24,649][187009] Avg episode reward: [(0, '1633.206')]
[2026-02-02 15:32:29,764][187009] Fps is (10 sec: 4111.3, 60 sec: 3537.2, 300 sec: 3441.2). Total num frames: 11272192. Throughput: 0: 3421.8. Samples: 11268096. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:32:29,764][187009] Avg episode reward: [(0, '1640.164')]
[2026-02-02 15:32:34,538][187009] Fps is (10 sec: 4142.2, 60 sec: 3551.4, 300 sec: 3444.3). Total num frames: 11288576. Throughput: 0: 3441.4. Samples: 11289088. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:32:34,538][187009] Avg episode reward: [(0, '1636.759')]
[2026-02-02 15:32:34,540][187009] Saving /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_accel_policy3_aggressive_magpie_refined_params_02022026_smooth_aggressive_ttc/checkpoint_p0/checkpoint_000044096_11288576.pth...
[2026-02-02 15:32:34,544][187009] Removing /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_accel_policy3_aggressive_magpie_refined_params_02022026_smooth_aggressive_ttc/checkpoint_p0/checkpoint_000040864_10461184.pth
[2026-02-02 15:32:39,527][187009] Fps is (10 sec: 3356.4, 60 sec: 3549.9, 300 sec: 3444.7). Total num frames: 11304960. Throughput: 0: 3452.8. Samples: 11298816. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:32:39,527][187009] Avg episode reward: [(0, '1643.164')]
[2026-02-02 15:32:44,531][187009] Fps is (10 sec: 3278.8, 60 sec: 3552.5, 300 sec: 3443.8). Total num frames: 11321344. Throughput: 0: 3448.8. Samples: 11319808. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:32:44,532][187009] Avg episode reward: [(0, '1644.975')]
[2026-02-02 15:32:49,524][187009] Fps is (10 sec: 3277.9, 60 sec: 3554.8, 300 sec: 3444.8). Total num frames: 11337728. Throughput: 0: 3408.3. Samples: 11338752. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:32:49,524][187009] Avg episode reward: [(0, '1614.385')]
[2026-02-02 15:32:54,533][187009] Fps is (10 sec: 3276.4, 60 sec: 3553.6, 300 sec: 3444.0). Total num frames: 11354112. Throughput: 0: 3467.3. Samples: 11351040. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:32:54,533][187009] Avg episode reward: [(0, '1647.164')]
[2026-02-02 15:32:59,605][187009] Fps is (10 sec: 3250.4, 60 sec: 3546.6, 300 sec: 3442.5). Total num frames: 11370496. Throughput: 0: 3444.5. Samples: 11371520. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:32:59,605][187009] Avg episode reward: [(0, '1628.300')]
[2026-02-02 15:33:04,628][187009] Fps is (10 sec: 3245.9, 60 sec: 3548.7, 300 sec: 3442.7). Total num frames: 11386880. Throughput: 0: 3449.4. Samples: 11392000. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:33:04,628][187009] Avg episode reward: [(0, '1645.382')]
[2026-02-02 15:33:09,639][187009] Fps is (10 sec: 3265.6, 60 sec: 3550.1, 300 sec: 3443.4). Total num frames: 11403264. Throughput: 0: 3471.0. Samples: 11403264. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:33:09,639][187009] Avg episode reward: [(0, '1600.341')]
[2026-02-02 15:33:14,572][187009] Fps is (10 sec: 3295.3, 60 sec: 3549.5, 300 sec: 3444.4). Total num frames: 11419648. Throughput: 0: 3450.8. Samples: 11422720. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:33:14,572][187009] Avg episode reward: [(0, '1606.103')]
[2026-02-02 15:33:19,544][187009] Fps is (10 sec: 3308.2, 60 sec: 3428.0, 300 sec: 3444.5). Total num frames: 11436032. Throughput: 0: 3435.6. Samples: 11443712. Policy #0 lag: (min: 2.0, avg: 5.0, max: 66.0)
[2026-02-02 15:33:19,544][187009] Avg episode reward: [(0, '1567.692')]
[2026-02-02 15:33:24,542][187009] Fps is (10 sec: 3286.5, 60 sec: 3419.4, 300 sec: 3444.2). Total num frames: 11452416. Throughput: 0: 3434.9. Samples: 11453440. Policy #0 lag: (min: 2.0, avg: 5.0, max: 66.0)
[2026-02-02 15:33:24,542][187009] Avg episode reward: [(0, '1563.364')]
[2026-02-02 15:33:29,532][187009] Fps is (10 sec: 3281.0, 60 sec: 3289.6, 300 sec: 3443.9). Total num frames: 11468800. Throughput: 0: 3447.5. Samples: 11474944. Policy #0 lag: (min: 2.0, avg: 5.0, max: 66.0)
[2026-02-02 15:33:29,532][187009] Avg episode reward: [(0, '1537.714')]
[2026-02-02 15:33:30,646][187009] Signal inference workers to stop experience collection... (2100 times)
[2026-02-02 15:33:31,011][187009] InferenceWorker_p0-w0: stopping experience collection (2100 times)
[2026-02-02 15:33:31,013][187009] Signal inference workers to resume experience collection... (2100 times)
[2026-02-02 15:33:31,143][187009] InferenceWorker_p0-w0: resuming experience collection (2100 times)
[2026-02-02 15:33:34,590][187009] Fps is (10 sec: 3261.2, 60 sec: 3273.9, 300 sec: 3417.6). Total num frames: 11485184. Throughput: 0: 3487.8. Samples: 11495936. Policy #0 lag: (min: 2.0, avg: 5.0, max: 66.0)
[2026-02-02 15:33:34,590][187009] Avg episode reward: [(0, '1561.816')]
[2026-02-02 15:33:39,578][187009] Fps is (10 sec: 3261.5, 60 sec: 3274.0, 300 sec: 3416.3). Total num frames: 11501568. Throughput: 0: 3432.6. Samples: 11505664. Policy #0 lag: (min: 2.0, avg: 5.0, max: 66.0)
[2026-02-02 15:33:39,579][187009] Avg episode reward: [(0, '1631.432')]
[2026-02-02 15:33:44,604][187009] Fps is (10 sec: 3272.3, 60 sec: 3272.8, 300 sec: 3390.9). Total num frames: 11517952. Throughput: 0: 3447.5. Samples: 11526656. Policy #0 lag: (min: 2.0, avg: 5.0, max: 66.0)
[2026-02-02 15:33:44,604][187009] Avg episode reward: [(0, '1634.236')]
[2026-02-02 15:33:49,633][187009] Fps is (10 sec: 3258.9, 60 sec: 3270.8, 300 sec: 3387.5). Total num frames: 11534336. Throughput: 0: 3469.8. Samples: 11548160. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:33:49,633][187009] Avg episode reward: [(0, '1633.832')]
[2026-02-02 15:33:54,813][187009] Fps is (10 sec: 4012.2, 60 sec: 3397.5, 300 sec: 3413.1). Total num frames: 11558912. Throughput: 0: 3411.5. Samples: 11557376. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:33:54,813][187009] Avg episode reward: [(0, '1613.154')]
[2026-02-02 15:33:59,591][187009] Fps is (10 sec: 4113.5, 60 sec: 3414.1, 300 sec: 3416.2). Total num frames: 11575296. Throughput: 0: 3468.8. Samples: 11578880. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:33:59,591][187009] Avg episode reward: [(0, '1652.945')]
[2026-02-02 15:34:04,690][187009] Fps is (10 sec: 4146.7, 60 sec: 3546.2, 300 sec: 3442.5). Total num frames: 11599872. Throughput: 0: 3459.0. Samples: 11599872. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:34:04,691][187009] Avg episode reward: [(0, '1655.494')]
[2026-02-02 15:34:09,563][187009] Fps is (10 sec: 4107.4, 60 sec: 3554.4, 300 sec: 3443.2). Total num frames: 11616256. Throughput: 0: 3468.6. Samples: 11609600. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:34:09,563][187009] Avg episode reward: [(0, '1622.904')]
[2026-02-02 15:34:14,656][187009] Fps is (10 sec: 3288.1, 60 sec: 3544.9, 300 sec: 3442.3). Total num frames: 11632640. Throughput: 0: 3449.3. Samples: 11630592. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:34:14,656][187009] Avg episode reward: [(0, '1627.579')]
[2026-02-02 15:34:19,640][187009] Fps is (10 sec: 3251.8, 60 sec: 3544.2, 300 sec: 3443.1). Total num frames: 11649024. Throughput: 0: 3420.9. Samples: 11650048. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:34:19,640][187009] Avg episode reward: [(0, '1610.806')]
[2026-02-02 15:34:24,571][187009] Fps is (10 sec: 3304.8, 60 sec: 3548.1, 300 sec: 3443.6). Total num frames: 11665408. Throughput: 0: 3459.4. Samples: 11661312. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:34:24,572][187009] Avg episode reward: [(0, '1625.082')]
[2026-02-02 15:34:29,649][187009] Fps is (10 sec: 3273.8, 60 sec: 3542.9, 300 sec: 3442.6). Total num frames: 11681792. Throughput: 0: 3455.4. Samples: 11682304. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:34:29,649][187009] Avg episode reward: [(0, '1629.044')]
[2026-02-02 15:34:34,549][187009] Fps is (10 sec: 3284.3, 60 sec: 3552.3, 300 sec: 3443.5). Total num frames: 11698176. Throughput: 0: 3419.8. Samples: 11701760. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:34:34,549][187009] Avg episode reward: [(0, '1630.428')]
[2026-02-02 15:34:34,692][187009] Saving /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_accel_policy3_aggressive_magpie_refined_params_02022026_smooth_aggressive_ttc/checkpoint_p0/checkpoint_000045696_11698176.pth...
[2026-02-02 15:34:34,696][187009] Removing /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_accel_policy3_aggressive_magpie_refined_params_02022026_smooth_aggressive_ttc/checkpoint_p0/checkpoint_000042464_10870784.pth
[2026-02-02 15:34:39,628][187009] Fps is (10 sec: 3283.8, 60 sec: 3546.9, 300 sec: 3442.9). Total num frames: 11714560. Throughput: 0: 3473.1. Samples: 11713024. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:34:39,628][187009] Avg episode reward: [(0, '1629.986')]
[2026-02-02 15:34:44,638][187009] Fps is (10 sec: 3247.8, 60 sec: 3547.9, 300 sec: 3443.4). Total num frames: 11730944. Throughput: 0: 3398.4. Samples: 11731968. Policy #0 lag: (min: 25.0, avg: 28.0, max: 89.0)
[2026-02-02 15:34:44,638][187009] Avg episode reward: [(0, '1631.261')]
[2026-02-02 15:34:47,214][187009] Signal inference workers to stop experience collection... (2150 times)
[2026-02-02 15:34:47,577][187009] InferenceWorker_p0-w0: stopping experience collection (2150 times)
[2026-02-02 15:34:47,577][187009] Signal inference workers to resume experience collection... (2150 times)
[2026-02-02 15:34:47,577][187009] InferenceWorker_p0-w0: resuming experience collection (2150 times)
[2026-02-02 15:34:49,587][187009] Fps is (10 sec: 3290.4, 60 sec: 3552.6, 300 sec: 3442.8). Total num frames: 11747328. Throughput: 0: 3421.2. Samples: 11753472. Policy #0 lag: (min: 25.0, avg: 28.0, max: 89.0)
[2026-02-02 15:34:49,587][187009] Avg episode reward: [(0, '1672.161')]
[2026-02-02 15:34:54,617][187009] Fps is (10 sec: 3283.6, 60 sec: 3424.5, 300 sec: 3442.6). Total num frames: 11763712. Throughput: 0: 3443.3. Samples: 11764736. Policy #0 lag: (min: 25.0, avg: 28.0, max: 89.0)
[2026-02-02 15:34:54,617][187009] Avg episode reward: [(0, '1679.491')]
[2026-02-02 15:34:59,552][187009] Fps is (10 sec: 3288.1, 60 sec: 3415.5, 300 sec: 3443.6). Total num frames: 11780096. Throughput: 0: 3421.2. Samples: 11784192. Policy #0 lag: (min: 25.0, avg: 28.0, max: 89.0)
[2026-02-02 15:34:59,552][187009] Avg episode reward: [(0, '1711.765')]
[2026-02-02 15:35:04,626][187009] Fps is (10 sec: 3274.1, 60 sec: 3280.3, 300 sec: 3443.6). Total num frames: 11796480. Throughput: 0: 3448.6. Samples: 11805184. Policy #0 lag: (min: 25.0, avg: 28.0, max: 89.0)
[2026-02-02 15:35:04,626][187009] Avg episode reward: [(0, '1643.048')]
[2026-02-02 15:35:09,541][187009] Fps is (10 sec: 3280.6, 60 sec: 3278.0, 300 sec: 3443.5). Total num frames: 11812864. Throughput: 0: 3415.7. Samples: 11814912. Policy #0 lag: (min: 25.0, avg: 28.0, max: 89.0)
[2026-02-02 15:35:09,541][187009] Avg episode reward: [(0, '1577.290')]
[2026-02-02 15:35:14,584][187009] Fps is (10 sec: 3290.6, 60 sec: 3280.8, 300 sec: 3443.5). Total num frames: 11829248. Throughput: 0: 3418.3. Samples: 11835904. Policy #0 lag: (min: 47.0, avg: 50.0, max: 111.0)
[2026-02-02 15:35:14,584][187009] Avg episode reward: [(0, '1585.946')]
[2026-02-02 15:35:19,610][187009] Fps is (10 sec: 3254.2, 60 sec: 3278.4, 300 sec: 3443.1). Total num frames: 11845632. Throughput: 0: 3442.8. Samples: 11856896. Policy #0 lag: (min: 47.0, avg: 50.0, max: 111.0)
[2026-02-02 15:35:19,610][187009] Avg episode reward: [(0, '1600.946')]
[2026-02-02 15:35:24,633][187009] Fps is (10 sec: 3260.6, 60 sec: 3273.4, 300 sec: 3442.2). Total num frames: 11862016. Throughput: 0: 3401.5. Samples: 11866112. Policy #0 lag: (min: 47.0, avg: 50.0, max: 111.0)
[2026-02-02 15:35:24,634][187009] Avg episode reward: [(0, '1668.244')]
[2026-02-02 15:35:29,578][187009] Fps is (10 sec: 3287.5, 60 sec: 3280.7, 300 sec: 3443.4). Total num frames: 11878400. Throughput: 0: 3452.1. Samples: 11887104. Policy #0 lag: (min: 47.0, avg: 50.0, max: 111.0)
[2026-02-02 15:35:29,578][187009] Avg episode reward: [(0, '1664.079')]
[2026-02-02 15:35:34,596][187009] Fps is (10 sec: 3289.0, 60 sec: 3274.2, 300 sec: 3417.7). Total num frames: 11894784. Throughput: 0: 3435.4. Samples: 11908096. Policy #0 lag: (min: 47.0, avg: 50.0, max: 111.0)
[2026-02-02 15:35:34,596][187009] Avg episode reward: [(0, '1683.016')]
[2026-02-02 15:35:39,847][187009] Fps is (10 sec: 3988.7, 60 sec: 3400.9, 300 sec: 3439.7). Total num frames: 11919360. Throughput: 0: 3384.7. Samples: 11917824. Policy #0 lag: (min: 47.0, avg: 50.0, max: 111.0)
[2026-02-02 15:35:39,847][187009] Avg episode reward: [(0, '1663.102')]
[2026-02-02 15:35:44,671][187009] Fps is (10 sec: 4065.7, 60 sec: 3411.5, 300 sec: 3415.3). Total num frames: 11935744. Throughput: 0: 3427.1. Samples: 11938816. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:35:44,671][187009] Avg episode reward: [(0, '1664.755')]
[2026-02-02 15:35:49,564][187009] Fps is (10 sec: 3371.9, 60 sec: 3414.6, 300 sec: 3416.5). Total num frames: 11952128. Throughput: 0: 3429.4. Samples: 11959296. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:35:49,565][187009] Avg episode reward: [(0, '1628.732')]
[2026-02-02 15:35:54,698][187009] Fps is (10 sec: 4084.9, 60 sec: 3545.1, 300 sec: 3441.8). Total num frames: 11976704. Throughput: 0: 3412.8. Samples: 11969024. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:35:54,698][187009] Avg episode reward: [(0, '1659.632')]
[2026-02-02 15:35:59,640][187009] Fps is (10 sec: 4065.1, 60 sec: 3544.7, 300 sec: 3442.9). Total num frames: 11993088. Throughput: 0: 3420.4. Samples: 11990016. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:35:59,641][187009] Avg episode reward: [(0, '1641.642')]
[2026-02-02 15:36:04,593][187009] Fps is (10 sec: 3311.5, 60 sec: 3551.8, 300 sec: 3443.7). Total num frames: 12009472. Throughput: 0: 3414.6. Samples: 12010496. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:36:04,594][187009] Avg episode reward: [(0, '1713.736')]
[2026-02-02 15:36:08,537][187009] Signal inference workers to stop experience collection... (2200 times)
[2026-02-02 15:36:08,537][187009] Signal inference workers to resume experience collection... (2200 times)
[2026-02-02 15:36:08,782][187009] InferenceWorker_p0-w0: stopping experience collection (2200 times)
[2026-02-02 15:36:08,782][187009] InferenceWorker_p0-w0: resuming experience collection (2200 times)
[2026-02-02 15:36:09,560][187009] Fps is (10 sec: 3303.3, 60 sec: 3548.7, 300 sec: 3443.2). Total num frames: 12025856. Throughput: 0: 3441.7. Samples: 12020736. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:36:09,560][187009] Avg episode reward: [(0, '1728.484')]
[2026-02-02 15:36:14,582][187009] Fps is (10 sec: 3280.4, 60 sec: 3549.9, 300 sec: 3443.1). Total num frames: 12042240. Throughput: 0: 3447.1. Samples: 12042240. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:36:14,583][187009] Avg episode reward: [(0, '1730.467')]
[2026-02-02 15:36:19,644][187009] Fps is (10 sec: 3249.4, 60 sec: 3547.8, 300 sec: 3443.2). Total num frames: 12058624. Throughput: 0: 3409.7. Samples: 12061696. Policy #0 lag: (min: 6.0, avg: 9.0, max: 70.0)
[2026-02-02 15:36:19,645][187009] Avg episode reward: [(0, '1741.129')]
[2026-02-02 15:36:19,647][187009] Saving new best policy, reward=1741.129!
[2026-02-02 15:36:24,606][187009] Fps is (10 sec: 3269.0, 60 sec: 3551.5, 300 sec: 3442.8). Total num frames: 12075008. Throughput: 0: 3466.0. Samples: 12072960. Policy #0 lag: (min: 6.0, avg: 9.0, max: 70.0)
[2026-02-02 15:36:24,606][187009] Avg episode reward: [(0, '1691.589')]
[2026-02-02 15:36:29,615][187009] Fps is (10 sec: 3286.6, 60 sec: 3547.7, 300 sec: 3442.8). Total num frames: 12091392. Throughput: 0: 3417.6. Samples: 12092416. Policy #0 lag: (min: 6.0, avg: 9.0, max: 70.0)
[2026-02-02 15:36:29,615][187009] Avg episode reward: [(0, '1672.793')]
[2026-02-02 15:36:34,535][187009] Fps is (10 sec: 3300.2, 60 sec: 3553.5, 300 sec: 3443.3). Total num frames: 12107776. Throughput: 0: 3426.9. Samples: 12113408. Policy #0 lag: (min: 6.0, avg: 9.0, max: 70.0)
[2026-02-02 15:36:34,536][187009] Avg episode reward: [(0, '1662.869')]
[2026-02-02 15:36:34,668][187009] Saving /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_accel_policy3_aggressive_magpie_refined_params_02022026_smooth_aggressive_ttc/checkpoint_p0/checkpoint_000047296_12107776.pth...
[2026-02-02 15:36:34,672][187009] Removing /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_accel_policy3_aggressive_magpie_refined_params_02022026_smooth_aggressive_ttc/checkpoint_p0/checkpoint_000044096_11288576.pth
[2026-02-02 15:36:39,531][187009] Fps is (10 sec: 3304.3, 60 sec: 3431.4, 300 sec: 3443.9). Total num frames: 12124160. Throughput: 0: 3483.1. Samples: 12125184. Policy #0 lag: (min: 6.0, avg: 9.0, max: 70.0)
[2026-02-02 15:36:39,532][187009] Avg episode reward: [(0, '1738.454')]
[2026-02-02 15:36:44,638][187009] Fps is (10 sec: 3243.5, 60 sec: 3415.2, 300 sec: 3443.1). Total num frames: 12140544. Throughput: 0: 3424.9. Samples: 12144128. Policy #0 lag: (min: 6.0, avg: 9.0, max: 70.0)
[2026-02-02 15:36:44,638][187009] Avg episode reward: [(0, '1752.532')]
[2026-02-02 15:36:44,784][187009] Saving new best policy, reward=1752.532!
[2026-02-02 15:36:49,524][187009] Fps is (10 sec: 3279.3, 60 sec: 3415.6, 300 sec: 3444.3). Total num frames: 12156928. Throughput: 0: 3452.8. Samples: 12165632. Policy #0 lag: (min: 6.0, avg: 9.0, max: 70.0)
[2026-02-02 15:36:49,524][187009] Avg episode reward: [(0, '1732.261')]
[2026-02-02 15:36:54,530][187009] Fps is (10 sec: 3312.7, 60 sec: 3286.0, 300 sec: 3443.6). Total num frames: 12173312. Throughput: 0: 3438.4. Samples: 12175360. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:36:54,530][187009] Avg episode reward: [(0, '1734.344')]
[2026-02-02 15:36:59,583][187009] Fps is (10 sec: 3257.4, 60 sec: 3279.9, 300 sec: 3443.7). Total num frames: 12189696. Throughput: 0: 3413.3. Samples: 12195840. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:36:59,584][187009] Avg episode reward: [(0, '1744.764')]
[2026-02-02 15:37:04,602][187009] Fps is (10 sec: 3253.3, 60 sec: 3276.3, 300 sec: 3443.9). Total num frames: 12206080. Throughput: 0: 3450.7. Samples: 12216832. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:37:04,602][187009] Avg episode reward: [(0, '1701.851')]
[2026-02-02 15:37:09,569][187009] Fps is (10 sec: 3281.5, 60 sec: 3276.3, 300 sec: 3443.4). Total num frames: 12222464. Throughput: 0: 3416.2. Samples: 12226560. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:37:09,569][187009] Avg episode reward: [(0, '1667.396')]
[2026-02-02 15:37:14,558][187009] Fps is (10 sec: 3291.2, 60 sec: 3278.1, 300 sec: 3418.5). Total num frames: 12238848. Throughput: 0: 3451.8. Samples: 12247552. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:37:14,558][187009] Avg episode reward: [(0, '1694.260')]
[2026-02-02 15:37:19,530][187009] Fps is (10 sec: 3289.7, 60 sec: 3283.1, 300 sec: 3417.0). Total num frames: 12255232. Throughput: 0: 3436.5. Samples: 12268032. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:37:19,530][187009] Avg episode reward: [(0, '1725.499')]
[2026-02-02 15:37:24,530][187009] Fps is (10 sec: 3286.1, 60 sec: 3281.0, 300 sec: 3390.6). Total num frames: 12271616. Throughput: 0: 3402.1. Samples: 12278272. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:37:24,530][187009] Avg episode reward: [(0, '1742.947')]
[2026-02-02 15:37:29,322][187009] Signal inference workers to stop experience collection... (2250 times)
[2026-02-02 15:37:29,681][187009] InferenceWorker_p0-w0: stopping experience collection (2250 times)
[2026-02-02 15:37:29,683][187009] Signal inference workers to resume experience collection... (2250 times)
[2026-02-02 15:37:29,683][187009] Fps is (10 sec: 4034.1, 60 sec: 3409.4, 300 sec: 3414.0). Total num frames: 12296192. Throughput: 0: 3444.0. Samples: 12299264. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:37:29,684][187009] Avg episode reward: [(0, '1767.482')]
[2026-02-02 15:37:29,812][187009] InferenceWorker_p0-w0: resuming experience collection (2250 times)
[2026-02-02 15:37:30,045][187009] Saving new best policy, reward=1767.482!
[2026-02-02 15:37:34,764][187009] Fps is (10 sec: 4802.8, 60 sec: 3536.4, 300 sec: 3440.7). Total num frames: 12320768. Throughput: 0: 3417.9. Samples: 12320256. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:37:34,764][187009] Avg episode reward: [(0, '1745.805')]
[2026-02-02 15:37:39,588][187009] Fps is (10 sec: 4135.3, 60 sec: 3546.5, 300 sec: 3442.8). Total num frames: 12337152. Throughput: 0: 3431.6. Samples: 12329984. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:37:39,589][187009] Avg episode reward: [(0, '1661.942')]
[2026-02-02 15:37:44,627][187009] Fps is (10 sec: 3322.1, 60 sec: 3550.5, 300 sec: 3442.2). Total num frames: 12353536. Throughput: 0: 3455.5. Samples: 12351488. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:37:44,628][187009] Avg episode reward: [(0, '1734.926')]
[2026-02-02 15:37:49,532][187009] Fps is (10 sec: 3295.3, 60 sec: 3549.4, 300 sec: 3443.4). Total num frames: 12369920. Throughput: 0: 3430.0. Samples: 12370944. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:37:49,532][187009] Avg episode reward: [(0, '1773.719')]
[2026-02-02 15:37:49,670][187009] Saving new best policy, reward=1773.719!
[2026-02-02 15:37:54,556][187009] Fps is (10 sec: 3300.5, 60 sec: 3548.3, 300 sec: 3444.0). Total num frames: 12386304. Throughput: 0: 3448.5. Samples: 12381696. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:37:54,556][187009] Avg episode reward: [(0, '1778.276')]
[2026-02-02 15:37:54,705][187009] Saving new best policy, reward=1778.276!
[2026-02-02 15:37:59,612][187009] Fps is (10 sec: 3250.8, 60 sec: 3548.2, 300 sec: 3443.6). Total num frames: 12402688. Throughput: 0: 3432.0. Samples: 12402176. Policy #0 lag: (min: 10.0, avg: 13.0, max: 74.0)
[2026-02-02 15:37:59,612][187009] Avg episode reward: [(0, '1704.393')]
[2026-02-02 15:38:04,598][187009] Fps is (10 sec: 3262.9, 60 sec: 3550.1, 300 sec: 3443.9). Total num frames: 12419072. Throughput: 0: 3396.8. Samples: 12421120. Policy #0 lag: (min: 10.0, avg: 13.0, max: 74.0)
[2026-02-02 15:38:04,599][187009] Avg episode reward: [(0, '1619.708')]
[2026-02-02 15:38:09,564][187009] Fps is (10 sec: 3292.7, 60 sec: 3550.2, 300 sec: 3443.5). Total num frames: 12435456. Throughput: 0: 3422.1. Samples: 12432384. Policy #0 lag: (min: 10.0, avg: 13.0, max: 74.0)
[2026-02-02 15:38:09,564][187009] Avg episode reward: [(0, '1687.141')]
[2026-02-02 15:38:14,632][187009] Fps is (10 sec: 3265.8, 60 sec: 3545.5, 300 sec: 3442.4). Total num frames: 12451840. Throughput: 0: 3417.2. Samples: 12452864. Policy #0 lag: (min: 10.0, avg: 13.0, max: 74.0)
[2026-02-02 15:38:14,632][187009] Avg episode reward: [(0, '1670.166')]
[2026-02-02 15:38:19,614][187009] Fps is (10 sec: 3260.5, 60 sec: 3544.9, 300 sec: 3442.6). Total num frames: 12468224. Throughput: 0: 3401.9. Samples: 12472832. Policy #0 lag: (min: 10.0, avg: 13.0, max: 74.0)
[2026-02-02 15:38:19,614][187009] Avg episode reward: [(0, '1755.874')]
[2026-02-02 15:38:24,520][187009] Fps is (10 sec: 3314.0, 60 sec: 3550.5, 300 sec: 3443.6). Total num frames: 12484608. Throughput: 0: 3429.9. Samples: 12484096. Policy #0 lag: (min: 10.0, avg: 13.0, max: 74.0)
[2026-02-02 15:38:24,520][187009] Avg episode reward: [(0, '1756.460')]
[2026-02-02 15:38:29,643][187009] Fps is (10 sec: 3267.2, 60 sec: 3415.6, 300 sec: 3442.8). Total num frames: 12500992. Throughput: 0: 3366.7. Samples: 12503040. Policy #0 lag: (min: 10.0, avg: 13.0, max: 74.0)
[2026-02-02 15:38:29,643][187009] Avg episode reward: [(0, '1790.336')]
[2026-02-02 15:38:29,783][187009] Saving new best policy, reward=1790.336!
[2026-02-02 15:38:34,532][187009] Fps is (10 sec: 3272.9, 60 sec: 3289.5, 300 sec: 3444.0). Total num frames: 12517376. Throughput: 0: 3390.6. Samples: 12523520. Policy #0 lag: (min: 12.0, avg: 15.0, max: 76.0)
[2026-02-02 15:38:34,532][187009] Avg episode reward: [(0, '1842.814')]
[2026-02-02 15:38:34,697][187009] Saving /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_accel_policy3_aggressive_magpie_refined_params_02022026_smooth_aggressive_ttc/checkpoint_p0/checkpoint_000048896_12517376.pth...
[2026-02-02 15:38:34,701][187009] Removing /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_accel_policy3_aggressive_magpie_refined_params_02022026_smooth_aggressive_ttc/checkpoint_p0/checkpoint_000045696_11698176.pth
[2026-02-02 15:38:34,701][187009] Saving new best policy, reward=1842.814!
[2026-02-02 15:38:39,528][187009] Fps is (10 sec: 3314.8, 60 sec: 3280.1, 300 sec: 3444.3). Total num frames: 12533760. Throughput: 0: 3392.7. Samples: 12534272. Policy #0 lag: (min: 12.0, avg: 15.0, max: 76.0)
[2026-02-02 15:38:39,528][187009] Avg episode reward: [(0, '1802.065')]
[2026-02-02 15:38:44,556][187009] Fps is (10 sec: 3268.8, 60 sec: 3280.7, 300 sec: 3444.3). Total num frames: 12550144. Throughput: 0: 3372.0. Samples: 12553728. Policy #0 lag: (min: 12.0, avg: 15.0, max: 76.0)
[2026-02-02 15:38:44,556][187009] Avg episode reward: [(0, '1751.653')]
[2026-02-02 15:38:46,819][187009] Signal inference workers to stop experience collection... (2300 times)
[2026-02-02 15:38:47,173][187009] InferenceWorker_p0-w0: stopping experience collection (2300 times)
[2026-02-02 15:38:47,173][187009] Signal inference workers to resume experience collection... (2300 times)
[2026-02-02 15:38:47,173][187009] InferenceWorker_p0-w0: resuming experience collection (2300 times)
[2026-02-02 15:38:49,592][187009] Fps is (10 sec: 3256.0, 60 sec: 3273.5, 300 sec: 3418.2). Total num frames: 12566528. Throughput: 0: 3402.4. Samples: 12574208. Policy #0 lag: (min: 12.0, avg: 15.0, max: 76.0)
[2026-02-02 15:38:49,592][187009] Avg episode reward: [(0, '1678.174')]
[2026-02-02 15:38:54,568][187009] Fps is (10 sec: 3272.9, 60 sec: 3276.1, 300 sec: 3415.9). Total num frames: 12582912. Throughput: 0: 3367.5. Samples: 12583936. Policy #0 lag: (min: 12.0, avg: 15.0, max: 76.0)
[2026-02-02 15:38:54,568][187009] Avg episode reward: [(0, '1726.559')]
[2026-02-02 15:38:59,647][187009] Fps is (10 sec: 3259.0, 60 sec: 3274.9, 300 sec: 3388.4). Total num frames: 12599296. Throughput: 0: 3332.6. Samples: 12602880. Policy #0 lag: (min: 12.0, avg: 15.0, max: 76.0)
[2026-02-02 15:38:59,647][187009] Avg episode reward: [(0, '1706.614')]
[2026-02-02 15:39:04,562][187009] Fps is (10 sec: 3278.8, 60 sec: 3278.8, 300 sec: 3387.9). Total num frames: 12615680. Throughput: 0: 3371.7. Samples: 12624384. Policy #0 lag: (min: 12.0, avg: 15.0, max: 76.0)
[2026-02-02 15:39:04,562][187009] Avg episode reward: [(0, '1709.381')]
[2026-02-02 15:39:09,523][187009] Fps is (10 sec: 3318.0, 60 sec: 3279.0, 300 sec: 3389.4). Total num frames: 12632064. Throughput: 0: 3310.7. Samples: 12633088. Policy #0 lag: (min: 10.0, avg: 13.0, max: 74.0)
[2026-02-02 15:39:09,523][187009] Avg episode reward: [(0, '1693.507')]
[2026-02-02 15:39:14,577][187009] Fps is (10 sec: 3271.9, 60 sec: 3279.8, 300 sec: 3388.6). Total num frames: 12648448. Throughput: 0: 3372.7. Samples: 12654592. Policy #0 lag: (min: 10.0, avg: 13.0, max: 74.0)
[2026-02-02 15:39:14,577][187009] Avg episode reward: [(0, '1651.319')]
[2026-02-02 15:39:19,620][187009] Fps is (10 sec: 3245.3, 60 sec: 3276.5, 300 sec: 3387.3). Total num frames: 12664832. Throughput: 0: 3372.6. Samples: 12675584. Policy #0 lag: (min: 10.0, avg: 13.0, max: 74.0)
[2026-02-02 15:39:19,620][187009] Avg episode reward: [(0, '1671.639')]
[2026-02-02 15:39:24,565][187009] Fps is (10 sec: 3280.7, 60 sec: 3274.3, 300 sec: 3388.8). Total num frames: 12681216. Throughput: 0: 3342.3. Samples: 12684800. Policy #0 lag: (min: 10.0, avg: 13.0, max: 74.0)
[2026-02-02 15:39:24,565][187009] Avg episode reward: [(0, '1655.108')]
[2026-02-02 15:39:29,608][187009] Fps is (10 sec: 3280.6, 60 sec: 3278.7, 300 sec: 3387.2). Total num frames: 12697600. Throughput: 0: 3352.6. Samples: 12704768. Policy #0 lag: (min: 10.0, avg: 13.0, max: 74.0)
[2026-02-02 15:39:29,608][187009] Avg episode reward: [(0, '1702.217')]
[2026-02-02 15:39:34,573][187009] Fps is (10 sec: 3274.1, 60 sec: 3274.5, 300 sec: 3388.5). Total num frames: 12713984. Throughput: 0: 3357.8. Samples: 12725248. Policy #0 lag: (min: 10.0, avg: 13.0, max: 74.0)
[2026-02-02 15:39:34,574][187009] Avg episode reward: [(0, '1684.227')]
[2026-02-02 15:39:39,566][187009] Fps is (10 sec: 3290.5, 60 sec: 3274.7, 300 sec: 3388.7). Total num frames: 12730368. Throughput: 0: 3356.6. Samples: 12734976. Policy #0 lag: (min: 10.0, avg: 13.0, max: 74.0)
[2026-02-02 15:39:39,567][187009] Avg episode reward: [(0, '1618.939')]
[2026-02-02 15:39:44,570][187009] Fps is (10 sec: 3277.9, 60 sec: 3276.0, 300 sec: 3388.1). Total num frames: 12746752. Throughput: 0: 3407.8. Samples: 12755968. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:39:44,570][187009] Avg episode reward: [(0, '1603.348')]
[2026-02-02 15:39:49,622][187009] Fps is (10 sec: 3258.6, 60 sec: 3275.1, 300 sec: 3387.8). Total num frames: 12763136. Throughput: 0: 3386.0. Samples: 12776960. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:39:49,623][187009] Avg episode reward: [(0, '1618.008')]
[2026-02-02 15:39:54,729][187009] Fps is (10 sec: 4031.8, 60 sec: 3404.2, 300 sec: 3413.6). Total num frames: 12787712. Throughput: 0: 3397.7. Samples: 12786688. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:39:54,729][187009] Avg episode reward: [(0, '1704.880')]
[2026-02-02 15:39:59,563][187009] Fps is (10 sec: 4120.4, 60 sec: 3418.1, 300 sec: 3416.4). Total num frames: 12804096. Throughput: 0: 3403.0. Samples: 12807680. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:39:59,563][187009] Avg episode reward: [(0, '1712.814')]
[2026-02-02 15:40:04,742][187009] Fps is (10 sec: 4090.8, 60 sec: 3539.3, 300 sec: 3441.1). Total num frames: 12828672. Throughput: 0: 3381.4. Samples: 12828160. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:40:04,742][187009] Avg episode reward: [(0, '1707.287')]
[2026-02-02 15:40:09,259][187009] Signal inference workers to stop experience collection... (2350 times)
[2026-02-02 15:40:09,259][187009] Signal inference workers to resume experience collection... (2350 times)
[2026-02-02 15:40:09,522][187009] InferenceWorker_p0-w0: stopping experience collection (2350 times)
[2026-02-02 15:40:09,522][187009] InferenceWorker_p0-w0: resuming experience collection (2350 times)
[2026-02-02 15:40:09,638][187009] Fps is (10 sec: 4065.7, 60 sec: 3543.1, 300 sec: 3442.8). Total num frames: 12845056. Throughput: 0: 3396.5. Samples: 12837888. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:40:09,638][187009] Avg episode reward: [(0, '1688.669')]
[2026-02-02 15:40:14,575][187009] Fps is (10 sec: 3332.3, 60 sec: 3550.0, 300 sec: 3443.8). Total num frames: 12861440. Throughput: 0: 3415.8. Samples: 12858368. Policy #0 lag: (min: 7.0, avg: 10.0, max: 71.0)
[2026-02-02 15:40:14,576][187009] Avg episode reward: [(0, '1699.938')]
[2026-02-02 15:40:19,645][187009] Fps is (10 sec: 3274.5, 60 sec: 3548.4, 300 sec: 3443.3). Total num frames: 12877824. Throughput: 0: 3407.9. Samples: 12878848. Policy #0 lag: (min: 7.0, avg: 10.0, max: 71.0)
[2026-02-02 15:40:19,645][187009] Avg episode reward: [(0, '1698.000')]
[2026-02-02 15:40:24,611][187009] Fps is (10 sec: 3265.3, 60 sec: 3547.2, 300 sec: 3443.0). Total num frames: 12894208. Throughput: 0: 3410.0. Samples: 12888576. Policy #0 lag: (min: 7.0, avg: 10.0, max: 71.0)
[2026-02-02 15:40:24,611][187009] Avg episode reward: [(0, '1625.767')]
[2026-02-02 15:40:29,525][187009] Fps is (10 sec: 3316.3, 60 sec: 3554.8, 300 sec: 3444.2). Total num frames: 12910592. Throughput: 0: 3428.1. Samples: 12910080. Policy #0 lag: (min: 7.0, avg: 10.0, max: 71.0)
[2026-02-02 15:40:29,526][187009] Avg episode reward: [(0, '1648.502')]
[2026-02-02 15:40:34,593][187009] Fps is (10 sec: 3282.5, 60 sec: 3548.7, 300 sec: 3418.6). Total num frames: 12926976. Throughput: 0: 3404.2. Samples: 12930048. Policy #0 lag: (min: 7.0, avg: 10.0, max: 71.0)
[2026-02-02 15:40:34,593][187009] Avg episode reward: [(0, '1669.630')]
[2026-02-02 15:40:34,725][187009] Saving /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_accel_policy3_aggressive_magpie_refined_params_02022026_smooth_aggressive_ttc/checkpoint_p0/checkpoint_000050496_12926976.pth...
[2026-02-02 15:40:34,729][187009] Removing /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_accel_policy3_aggressive_magpie_refined_params_02022026_smooth_aggressive_ttc/checkpoint_p0/checkpoint_000047296_12107776.pth
[2026-02-02 15:40:39,531][187009] Fps is (10 sec: 3275.0, 60 sec: 3552.0, 300 sec: 3417.3). Total num frames: 12943360. Throughput: 0: 3451.3. Samples: 12941312. Policy #0 lag: (min: 7.0, avg: 10.0, max: 71.0)
[2026-02-02 15:40:39,531][187009] Avg episode reward: [(0, '1703.713')]
[2026-02-02 15:40:44,564][187009] Fps is (10 sec: 3286.5, 60 sec: 3550.2, 300 sec: 3415.7). Total num frames: 12959744. Throughput: 0: 3401.9. Samples: 12960768. Policy #0 lag: (min: 7.0, avg: 10.0, max: 71.0)
[2026-02-02 15:40:44,564][187009] Avg episode reward: [(0, '1725.333')]
[2026-02-02 15:40:49,634][187009] Fps is (10 sec: 3243.3, 60 sec: 3549.2, 300 sec: 3388.6). Total num frames: 12976128. Throughput: 0: 3421.5. Samples: 12981760. Policy #0 lag: (min: 1.0, avg: 4.0, max: 65.0)
[2026-02-02 15:40:49,634][187009] Avg episode reward: [(0, '1697.508')]
[2026-02-02 15:40:54,569][187009] Fps is (10 sec: 3275.0, 60 sec: 3422.5, 300 sec: 3388.7). Total num frames: 12992512. Throughput: 0: 3452.7. Samples: 12993024. Policy #0 lag: (min: 1.0, avg: 4.0, max: 65.0)
[2026-02-02 15:40:54,569][187009] Avg episode reward: [(0, '1701.680')]
[2026-02-02 15:40:59,580][187009] Fps is (10 sec: 3294.6, 60 sec: 3412.4, 300 sec: 3388.0). Total num frames: 13008896. Throughput: 0: 3413.0. Samples: 13011968. Policy #0 lag: (min: 1.0, avg: 4.0, max: 65.0)
[2026-02-02 15:40:59,580][187009] Avg episode reward: [(0, '1654.000')]
[2026-02-02 15:41:04,581][187009] Fps is (10 sec: 3272.8, 60 sec: 3285.6, 300 sec: 3387.6). Total num frames: 13025280. Throughput: 0: 3429.5. Samples: 13032960. Policy #0 lag: (min: 1.0, avg: 4.0, max: 65.0)
[2026-02-02 15:41:04,582][187009] Avg episode reward: [(0, '1647.779')]
[2026-02-02 15:41:09,626][187009] Fps is (10 sec: 3261.8, 60 sec: 3277.4, 300 sec: 3387.4). Total num frames: 13041664. Throughput: 0: 3423.5. Samples: 13042688. Policy #0 lag: (min: 1.0, avg: 4.0, max: 65.0)
[2026-02-02 15:41:09,626][187009] Avg episode reward: [(0, '1666.871')]
[2026-02-02 15:41:14,525][187009] Fps is (10 sec: 3295.3, 60 sec: 3279.5, 300 sec: 3389.2). Total num frames: 13058048. Throughput: 0: 3413.3. Samples: 13063680. Policy #0 lag: (min: 1.0, avg: 4.0, max: 65.0)
[2026-02-02 15:41:14,525][187009] Avg episode reward: [(0, '1715.925')]
[2026-02-02 15:41:19,601][187009] Fps is (10 sec: 3285.2, 60 sec: 3279.2, 300 sec: 3387.9). Total num frames: 13074432. Throughput: 0: 3412.8. Samples: 13083648. Policy #0 lag: (min: 1.0, avg: 4.0, max: 65.0)
[2026-02-02 15:41:19,601][187009] Avg episode reward: [(0, '1685.604')]
[2026-02-02 15:41:24,549][187009] Fps is (10 sec: 3269.1, 60 sec: 3280.2, 300 sec: 3388.6). Total num frames: 13090816. Throughput: 0: 3366.5. Samples: 13092864. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:41:24,549][187009] Avg episode reward: [(0, '1664.606')]
[2026-02-02 15:41:29,651][187009] Fps is (10 sec: 3260.6, 60 sec: 3270.0, 300 sec: 3386.6). Total num frames: 13107200. Throughput: 0: 3406.7. Samples: 13114368. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:41:29,651][187009] Avg episode reward: [(0, '1676.084')]
[2026-02-02 15:41:30,511][187009] Signal inference workers to stop experience collection... (2400 times)
[2026-02-02 15:41:30,890][187009] InferenceWorker_p0-w0: stopping experience collection (2400 times)
[2026-02-02 15:41:30,891][187009] Signal inference workers to resume experience collection... (2400 times)
[2026-02-02 15:41:31,029][187009] InferenceWorker_p0-w0: resuming experience collection (2400 times)
[2026-02-02 15:41:34,603][187009] Fps is (10 sec: 3259.0, 60 sec: 3276.2, 300 sec: 3387.1). Total num frames: 13123584. Throughput: 0: 3392.9. Samples: 13134336. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:41:34,604][187009] Avg episode reward: [(0, '1758.575')]
[2026-02-02 15:41:39,625][187009] Fps is (10 sec: 3285.3, 60 sec: 3271.7, 300 sec: 3388.0). Total num frames: 13139968. Throughput: 0: 3352.3. Samples: 13144064. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:41:39,625][187009] Avg episode reward: [(0, '1774.315')]
[2026-02-02 15:41:44,567][187009] Fps is (10 sec: 3288.8, 60 sec: 3276.6, 300 sec: 3387.4). Total num frames: 13156352. Throughput: 0: 3403.0. Samples: 13165056. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:41:44,567][187009] Avg episode reward: [(0, '1748.893')]
[2026-02-02 15:41:49,543][187009] Fps is (10 sec: 3303.8, 60 sec: 3281.8, 300 sec: 3387.7). Total num frames: 13172736. Throughput: 0: 3404.9. Samples: 13186048. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:41:49,543][187009] Avg episode reward: [(0, '1735.926')]
[2026-02-02 15:41:54,755][187009] Fps is (10 sec: 4020.4, 60 sec: 3402.8, 300 sec: 3413.7). Total num frames: 13197312. Throughput: 0: 3403.6. Samples: 13196288. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:41:54,755][187009] Avg episode reward: [(0, '1717.341')]
[2026-02-02 15:41:59,808][187009] Fps is (10 sec: 4788.0, 60 sec: 3536.4, 300 sec: 3441.0). Total num frames: 13221888. Throughput: 0: 3392.0. Samples: 13217280. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:41:59,809][187009] Avg episode reward: [(0, '1790.724')]
[2026-02-02 15:42:04,628][187009] Fps is (10 sec: 4148.9, 60 sec: 3547.1, 300 sec: 3442.7). Total num frames: 13238272. Throughput: 0: 3434.0. Samples: 13238272. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:42:04,628][187009] Avg episode reward: [(0, '1806.067')]
[2026-02-02 15:42:09,524][187009] Fps is (10 sec: 3372.6, 60 sec: 3555.9, 300 sec: 3443.8). Total num frames: 13254656. Throughput: 0: 3449.4. Samples: 13248000. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:42:09,524][187009] Avg episode reward: [(0, '1828.396')]
[2026-02-02 15:42:14,619][187009] Fps is (10 sec: 3279.7, 60 sec: 3544.3, 300 sec: 3442.4). Total num frames: 13271040. Throughput: 0: 3427.1. Samples: 13268480. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:42:14,619][187009] Avg episode reward: [(0, '1766.009')]
[2026-02-02 15:42:19,584][187009] Fps is (10 sec: 3257.2, 60 sec: 3550.8, 300 sec: 3442.8). Total num frames: 13287424. Throughput: 0: 3426.2. Samples: 13288448. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:42:19,585][187009] Avg episode reward: [(0, '1754.662')]
[2026-02-02 15:42:24,579][187009] Fps is (10 sec: 3290.0, 60 sec: 3548.1, 300 sec: 3416.9). Total num frames: 13303808. Throughput: 0: 3416.8. Samples: 13297664. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:42:24,579][187009] Avg episode reward: [(0, '1696.019')]
[2026-02-02 15:42:29,533][187009] Fps is (10 sec: 3293.8, 60 sec: 3556.8, 300 sec: 3390.5). Total num frames: 13320192. Throughput: 0: 3404.5. Samples: 13318144. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:42:29,533][187009] Avg episode reward: [(0, '1753.800')]
[2026-02-02 15:42:34,581][187009] Fps is (10 sec: 3276.0, 60 sec: 3551.2, 300 sec: 3388.0). Total num frames: 13336576. Throughput: 0: 3364.9. Samples: 13337600. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:42:34,582][187009] Avg episode reward: [(0, '1787.888')]
[2026-02-02 15:42:34,728][187009] Saving /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_accel_policy3_aggressive_magpie_refined_params_02022026_smooth_aggressive_ttc/checkpoint_p0/checkpoint_000052096_13336576.pth...
[2026-02-02 15:42:34,732][187009] Removing /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_accel_policy3_aggressive_magpie_refined_params_02022026_smooth_aggressive_ttc/checkpoint_p0/checkpoint_000048896_12517376.pth
[2026-02-02 15:42:39,604][187009] Fps is (10 sec: 3253.8, 60 sec: 3551.1, 300 sec: 3388.2). Total num frames: 13352960. Throughput: 0: 3390.6. Samples: 13348352. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:42:39,604][187009] Avg episode reward: [(0, '1806.431')]
[2026-02-02 15:42:44,626][187009] Fps is (10 sec: 3262.3, 60 sec: 3546.4, 300 sec: 3386.8). Total num frames: 13369344. Throughput: 0: 3393.0. Samples: 13369344. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:42:44,626][187009] Avg episode reward: [(0, '1794.314')]
[2026-02-02 15:42:48,091][187009] Signal inference workers to stop experience collection... (2450 times)
[2026-02-02 15:42:48,448][187009] InferenceWorker_p0-w0: stopping experience collection (2450 times)
[2026-02-02 15:42:48,448][187009] Signal inference workers to resume experience collection... (2450 times)
[2026-02-02 15:42:48,448][187009] InferenceWorker_p0-w0: resuming experience collection (2450 times)
[2026-02-02 15:42:49,534][187009] Fps is (10 sec: 3299.8, 60 sec: 3550.4, 300 sec: 3388.1). Total num frames: 13385728. Throughput: 0: 3352.1. Samples: 13388800. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:42:49,534][187009] Avg episode reward: [(0, '1768.472')]
[2026-02-02 15:42:54,577][187009] Fps is (10 sec: 3292.9, 60 sec: 3423.5, 300 sec: 3388.3). Total num frames: 13402112. Throughput: 0: 3363.9. Samples: 13399552. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:42:54,577][187009] Avg episode reward: [(0, '1757.003')]
[2026-02-02 15:42:59,533][187009] Fps is (10 sec: 3277.1, 60 sec: 3291.9, 300 sec: 3388.6). Total num frames: 13418496. Throughput: 0: 3362.9. Samples: 13419520. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:42:59,533][187009] Avg episode reward: [(0, '1738.025')]
[2026-02-02 15:43:04,655][187009] Fps is (10 sec: 3251.5, 60 sec: 3275.3, 300 sec: 3386.8). Total num frames: 13434880. Throughput: 0: 3351.2. Samples: 13439488. Policy #0 lag: (min: 5.0, avg: 8.0, max: 69.0)
[2026-02-02 15:43:04,655][187009] Avg episode reward: [(0, '1778.976')]
[2026-02-02 15:43:09,597][187009] Fps is (10 sec: 3256.1, 60 sec: 3272.9, 300 sec: 3388.3). Total num frames: 13451264. Throughput: 0: 3389.2. Samples: 13450240. Policy #0 lag: (min: 5.0, avg: 8.0, max: 69.0)
[2026-02-02 15:43:09,597][187009] Avg episode reward: [(0, '1761.376')]
[2026-02-02 15:43:14,571][187009] Fps is (10 sec: 3304.6, 60 sec: 3279.4, 300 sec: 3388.4). Total num frames: 13467648. Throughput: 0: 3376.4. Samples: 13470208. Policy #0 lag: (min: 5.0, avg: 8.0, max: 69.0)
[2026-02-02 15:43:14,571][187009] Avg episode reward: [(0, '1800.488')]
[2026-02-02 15:43:19,641][187009] Fps is (10 sec: 3262.4, 60 sec: 3273.7, 300 sec: 3386.5). Total num frames: 13484032. Throughput: 0: 3420.2. Samples: 13491712. Policy #0 lag: (min: 5.0, avg: 8.0, max: 69.0)
[2026-02-02 15:43:19,641][187009] Avg episode reward: [(0, '1809.856')]
[2026-02-02 15:43:24,584][187009] Fps is (10 sec: 3272.4, 60 sec: 3276.5, 300 sec: 3388.6). Total num frames: 13500416. Throughput: 0: 3403.4. Samples: 13501440. Policy #0 lag: (min: 5.0, avg: 8.0, max: 69.0)
[2026-02-02 15:43:24,584][187009] Avg episode reward: [(0, '1884.750')]
[2026-02-02 15:43:24,731][187009] Saving new best policy, reward=1884.750!
[2026-02-02 15:43:29,529][187009] Fps is (10 sec: 3314.0, 60 sec: 3277.0, 300 sec: 3387.9). Total num frames: 13516800. Throughput: 0: 3397.9. Samples: 13521920. Policy #0 lag: (min: 5.0, avg: 8.0, max: 69.0)
[2026-02-02 15:43:29,529][187009] Avg episode reward: [(0, '1898.263')]
[2026-02-02 15:43:29,667][187009] Saving new best policy, reward=1898.263!
[2026-02-02 15:43:34,666][187009] Fps is (10 sec: 3250.3, 60 sec: 3272.2, 300 sec: 3386.3). Total num frames: 13533184. Throughput: 0: 3414.7. Samples: 13542912. Policy #0 lag: (min: 5.0, avg: 8.0, max: 69.0)
[2026-02-02 15:43:34,666][187009] Avg episode reward: [(0, '1873.447')]
[2026-02-02 15:43:39,567][187009] Fps is (10 sec: 3264.1, 60 sec: 3278.8, 300 sec: 3387.7). Total num frames: 13549568. Throughput: 0: 3379.9. Samples: 13551616. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 15:43:39,568][187009] Avg episode reward: [(0, '1782.386')]
