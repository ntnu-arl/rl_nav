[2025-11-06 15:58:15,184][322896] Saving configuration to /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_lidar_policy2_acc_yaw_sp/config.json...
[2025-11-06 15:58:15,215][322896] Using GPUs [0] for process 0 (actually maps to GPUs [0])
[2025-11-06 15:58:15,215][322896] Rollout worker 0 uses device cuda:0
[2025-11-06 15:58:15,247][322896] Using GPUs [0] for process 0 (actually maps to GPUs [0])
[2025-11-06 15:58:15,247][322896] InferenceWorker_p0-w0: min num requests: 1
[2025-11-06 15:58:15,248][322896] Using GPUs [0] for process 0 (actually maps to GPUs [0])
[2025-11-06 15:58:15,248][322896] Starting seed is not provided
[2025-11-06 15:58:15,248][322896] Using GPUs [0] for process 0 (actually maps to GPUs [0])
[2025-11-06 15:58:15,248][322896] Initializing actor-critic model on device cuda:0
[2025-11-06 15:58:15,249][322896] RunningMeanStd input shape: (337,)
[2025-11-06 15:58:15,249][322896] RunningMeanStd input shape: (1,)
[2025-11-06 15:58:15,263][322896] Created Actor Critic model with architecture:
[2025-11-06 15:58:15,263][322896] ActorCriticSharedWeights(
  (obs_normalizer): ObservationNormalizer(
    (running_mean_std): RunningMeanStdDictInPlace(
      (running_mean_std): ModuleDict(
        (observations): RunningMeanStdInPlace()
      )
    )
  )
  (returns_normalizer): RecursiveScriptModule(original_name=RunningMeanStdInPlace)
  (encoder): CustomEncoder(
    (encoders): ModuleDict(
      (obs_image): Sequential(
        (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): ELU(alpha=1.0)
        (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
        (3): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (4): ELU(alpha=1.0)
        (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
        (6): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (7): ELU(alpha=1.0)
        (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        (9): Flatten(start_dim=1, end_dim=-1)
      )
    )
    (mlp_head_custom): Sequential(
      (0): Linear(in_features=145, out_features=256, bias=True)
      (1): ELU(alpha=1.0)
      (2): Linear(in_features=256, out_features=128, bias=True)
      (3): ELU(alpha=1.0)
      (4): Linear(in_features=128, out_features=64, bias=True)
      (5): ELU(alpha=1.0)
    )
  )
  (core): ModelCoreRNN(
    (core): GRU(64, 128)
  )
  (decoder): MlpDecoder(
    (mlp): Identity()
  )
  (critic_linear): Linear(in_features=128, out_features=1, bias=True)
  (action_parameterization): ActionParameterizationDefault(
    (distribution_linear): Linear(in_features=128, out_features=8, bias=True)
  )
)
[2025-11-06 15:58:15,684][322896] Using optimizer <class 'torch.optim.adam.Adam'>
[2025-11-06 15:58:15,684][322896] No checkpoints found
[2025-11-06 15:58:15,684][322896] Did not load from checkpoint, starting from scratch!
[2025-11-06 15:58:15,685][322896] Initialized policy 0 weights for model version 0
[2025-11-06 15:58:15,685][322896] LearnerWorker_p0 finished initialization!
[2025-11-06 15:58:15,685][322896] Using GPUs [0] for process 0 (actually maps to GPUs [0])
[2025-11-06 15:58:15,691][322896] Fps is (10 sec: nan, 60 sec: nan, 300 sec: nan). Total num frames: 0. Throughput: 0: nan. Samples: 0. Policy #0 lag: (min: -1.0, avg: -1.0, max: -1.0)
[2025-11-06 15:58:15,691][322896] Inference worker 0-0 is ready!
[2025-11-06 15:58:15,691][322896] All inference workers are ready! Signal rollout workers to start!
[2025-11-06 15:58:15,691][322896] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 0.0). Total num frames: 0. Throughput: 0: 0.0. Samples: 0. Policy #0 lag: (min: -1.0, avg: -1.0, max: -1.0)
[2025-11-06 15:58:15,691][322896] EnvRunner 0-0 uses policy 0
[2025-11-06 15:58:29,395][322896] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 0.0). Total num frames: 0. Throughput: 0: 0.0. Samples: 0. Policy #0 lag: (min: -1.0, avg: -1.0, max: -1.0)
[2025-11-06 15:58:33,584][322896] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 0.0). Total num frames: 0. Throughput: 0: 0.0. Samples: 0. Policy #0 lag: (min: -1.0, avg: -1.0, max: -1.0)
[2025-11-06 15:58:33,688][322896] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 0.0). Total num frames: 0. Throughput: 0: 28.4. Samples: 512. Policy #0 lag: (min: -1.0, avg: -1.0, max: -1.0)
[2025-11-06 15:58:33,689][322896] Avg episode reward: [(0, '-10.000')]
[2025-11-06 15:58:34,882][322896] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 0.0). Total num frames: 0. Throughput: 0: 53.4. Samples: 1024. Policy #0 lag: (min: -1.0, avg: -1.0, max: -1.0)
[2025-11-06 15:58:34,882][322896] Avg episode reward: [(0, '-10.000')]
[2025-11-06 15:58:35,371][322896] Heartbeat connected on Batcher_0
[2025-11-06 15:58:35,371][322896] Heartbeat connected on LearnerWorker_p0
[2025-11-06 15:58:35,371][322896] Heartbeat connected on InferenceWorker_p0-w0
[2025-11-06 15:58:35,371][322896] Heartbeat connected on RolloutWorker_w0
[2025-11-06 15:58:37,798][322896] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 0.0). Total num frames: 0. Throughput: 0: 301.1. Samples: 6656. Policy #0 lag: (min: -1.0, avg: -1.0, max: -1.0)
[2025-11-06 15:58:37,798][322896] Avg episode reward: [(0, '-9.850')]
[2025-11-06 15:58:39,168][322896] Signal inference workers to stop experience collection...
[2025-11-06 15:58:40,497][322896] InferenceWorker_p0-w0: stopping experience collection
[2025-11-06 15:58:40,499][322896] Signal inference workers to resume experience collection...
[2025-11-06 15:58:40,636][322896] InferenceWorker_p0-w0: resuming experience collection
[2025-11-06 15:58:42,767][322896] Fps is (10 sec: 2077.8, 60 sec: 605.1, 300 sec: 605.1). Total num frames: 16384. Throughput: 0: 642.9. Samples: 17408. Policy #0 lag: (min: 15.0, avg: 15.0, max: 15.0)
[2025-11-06 15:58:42,768][322896] Avg episode reward: [(0, '-10.354')]
[2025-11-06 15:58:47,769][322896] Fps is (10 sec: 3286.1, 60 sec: 1021.5, 300 sec: 1021.5). Total num frames: 32768. Throughput: 0: 1165.1. Samples: 37376. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 15:58:47,770][322896] Avg episode reward: [(0, '-8.989')]
[2025-11-06 15:58:52,722][322896] Fps is (10 sec: 3291.8, 60 sec: 1327.3, 300 sec: 1327.3). Total num frames: 49152. Throughput: 0: 1576.2. Samples: 58368. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 15:58:52,722][322896] Avg episode reward: [(0, '-198.687')]
[2025-11-06 15:58:57,690][322896] Fps is (10 sec: 3303.1, 60 sec: 1560.4, 300 sec: 1560.4). Total num frames: 65536. Throughput: 0: 1633.6. Samples: 68608. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 15:58:57,690][322896] Avg episode reward: [(0, '-68.959')]
[2025-11-06 15:59:02,711][322896] Fps is (10 sec: 4920.3, 60 sec: 2090.7, 300 sec: 2090.7). Total num frames: 98304. Throughput: 0: 2827.7. Samples: 94208. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 15:59:02,711][322896] Avg episode reward: [(0, '-15.875')]
[2025-11-06 15:59:07,753][322896] Fps is (10 sec: 4884.2, 60 sec: 2202.9, 300 sec: 2202.9). Total num frames: 114688. Throughput: 0: 3386.5. Samples: 115712. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 15:59:07,754][322896] Avg episode reward: [(0, '-136.577')]
[2025-11-06 15:59:07,883][322896] Saving new best policy, reward=-136.577!
[2025-11-06 15:59:12,757][322896] Fps is (10 sec: 3261.9, 60 sec: 2296.9, 300 sec: 2296.8). Total num frames: 131072. Throughput: 0: 3250.1. Samples: 127488. Policy #0 lag: (min: 3.0, avg: 6.0, max: 67.0)
[2025-11-06 15:59:12,757][322896] Avg episode reward: [(0, '-28.096')]
[2025-11-06 15:59:12,867][322896] Saving new best policy, reward=-28.096!
[2025-11-06 15:59:17,783][322896] Fps is (10 sec: 3267.2, 60 sec: 3047.4, 300 sec: 2374.8). Total num frames: 147456. Throughput: 0: 3520.7. Samples: 152064. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 15:59:17,783][322896] Avg episode reward: [(0, '-65.487')]
[2025-11-06 15:59:22,715][322896] Fps is (10 sec: 3290.7, 60 sec: 3334.8, 300 sec: 2444.5). Total num frames: 163840. Throughput: 0: 3727.4. Samples: 174080. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 15:59:22,715][322896] Avg episode reward: [(0, '-55.329')]
[2025-11-06 15:59:27,806][322896] Fps is (10 sec: 4086.5, 60 sec: 3481.6, 300 sec: 2612.7). Total num frames: 188416. Throughput: 0: 3717.3. Samples: 184832. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 15:59:27,806][322896] Avg episode reward: [(0, '2.077')]
[2025-11-06 15:59:28,144][322896] Saving new best policy, reward=2.077!
[2025-11-06 15:59:32,742][322896] Fps is (10 sec: 4901.8, 60 sec: 3681.2, 300 sec: 2764.3). Total num frames: 212992. Throughput: 0: 3813.9. Samples: 208896. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 15:59:32,742][322896] Avg episode reward: [(0, '10.902')]
[2025-11-06 15:59:32,864][322896] Saving new best policy, reward=10.902!
[2025-11-06 15:59:37,709][322896] Fps is (10 sec: 4136.1, 60 sec: 3828.6, 300 sec: 2796.6). Total num frames: 229376. Throughput: 0: 3824.0. Samples: 230400. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 15:59:37,709][322896] Avg episode reward: [(0, '17.998')]
[2025-11-06 15:59:37,836][322896] Saving new best policy, reward=17.998!
[2025-11-06 15:59:42,689][322896] Fps is (10 sec: 3294.2, 60 sec: 3827.9, 300 sec: 2824.9). Total num frames: 245760. Throughput: 0: 3879.9. Samples: 243200. Policy #0 lag: (min: 12.0, avg: 15.0, max: 76.0)
[2025-11-06 15:59:42,689][322896] Avg episode reward: [(0, '33.571')]
[2025-11-06 15:59:42,808][322896] Saving new best policy, reward=33.571!
[2025-11-06 15:59:47,686][322896] Fps is (10 sec: 3284.4, 60 sec: 3828.3, 300 sec: 2849.5). Total num frames: 262144. Throughput: 0: 3790.9. Samples: 264704. Policy #0 lag: (min: 11.0, avg: 14.0, max: 75.0)
[2025-11-06 15:59:47,686][322896] Avg episode reward: [(0, '44.288')]
[2025-11-06 15:59:47,811][322896] Saving new best policy, reward=44.288!
[2025-11-06 15:59:49,525][322896] Signal inference workers to stop experience collection... (50 times)
[2025-11-06 15:59:49,866][322896] InferenceWorker_p0-w0: stopping experience collection (50 times)
[2025-11-06 15:59:49,867][322896] Signal inference workers to resume experience collection... (50 times)
[2025-11-06 15:59:49,867][322896] InferenceWorker_p0-w0: resuming experience collection (50 times)
[2025-11-06 15:59:52,764][322896] Fps is (10 sec: 3252.4, 60 sec: 3820.2, 300 sec: 2869.2). Total num frames: 278528. Throughput: 0: 3833.4. Samples: 288256. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 15:59:52,765][322896] Avg episode reward: [(0, '54.498')]
[2025-11-06 15:59:52,886][322896] Saving new best policy, reward=54.498!
[2025-11-06 15:59:57,761][322896] Fps is (10 sec: 3252.3, 60 sec: 3818.4, 300 sec: 2889.3). Total num frames: 294912. Throughput: 0: 3799.8. Samples: 298496. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 15:59:57,762][322896] Avg episode reward: [(0, '68.861')]
[2025-11-06 15:59:57,881][322896] Saving /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_lidar_policy2_acc_yaw_sp/checkpoint_p0/checkpoint_000001152_294912.pth...
[2025-11-06 15:59:57,885][322896] Saving new best policy, reward=68.861!
[2025-11-06 16:00:02,806][322896] Fps is (10 sec: 4895.0, 60 sec: 3816.9, 300 sec: 3059.1). Total num frames: 327680. Throughput: 0: 3775.5. Samples: 322048. Policy #0 lag: (min: 13.0, avg: 16.0, max: 77.0)
[2025-11-06 16:00:02,806][322896] Avg episode reward: [(0, '77.958')]
[2025-11-06 16:00:02,806][322896] Saving new best policy, reward=77.958!
[2025-11-06 16:00:07,767][322896] Fps is (10 sec: 4912.2, 60 sec: 3822.0, 300 sec: 3069.9). Total num frames: 344064. Throughput: 0: 3795.7. Samples: 345088. Policy #0 lag: (min: 12.0, avg: 15.0, max: 76.0)
[2025-11-06 16:00:07,768][322896] Avg episode reward: [(0, '93.692')]
[2025-11-06 16:00:07,896][322896] Saving new best policy, reward=93.692!
[2025-11-06 16:00:12,747][322896] Fps is (10 sec: 3296.0, 60 sec: 3823.5, 300 sec: 3079.3). Total num frames: 360448. Throughput: 0: 3816.5. Samples: 356352. Policy #0 lag: (min: 7.0, avg: 10.0, max: 71.0)
[2025-11-06 16:00:12,748][322896] Avg episode reward: [(0, '107.475')]
[2025-11-06 16:00:12,870][322896] Saving new best policy, reward=107.475!
[2025-11-06 16:00:17,707][322896] Fps is (10 sec: 3296.7, 60 sec: 3827.8, 300 sec: 3088.4). Total num frames: 376832. Throughput: 0: 3757.6. Samples: 377856. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:00:17,707][322896] Avg episode reward: [(0, '127.587')]
[2025-11-06 16:00:17,839][322896] Saving new best policy, reward=127.587!
[2025-11-06 16:00:22,695][322896] Fps is (10 sec: 3294.1, 60 sec: 3824.2, 300 sec: 3096.1). Total num frames: 393216. Throughput: 0: 3790.0. Samples: 400896. Policy #0 lag: (min: 11.0, avg: 14.0, max: 75.0)
[2025-11-06 16:00:22,695][322896] Avg episode reward: [(0, '145.917')]
[2025-11-06 16:00:22,823][322896] Saving new best policy, reward=145.917!
[2025-11-06 16:00:27,673][322896] Fps is (10 sec: 3288.0, 60 sec: 3694.6, 300 sec: 3103.4). Total num frames: 409600. Throughput: 0: 3744.6. Samples: 411648. Policy #0 lag: (min: 1.0, avg: 4.0, max: 65.0)
[2025-11-06 16:00:27,673][322896] Avg episode reward: [(0, '158.255')]
[2025-11-06 16:00:27,803][322896] Saving new best policy, reward=158.255!
[2025-11-06 16:00:32,693][322896] Fps is (10 sec: 3277.4, 60 sec: 3552.8, 300 sec: 3109.3). Total num frames: 425984. Throughput: 0: 3765.5. Samples: 434176. Policy #0 lag: (min: 9.0, avg: 12.0, max: 73.0)
[2025-11-06 16:00:32,693][322896] Avg episode reward: [(0, '170.288')]
[2025-11-06 16:00:32,822][322896] Saving new best policy, reward=170.288!
[2025-11-06 16:00:37,816][322896] Fps is (10 sec: 4845.9, 60 sec: 3816.1, 300 sec: 3227.8). Total num frames: 458752. Throughput: 0: 3761.7. Samples: 457728. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:00:37,816][322896] Avg episode reward: [(0, '180.057')]
[2025-11-06 16:00:37,818][322896] Saving new best policy, reward=180.057!
[2025-11-06 16:00:42,677][322896] Fps is (10 sec: 4922.9, 60 sec: 3823.7, 300 sec: 3232.5). Total num frames: 475136. Throughput: 0: 3784.5. Samples: 468480. Policy #0 lag: (min: 8.0, avg: 11.0, max: 72.0)
[2025-11-06 16:00:42,678][322896] Avg episode reward: [(0, '187.432')]
[2025-11-06 16:00:42,802][322896] Saving new best policy, reward=187.432!
[2025-11-06 16:00:47,697][322896] Fps is (10 sec: 3316.2, 60 sec: 3822.2, 300 sec: 3233.5). Total num frames: 491520. Throughput: 0: 3775.1. Samples: 491520. Policy #0 lag: (min: 10.0, avg: 13.0, max: 74.0)
[2025-11-06 16:00:47,697][322896] Avg episode reward: [(0, '189.249')]
[2025-11-06 16:00:47,833][322896] Saving new best policy, reward=189.249!
[2025-11-06 16:00:52,688][322896] Fps is (10 sec: 3273.3, 60 sec: 3827.8, 300 sec: 3235.1). Total num frames: 507904. Throughput: 0: 3727.1. Samples: 512512. Policy #0 lag: (min: 14.0, avg: 17.0, max: 78.0)
[2025-11-06 16:00:52,688][322896] Avg episode reward: [(0, '197.212')]
[2025-11-06 16:00:52,822][322896] Saving new best policy, reward=197.212!
[2025-11-06 16:00:57,773][322896] Fps is (10 sec: 3252.1, 60 sec: 3822.2, 300 sec: 3234.7). Total num frames: 524288. Throughput: 0: 3752.5. Samples: 525312. Policy #0 lag: (min: 3.0, avg: 6.0, max: 67.0)
[2025-11-06 16:00:57,773][322896] Avg episode reward: [(0, '202.217')]
[2025-11-06 16:00:57,903][322896] Saving new best policy, reward=202.217!
[2025-11-06 16:01:02,750][322896] Fps is (10 sec: 3256.8, 60 sec: 3553.2, 300 sec: 3236.4). Total num frames: 540672. Throughput: 0: 3751.1. Samples: 546816. Policy #0 lag: (min: 12.0, avg: 15.0, max: 76.0)
[2025-11-06 16:01:02,750][322896] Avg episode reward: [(0, '206.772')]
[2025-11-06 16:01:02,880][322896] Saving new best policy, reward=206.772!
[2025-11-06 16:01:03,725][322896] Signal inference workers to stop experience collection... (100 times)
[2025-11-06 16:01:03,730][322896] Signal inference workers to resume experience collection... (100 times)
[2025-11-06 16:01:03,956][322896] InferenceWorker_p0-w0: stopping experience collection (100 times)
[2025-11-06 16:01:03,956][322896] InferenceWorker_p0-w0: resuming experience collection (100 times)
[2025-11-06 16:01:08,011][322896] Fps is (10 sec: 4000.6, 60 sec: 3671.5, 300 sec: 3280.2). Total num frames: 565248. Throughput: 0: 3728.4. Samples: 569856. Policy #0 lag: (min: 11.0, avg: 14.0, max: 75.0)
[2025-11-06 16:01:08,012][322896] Avg episode reward: [(0, '211.380')]
[2025-11-06 16:01:08,355][322896] Saving new best policy, reward=211.380!
[2025-11-06 16:01:12,717][322896] Fps is (10 sec: 4931.1, 60 sec: 3824.8, 300 sec: 3331.8). Total num frames: 589824. Throughput: 0: 3751.0. Samples: 580608. Policy #0 lag: (min: 11.0, avg: 14.0, max: 75.0)
[2025-11-06 16:01:12,718][322896] Avg episode reward: [(0, '212.364')]
[2025-11-06 16:01:12,718][322896] Saving new best policy, reward=212.364!
[2025-11-06 16:01:17,723][322896] Fps is (10 sec: 4217.5, 60 sec: 3821.9, 300 sec: 3330.2). Total num frames: 606208. Throughput: 0: 3774.9. Samples: 604160. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:01:17,724][322896] Avg episode reward: [(0, '212.000')]
[2025-11-06 16:01:22,784][322896] Fps is (10 sec: 3255.1, 60 sec: 3817.3, 300 sec: 3327.7). Total num frames: 622592. Throughput: 0: 3723.2. Samples: 625152. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:01:22,784][322896] Avg episode reward: [(0, '208.936')]
[2025-11-06 16:01:27,742][322896] Fps is (10 sec: 3270.8, 60 sec: 3818.6, 300 sec: 3327.1). Total num frames: 638976. Throughput: 0: 3760.7. Samples: 637952. Policy #0 lag: (min: 4.0, avg: 7.0, max: 68.0)
[2025-11-06 16:01:27,742][322896] Avg episode reward: [(0, '211.287')]
[2025-11-06 16:01:32,761][322896] Fps is (10 sec: 3284.4, 60 sec: 3818.6, 300 sec: 3325.5). Total num frames: 655360. Throughput: 0: 3726.6. Samples: 659456. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:01:32,761][322896] Avg episode reward: [(0, '212.842')]
[2025-11-06 16:01:32,892][322896] Saving new best policy, reward=212.842!
[2025-11-06 16:01:37,748][322896] Fps is (10 sec: 3274.7, 60 sec: 3553.9, 300 sec: 3324.5). Total num frames: 671744. Throughput: 0: 3772.4. Samples: 682496. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:01:37,748][322896] Avg episode reward: [(0, '218.076')]
[2025-11-06 16:01:37,878][322896] Saving new best policy, reward=218.076!
[2025-11-06 16:01:42,960][322896] Fps is (10 sec: 4015.9, 60 sec: 3669.1, 300 sec: 3359.5). Total num frames: 696320. Throughput: 0: 3716.4. Samples: 693248. Policy #0 lag: (min: 12.0, avg: 15.0, max: 76.0)
[2025-11-06 16:01:42,960][322896] Avg episode reward: [(0, '219.287')]
[2025-11-06 16:01:43,315][322896] Saving new best policy, reward=219.287!
[2025-11-06 16:01:47,688][322896] Fps is (10 sec: 4944.9, 60 sec: 3823.5, 300 sec: 3400.5). Total num frames: 720896. Throughput: 0: 3771.2. Samples: 716288. Policy #0 lag: (min: 13.0, avg: 16.0, max: 77.0)
[2025-11-06 16:01:47,688][322896] Avg episode reward: [(0, '224.374')]
[2025-11-06 16:01:47,690][322896] Saving new best policy, reward=224.374!
[2025-11-06 16:01:52,727][322896] Fps is (10 sec: 4193.8, 60 sec: 3820.5, 300 sec: 3397.0). Total num frames: 737280. Throughput: 0: 3767.1. Samples: 738304. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:01:52,727][322896] Avg episode reward: [(0, '226.945')]
[2025-11-06 16:01:52,855][322896] Saving new best policy, reward=226.945!
[2025-11-06 16:01:57,766][322896] Fps is (10 sec: 3251.5, 60 sec: 3823.4, 300 sec: 3393.7). Total num frames: 753664. Throughput: 0: 3762.0. Samples: 750080. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:01:57,766][322896] Avg episode reward: [(0, '229.288')]
[2025-11-06 16:01:57,896][322896] Saving /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_lidar_policy2_acc_yaw_sp/checkpoint_p0/checkpoint_000002944_753664.pth...
[2025-11-06 16:01:57,901][322896] Saving new best policy, reward=229.288!
[2025-11-06 16:02:02,769][322896] Fps is (10 sec: 3263.1, 60 sec: 3821.7, 300 sec: 3391.1). Total num frames: 770048. Throughput: 0: 3705.4. Samples: 771072. Policy #0 lag: (min: 2.0, avg: 5.0, max: 66.0)
[2025-11-06 16:02:02,769][322896] Avg episode reward: [(0, '231.076')]
[2025-11-06 16:02:02,894][322896] Saving new best policy, reward=231.076!
[2025-11-06 16:02:07,683][322896] Fps is (10 sec: 3304.0, 60 sec: 3706.7, 300 sec: 3389.9). Total num frames: 786432. Throughput: 0: 3763.1. Samples: 794112. Policy #0 lag: (min: 11.0, avg: 14.0, max: 75.0)
[2025-11-06 16:02:07,684][322896] Avg episode reward: [(0, '234.569')]
[2025-11-06 16:02:07,813][322896] Saving new best policy, reward=234.569!
[2025-11-06 16:02:12,681][322896] Fps is (10 sec: 3305.8, 60 sec: 3552.0, 300 sec: 3387.5). Total num frames: 802816. Throughput: 0: 3714.2. Samples: 804864. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:02:12,681][322896] Avg episode reward: [(0, '234.490')]
[2025-11-06 16:02:17,685][322896] Signal inference workers to stop experience collection... (150 times)
[2025-11-06 16:02:17,685][322896] Fps is (10 sec: 3276.2, 60 sec: 3552.1, 300 sec: 3385.2). Total num frames: 819200. Throughput: 0: 3749.6. Samples: 827904. Policy #0 lag: (min: 6.0, avg: 9.0, max: 70.0)
[2025-11-06 16:02:17,685][322896] Avg episode reward: [(0, '236.605')]
[2025-11-06 16:02:18,036][322896] InferenceWorker_p0-w0: stopping experience collection (150 times)
[2025-11-06 16:02:18,042][322896] Saving new best policy, reward=236.605!
[2025-11-06 16:02:18,046][322896] Signal inference workers to resume experience collection... (150 times)
[2025-11-06 16:02:18,165][322896] InferenceWorker_p0-w0: resuming experience collection (150 times)
[2025-11-06 16:02:22,716][322896] Fps is (10 sec: 4898.1, 60 sec: 3827.3, 300 sec: 3448.9). Total num frames: 851968. Throughput: 0: 3757.3. Samples: 851456. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:02:22,716][322896] Avg episode reward: [(0, '238.711')]
[2025-11-06 16:02:22,717][322896] Saving new best policy, reward=238.711!
[2025-11-06 16:02:27,704][322896] Fps is (10 sec: 4906.0, 60 sec: 3825.3, 300 sec: 3445.7). Total num frames: 868352. Throughput: 0: 3764.7. Samples: 861696. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:02:27,704][322896] Avg episode reward: [(0, '240.085')]
[2025-11-06 16:02:27,831][322896] Saving new best policy, reward=240.085!
[2025-11-06 16:02:32,678][322896] Fps is (10 sec: 3289.4, 60 sec: 3828.2, 300 sec: 3442.7). Total num frames: 884736. Throughput: 0: 3755.5. Samples: 885248. Policy #0 lag: (min: 0.0, avg: 3.0, max: 64.0)
[2025-11-06 16:02:32,678][322896] Avg episode reward: [(0, '238.424')]
[2025-11-06 16:02:37,790][322896] Fps is (10 sec: 3248.9, 60 sec: 3820.3, 300 sec: 3438.1). Total num frames: 901120. Throughput: 0: 3726.7. Samples: 906240. Policy #0 lag: (min: 8.0, avg: 11.0, max: 72.0)
[2025-11-06 16:02:37,790][322896] Avg episode reward: [(0, '237.515')]
[2025-11-06 16:02:42,689][322896] Fps is (10 sec: 3273.0, 60 sec: 3703.1, 300 sec: 3436.4). Total num frames: 917504. Throughput: 0: 3749.7. Samples: 918528. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:02:42,690][322896] Avg episode reward: [(0, '240.397')]
[2025-11-06 16:02:42,817][322896] Saving new best policy, reward=240.397!
[2025-11-06 16:02:47,732][322896] Fps is (10 sec: 3296.1, 60 sec: 3547.3, 300 sec: 3432.9). Total num frames: 933888. Throughput: 0: 3757.8. Samples: 940032. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:02:47,732][322896] Avg episode reward: [(0, '241.641')]
[2025-11-06 16:02:47,863][322896] Saving new best policy, reward=241.641!
[2025-11-06 16:02:52,740][322896] Fps is (10 sec: 3260.2, 60 sec: 3549.1, 300 sec: 3430.0). Total num frames: 950272. Throughput: 0: 3749.9. Samples: 963072. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:02:52,740][322896] Avg episode reward: [(0, '240.023')]
[2025-11-06 16:02:57,842][322896] Fps is (10 sec: 4861.3, 60 sec: 3818.1, 300 sec: 3484.1). Total num frames: 983040. Throughput: 0: 3741.3. Samples: 973824. Policy #0 lag: (min: 6.0, avg: 9.0, max: 70.0)
[2025-11-06 16:02:57,843][322896] Avg episode reward: [(0, '240.234')]
[2025-11-06 16:03:02,753][322896] Fps is (10 sec: 4908.8, 60 sec: 3823.9, 300 sec: 3481.6). Total num frames: 999424. Throughput: 0: 3737.6. Samples: 996352. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:03:02,753][322896] Avg episode reward: [(0, '242.483')]
[2025-11-06 16:03:02,887][322896] Saving new best policy, reward=242.483!
[2025-11-06 16:03:07,786][322896] Fps is (10 sec: 3295.4, 60 sec: 3816.4, 300 sec: 3477.7). Total num frames: 1015808. Throughput: 0: 3692.0. Samples: 1017856. Policy #0 lag: (min: 14.0, avg: 17.0, max: 78.0)
[2025-11-06 16:03:07,786][322896] Avg episode reward: [(0, '245.560')]
[2025-11-06 16:03:07,912][322896] Saving new best policy, reward=245.560!
[2025-11-06 16:03:12,747][322896] Fps is (10 sec: 3278.8, 60 sec: 3818.7, 300 sec: 3642.8). Total num frames: 1032192. Throughput: 0: 3739.7. Samples: 1030144. Policy #0 lag: (min: 10.0, avg: 13.0, max: 74.0)
[2025-11-06 16:03:12,747][322896] Avg episode reward: [(0, '249.179')]
[2025-11-06 16:03:12,871][322896] Saving new best policy, reward=249.179!
[2025-11-06 16:03:17,730][322896] Fps is (10 sec: 3295.3, 60 sec: 3820.1, 300 sec: 3690.3). Total num frames: 1048576. Throughput: 0: 3670.8. Samples: 1050624. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:03:17,730][322896] Avg episode reward: [(0, '251.397')]
[2025-11-06 16:03:17,860][322896] Saving new best policy, reward=251.397!
[2025-11-06 16:03:22,743][322896] Fps is (10 sec: 3278.0, 60 sec: 3548.3, 300 sec: 3684.3). Total num frames: 1064960. Throughput: 0: 3724.4. Samples: 1073664. Policy #0 lag: (min: 26.0, avg: 29.0, max: 90.0)
[2025-11-06 16:03:22,744][322896] Avg episode reward: [(0, '252.947')]
[2025-11-06 16:03:22,868][322896] Saving new best policy, reward=252.947!
[2025-11-06 16:03:27,762][322896] Fps is (10 sec: 3266.2, 60 sec: 3546.4, 300 sec: 3692.1). Total num frames: 1081344. Throughput: 0: 3680.4. Samples: 1084416. Policy #0 lag: (min: 47.0, avg: 50.0, max: 111.0)
[2025-11-06 16:03:27,763][322896] Avg episode reward: [(0, '251.905')]
[2025-11-06 16:03:28,483][322896] Signal inference workers to stop experience collection... (200 times)
[2025-11-06 16:03:28,820][322896] InferenceWorker_p0-w0: stopping experience collection (200 times)
[2025-11-06 16:03:28,820][322896] Signal inference workers to resume experience collection... (200 times)
[2025-11-06 16:03:28,820][322896] InferenceWorker_p0-w0: resuming experience collection (200 times)
[2025-11-06 16:03:32,840][322896] Fps is (10 sec: 4056.9, 60 sec: 3676.5, 300 sec: 3748.3). Total num frames: 1105920. Throughput: 0: 3711.6. Samples: 1107456. Policy #0 lag: (min: 2.0, avg: 5.0, max: 66.0)
[2025-11-06 16:03:32,840][322896] Avg episode reward: [(0, '247.604')]
[2025-11-06 16:03:37,761][322896] Fps is (10 sec: 4915.9, 60 sec: 3824.8, 300 sec: 3776.7). Total num frames: 1130496. Throughput: 0: 3718.8. Samples: 1130496. Policy #0 lag: (min: 47.0, avg: 50.0, max: 111.0)
[2025-11-06 16:03:37,761][322896] Avg episode reward: [(0, '248.159')]
[2025-11-06 16:03:42,742][322896] Fps is (10 sec: 4136.5, 60 sec: 3819.6, 300 sec: 3777.0). Total num frames: 1146880. Throughput: 0: 3728.9. Samples: 1141248. Policy #0 lag: (min: 47.0, avg: 50.0, max: 111.0)
[2025-11-06 16:03:42,742][322896] Avg episode reward: [(0, '247.440')]
[2025-11-06 16:03:47,680][322896] Fps is (10 sec: 3303.6, 60 sec: 3826.2, 300 sec: 3777.2). Total num frames: 1163264. Throughput: 0: 3738.0. Samples: 1164288. Policy #0 lag: (min: 1.0, avg: 4.0, max: 65.0)
[2025-11-06 16:03:47,680][322896] Avg episode reward: [(0, '251.523')]
[2025-11-06 16:03:52,787][322896] Fps is (10 sec: 3262.0, 60 sec: 3819.9, 300 sec: 3775.4). Total num frames: 1179648. Throughput: 0: 3731.8. Samples: 1185792. Policy #0 lag: (min: 38.0, avg: 41.0, max: 102.0)
[2025-11-06 16:03:52,787][322896] Avg episode reward: [(0, '257.145')]
[2025-11-06 16:03:52,911][322896] Saving new best policy, reward=257.145!
[2025-11-06 16:03:57,774][322896] Fps is (10 sec: 3246.2, 60 sec: 3553.9, 300 sec: 3720.3). Total num frames: 1196032. Throughput: 0: 3706.9. Samples: 1197056. Policy #0 lag: (min: 38.0, avg: 41.0, max: 102.0)
[2025-11-06 16:03:57,774][322896] Avg episode reward: [(0, '258.185')]
[2025-11-06 16:03:57,909][322896] Saving /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_lidar_policy2_acc_yaw_sp/checkpoint_p0/checkpoint_000004672_1196032.pth...
[2025-11-06 16:03:57,913][322896] Removing /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_lidar_policy2_acc_yaw_sp/checkpoint_p0/checkpoint_000001152_294912.pth
[2025-11-06 16:03:57,913][322896] Saving new best policy, reward=258.185!
[2025-11-06 16:04:02,693][322896] Fps is (10 sec: 3308.1, 60 sec: 3553.5, 300 sec: 3721.9). Total num frames: 1212416. Throughput: 0: 3746.4. Samples: 1219072. Policy #0 lag: (min: 11.0, avg: 14.0, max: 75.0)
[2025-11-06 16:04:02,693][322896] Avg episode reward: [(0, '260.105')]
[2025-11-06 16:04:02,826][322896] Saving new best policy, reward=260.105!
[2025-11-06 16:04:07,952][322896] Fps is (10 sec: 4024.4, 60 sec: 3676.2, 300 sec: 3746.4). Total num frames: 1236992. Throughput: 0: 3726.0. Samples: 1242112. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:04:07,952][322896] Avg episode reward: [(0, '264.076')]
[2025-11-06 16:04:08,295][322896] Saving new best policy, reward=264.076!
[2025-11-06 16:04:12,683][322896] Fps is (10 sec: 4919.9, 60 sec: 3827.0, 300 sec: 3777.9). Total num frames: 1261568. Throughput: 0: 3749.9. Samples: 1252864. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:04:12,683][322896] Avg episode reward: [(0, '265.603')]
[2025-11-06 16:04:12,683][322896] Saving new best policy, reward=265.603!
[2025-11-06 16:04:17,674][322896] Fps is (10 sec: 4213.0, 60 sec: 3826.5, 300 sec: 3777.2). Total num frames: 1277952. Throughput: 0: 3757.1. Samples: 1275904. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:04:17,674][322896] Avg episode reward: [(0, '264.483')]
[2025-11-06 16:04:22,786][322896] Fps is (10 sec: 3243.6, 60 sec: 3820.3, 300 sec: 3749.1). Total num frames: 1294336. Throughput: 0: 3661.6. Samples: 1295360. Policy #0 lag: (min: 53.0, avg: 56.0, max: 117.0)
[2025-11-06 16:04:22,786][322896] Avg episode reward: [(0, '262.016')]
[2025-11-06 16:04:27,745][322896] Fps is (10 sec: 3253.7, 60 sec: 3824.0, 300 sec: 3721.1). Total num frames: 1310720. Throughput: 0: 3697.5. Samples: 1307648. Policy #0 lag: (min: 53.0, avg: 56.0, max: 117.0)
[2025-11-06 16:04:27,746][322896] Avg episode reward: [(0, '264.533')]
[2025-11-06 16:04:32,678][322896] Fps is (10 sec: 3312.3, 60 sec: 3696.3, 300 sec: 3721.5). Total num frames: 1327104. Throughput: 0: 3641.0. Samples: 1328128. Policy #0 lag: (min: 4.0, avg: 7.0, max: 68.0)
[2025-11-06 16:04:32,679][322896] Avg episode reward: [(0, '266.765')]
[2025-11-06 16:04:32,827][322896] Saving new best policy, reward=266.765!
[2025-11-06 16:04:37,797][322896] Fps is (10 sec: 3259.8, 60 sec: 3547.7, 300 sec: 3719.7). Total num frames: 1343488. Throughput: 0: 3617.3. Samples: 1348608. Policy #0 lag: (min: 50.0, avg: 53.0, max: 114.0)
[2025-11-06 16:04:37,798][322896] Avg episode reward: [(0, '269.843')]
[2025-11-06 16:04:37,940][322896] Saving new best policy, reward=269.843!
[2025-11-06 16:04:42,704][322896] Fps is (10 sec: 3268.5, 60 sec: 3552.1, 300 sec: 3720.9). Total num frames: 1359872. Throughput: 0: 3635.2. Samples: 1360384. Policy #0 lag: (min: 50.0, avg: 53.0, max: 114.0)
[2025-11-06 16:04:42,704][322896] Avg episode reward: [(0, '268.240')]
[2025-11-06 16:04:44,609][322896] Signal inference workers to stop experience collection... (250 times)
[2025-11-06 16:04:44,612][322896] Signal inference workers to resume experience collection... (250 times)
[2025-11-06 16:04:44,856][322896] InferenceWorker_p0-w0: stopping experience collection (250 times)
[2025-11-06 16:04:44,856][322896] InferenceWorker_p0-w0: resuming experience collection (250 times)
[2025-11-06 16:04:47,810][322896] Fps is (10 sec: 3272.7, 60 sec: 3542.2, 300 sec: 3720.5). Total num frames: 1376256. Throughput: 0: 3586.0. Samples: 1380864. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:04:47,810][322896] Avg episode reward: [(0, '266.172')]
[2025-11-06 16:04:52,731][322896] Fps is (10 sec: 3267.9, 60 sec: 3553.2, 300 sec: 3721.5). Total num frames: 1392640. Throughput: 0: 3590.3. Samples: 1402880. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:04:52,731][322896] Avg episode reward: [(0, '267.245')]
[2025-11-06 16:04:57,679][322896] Fps is (10 sec: 3320.0, 60 sec: 3555.5, 300 sec: 3667.1). Total num frames: 1409024. Throughput: 0: 3561.5. Samples: 1413120. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:04:57,680][322896] Avg episode reward: [(0, '265.553')]
[2025-11-06 16:05:02,778][322896] Fps is (10 sec: 4076.9, 60 sec: 3681.2, 300 sec: 3693.2). Total num frames: 1433600. Throughput: 0: 3530.4. Samples: 1435136. Policy #0 lag: (min: 4.0, avg: 7.0, max: 68.0)
[2025-11-06 16:05:02,778][322896] Avg episode reward: [(0, '273.253')]
[2025-11-06 16:05:03,136][322896] Saving new best policy, reward=273.253!
[2025-11-06 16:05:07,760][322896] Fps is (10 sec: 4876.0, 60 sec: 3698.2, 300 sec: 3721.0). Total num frames: 1458176. Throughput: 0: 3608.8. Samples: 1457664. Policy #0 lag: (min: 4.0, avg: 7.0, max: 68.0)
[2025-11-06 16:05:07,760][322896] Avg episode reward: [(0, '279.087')]
[2025-11-06 16:05:07,762][322896] Saving new best policy, reward=279.087!
[2025-11-06 16:05:12,720][322896] Fps is (10 sec: 4120.0, 60 sec: 3547.7, 300 sec: 3721.0). Total num frames: 1474560. Throughput: 0: 3563.3. Samples: 1467904. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:05:12,720][322896] Avg episode reward: [(0, '282.379')]
[2025-11-06 16:05:12,855][322896] Saving new best policy, reward=282.379!
[2025-11-06 16:05:17,720][322896] Fps is (10 sec: 3290.0, 60 sec: 3547.2, 300 sec: 3720.8). Total num frames: 1490944. Throughput: 0: 3580.7. Samples: 1489408. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:05:17,720][322896] Avg episode reward: [(0, '282.149')]
[2025-11-06 16:05:22,767][322896] Fps is (10 sec: 3261.5, 60 sec: 3551.0, 300 sec: 3719.9). Total num frames: 1507328. Throughput: 0: 3586.4. Samples: 1509888. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:05:22,767][322896] Avg episode reward: [(0, '281.692')]
[2025-11-06 16:05:27,727][322896] Fps is (10 sec: 3274.5, 60 sec: 3551.0, 300 sec: 3720.7). Total num frames: 1523712. Throughput: 0: 3593.5. Samples: 1522176. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:05:27,727][322896] Avg episode reward: [(0, '281.806')]
[2025-11-06 16:05:32,784][322896] Fps is (10 sec: 3271.3, 60 sec: 3543.7, 300 sec: 3666.0). Total num frames: 1540096. Throughput: 0: 3586.1. Samples: 1542144. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:05:32,784][322896] Avg episode reward: [(0, '280.529')]
[2025-11-06 16:05:37,710][322896] Fps is (10 sec: 3282.2, 60 sec: 3555.0, 300 sec: 3665.2). Total num frames: 1556480. Throughput: 0: 3585.6. Samples: 1564160. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:05:37,711][322896] Avg episode reward: [(0, '284.412')]
[2025-11-06 16:05:37,841][322896] Saving new best policy, reward=284.412!
[2025-11-06 16:05:42,715][322896] Fps is (10 sec: 3299.3, 60 sec: 3549.2, 300 sec: 3665.3). Total num frames: 1572864. Throughput: 0: 3569.8. Samples: 1573888. Policy #0 lag: (min: 7.0, avg: 10.0, max: 71.0)
[2025-11-06 16:05:42,716][322896] Avg episode reward: [(0, '283.995')]
[2025-11-06 16:05:47,712][322896] Fps is (10 sec: 3276.2, 60 sec: 3555.6, 300 sec: 3665.3). Total num frames: 1589248. Throughput: 0: 3612.0. Samples: 1597440. Policy #0 lag: (min: 7.0, avg: 10.0, max: 71.0)
[2025-11-06 16:05:47,713][322896] Avg episode reward: [(0, '283.956')]
[2025-11-06 16:05:52,817][322896] Fps is (10 sec: 4054.9, 60 sec: 3681.1, 300 sec: 3692.8). Total num frames: 1613824. Throughput: 0: 3590.8. Samples: 1619456. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:05:52,817][322896] Avg episode reward: [(0, '286.112')]
[2025-11-06 16:05:53,151][322896] Saving new best policy, reward=286.112!
[2025-11-06 16:05:57,731][322896] Fps is (10 sec: 4906.2, 60 sec: 3819.7, 300 sec: 3721.3). Total num frames: 1638400. Throughput: 0: 3605.9. Samples: 1630208. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:05:57,731][322896] Avg episode reward: [(0, '288.592')]
[2025-11-06 16:05:57,733][322896] Saving /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_lidar_policy2_acc_yaw_sp/checkpoint_p0/checkpoint_000006400_1638400.pth...
[2025-11-06 16:05:57,737][322896] Removing /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_lidar_policy2_acc_yaw_sp/checkpoint_p0/checkpoint_000002944_753664.pth
[2025-11-06 16:05:57,737][322896] Saving new best policy, reward=288.592!
[2025-11-06 16:06:01,433][322896] Signal inference workers to stop experience collection... (300 times)
[2025-11-06 16:06:01,801][322896] InferenceWorker_p0-w0: stopping experience collection (300 times)
[2025-11-06 16:06:01,803][322896] Signal inference workers to resume experience collection... (300 times)
[2025-11-06 16:06:01,924][322896] InferenceWorker_p0-w0: resuming experience collection (300 times)
[2025-11-06 16:06:02,800][322896] Fps is (10 sec: 4102.8, 60 sec: 3685.0, 300 sec: 3696.0). Total num frames: 1654784. Throughput: 0: 3611.7. Samples: 1652224. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:06:02,800][322896] Avg episode reward: [(0, '292.124')]
[2025-11-06 16:06:02,930][322896] Saving new best policy, reward=292.124!
[2025-11-06 16:06:07,707][322896] Fps is (10 sec: 3284.5, 60 sec: 3553.0, 300 sec: 3665.7). Total num frames: 1671168. Throughput: 0: 3634.3. Samples: 1673216. Policy #0 lag: (min: 10.0, avg: 13.0, max: 74.0)
[2025-11-06 16:06:07,708][322896] Avg episode reward: [(0, '295.630')]
[2025-11-06 16:06:07,846][322896] Saving new best policy, reward=295.630!
[2025-11-06 16:06:12,707][322896] Fps is (10 sec: 3307.5, 60 sec: 3550.6, 300 sec: 3665.8). Total num frames: 1687552. Throughput: 0: 3631.1. Samples: 1685504. Policy #0 lag: (min: 10.0, avg: 13.0, max: 74.0)
[2025-11-06 16:06:12,708][322896] Avg episode reward: [(0, '294.672')]
[2025-11-06 16:06:17,690][322896] Fps is (10 sec: 3282.5, 60 sec: 3551.6, 300 sec: 3666.7). Total num frames: 1703936. Throughput: 0: 3659.9. Samples: 1706496. Policy #0 lag: (min: 8.0, avg: 11.0, max: 72.0)
[2025-11-06 16:06:17,690][322896] Avg episode reward: [(0, '298.135')]
[2025-11-06 16:06:17,826][322896] Saving new best policy, reward=298.135!
[2025-11-06 16:06:22,736][322896] Fps is (10 sec: 3267.5, 60 sec: 3551.7, 300 sec: 3665.6). Total num frames: 1720320. Throughput: 0: 3661.6. Samples: 1729024. Policy #0 lag: (min: 8.0, avg: 11.0, max: 72.0)
[2025-11-06 16:06:22,736][322896] Avg episode reward: [(0, '300.073')]
[2025-11-06 16:06:22,863][322896] Saving new best policy, reward=300.073!
[2025-11-06 16:06:27,673][322896] Fps is (10 sec: 3282.2, 60 sec: 3553.0, 300 sec: 3666.7). Total num frames: 1736704. Throughput: 0: 3689.9. Samples: 1739776. Policy #0 lag: (min: 11.0, avg: 14.0, max: 75.0)
[2025-11-06 16:06:27,674][322896] Avg episode reward: [(0, '303.291')]
[2025-11-06 16:06:27,811][322896] Saving new best policy, reward=303.291!
[2025-11-06 16:06:32,723][322896] Fps is (10 sec: 3281.0, 60 sec: 3553.5, 300 sec: 3665.9). Total num frames: 1753088. Throughput: 0: 3651.4. Samples: 1761792. Policy #0 lag: (min: 11.0, avg: 14.0, max: 75.0)
[2025-11-06 16:06:32,723][322896] Avg episode reward: [(0, '306.490')]
[2025-11-06 16:06:32,854][322896] Saving new best policy, reward=306.490!
[2025-11-06 16:06:37,839][322896] Fps is (10 sec: 4029.4, 60 sec: 3678.5, 300 sec: 3667.1). Total num frames: 1777664. Throughput: 0: 3639.1. Samples: 1783296. Policy #0 lag: (min: 1.0, avg: 4.0, max: 65.0)
[2025-11-06 16:06:37,839][322896] Avg episode reward: [(0, '304.433')]
[2025-11-06 16:06:42,718][322896] Fps is (10 sec: 4917.7, 60 sec: 3822.8, 300 sec: 3665.2). Total num frames: 1802240. Throughput: 0: 3641.9. Samples: 1794048. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:06:42,718][322896] Avg episode reward: [(0, '302.916')]
[2025-11-06 16:06:47,712][322896] Fps is (10 sec: 4148.6, 60 sec: 3823.0, 300 sec: 3665.8). Total num frames: 1818624. Throughput: 0: 3670.9. Samples: 1817088. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:06:47,712][322896] Avg episode reward: [(0, '299.125')]
[2025-11-06 16:06:52,755][322896] Fps is (10 sec: 3264.5, 60 sec: 3690.2, 300 sec: 3665.7). Total num frames: 1835008. Throughput: 0: 3659.7. Samples: 1838080. Policy #0 lag: (min: 1.0, avg: 4.0, max: 65.0)
[2025-11-06 16:06:52,756][322896] Avg episode reward: [(0, '305.111')]
[2025-11-06 16:06:57,770][322896] Fps is (10 sec: 3258.0, 60 sec: 3547.6, 300 sec: 3665.6). Total num frames: 1851392. Throughput: 0: 3658.6. Samples: 1850368. Policy #0 lag: (min: 1.0, avg: 4.0, max: 65.0)
[2025-11-06 16:06:57,770][322896] Avg episode reward: [(0, '316.960')]
[2025-11-06 16:06:57,898][322896] Saving new best policy, reward=316.960!
[2025-11-06 16:07:02,676][322896] Fps is (10 sec: 3303.0, 60 sec: 3557.2, 300 sec: 3665.7). Total num frames: 1867776. Throughput: 0: 3653.4. Samples: 1870848. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:07:02,676][322896] Avg episode reward: [(0, '314.640')]
[2025-11-06 16:07:07,788][322896] Fps is (10 sec: 3270.8, 60 sec: 3545.1, 300 sec: 3664.2). Total num frames: 1884160. Throughput: 0: 3648.0. Samples: 1893376. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:07:07,788][322896] Avg episode reward: [(0, '316.243')]
[2025-11-06 16:07:12,787][322896] Fps is (10 sec: 3240.7, 60 sec: 3545.1, 300 sec: 3664.3). Total num frames: 1900544. Throughput: 0: 3620.3. Samples: 1903104. Policy #0 lag: (min: 5.0, avg: 8.0, max: 69.0)
[2025-11-06 16:07:12,788][322896] Avg episode reward: [(0, '324.289')]
[2025-11-06 16:07:12,914][322896] Saving new best policy, reward=324.289!
[2025-11-06 16:07:13,649][322896] Signal inference workers to stop experience collection... (350 times)
[2025-11-06 16:07:13,981][322896] InferenceWorker_p0-w0: stopping experience collection (350 times)
[2025-11-06 16:07:13,981][322896] Signal inference workers to resume experience collection... (350 times)
[2025-11-06 16:07:13,981][322896] InferenceWorker_p0-w0: resuming experience collection (350 times)
[2025-11-06 16:07:17,714][322896] Fps is (10 sec: 3301.3, 60 sec: 3548.5, 300 sec: 3610.1). Total num frames: 1916928. Throughput: 0: 3641.6. Samples: 1925632. Policy #0 lag: (min: 5.0, avg: 8.0, max: 69.0)
[2025-11-06 16:07:17,714][322896] Avg episode reward: [(0, '331.559')]
[2025-11-06 16:07:17,850][322896] Saving new best policy, reward=331.559!
[2025-11-06 16:07:22,793][322896] Fps is (10 sec: 4093.7, 60 sec: 3682.9, 300 sec: 3636.7). Total num frames: 1941504. Throughput: 0: 3656.0. Samples: 1947648. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:07:22,793][322896] Avg episode reward: [(0, '344.522')]
[2025-11-06 16:07:23,183][322896] Saving new best policy, reward=344.522!
[2025-11-06 16:07:27,673][322896] Fps is (10 sec: 4935.3, 60 sec: 3822.9, 300 sec: 3665.6). Total num frames: 1966080. Throughput: 0: 3633.1. Samples: 1957376. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:07:27,673][322896] Avg episode reward: [(0, '342.129')]
[2025-11-06 16:07:32,748][322896] Fps is (10 sec: 4114.4, 60 sec: 3821.3, 300 sec: 3666.1). Total num frames: 1982464. Throughput: 0: 3615.2. Samples: 1979904. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:07:32,749][322896] Avg episode reward: [(0, '337.882')]
[2025-11-06 16:07:37,704][322896] Fps is (10 sec: 3266.6, 60 sec: 3694.7, 300 sec: 3665.4). Total num frames: 1998848. Throughput: 0: 3622.3. Samples: 2000896. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:07:37,705][322896] Avg episode reward: [(0, '339.135')]
[2025-11-06 16:07:42,685][322896] Fps is (10 sec: 3297.7, 60 sec: 3551.8, 300 sec: 3666.2). Total num frames: 2015232. Throughput: 0: 3613.5. Samples: 2012672. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:07:42,685][322896] Avg episode reward: [(0, '347.603')]
[2025-11-06 16:07:42,817][322896] Saving new best policy, reward=347.603!
[2025-11-06 16:07:47,719][322896] Fps is (10 sec: 3271.8, 60 sec: 3549.4, 300 sec: 3665.8). Total num frames: 2031616. Throughput: 0: 3591.9. Samples: 2032640. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:07:47,720][322896] Avg episode reward: [(0, '348.272')]
[2025-11-06 16:07:47,851][322896] Saving new best policy, reward=348.272!
[2025-11-06 16:07:52,782][322896] Fps is (10 sec: 3245.3, 60 sec: 3548.3, 300 sec: 3610.8). Total num frames: 2048000. Throughput: 0: 3595.8. Samples: 2055168. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:07:52,782][322896] Avg episode reward: [(0, '345.105')]
[2025-11-06 16:07:57,756][322896] Fps is (10 sec: 3264.8, 60 sec: 3550.7, 300 sec: 3610.0). Total num frames: 2064384. Throughput: 0: 3609.3. Samples: 2065408. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:07:57,756][322896] Avg episode reward: [(0, '346.170')]
[2025-11-06 16:07:57,879][322896] Saving /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_lidar_policy2_acc_yaw_sp/checkpoint_p0/checkpoint_000008064_2064384.pth...
[2025-11-06 16:07:57,883][322896] Removing /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_lidar_policy2_acc_yaw_sp/checkpoint_p0/checkpoint_000004672_1196032.pth
[2025-11-06 16:08:02,717][322896] Fps is (10 sec: 3298.3, 60 sec: 3547.5, 300 sec: 3610.9). Total num frames: 2080768. Throughput: 0: 3595.1. Samples: 2087424. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:08:02,717][322896] Avg episode reward: [(0, '346.954')]
[2025-11-06 16:08:07,961][322896] Fps is (10 sec: 4013.7, 60 sec: 3675.8, 300 sec: 3635.2). Total num frames: 2105344. Throughput: 0: 3604.7. Samples: 2110464. Policy #0 lag: (min: 11.0, avg: 14.0, max: 75.0)
[2025-11-06 16:08:07,961][322896] Avg episode reward: [(0, '352.403')]
[2025-11-06 16:08:08,302][322896] Saving new best policy, reward=352.403!
[2025-11-06 16:08:12,751][322896] Fps is (10 sec: 4898.7, 60 sec: 3825.3, 300 sec: 3665.3). Total num frames: 2129920. Throughput: 0: 3634.6. Samples: 2121216. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:08:12,751][322896] Avg episode reward: [(0, '371.137')]
[2025-11-06 16:08:12,880][322896] Saving new best policy, reward=371.137!
[2025-11-06 16:08:17,689][322896] Fps is (10 sec: 4210.6, 60 sec: 3824.5, 300 sec: 3666.2). Total num frames: 2146304. Throughput: 0: 3657.1. Samples: 2144256. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:08:17,689][322896] Avg episode reward: [(0, '384.297')]
[2025-11-06 16:08:17,836][322896] Saving new best policy, reward=384.297!
[2025-11-06 16:08:22,703][322896] Fps is (10 sec: 3292.6, 60 sec: 3692.0, 300 sec: 3666.3). Total num frames: 2162688. Throughput: 0: 3641.0. Samples: 2164736. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:08:22,703][322896] Avg episode reward: [(0, '387.671')]
[2025-11-06 16:08:22,843][322896] Saving new best policy, reward=387.671!
[2025-11-06 16:08:27,783][322896] Fps is (10 sec: 3246.3, 60 sec: 3543.4, 300 sec: 3638.5). Total num frames: 2179072. Throughput: 0: 3644.3. Samples: 2177024. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:08:27,783][322896] Avg episode reward: [(0, '378.988')]
[2025-11-06 16:08:30,282][322896] Signal inference workers to stop experience collection... (400 times)
[2025-11-06 16:08:30,284][322896] Signal inference workers to resume experience collection... (400 times)
[2025-11-06 16:08:30,522][322896] InferenceWorker_p0-w0: stopping experience collection (400 times)
[2025-11-06 16:08:30,522][322896] InferenceWorker_p0-w0: resuming experience collection (400 times)
[2025-11-06 16:08:32,751][322896] Fps is (10 sec: 3261.1, 60 sec: 3549.7, 300 sec: 3610.2). Total num frames: 2195456. Throughput: 0: 3661.1. Samples: 2197504. Policy #0 lag: (min: 8.0, avg: 11.0, max: 72.0)
[2025-11-06 16:08:32,751][322896] Avg episode reward: [(0, '377.082')]
[2025-11-06 16:08:37,726][322896] Fps is (10 sec: 3295.5, 60 sec: 3548.6, 300 sec: 3610.2). Total num frames: 2211840. Throughput: 0: 3668.2. Samples: 2220032. Policy #0 lag: (min: 8.0, avg: 11.0, max: 72.0)
[2025-11-06 16:08:37,726][322896] Avg episode reward: [(0, '375.478')]
[2025-11-06 16:08:42,776][322896] Fps is (10 sec: 3268.7, 60 sec: 3544.5, 300 sec: 3608.9). Total num frames: 2228224. Throughput: 0: 3662.1. Samples: 2230272. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:08:42,776][322896] Avg episode reward: [(0, '382.812')]
[2025-11-06 16:08:47,694][322896] Fps is (10 sec: 3287.4, 60 sec: 3551.4, 300 sec: 3611.2). Total num frames: 2244608. Throughput: 0: 3688.3. Samples: 2253312. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:08:47,694][322896] Avg episode reward: [(0, '385.970')]
[2025-11-06 16:08:52,812][322896] Fps is (10 sec: 4897.5, 60 sec: 3821.1, 300 sec: 3665.1). Total num frames: 2277376. Throughput: 0: 3698.7. Samples: 2276352. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:08:52,812][322896] Avg episode reward: [(0, '397.364')]
[2025-11-06 16:08:52,812][322896] Saving new best policy, reward=397.364!
[2025-11-06 16:08:57,723][322896] Fps is (10 sec: 4901.1, 60 sec: 3825.1, 300 sec: 3665.2). Total num frames: 2293760. Throughput: 0: 3688.7. Samples: 2287104. Policy #0 lag: (min: 3.0, avg: 6.0, max: 67.0)
[2025-11-06 16:08:57,723][322896] Avg episode reward: [(0, '392.399')]
[2025-11-06 16:09:02,795][322896] Fps is (10 sec: 3282.3, 60 sec: 3818.0, 300 sec: 3639.7). Total num frames: 2310144. Throughput: 0: 3655.0. Samples: 2309120. Policy #0 lag: (min: 3.0, avg: 6.0, max: 67.0)
[2025-11-06 16:09:02,795][322896] Avg episode reward: [(0, '393.122')]
[2025-11-06 16:09:07,736][322896] Fps is (10 sec: 3272.6, 60 sec: 3700.3, 300 sec: 3609.4). Total num frames: 2326528. Throughput: 0: 3661.0. Samples: 2329600. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:09:07,736][322896] Avg episode reward: [(0, '399.093')]
[2025-11-06 16:09:07,866][322896] Saving new best policy, reward=399.093!
[2025-11-06 16:09:12,758][322896] Fps is (10 sec: 3289.1, 60 sec: 3549.5, 300 sec: 3609.0). Total num frames: 2342912. Throughput: 0: 3665.7. Samples: 2341888. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:09:12,758][322896] Avg episode reward: [(0, '412.815')]
[2025-11-06 16:09:12,933][322896] Saving new best policy, reward=412.815!
[2025-11-06 16:09:17,768][322896] Fps is (10 sec: 3266.2, 60 sec: 3545.2, 300 sec: 3610.2). Total num frames: 2359296. Throughput: 0: 3650.8. Samples: 2361856. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:09:17,768][322896] Avg episode reward: [(0, '414.132')]
[2025-11-06 16:09:17,901][322896] Saving new best policy, reward=414.132!
[2025-11-06 16:09:22,797][322896] Fps is (10 sec: 3263.9, 60 sec: 3544.3, 300 sec: 3609.4). Total num frames: 2375680. Throughput: 0: 3635.2. Samples: 2383872. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:09:22,797][322896] Avg episode reward: [(0, '406.370')]
[2025-11-06 16:09:27,745][322896] Fps is (10 sec: 3284.4, 60 sec: 3552.1, 300 sec: 3609.2). Total num frames: 2392064. Throughput: 0: 3643.4. Samples: 2394112. Policy #0 lag: (min: 11.0, avg: 14.0, max: 75.0)
[2025-11-06 16:09:27,745][322896] Avg episode reward: [(0, '402.518')]
[2025-11-06 16:09:32,771][322896] Fps is (10 sec: 3285.3, 60 sec: 3548.7, 300 sec: 3610.4). Total num frames: 2408448. Throughput: 0: 3623.3. Samples: 2416640. Policy #0 lag: (min: 11.0, avg: 14.0, max: 75.0)
[2025-11-06 16:09:32,771][322896] Avg episode reward: [(0, '409.779')]
[2025-11-06 16:09:37,822][322896] Fps is (10 sec: 4877.7, 60 sec: 3816.8, 300 sec: 3664.1). Total num frames: 2441216. Throughput: 0: 3640.1. Samples: 2440192. Policy #0 lag: (min: 1.0, avg: 4.0, max: 65.0)
[2025-11-06 16:09:37,822][322896] Avg episode reward: [(0, '410.113')]
[2025-11-06 16:09:42,705][322896] Fps is (10 sec: 4947.9, 60 sec: 3827.4, 300 sec: 3666.9). Total num frames: 2457600. Throughput: 0: 3642.3. Samples: 2450944. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:09:42,705][322896] Avg episode reward: [(0, '406.036')]
[2025-11-06 16:09:46,163][322896] Signal inference workers to stop experience collection... (450 times)
[2025-11-06 16:09:46,505][322896] InferenceWorker_p0-w0: stopping experience collection (450 times)
[2025-11-06 16:09:46,507][322896] Signal inference workers to resume experience collection... (450 times)
[2025-11-06 16:09:46,630][322896] InferenceWorker_p0-w0: resuming experience collection (450 times)
[2025-11-06 16:09:47,725][322896] Fps is (10 sec: 3308.7, 60 sec: 3820.9, 300 sec: 3665.6). Total num frames: 2473984. Throughput: 0: 3646.5. Samples: 2472960. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:09:47,726][322896] Avg episode reward: [(0, '407.774')]
[2025-11-06 16:09:52,759][322896] Fps is (10 sec: 3259.2, 60 sec: 3553.0, 300 sec: 3664.6). Total num frames: 2490368. Throughput: 0: 3650.4. Samples: 2493952. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:09:52,759][322896] Avg episode reward: [(0, '396.497')]
[2025-11-06 16:09:57,736][322896] Fps is (10 sec: 3273.3, 60 sec: 3549.1, 300 sec: 3638.3). Total num frames: 2506752. Throughput: 0: 3654.0. Samples: 2506240. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:09:57,736][322896] Avg episode reward: [(0, '402.939')]
[2025-11-06 16:09:57,876][322896] Saving /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_lidar_policy2_acc_yaw_sp/checkpoint_p0/checkpoint_000009792_2506752.pth...
[2025-11-06 16:09:57,880][322896] Removing /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_lidar_policy2_acc_yaw_sp/checkpoint_p0/checkpoint_000006400_1638400.pth
[2025-11-06 16:10:02,765][322896] Fps is (10 sec: 3274.8, 60 sec: 3551.6, 300 sec: 3610.0). Total num frames: 2523136. Throughput: 0: 3663.9. Samples: 2526720. Policy #0 lag: (min: 2.0, avg: 5.0, max: 66.0)
[2025-11-06 16:10:02,765][322896] Avg episode reward: [(0, '408.627')]
[2025-11-06 16:10:07,688][322896] Fps is (10 sec: 3292.5, 60 sec: 3552.7, 300 sec: 3610.4). Total num frames: 2539520. Throughput: 0: 3683.9. Samples: 2549248. Policy #0 lag: (min: 2.0, avg: 5.0, max: 66.0)
[2025-11-06 16:10:07,688][322896] Avg episode reward: [(0, '417.026')]
[2025-11-06 16:10:07,820][322896] Saving new best policy, reward=417.026!
[2025-11-06 16:10:12,773][322896] Fps is (10 sec: 3274.2, 60 sec: 3548.9, 300 sec: 3609.4). Total num frames: 2555904. Throughput: 0: 3672.7. Samples: 2559488. Policy #0 lag: (min: 7.0, avg: 10.0, max: 71.0)
[2025-11-06 16:10:12,773][322896] Avg episode reward: [(0, '428.395')]
[2025-11-06 16:10:12,894][322896] Saving new best policy, reward=428.395!
[2025-11-06 16:10:17,765][322896] Fps is (10 sec: 4065.0, 60 sec: 3686.6, 300 sec: 3637.8). Total num frames: 2580480. Throughput: 0: 3686.9. Samples: 2582528. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:10:17,765][322896] Avg episode reward: [(0, '441.814')]
[2025-11-06 16:10:18,119][322896] Saving new best policy, reward=441.814!
[2025-11-06 16:10:22,778][322896] Fps is (10 sec: 4912.9, 60 sec: 3824.2, 300 sec: 3664.9). Total num frames: 2605056. Throughput: 0: 3667.2. Samples: 2605056. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:10:22,778][322896] Avg episode reward: [(0, '446.606')]
[2025-11-06 16:10:22,908][322896] Saving new best policy, reward=446.606!
[2025-11-06 16:10:27,709][322896] Fps is (10 sec: 4119.0, 60 sec: 3825.3, 300 sec: 3666.5). Total num frames: 2621440. Throughput: 0: 3663.3. Samples: 2615808. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:10:27,709][322896] Avg episode reward: [(0, '445.745')]
[2025-11-06 16:10:32,776][322896] Fps is (10 sec: 3277.4, 60 sec: 3822.6, 300 sec: 3664.8). Total num frames: 2637824. Throughput: 0: 3682.3. Samples: 2638848. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:10:32,776][322896] Avg episode reward: [(0, '444.773')]
[2025-11-06 16:10:37,767][322896] Fps is (10 sec: 3257.9, 60 sec: 3553.1, 300 sec: 3664.9). Total num frames: 2654208. Throughput: 0: 3674.4. Samples: 2659328. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:10:37,767][322896] Avg episode reward: [(0, '455.158')]
[2025-11-06 16:10:37,889][322896] Saving new best policy, reward=455.158!
[2025-11-06 16:10:42,677][322896] Fps is (10 sec: 3309.7, 60 sec: 3551.5, 300 sec: 3666.0). Total num frames: 2670592. Throughput: 0: 3668.5. Samples: 2671104. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:10:42,677][322896] Avg episode reward: [(0, '447.452')]
[2025-11-06 16:10:47,812][322896] Fps is (10 sec: 3262.1, 60 sec: 3544.8, 300 sec: 3637.9). Total num frames: 2686976. Throughput: 0: 3659.8. Samples: 2691584. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:10:47,812][322896] Avg episode reward: [(0, '455.845')]
[2025-11-06 16:10:47,944][322896] Saving new best policy, reward=455.845!
[2025-11-06 16:10:52,764][322896] Fps is (10 sec: 3248.4, 60 sec: 3549.6, 300 sec: 3609.6). Total num frames: 2703360. Throughput: 0: 3634.8. Samples: 2713088. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:10:52,764][322896] Avg episode reward: [(0, '455.376')]
[2025-11-06 16:10:57,720][322896] Fps is (10 sec: 3307.2, 60 sec: 3550.8, 300 sec: 3611.0). Total num frames: 2719744. Throughput: 0: 3645.2. Samples: 2723328. Policy #0 lag: (min: 12.0, avg: 15.0, max: 76.0)
[2025-11-06 16:10:57,720][322896] Avg episode reward: [(0, '466.087')]
[2025-11-06 16:10:57,865][322896] Saving new best policy, reward=466.087!
[2025-11-06 16:10:58,490][322896] Signal inference workers to stop experience collection... (500 times)
[2025-11-06 16:10:58,846][322896] InferenceWorker_p0-w0: stopping experience collection (500 times)
[2025-11-06 16:10:58,847][322896] Signal inference workers to resume experience collection... (500 times)
[2025-11-06 16:10:58,847][322896] InferenceWorker_p0-w0: resuming experience collection (500 times)
[2025-11-06 16:11:02,706][322896] Fps is (10 sec: 3296.0, 60 sec: 3553.4, 300 sec: 3610.1). Total num frames: 2736128. Throughput: 0: 3622.9. Samples: 2745344. Policy #0 lag: (min: 12.0, avg: 15.0, max: 76.0)
[2025-11-06 16:11:02,706][322896] Avg episode reward: [(0, '482.423')]
[2025-11-06 16:11:03,065][322896] Saving new best policy, reward=482.423!
[2025-11-06 16:11:07,690][322896] Fps is (10 sec: 4108.2, 60 sec: 3686.3, 300 sec: 3638.0). Total num frames: 2760704. Throughput: 0: 3613.8. Samples: 2767360. Policy #0 lag: (min: 5.0, avg: 8.0, max: 69.0)
[2025-11-06 16:11:07,690][322896] Avg episode reward: [(0, '480.052')]
[2025-11-06 16:11:12,735][322896] Fps is (10 sec: 4900.7, 60 sec: 3825.3, 300 sec: 3665.0). Total num frames: 2785280. Throughput: 0: 3581.9. Samples: 2777088. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:11:12,736][322896] Avg episode reward: [(0, '471.530')]
[2025-11-06 16:11:17,701][322896] Fps is (10 sec: 4091.4, 60 sec: 3690.3, 300 sec: 3666.0). Total num frames: 2801664. Throughput: 0: 3578.6. Samples: 2799616. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:11:17,702][322896] Avg episode reward: [(0, '473.783')]
[2025-11-06 16:11:22,683][322896] Fps is (10 sec: 3294.1, 60 sec: 3555.5, 300 sec: 3665.5). Total num frames: 2818048. Throughput: 0: 3556.5. Samples: 2819072. Policy #0 lag: (min: 8.0, avg: 11.0, max: 72.0)
[2025-11-06 16:11:22,683][322896] Avg episode reward: [(0, '476.397')]
[2025-11-06 16:11:27,679][322896] Fps is (10 sec: 3284.3, 60 sec: 3551.6, 300 sec: 3666.1). Total num frames: 2834432. Throughput: 0: 3561.1. Samples: 2831360. Policy #0 lag: (min: 8.0, avg: 11.0, max: 72.0)
[2025-11-06 16:11:27,679][322896] Avg episode reward: [(0, '489.920')]
[2025-11-06 16:11:27,815][322896] Saving new best policy, reward=489.920!
[2025-11-06 16:11:32,697][322896] Fps is (10 sec: 3272.0, 60 sec: 3554.5, 300 sec: 3639.5). Total num frames: 2850816. Throughput: 0: 3570.3. Samples: 2851840. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:11:32,698][322896] Avg episode reward: [(0, '514.437')]
[2025-11-06 16:11:32,828][322896] Saving new best policy, reward=514.437!
[2025-11-06 16:11:37,791][322896] Fps is (10 sec: 3240.4, 60 sec: 3548.4, 300 sec: 3609.1). Total num frames: 2867200. Throughput: 0: 3593.2. Samples: 2874880. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:11:37,791][322896] Avg episode reward: [(0, '509.686')]
[2025-11-06 16:11:42,711][322896] Fps is (10 sec: 3272.2, 60 sec: 3547.8, 300 sec: 3610.0). Total num frames: 2883584. Throughput: 0: 3584.7. Samples: 2884608. Policy #0 lag: (min: 13.0, avg: 16.0, max: 77.0)
[2025-11-06 16:11:42,712][322896] Avg episode reward: [(0, '499.422')]
[2025-11-06 16:11:47,778][322896] Fps is (10 sec: 3281.0, 60 sec: 3551.9, 300 sec: 3609.8). Total num frames: 2899968. Throughput: 0: 3600.9. Samples: 2907648. Policy #0 lag: (min: 13.0, avg: 16.0, max: 77.0)
[2025-11-06 16:11:47,778][322896] Avg episode reward: [(0, '507.469')]
[2025-11-06 16:11:52,959][322896] Fps is (10 sec: 3996.8, 60 sec: 3674.4, 300 sec: 3635.5). Total num frames: 2924544. Throughput: 0: 3596.6. Samples: 2930176. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:11:52,960][322896] Avg episode reward: [(0, '538.802')]
[2025-11-06 16:11:53,308][322896] Saving new best policy, reward=538.802!
[2025-11-06 16:11:57,853][322896] Fps is (10 sec: 4878.8, 60 sec: 3814.5, 300 sec: 3663.4). Total num frames: 2949120. Throughput: 0: 3608.7. Samples: 2939904. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:11:57,853][322896] Avg episode reward: [(0, '557.766')]
[2025-11-06 16:11:57,855][322896] Saving /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_lidar_policy2_acc_yaw_sp/checkpoint_p0/checkpoint_000011520_2949120.pth...
[2025-11-06 16:11:57,860][322896] Removing /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_lidar_policy2_acc_yaw_sp/checkpoint_p0/checkpoint_000008064_2064384.pth
[2025-11-06 16:11:57,860][322896] Saving new best policy, reward=557.766!
[2025-11-06 16:12:02,740][322896] Fps is (10 sec: 4187.7, 60 sec: 3820.7, 300 sec: 3666.2). Total num frames: 2965504. Throughput: 0: 3603.6. Samples: 2961920. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:12:02,741][322896] Avg episode reward: [(0, '566.813')]
[2025-11-06 16:12:02,878][322896] Saving new best policy, reward=566.813!
[2025-11-06 16:12:07,705][322896] Fps is (10 sec: 3326.1, 60 sec: 3685.5, 300 sec: 3666.6). Total num frames: 2981888. Throughput: 0: 3639.1. Samples: 2982912. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:12:07,705][322896] Avg episode reward: [(0, '563.335')]
[2025-11-06 16:12:12,750][322896] Fps is (10 sec: 3273.6, 60 sec: 3549.0, 300 sec: 3665.1). Total num frames: 2998272. Throughput: 0: 3623.7. Samples: 2994688. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:12:12,751][322896] Avg episode reward: [(0, '556.164')]
[2025-11-06 16:12:15,883][322896] Signal inference workers to stop experience collection... (550 times)
[2025-11-06 16:12:15,884][322896] Signal inference workers to resume experience collection... (550 times)
[2025-11-06 16:12:16,135][322896] InferenceWorker_p0-w0: stopping experience collection (550 times)
[2025-11-06 16:12:16,135][322896] InferenceWorker_p0-w0: resuming experience collection (550 times)
[2025-11-06 16:12:17,744][322896] Fps is (10 sec: 3264.0, 60 sec: 3547.3, 300 sec: 3638.4). Total num frames: 3014656. Throughput: 0: 3637.1. Samples: 3015680. Policy #0 lag: (min: 7.0, avg: 10.0, max: 71.0)
[2025-11-06 16:12:17,744][322896] Avg episode reward: [(0, '532.302')]
[2025-11-06 16:12:22,723][322896] Fps is (10 sec: 3285.7, 60 sec: 3547.5, 300 sec: 3609.4). Total num frames: 3031040. Throughput: 0: 3578.0. Samples: 3035648. Policy #0 lag: (min: 7.0, avg: 10.0, max: 71.0)
[2025-11-06 16:12:22,723][322896] Avg episode reward: [(0, '523.704')]
[2025-11-06 16:12:27,736][322896] Fps is (10 sec: 3279.5, 60 sec: 3546.5, 300 sec: 3610.2). Total num frames: 3047424. Throughput: 0: 3604.8. Samples: 3046912. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:12:27,736][322896] Avg episode reward: [(0, '514.972')]
[2025-11-06 16:12:32,683][322896] Fps is (10 sec: 3289.9, 60 sec: 3550.7, 300 sec: 3610.3). Total num frames: 3063808. Throughput: 0: 3546.0. Samples: 3066880. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:12:32,683][322896] Avg episode reward: [(0, '532.070')]
[2025-11-06 16:12:37,708][322896] Fps is (10 sec: 3285.9, 60 sec: 3554.8, 300 sec: 3609.7). Total num frames: 3080192. Throughput: 0: 3569.8. Samples: 3089920. Policy #0 lag: (min: 31.0, avg: 34.0, max: 95.0)
[2025-11-06 16:12:37,708][322896] Avg episode reward: [(0, '529.637')]
[2025-11-06 16:12:42,779][322896] Fps is (10 sec: 3245.8, 60 sec: 3545.9, 300 sec: 3609.3). Total num frames: 3096576. Throughput: 0: 3567.1. Samples: 3100160. Policy #0 lag: (min: 31.0, avg: 34.0, max: 95.0)
[2025-11-06 16:12:42,779][322896] Avg episode reward: [(0, '516.421')]
[2025-11-06 16:12:47,813][322896] Fps is (10 sec: 4053.6, 60 sec: 3684.3, 300 sec: 3637.4). Total num frames: 3121152. Throughput: 0: 3566.9. Samples: 3122688. Policy #0 lag: (min: 47.0, avg: 50.0, max: 111.0)
[2025-11-06 16:12:47,813][322896] Avg episode reward: [(0, '511.348')]
[2025-11-06 16:12:52,742][322896] Fps is (10 sec: 4933.6, 60 sec: 3699.8, 300 sec: 3665.8). Total num frames: 3145728. Throughput: 0: 3615.2. Samples: 3145728. Policy #0 lag: (min: 47.0, avg: 50.0, max: 111.0)
[2025-11-06 16:12:52,742][322896] Avg episode reward: [(0, '508.615')]
[2025-11-06 16:12:57,686][322896] Fps is (10 sec: 4148.6, 60 sec: 3559.8, 300 sec: 3666.0). Total num frames: 3162112. Throughput: 0: 3589.1. Samples: 3155968. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:12:57,686][322896] Avg episode reward: [(0, '513.364')]
[2025-11-06 16:13:02,795][322896] Fps is (10 sec: 3259.3, 60 sec: 3546.6, 300 sec: 3639.9). Total num frames: 3178496. Throughput: 0: 3602.7. Samples: 3177984. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:13:02,795][322896] Avg episode reward: [(0, '507.998')]
[2025-11-06 16:13:07,691][322896] Fps is (10 sec: 3275.0, 60 sec: 3550.7, 300 sec: 3610.8). Total num frames: 3194880. Throughput: 0: 3620.7. Samples: 3198464. Policy #0 lag: (min: 38.0, avg: 41.0, max: 102.0)
[2025-11-06 16:13:07,692][322896] Avg episode reward: [(0, '519.196')]
[2025-11-06 16:13:12,716][322896] Fps is (10 sec: 3302.8, 60 sec: 3551.9, 300 sec: 3609.7). Total num frames: 3211264. Throughput: 0: 3642.5. Samples: 3210752. Policy #0 lag: (min: 38.0, avg: 41.0, max: 102.0)
[2025-11-06 16:13:12,717][322896] Avg episode reward: [(0, '511.097')]
[2025-11-06 16:13:17,676][322896] Fps is (10 sec: 3281.8, 60 sec: 3553.9, 300 sec: 3610.4). Total num frames: 3227648. Throughput: 0: 3652.8. Samples: 3231232. Policy #0 lag: (min: 38.0, avg: 41.0, max: 102.0)
[2025-11-06 16:13:17,677][322896] Avg episode reward: [(0, '534.862')]
[2025-11-06 16:13:22,720][322896] Fps is (10 sec: 3275.7, 60 sec: 3550.1, 300 sec: 3610.8). Total num frames: 3244032. Throughput: 0: 3651.3. Samples: 3254272. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:13:22,720][322896] Avg episode reward: [(0, '554.779')]
[2025-11-06 16:13:27,707][322896] Fps is (10 sec: 3266.7, 60 sec: 3551.6, 300 sec: 3610.6). Total num frames: 3260416. Throughput: 0: 3669.5. Samples: 3265024. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:13:27,708][322896] Avg episode reward: [(0, '575.269')]
[2025-11-06 16:13:27,848][322896] Saving new best policy, reward=575.269!
[2025-11-06 16:13:32,400][322896] Signal inference workers to stop experience collection... (600 times)
[2025-11-06 16:13:32,742][322896] InferenceWorker_p0-w0: stopping experience collection (600 times)
[2025-11-06 16:13:32,744][322896] Signal inference workers to resume experience collection... (600 times)
[2025-11-06 16:13:32,747][322896] Fps is (10 sec: 4085.0, 60 sec: 3682.5, 300 sec: 3637.6). Total num frames: 3284992. Throughput: 0: 3657.6. Samples: 3287040. Policy #0 lag: (min: 6.0, avg: 9.0, max: 70.0)
[2025-11-06 16:13:32,747][322896] Avg episode reward: [(0, '585.624')]
[2025-11-06 16:13:32,871][322896] InferenceWorker_p0-w0: resuming experience collection (600 times)
[2025-11-06 16:13:33,102][322896] Saving new best policy, reward=585.624!
[2025-11-06 16:13:37,743][322896] Fps is (10 sec: 4897.7, 60 sec: 3820.7, 300 sec: 3666.0). Total num frames: 3309568. Throughput: 0: 3629.4. Samples: 3309056. Policy #0 lag: (min: 6.0, avg: 9.0, max: 70.0)
[2025-11-06 16:13:37,743][322896] Avg episode reward: [(0, '592.032')]
[2025-11-06 16:13:37,873][322896] Saving new best policy, reward=592.032!
[2025-11-06 16:13:42,741][322896] Fps is (10 sec: 4098.3, 60 sec: 3825.3, 300 sec: 3665.0). Total num frames: 3325952. Throughput: 0: 3625.1. Samples: 3319296. Policy #0 lag: (min: 6.0, avg: 9.0, max: 70.0)
[2025-11-06 16:13:42,741][322896] Avg episode reward: [(0, '596.845')]
[2025-11-06 16:13:42,868][322896] Saving new best policy, reward=596.845!
[2025-11-06 16:13:47,759][322896] Fps is (10 sec: 3271.8, 60 sec: 3689.7, 300 sec: 3610.7). Total num frames: 3342336. Throughput: 0: 3655.2. Samples: 3342336. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:13:47,759][322896] Avg episode reward: [(0, '573.687')]
[2025-11-06 16:13:52,750][322896] Fps is (10 sec: 3273.8, 60 sec: 3549.4, 300 sec: 3609.7). Total num frames: 3358720. Throughput: 0: 3670.2. Samples: 3363840. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:13:52,750][322896] Avg episode reward: [(0, '587.527')]
[2025-11-06 16:13:57,731][322896] Fps is (10 sec: 3285.7, 60 sec: 3547.2, 300 sec: 3610.8). Total num frames: 3375104. Throughput: 0: 3651.0. Samples: 3375104. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:13:57,732][322896] Avg episode reward: [(0, '588.560')]
[2025-11-06 16:13:57,884][322896] Saving /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_lidar_policy2_acc_yaw_sp/checkpoint_p0/checkpoint_000013184_3375104.pth...
[2025-11-06 16:13:57,888][322896] Removing /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_lidar_policy2_acc_yaw_sp/checkpoint_p0/checkpoint_000009792_2506752.pth
[2025-11-06 16:14:02,697][322896] Fps is (10 sec: 3294.4, 60 sec: 3555.7, 300 sec: 3610.5). Total num frames: 3391488. Throughput: 0: 3650.6. Samples: 3395584. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:14:02,697][322896] Avg episode reward: [(0, '593.190')]
[2025-11-06 16:14:07,789][322896] Fps is (10 sec: 3258.0, 60 sec: 3544.1, 300 sec: 3609.6). Total num frames: 3407872. Throughput: 0: 3578.5. Samples: 3415552. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:14:07,789][322896] Avg episode reward: [(0, '601.991')]
[2025-11-06 16:14:07,944][322896] Saving new best policy, reward=601.991!
[2025-11-06 16:14:12,749][322896] Fps is (10 sec: 3259.7, 60 sec: 3547.9, 300 sec: 3610.3). Total num frames: 3424256. Throughput: 0: 3557.9. Samples: 3425280. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:14:12,750][322896] Avg episode reward: [(0, '605.216')]
[2025-11-06 16:14:12,893][322896] Saving new best policy, reward=605.216!
[2025-11-06 16:14:17,703][322896] Fps is (10 sec: 3305.4, 60 sec: 3548.3, 300 sec: 3611.2). Total num frames: 3440640. Throughput: 0: 3507.8. Samples: 3444736. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:14:17,703][322896] Avg episode reward: [(0, '613.009')]
[2025-11-06 16:14:17,844][322896] Saving new best policy, reward=613.009!
[2025-11-06 16:14:22,798][322896] Fps is (10 sec: 3260.9, 60 sec: 3545.2, 300 sec: 3609.4). Total num frames: 3457024. Throughput: 0: 3466.0. Samples: 3465216. Policy #0 lag: (min: 47.0, avg: 50.0, max: 111.0)
[2025-11-06 16:14:22,798][322896] Avg episode reward: [(0, '610.755')]
[2025-11-06 16:14:27,744][322896] Fps is (10 sec: 3263.4, 60 sec: 3547.7, 300 sec: 3610.4). Total num frames: 3473408. Throughput: 0: 3447.2. Samples: 3474432. Policy #0 lag: (min: 47.0, avg: 50.0, max: 111.0)
[2025-11-06 16:14:27,744][322896] Avg episode reward: [(0, '612.324')]
[2025-11-06 16:14:32,722][322896] Fps is (10 sec: 3301.8, 60 sec: 3414.7, 300 sec: 3555.7). Total num frames: 3489792. Throughput: 0: 3416.1. Samples: 3495936. Policy #0 lag: (min: 47.0, avg: 50.0, max: 111.0)
[2025-11-06 16:14:32,723][322896] Avg episode reward: [(0, '591.997')]
[2025-11-06 16:14:37,777][322896] Fps is (10 sec: 3266.1, 60 sec: 3275.0, 300 sec: 3553.6). Total num frames: 3506176. Throughput: 0: 3388.6. Samples: 3516416. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:14:37,777][322896] Avg episode reward: [(0, '560.345')]
[2025-11-06 16:14:42,751][322896] Fps is (10 sec: 3267.5, 60 sec: 3276.3, 300 sec: 3554.2). Total num frames: 3522560. Throughput: 0: 3343.6. Samples: 3525632. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:14:42,751][322896] Avg episode reward: [(0, '546.305')]
[2025-11-06 16:14:47,706][322896] Fps is (10 sec: 3300.0, 60 sec: 3279.7, 300 sec: 3555.1). Total num frames: 3538944. Throughput: 0: 3355.7. Samples: 3546624. Policy #0 lag: (min: 55.0, avg: 58.0, max: 119.0)
[2025-11-06 16:14:47,707][322896] Avg episode reward: [(0, '554.729')]
[2025-11-06 16:14:48,612][322896] Signal inference workers to stop experience collection... (650 times)
[2025-11-06 16:14:48,965][322896] InferenceWorker_p0-w0: stopping experience collection (650 times)
[2025-11-06 16:14:48,965][322896] Signal inference workers to resume experience collection... (650 times)
[2025-11-06 16:14:48,966][322896] InferenceWorker_p0-w0: resuming experience collection (650 times)
[2025-11-06 16:14:52,797][322896] Fps is (10 sec: 3261.9, 60 sec: 3274.3, 300 sec: 3553.8). Total num frames: 3555328. Throughput: 0: 3367.3. Samples: 3567104. Policy #0 lag: (min: 55.0, avg: 58.0, max: 119.0)
[2025-11-06 16:14:52,797][322896] Avg episode reward: [(0, '561.777')]
[2025-11-06 16:14:57,746][322896] Fps is (10 sec: 3263.7, 60 sec: 3276.0, 300 sec: 3554.7). Total num frames: 3571712. Throughput: 0: 3368.0. Samples: 3576832. Policy #0 lag: (min: 55.0, avg: 58.0, max: 119.0)
[2025-11-06 16:14:57,747][322896] Avg episode reward: [(0, '580.819')]
[2025-11-06 16:15:02,701][322896] Fps is (10 sec: 3308.6, 60 sec: 3276.6, 300 sec: 3554.3). Total num frames: 3588096. Throughput: 0: 3402.1. Samples: 3597824. Policy #0 lag: (min: 6.0, avg: 9.0, max: 70.0)
[2025-11-06 16:15:02,701][322896] Avg episode reward: [(0, '582.629')]
[2025-11-06 16:15:07,902][322896] Fps is (10 sec: 4033.3, 60 sec: 3406.9, 300 sec: 3580.7). Total num frames: 3612672. Throughput: 0: 3394.1. Samples: 3618304. Policy #0 lag: (min: 6.0, avg: 9.0, max: 70.0)
[2025-11-06 16:15:07,902][322896] Avg episode reward: [(0, '595.736')]
[2025-11-06 16:15:12,705][322896] Fps is (10 sec: 4094.1, 60 sec: 3415.8, 300 sec: 3555.2). Total num frames: 3629056. Throughput: 0: 3416.3. Samples: 3628032. Policy #0 lag: (min: 10.0, avg: 13.0, max: 74.0)
[2025-11-06 16:15:12,706][322896] Avg episode reward: [(0, '617.935')]
[2025-11-06 16:15:13,060][322896] Saving new best policy, reward=617.935!
[2025-11-06 16:15:17,851][322896] Fps is (10 sec: 4116.8, 60 sec: 3541.1, 300 sec: 3553.6). Total num frames: 3653632. Throughput: 0: 3392.2. Samples: 3649024. Policy #0 lag: (min: 10.0, avg: 13.0, max: 74.0)
[2025-11-06 16:15:17,852][322896] Avg episode reward: [(0, '652.290')]
[2025-11-06 16:15:17,857][322896] Saving new best policy, reward=652.290!
[2025-11-06 16:15:22,746][322896] Fps is (10 sec: 4079.4, 60 sec: 3553.0, 300 sec: 3554.0). Total num frames: 3670016. Throughput: 0: 3415.7. Samples: 3670016. Policy #0 lag: (min: 10.0, avg: 13.0, max: 74.0)
[2025-11-06 16:15:22,746][322896] Avg episode reward: [(0, '651.235')]
[2025-11-06 16:15:27,757][322896] Fps is (10 sec: 3308.0, 60 sec: 3549.1, 300 sec: 3554.7). Total num frames: 3686400. Throughput: 0: 3424.2. Samples: 3679744. Policy #0 lag: (min: 14.0, avg: 17.0, max: 78.0)
[2025-11-06 16:15:27,757][322896] Avg episode reward: [(0, '643.716')]
[2025-11-06 16:15:32,739][322896] Fps is (10 sec: 3279.0, 60 sec: 3548.9, 300 sec: 3554.8). Total num frames: 3702784. Throughput: 0: 3433.6. Samples: 3701248. Policy #0 lag: (min: 14.0, avg: 17.0, max: 78.0)
[2025-11-06 16:15:32,739][322896] Avg episode reward: [(0, '635.603')]
[2025-11-06 16:15:37,758][322896] Fps is (10 sec: 3276.7, 60 sec: 3551.0, 300 sec: 3553.5). Total num frames: 3719168. Throughput: 0: 3439.1. Samples: 3721728. Policy #0 lag: (min: 14.0, avg: 17.0, max: 78.0)
[2025-11-06 16:15:37,758][322896] Avg episode reward: [(0, '628.425')]
[2025-11-06 16:15:42,699][322896] Fps is (10 sec: 3290.1, 60 sec: 3552.9, 300 sec: 3555.9). Total num frames: 3735552. Throughput: 0: 3496.7. Samples: 3734016. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:15:42,699][322896] Avg episode reward: [(0, '601.997')]
[2025-11-06 16:15:47,712][322896] Fps is (10 sec: 3291.9, 60 sec: 3549.5, 300 sec: 3555.1). Total num frames: 3751936. Throughput: 0: 3480.7. Samples: 3754496. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:15:47,712][322896] Avg episode reward: [(0, '614.122')]
[2025-11-06 16:15:52,769][322896] Fps is (10 sec: 3254.0, 60 sec: 3551.5, 300 sec: 3553.9). Total num frames: 3768320. Throughput: 0: 3549.0. Samples: 3777536. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:15:52,769][322896] Avg episode reward: [(0, '651.430')]
[2025-11-06 16:15:57,731][322896] Fps is (10 sec: 3270.5, 60 sec: 3550.8, 300 sec: 3554.2). Total num frames: 3784704. Throughput: 0: 3547.8. Samples: 3787776. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:15:57,731][322896] Avg episode reward: [(0, '686.201')]
[2025-11-06 16:15:57,874][322896] Saving /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_lidar_policy2_acc_yaw_sp/checkpoint_p0/checkpoint_000014784_3784704.pth...
[2025-11-06 16:15:57,878][322896] Removing /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_lidar_policy2_acc_yaw_sp/checkpoint_p0/checkpoint_000011520_2949120.pth
[2025-11-06 16:15:57,878][322896] Saving new best policy, reward=686.201!
[2025-11-06 16:16:02,774][322896] Fps is (10 sec: 3275.3, 60 sec: 3545.6, 300 sec: 3525.7). Total num frames: 3801088. Throughput: 0: 3567.4. Samples: 3809280. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:16:02,774][322896] Avg episode reward: [(0, '685.809')]
[2025-11-06 16:16:08,020][322896] Signal inference workers to stop experience collection... (700 times)
[2025-11-06 16:16:08,023][322896] Signal inference workers to resume experience collection... (700 times)
[2025-11-06 16:16:08,023][322896] Fps is (10 sec: 3979.7, 60 sec: 3542.7, 300 sec: 3523.3). Total num frames: 3825664. Throughput: 0: 3550.8. Samples: 3830784. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:16:08,023][322896] Avg episode reward: [(0, '670.070')]
[2025-11-06 16:16:08,281][322896] InferenceWorker_p0-w0: stopping experience collection (700 times)
[2025-11-06 16:16:08,281][322896] InferenceWorker_p0-w0: resuming experience collection (700 times)
[2025-11-06 16:16:12,901][322896] Fps is (10 sec: 4853.6, 60 sec: 3674.4, 300 sec: 3552.1). Total num frames: 3850240. Throughput: 0: 3572.6. Samples: 3841024. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:16:12,901][322896] Avg episode reward: [(0, '699.325')]
[2025-11-06 16:16:12,901][322896] Saving new best policy, reward=699.325!
[2025-11-06 16:16:17,731][322896] Fps is (10 sec: 4219.4, 60 sec: 3557.0, 300 sec: 3553.9). Total num frames: 3866624. Throughput: 0: 3596.0. Samples: 3863040. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:16:17,731][322896] Avg episode reward: [(0, '693.772')]
[2025-11-06 16:16:22,778][322896] Fps is (10 sec: 3317.4, 60 sec: 3548.0, 300 sec: 3553.3). Total num frames: 3883008. Throughput: 0: 3605.1. Samples: 3884032. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:16:22,778][322896] Avg episode reward: [(0, '696.485')]
[2025-11-06 16:16:27,775][322896] Fps is (10 sec: 3262.4, 60 sec: 3548.8, 300 sec: 3553.6). Total num frames: 3899392. Throughput: 0: 3589.3. Samples: 3895808. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:16:27,775][322896] Avg episode reward: [(0, '675.371')]
[2025-11-06 16:16:32,726][322896] Fps is (10 sec: 3293.8, 60 sec: 3550.6, 300 sec: 3555.3). Total num frames: 3915776. Throughput: 0: 3605.6. Samples: 3916800. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:16:32,727][322896] Avg episode reward: [(0, '694.455')]
[2025-11-06 16:16:37,759][322896] Fps is (10 sec: 3282.0, 60 sec: 3549.8, 300 sec: 3553.9). Total num frames: 3932160. Throughput: 0: 3596.2. Samples: 3939328. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:16:37,759][322896] Avg episode reward: [(0, '679.160')]
[2025-11-06 16:16:42,789][322896] Fps is (10 sec: 3256.4, 60 sec: 3544.5, 300 sec: 3554.4). Total num frames: 3948544. Throughput: 0: 3590.7. Samples: 3949568. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:16:42,789][322896] Avg episode reward: [(0, '667.657')]
[2025-11-06 16:16:47,744][322896] Fps is (10 sec: 3281.6, 60 sec: 3547.9, 300 sec: 3529.3). Total num frames: 3964928. Throughput: 0: 3620.5. Samples: 3972096. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:16:47,745][322896] Avg episode reward: [(0, '676.379')]
[2025-11-06 16:16:52,784][322896] Fps is (10 sec: 3278.6, 60 sec: 3549.0, 300 sec: 3499.8). Total num frames: 3981312. Throughput: 0: 3648.9. Samples: 3994112. Policy #0 lag: (min: 3.0, avg: 6.0, max: 67.0)
[2025-11-06 16:16:52,784][322896] Avg episode reward: [(0, '704.318')]
[2025-11-06 16:16:53,142][322896] Saving new best policy, reward=704.318!
[2025-11-06 16:16:57,734][322896] Fps is (10 sec: 4100.3, 60 sec: 3686.2, 300 sec: 3526.8). Total num frames: 4005888. Throughput: 0: 3643.0. Samples: 4004352. Policy #0 lag: (min: 3.0, avg: 6.0, max: 67.0)
[2025-11-06 16:16:57,734][322896] Avg episode reward: [(0, '705.182')]
[2025-11-06 16:16:58,093][322896] Saving new best policy, reward=705.182!
[2025-11-06 16:17:02,712][322896] Fps is (10 sec: 4950.9, 60 sec: 3826.9, 300 sec: 3554.4). Total num frames: 4030464. Throughput: 0: 3619.7. Samples: 4025856. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:17:02,712][322896] Avg episode reward: [(0, '684.891')]
[2025-11-06 16:17:07,731][322896] Fps is (10 sec: 4097.3, 60 sec: 3704.5, 300 sec: 3554.7). Total num frames: 4046848. Throughput: 0: 3644.7. Samples: 4047872. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:17:07,731][322896] Avg episode reward: [(0, '677.130')]
[2025-11-06 16:17:12,750][322896] Fps is (10 sec: 3264.4, 60 sec: 3558.8, 300 sec: 3554.4). Total num frames: 4063232. Throughput: 0: 3597.4. Samples: 4057600. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:17:12,750][322896] Avg episode reward: [(0, '715.312')]
[2025-11-06 16:17:12,886][322896] Saving new best policy, reward=715.312!
[2025-11-06 16:17:17,721][322896] Fps is (10 sec: 3280.0, 60 sec: 3550.4, 300 sec: 3554.5). Total num frames: 4079616. Throughput: 0: 3607.2. Samples: 4079104. Policy #0 lag: (min: 7.0, avg: 10.0, max: 71.0)
[2025-11-06 16:17:17,721][322896] Avg episode reward: [(0, '749.992')]
[2025-11-06 16:17:17,867][322896] Saving new best policy, reward=749.992!
[2025-11-06 16:17:22,772][322896] Fps is (10 sec: 3269.6, 60 sec: 3550.3, 300 sec: 3554.1). Total num frames: 4096000. Throughput: 0: 3560.3. Samples: 4099584. Policy #0 lag: (min: 7.0, avg: 10.0, max: 71.0)
[2025-11-06 16:17:22,772][322896] Avg episode reward: [(0, '740.573')]
[2025-11-06 16:17:25,164][322896] Signal inference workers to stop experience collection... (750 times)
[2025-11-06 16:17:25,553][322896] InferenceWorker_p0-w0: stopping experience collection (750 times)
[2025-11-06 16:17:25,555][322896] Signal inference workers to resume experience collection... (750 times)
[2025-11-06 16:17:25,686][322896] InferenceWorker_p0-w0: resuming experience collection (750 times)
[2025-11-06 16:17:27,766][322896] Fps is (10 sec: 3262.2, 60 sec: 3550.4, 300 sec: 3553.5). Total num frames: 4112384. Throughput: 0: 3597.2. Samples: 4111360. Policy #0 lag: (min: 7.0, avg: 10.0, max: 71.0)
[2025-11-06 16:17:27,766][322896] Avg episode reward: [(0, '733.528')]
[2025-11-06 16:17:32,707][322896] Fps is (10 sec: 3298.1, 60 sec: 3551.0, 300 sec: 3554.5). Total num frames: 4128768. Throughput: 0: 3530.0. Samples: 4130816. Policy #0 lag: (min: 4.0, avg: 7.0, max: 68.0)
[2025-11-06 16:17:32,707][322896] Avg episode reward: [(0, '722.836')]
[2025-11-06 16:17:37,737][322896] Fps is (10 sec: 3286.4, 60 sec: 3551.2, 300 sec: 3555.0). Total num frames: 4145152. Throughput: 0: 3530.8. Samples: 4152832. Policy #0 lag: (min: 4.0, avg: 7.0, max: 68.0)
[2025-11-06 16:17:37,737][322896] Avg episode reward: [(0, '700.762')]
[2025-11-06 16:17:42,714][322896] Fps is (10 sec: 3274.5, 60 sec: 3554.3, 300 sec: 3527.9). Total num frames: 4161536. Throughput: 0: 3517.3. Samples: 4162560. Policy #0 lag: (min: 4.0, avg: 7.0, max: 68.0)
[2025-11-06 16:17:42,714][322896] Avg episode reward: [(0, '674.926')]
[2025-11-06 16:17:47,747][322896] Fps is (10 sec: 3273.3, 60 sec: 3549.7, 300 sec: 3498.9). Total num frames: 4177920. Throughput: 0: 3524.3. Samples: 4184576. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:17:47,748][322896] Avg episode reward: [(0, '662.743')]
[2025-11-06 16:17:52,735][322896] Fps is (10 sec: 3269.9, 60 sec: 3552.8, 300 sec: 3498.4). Total num frames: 4194304. Throughput: 0: 3515.4. Samples: 4206080. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:17:52,735][322896] Avg episode reward: [(0, '711.262')]
[2025-11-06 16:17:57,835][322896] Fps is (10 sec: 4060.3, 60 sec: 3543.9, 300 sec: 3526.2). Total num frames: 4218880. Throughput: 0: 3520.4. Samples: 4216320. Policy #0 lag: (min: 8.0, avg: 11.0, max: 72.0)
[2025-11-06 16:17:57,836][322896] Avg episode reward: [(0, '730.246')]
[2025-11-06 16:17:58,181][322896] Saving /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_lidar_policy2_acc_yaw_sp/checkpoint_p0/checkpoint_000016512_4227072.pth...
[2025-11-06 16:17:58,185][322896] Removing /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_lidar_policy2_acc_yaw_sp/checkpoint_p0/checkpoint_000013184_3375104.pth
[2025-11-06 16:18:02,752][322896] Fps is (10 sec: 4906.8, 60 sec: 3547.5, 300 sec: 3553.8). Total num frames: 4243456. Throughput: 0: 3547.4. Samples: 4238848. Policy #0 lag: (min: 8.0, avg: 11.0, max: 72.0)
[2025-11-06 16:18:02,752][322896] Avg episode reward: [(0, '761.287')]
[2025-11-06 16:18:02,752][322896] Saving new best policy, reward=761.287!
[2025-11-06 16:18:07,760][322896] Fps is (10 sec: 4127.1, 60 sec: 3548.1, 300 sec: 3554.0). Total num frames: 4259840. Throughput: 0: 3584.9. Samples: 4260864. Policy #0 lag: (min: 8.0, avg: 11.0, max: 72.0)
[2025-11-06 16:18:07,760][322896] Avg episode reward: [(0, '777.498')]
[2025-11-06 16:18:07,894][322896] Saving new best policy, reward=777.498!
[2025-11-06 16:18:12,774][322896] Fps is (10 sec: 3269.5, 60 sec: 3548.4, 300 sec: 3553.3). Total num frames: 4276224. Throughput: 0: 3549.2. Samples: 4271104. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:18:12,774][322896] Avg episode reward: [(0, '755.701')]
[2025-11-06 16:18:17,703][322896] Fps is (10 sec: 3295.5, 60 sec: 3550.9, 300 sec: 3554.7). Total num frames: 4292608. Throughput: 0: 3607.0. Samples: 4293120. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:18:17,704][322896] Avg episode reward: [(0, '733.419')]
[2025-11-06 16:18:22,748][322896] Fps is (10 sec: 3285.3, 60 sec: 3551.3, 300 sec: 3554.0). Total num frames: 4308992. Throughput: 0: 3571.7. Samples: 4313600. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:18:22,748][322896] Avg episode reward: [(0, '734.797')]
[2025-11-06 16:18:27,673][322896] Fps is (10 sec: 3286.7, 60 sec: 3555.4, 300 sec: 3527.6). Total num frames: 4325376. Throughput: 0: 3632.8. Samples: 4325888. Policy #0 lag: (min: 1.0, avg: 4.0, max: 65.0)
[2025-11-06 16:18:27,673][322896] Avg episode reward: [(0, '755.838')]
[2025-11-06 16:18:32,793][322896] Fps is (10 sec: 3262.0, 60 sec: 3544.8, 300 sec: 3498.4). Total num frames: 4341760. Throughput: 0: 3603.1. Samples: 4346880. Policy #0 lag: (min: 1.0, avg: 4.0, max: 65.0)
[2025-11-06 16:18:32,794][322896] Avg episode reward: [(0, '740.056')]
[2025-11-06 16:18:37,716][322896] Fps is (10 sec: 3262.7, 60 sec: 3551.1, 300 sec: 3499.2). Total num frames: 4358144. Throughput: 0: 3608.2. Samples: 4368384. Policy #0 lag: (min: 1.0, avg: 4.0, max: 65.0)
[2025-11-06 16:18:37,717][322896] Avg episode reward: [(0, '768.720')]
[2025-11-06 16:18:38,684][322896] Signal inference workers to stop experience collection... (800 times)
[2025-11-06 16:18:39,018][322896] InferenceWorker_p0-w0: stopping experience collection (800 times)
[2025-11-06 16:18:39,018][322896] Signal inference workers to resume experience collection... (800 times)
[2025-11-06 16:18:39,019][322896] InferenceWorker_p0-w0: resuming experience collection (800 times)
[2025-11-06 16:18:42,713][322896] Fps is (10 sec: 3303.5, 60 sec: 3549.9, 300 sec: 3499.5). Total num frames: 4374528. Throughput: 0: 3628.0. Samples: 4379136. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:18:42,713][322896] Avg episode reward: [(0, '754.371')]
[2025-11-06 16:18:47,932][322896] Fps is (10 sec: 4811.3, 60 sec: 3811.2, 300 sec: 3552.3). Total num frames: 4407296. Throughput: 0: 3603.7. Samples: 4401664. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:18:47,933][322896] Avg episode reward: [(0, '746.791')]
[2025-11-06 16:18:52,711][322896] Fps is (10 sec: 4915.7, 60 sec: 3824.4, 300 sec: 3554.7). Total num frames: 4423680. Throughput: 0: 3622.1. Samples: 4423680. Policy #0 lag: (min: 8.0, avg: 11.0, max: 72.0)
[2025-11-06 16:18:52,712][322896] Avg episode reward: [(0, '754.758')]
[2025-11-06 16:18:57,693][322896] Fps is (10 sec: 3357.2, 60 sec: 3695.2, 300 sec: 3554.5). Total num frames: 4440064. Throughput: 0: 3613.3. Samples: 4433408. Policy #0 lag: (min: 8.0, avg: 11.0, max: 72.0)
[2025-11-06 16:18:57,693][322896] Avg episode reward: [(0, '758.819')]
[2025-11-06 16:19:02,778][322896] Fps is (10 sec: 3255.3, 60 sec: 3548.4, 300 sec: 3554.6). Total num frames: 4456448. Throughput: 0: 3589.5. Samples: 4454912. Policy #0 lag: (min: 8.0, avg: 11.0, max: 72.0)
[2025-11-06 16:19:02,778][322896] Avg episode reward: [(0, '763.673')]
[2025-11-06 16:19:07,714][322896] Fps is (10 sec: 3270.0, 60 sec: 3552.6, 300 sec: 3554.9). Total num frames: 4472832. Throughput: 0: 3609.5. Samples: 4475904. Policy #0 lag: (min: 6.0, avg: 9.0, max: 70.0)
[2025-11-06 16:19:07,714][322896] Avg episode reward: [(0, '751.310')]
[2025-11-06 16:19:12,738][322896] Fps is (10 sec: 3289.7, 60 sec: 3552.0, 300 sec: 3554.1). Total num frames: 4489216. Throughput: 0: 3612.9. Samples: 4488704. Policy #0 lag: (min: 6.0, avg: 9.0, max: 70.0)
[2025-11-06 16:19:12,739][322896] Avg episode reward: [(0, '791.635')]
[2025-11-06 16:19:12,890][322896] Saving new best policy, reward=791.635!
[2025-11-06 16:19:17,716][322896] Fps is (10 sec: 3275.9, 60 sec: 3549.1, 300 sec: 3555.5). Total num frames: 4505600. Throughput: 0: 3612.9. Samples: 4509184. Policy #0 lag: (min: 6.0, avg: 9.0, max: 70.0)
[2025-11-06 16:19:17,717][322896] Avg episode reward: [(0, '789.155')]
[2025-11-06 16:19:22,700][322896] Fps is (10 sec: 3289.3, 60 sec: 3552.7, 300 sec: 3555.0). Total num frames: 4521984. Throughput: 0: 3608.0. Samples: 4530688. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:19:22,701][322896] Avg episode reward: [(0, '776.157')]
[2025-11-06 16:19:27,765][322896] Fps is (10 sec: 3261.0, 60 sec: 3544.5, 300 sec: 3554.0). Total num frames: 4538368. Throughput: 0: 3579.8. Samples: 4540416. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:19:27,765][322896] Avg episode reward: [(0, '729.524')]
[2025-11-06 16:19:32,736][322896] Fps is (10 sec: 3265.2, 60 sec: 3553.3, 300 sec: 3555.0). Total num frames: 4554752. Throughput: 0: 3599.7. Samples: 4562944. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:19:32,736][322896] Avg episode reward: [(0, '747.535')]
[2025-11-06 16:19:37,954][322896] Fps is (10 sec: 4823.9, 60 sec: 3807.8, 300 sec: 3607.5). Total num frames: 4587520. Throughput: 0: 3587.4. Samples: 4585984. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:19:37,954][322896] Avg episode reward: [(0, '775.189')]
[2025-11-06 16:19:42,787][322896] Fps is (10 sec: 4890.0, 60 sec: 3818.2, 300 sec: 3609.0). Total num frames: 4603904. Throughput: 0: 3621.9. Samples: 4596736. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:19:42,787][322896] Avg episode reward: [(0, '797.297')]
[2025-11-06 16:19:42,911][322896] Saving new best policy, reward=797.297!
[2025-11-06 16:19:47,775][322896] Fps is (10 sec: 3336.6, 60 sec: 3559.2, 300 sec: 3610.3). Total num frames: 4620288. Throughput: 0: 3652.5. Samples: 4619264. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:19:47,775][322896] Avg episode reward: [(0, '753.014')]
[2025-11-06 16:19:52,777][322896] Fps is (10 sec: 3280.0, 60 sec: 3546.0, 300 sec: 3609.7). Total num frames: 4636672. Throughput: 0: 3647.1. Samples: 4640256. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:19:52,778][322896] Avg episode reward: [(0, '767.120')]
[2025-11-06 16:19:55,413][322896] Signal inference workers to stop experience collection... (850 times)
[2025-11-06 16:19:55,413][322896] Signal inference workers to resume experience collection... (850 times)
[2025-11-06 16:19:55,652][322896] InferenceWorker_p0-w0: stopping experience collection (850 times)
[2025-11-06 16:19:55,652][322896] InferenceWorker_p0-w0: resuming experience collection (850 times)
[2025-11-06 16:19:57,776][322896] Fps is (10 sec: 3276.4, 60 sec: 3544.9, 300 sec: 3609.1). Total num frames: 4653056. Throughput: 0: 3637.8. Samples: 4652544. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:19:57,776][322896] Avg episode reward: [(0, '756.662')]
[2025-11-06 16:19:57,898][322896] Saving /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_lidar_policy2_acc_yaw_sp/checkpoint_p0/checkpoint_000018176_4653056.pth...
[2025-11-06 16:19:57,902][322896] Removing /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_lidar_policy2_acc_yaw_sp/checkpoint_p0/checkpoint_000014784_3784704.pth
[2025-11-06 16:20:02,695][322896] Fps is (10 sec: 3304.0, 60 sec: 3554.8, 300 sec: 3584.8). Total num frames: 4669440. Throughput: 0: 3642.6. Samples: 4673024. Policy #0 lag: (min: 0.0, avg: 3.0, max: 64.0)
[2025-11-06 16:20:02,695][322896] Avg episode reward: [(0, '779.492')]
[2025-11-06 16:20:07,791][322896] Fps is (10 sec: 3271.8, 60 sec: 3545.3, 300 sec: 3581.2). Total num frames: 4685824. Throughput: 0: 3656.3. Samples: 4695552. Policy #0 lag: (min: 0.0, avg: 3.0, max: 64.0)
[2025-11-06 16:20:07,792][322896] Avg episode reward: [(0, '820.020')]
[2025-11-06 16:20:07,912][322896] Saving new best policy, reward=820.020!
[2025-11-06 16:20:12,688][322896] Fps is (10 sec: 3279.0, 60 sec: 3552.8, 300 sec: 3556.5). Total num frames: 4702208. Throughput: 0: 3681.3. Samples: 4705792. Policy #0 lag: (min: 0.0, avg: 3.0, max: 64.0)
[2025-11-06 16:20:12,689][322896] Avg episode reward: [(0, '830.728')]
[2025-11-06 16:20:12,825][322896] Saving new best policy, reward=830.728!
[2025-11-06 16:20:17,958][322896] Fps is (10 sec: 4028.9, 60 sec: 3671.6, 300 sec: 3579.7). Total num frames: 4726784. Throughput: 0: 3657.0. Samples: 4728320. Policy #0 lag: (min: 0.0, avg: 3.0, max: 64.0)
[2025-11-06 16:20:17,958][322896] Avg episode reward: [(0, '829.009')]
[2025-11-06 16:20:22,697][322896] Fps is (10 sec: 4911.0, 60 sec: 3823.2, 300 sec: 3610.8). Total num frames: 4751360. Throughput: 0: 3684.7. Samples: 4750848. Policy #0 lag: (min: 0.0, avg: 3.0, max: 64.0)
[2025-11-06 16:20:22,697][322896] Avg episode reward: [(0, '806.897')]
[2025-11-06 16:20:27,684][322896] Fps is (10 sec: 4211.2, 60 sec: 3828.1, 300 sec: 3610.7). Total num frames: 4767744. Throughput: 0: 3660.6. Samples: 4761088. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:20:27,685][322896] Avg episode reward: [(0, '821.574')]
[2025-11-06 16:20:32,707][322896] Fps is (10 sec: 3273.6, 60 sec: 3824.8, 300 sec: 3610.7). Total num frames: 4784128. Throughput: 0: 3657.8. Samples: 4783616. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:20:32,707][322896] Avg episode reward: [(0, '822.359')]
[2025-11-06 16:20:37,726][322896] Fps is (10 sec: 3263.3, 60 sec: 3563.4, 300 sec: 3609.7). Total num frames: 4800512. Throughput: 0: 3645.1. Samples: 4804096. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:20:37,726][322896] Avg episode reward: [(0, '822.981')]
[2025-11-06 16:20:42,772][322896] Fps is (10 sec: 3255.5, 60 sec: 3550.8, 300 sec: 3609.3). Total num frames: 4816896. Throughput: 0: 3641.2. Samples: 4816384. Policy #0 lag: (min: 8.0, avg: 11.0, max: 72.0)
[2025-11-06 16:20:42,772][322896] Avg episode reward: [(0, '782.824')]
[2025-11-06 16:20:47,700][322896] Fps is (10 sec: 3285.3, 60 sec: 3554.3, 300 sec: 3610.9). Total num frames: 4833280. Throughput: 0: 3651.9. Samples: 4837376. Policy #0 lag: (min: 8.0, avg: 11.0, max: 72.0)
[2025-11-06 16:20:47,700][322896] Avg episode reward: [(0, '803.356')]
[2025-11-06 16:20:52,702][322896] Fps is (10 sec: 3300.0, 60 sec: 3554.3, 300 sec: 3610.4). Total num frames: 4849664. Throughput: 0: 3671.0. Samples: 4860416. Policy #0 lag: (min: 8.0, avg: 11.0, max: 72.0)
[2025-11-06 16:20:52,702][322896] Avg episode reward: [(0, '813.435')]
[2025-11-06 16:20:57,976][322896] Fps is (10 sec: 3986.1, 60 sec: 3674.2, 300 sec: 3635.3). Total num frames: 4874240. Throughput: 0: 3651.7. Samples: 4871168. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:20:57,976][322896] Avg episode reward: [(0, '846.662')]
[2025-11-06 16:20:58,338][322896] Saving new best policy, reward=846.662!
[2025-11-06 16:21:02,740][322896] Fps is (10 sec: 4896.5, 60 sec: 3820.1, 300 sec: 3641.3). Total num frames: 4898816. Throughput: 0: 3692.9. Samples: 4893696. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:21:02,740][322896] Avg episode reward: [(0, '870.891')]
[2025-11-06 16:21:02,740][322896] Saving new best policy, reward=870.891!
[2025-11-06 16:21:07,677][322896] Fps is (10 sec: 4222.3, 60 sec: 3830.3, 300 sec: 3612.8). Total num frames: 4915200. Throughput: 0: 3676.7. Samples: 4916224. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:21:07,677][322896] Avg episode reward: [(0, '838.392')]
[2025-11-06 16:21:10,832][322896] Signal inference workers to stop experience collection... (900 times)
[2025-11-06 16:21:11,182][322896] InferenceWorker_p0-w0: stopping experience collection (900 times)
[2025-11-06 16:21:11,184][322896] Signal inference workers to resume experience collection... (900 times)
[2025-11-06 16:21:11,309][322896] InferenceWorker_p0-w0: resuming experience collection (900 times)
[2025-11-06 16:21:12,731][322896] Fps is (10 sec: 3279.7, 60 sec: 3820.2, 300 sec: 3610.0). Total num frames: 4931584. Throughput: 0: 3693.9. Samples: 4927488. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:21:12,731][322896] Avg episode reward: [(0, '792.580')]
[2025-11-06 16:21:17,715][322896] Fps is (10 sec: 3264.3, 60 sec: 3701.4, 300 sec: 3610.8). Total num frames: 4947968. Throughput: 0: 3674.4. Samples: 4948992. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:21:17,715][322896] Avg episode reward: [(0, '813.584')]
[2025-11-06 16:21:22,789][322896] Fps is (10 sec: 3257.8, 60 sec: 3544.4, 300 sec: 3609.9). Total num frames: 4964352. Throughput: 0: 3692.6. Samples: 4970496. Policy #0 lag: (min: 31.0, avg: 34.0, max: 95.0)
[2025-11-06 16:21:22,790][322896] Avg episode reward: [(0, '809.805')]
[2025-11-06 16:21:27,792][322896] Fps is (10 sec: 3251.6, 60 sec: 3543.5, 300 sec: 3609.2). Total num frames: 4980736. Throughput: 0: 3673.4. Samples: 4981760. Policy #0 lag: (min: 31.0, avg: 34.0, max: 95.0)
[2025-11-06 16:21:27,793][322896] Avg episode reward: [(0, '828.162')]
[2025-11-06 16:21:32,790][322896] Fps is (10 sec: 3276.5, 60 sec: 3544.9, 300 sec: 3609.7). Total num frames: 4997120. Throughput: 0: 3679.0. Samples: 5003264. Policy #0 lag: (min: 31.0, avg: 34.0, max: 95.0)
[2025-11-06 16:21:32,790][322896] Avg episode reward: [(0, '825.769')]
[2025-11-06 16:21:37,696][322896] Fps is (10 sec: 3308.6, 60 sec: 3551.6, 300 sec: 3611.2). Total num frames: 5013504. Throughput: 0: 3641.3. Samples: 5024256. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:21:37,697][322896] Avg episode reward: [(0, '823.458')]
[2025-11-06 16:21:42,997][322896] Fps is (10 sec: 4012.9, 60 sec: 3672.6, 300 sec: 3634.7). Total num frames: 5038080. Throughput: 0: 3639.1. Samples: 5035008. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:21:42,997][322896] Avg episode reward: [(0, '843.004')]
[2025-11-06 16:21:47,867][322896] Fps is (10 sec: 4832.6, 60 sec: 3812.3, 300 sec: 3664.5). Total num frames: 5062656. Throughput: 0: 3630.6. Samples: 5057536. Policy #0 lag: (min: 20.0, avg: 23.0, max: 84.0)
[2025-11-06 16:21:47,867][322896] Avg episode reward: [(0, '861.351')]
[2025-11-06 16:21:52,723][322896] Fps is (10 sec: 4211.4, 60 sec: 3821.6, 300 sec: 3637.9). Total num frames: 5079040. Throughput: 0: 3637.1. Samples: 5080064. Policy #0 lag: (min: 20.0, avg: 23.0, max: 84.0)
[2025-11-06 16:21:52,723][322896] Avg episode reward: [(0, '809.893')]
[2025-11-06 16:21:57,675][322896] Fps is (10 sec: 3340.9, 60 sec: 3705.0, 300 sec: 3610.5). Total num frames: 5095424. Throughput: 0: 3611.2. Samples: 5089792. Policy #0 lag: (min: 20.0, avg: 23.0, max: 84.0)
[2025-11-06 16:21:57,675][322896] Avg episode reward: [(0, '821.235')]
[2025-11-06 16:21:57,813][322896] Saving /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_lidar_policy2_acc_yaw_sp/checkpoint_p0/checkpoint_000019904_5095424.pth...
[2025-11-06 16:21:57,817][322896] Removing /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_lidar_policy2_acc_yaw_sp/checkpoint_p0/checkpoint_000016512_4227072.pth
[2025-11-06 16:22:02,725][322896] Fps is (10 sec: 3276.3, 60 sec: 3550.8, 300 sec: 3610.1). Total num frames: 5111808. Throughput: 0: 3617.3. Samples: 5111808. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:22:02,725][322896] Avg episode reward: [(0, '816.878')]
[2025-11-06 16:22:07,740][322896] Fps is (10 sec: 3255.8, 60 sec: 3546.1, 300 sec: 3610.2). Total num frames: 5128192. Throughput: 0: 3599.4. Samples: 5132288. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:22:07,740][322896] Avg episode reward: [(0, '859.393')]
[2025-11-06 16:22:12,775][322896] Fps is (10 sec: 3260.4, 60 sec: 3547.3, 300 sec: 3609.4). Total num frames: 5144576. Throughput: 0: 3619.5. Samples: 5144576. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:22:12,775][322896] Avg episode reward: [(0, '867.193')]
[2025-11-06 16:22:17,798][322896] Fps is (10 sec: 3257.8, 60 sec: 3545.0, 300 sec: 3609.7). Total num frames: 5160960. Throughput: 0: 3594.8. Samples: 5165056. Policy #0 lag: (min: 47.0, avg: 50.0, max: 111.0)
[2025-11-06 16:22:17,798][322896] Avg episode reward: [(0, '865.306')]
[2025-11-06 16:22:22,710][322896] Fps is (10 sec: 3298.2, 60 sec: 3554.6, 300 sec: 3610.7). Total num frames: 5177344. Throughput: 0: 3617.0. Samples: 5187072. Policy #0 lag: (min: 47.0, avg: 50.0, max: 111.0)
[2025-11-06 16:22:22,710][322896] Avg episode reward: [(0, '836.828')]
[2025-11-06 16:22:23,849][322896] Signal inference workers to stop experience collection... (950 times)
[2025-11-06 16:22:24,186][322896] InferenceWorker_p0-w0: stopping experience collection (950 times)
[2025-11-06 16:22:24,186][322896] Signal inference workers to resume experience collection... (950 times)
[2025-11-06 16:22:24,187][322896] InferenceWorker_p0-w0: resuming experience collection (950 times)
[2025-11-06 16:22:27,724][322896] Fps is (10 sec: 3301.1, 60 sec: 3553.9, 300 sec: 3609.8). Total num frames: 5193728. Throughput: 0: 3628.8. Samples: 5197312. Policy #0 lag: (min: 47.0, avg: 50.0, max: 111.0)
[2025-11-06 16:22:27,724][322896] Avg episode reward: [(0, '818.664')]
[2025-11-06 16:22:32,941][322896] Fps is (10 sec: 4003.5, 60 sec: 3677.1, 300 sec: 3635.3). Total num frames: 5218304. Throughput: 0: 3600.8. Samples: 5219840. Policy #0 lag: (min: 4.0, avg: 7.0, max: 68.0)
[2025-11-06 16:22:32,942][322896] Avg episode reward: [(0, '810.338')]
[2025-11-06 16:22:37,713][322896] Fps is (10 sec: 4100.6, 60 sec: 3685.4, 300 sec: 3637.8). Total num frames: 5234688. Throughput: 0: 3584.8. Samples: 5241344. Policy #0 lag: (min: 4.0, avg: 7.0, max: 68.0)
[2025-11-06 16:22:37,713][322896] Avg episode reward: [(0, '818.855')]
[2025-11-06 16:22:42,764][322896] Fps is (10 sec: 4169.9, 60 sec: 3700.8, 300 sec: 3665.4). Total num frames: 5259264. Throughput: 0: 3576.9. Samples: 5251072. Policy #0 lag: (min: 4.0, avg: 7.0, max: 68.0)
[2025-11-06 16:22:42,764][322896] Avg episode reward: [(0, '821.727')]
[2025-11-06 16:22:47,709][322896] Fps is (10 sec: 4097.7, 60 sec: 3559.3, 300 sec: 3665.9). Total num frames: 5275648. Throughput: 0: 3585.3. Samples: 5273088. Policy #0 lag: (min: 9.0, avg: 12.0, max: 73.0)
[2025-11-06 16:22:47,709][322896] Avg episode reward: [(0, '835.020')]
[2025-11-06 16:22:52,790][322896] Fps is (10 sec: 3268.4, 60 sec: 3545.9, 300 sec: 3638.4). Total num frames: 5292032. Throughput: 0: 3568.6. Samples: 5293056. Policy #0 lag: (min: 9.0, avg: 12.0, max: 73.0)
[2025-11-06 16:22:52,790][322896] Avg episode reward: [(0, '870.023')]
[2025-11-06 16:22:57,730][322896] Fps is (10 sec: 3269.7, 60 sec: 3546.6, 300 sec: 3610.3). Total num frames: 5308416. Throughput: 0: 3576.2. Samples: 5305344. Policy #0 lag: (min: 9.0, avg: 12.0, max: 73.0)
[2025-11-06 16:22:57,730][322896] Avg episode reward: [(0, '872.541')]
[2025-11-06 16:22:57,876][322896] Saving new best policy, reward=872.541!
[2025-11-06 16:23:02,677][322896] Fps is (10 sec: 3314.2, 60 sec: 3552.7, 300 sec: 3611.1). Total num frames: 5324800. Throughput: 0: 3582.2. Samples: 5325824. Policy #0 lag: (min: 59.0, avg: 62.0, max: 123.0)
[2025-11-06 16:23:02,677][322896] Avg episode reward: [(0, '847.975')]
[2025-11-06 16:23:07,684][322896] Fps is (10 sec: 3292.1, 60 sec: 3553.2, 300 sec: 3611.1). Total num frames: 5341184. Throughput: 0: 3574.7. Samples: 5347840. Policy #0 lag: (min: 59.0, avg: 62.0, max: 123.0)
[2025-11-06 16:23:07,684][322896] Avg episode reward: [(0, '881.989')]
[2025-11-06 16:23:07,818][322896] Saving new best policy, reward=881.989!
[2025-11-06 16:23:12,778][322896] Fps is (10 sec: 3244.0, 60 sec: 3549.7, 300 sec: 3609.1). Total num frames: 5357568. Throughput: 0: 3579.7. Samples: 5358592. Policy #0 lag: (min: 59.0, avg: 62.0, max: 123.0)
[2025-11-06 16:23:12,778][322896] Avg episode reward: [(0, '866.790')]
[2025-11-06 16:23:17,678][322896] Fps is (10 sec: 3278.7, 60 sec: 3557.0, 300 sec: 3610.9). Total num frames: 5373952. Throughput: 0: 3593.6. Samples: 5380608. Policy #0 lag: (min: 59.0, avg: 62.0, max: 123.0)
[2025-11-06 16:23:17,678][322896] Avg episode reward: [(0, '897.733')]
[2025-11-06 16:23:17,817][322896] Saving new best policy, reward=897.733!
[2025-11-06 16:23:22,711][322896] Fps is (10 sec: 3299.1, 60 sec: 3549.8, 300 sec: 3609.6). Total num frames: 5390336. Throughput: 0: 3572.8. Samples: 5402112. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:23:22,711][322896] Avg episode reward: [(0, '888.229')]
[2025-11-06 16:23:27,853][322896] Fps is (10 sec: 4025.6, 60 sec: 3678.5, 300 sec: 3637.1). Total num frames: 5414912. Throughput: 0: 3576.9. Samples: 5412352. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:23:27,853][322896] Avg episode reward: [(0, '867.983')]
[2025-11-06 16:23:32,766][322896] Fps is (10 sec: 4888.2, 60 sec: 3697.2, 300 sec: 3665.0). Total num frames: 5439488. Throughput: 0: 3590.8. Samples: 5434880. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:23:32,766][322896] Avg episode reward: [(0, '878.805')]
[2025-11-06 16:23:37,758][322896] Fps is (10 sec: 4135.5, 60 sec: 3683.7, 300 sec: 3665.0). Total num frames: 5455872. Throughput: 0: 3643.5. Samples: 5456896. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:23:37,758][322896] Avg episode reward: [(0, '906.191')]
[2025-11-06 16:23:37,889][322896] Saving new best policy, reward=906.191!
[2025-11-06 16:23:41,518][322896] Signal inference workers to stop experience collection... (1000 times)
[2025-11-06 16:23:41,518][322896] Signal inference workers to resume experience collection... (1000 times)
[2025-11-06 16:23:41,760][322896] InferenceWorker_p0-w0: stopping experience collection (1000 times)
[2025-11-06 16:23:41,760][322896] InferenceWorker_p0-w0: resuming experience collection (1000 times)
[2025-11-06 16:23:42,763][322896] Fps is (10 sec: 3277.7, 60 sec: 3549.9, 300 sec: 3612.1). Total num frames: 5472256. Throughput: 0: 3592.7. Samples: 5467136. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:23:42,763][322896] Avg episode reward: [(0, '864.216')]
[2025-11-06 16:23:47,742][322896] Fps is (10 sec: 3281.8, 60 sec: 3547.9, 300 sec: 3609.7). Total num frames: 5488640. Throughput: 0: 3624.3. Samples: 5489152. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:23:47,743][322896] Avg episode reward: [(0, '858.960')]
[2025-11-06 16:23:52,742][322896] Fps is (10 sec: 3283.7, 60 sec: 3552.7, 300 sec: 3609.4). Total num frames: 5505024. Throughput: 0: 3579.4. Samples: 5509120. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:23:52,742][322896] Avg episode reward: [(0, '857.780')]
[2025-11-06 16:23:57,786][322896] Fps is (10 sec: 3262.6, 60 sec: 3546.6, 300 sec: 3609.9). Total num frames: 5521408. Throughput: 0: 3617.5. Samples: 5521408. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:23:57,786][322896] Avg episode reward: [(0, '832.559')]
[2025-11-06 16:23:57,917][322896] Saving /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_lidar_policy2_acc_yaw_sp/checkpoint_p0/checkpoint_000021568_5521408.pth...
[2025-11-06 16:23:57,921][322896] Removing /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_lidar_policy2_acc_yaw_sp/checkpoint_p0/checkpoint_000018176_4653056.pth
[2025-11-06 16:24:02,784][322896] Fps is (10 sec: 3263.2, 60 sec: 3543.6, 300 sec: 3609.2). Total num frames: 5537792. Throughput: 0: 3575.6. Samples: 5541888. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:24:02,784][322896] Avg episode reward: [(0, '816.113')]
[2025-11-06 16:24:07,700][322896] Fps is (10 sec: 3305.3, 60 sec: 3548.9, 300 sec: 3610.5). Total num frames: 5554176. Throughput: 0: 3619.0. Samples: 5564928. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:24:07,700][322896] Avg episode reward: [(0, '843.325')]
[2025-11-06 16:24:12,696][322896] Fps is (10 sec: 3306.0, 60 sec: 3554.8, 300 sec: 3610.3). Total num frames: 5570560. Throughput: 0: 3630.8. Samples: 5575168. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:24:12,696][322896] Avg episode reward: [(0, '888.668')]
[2025-11-06 16:24:17,696][322896] Fps is (10 sec: 4097.5, 60 sec: 3685.3, 300 sec: 3637.9). Total num frames: 5595136. Throughput: 0: 3623.8. Samples: 5597696. Policy #0 lag: (min: 0.0, avg: 3.0, max: 64.0)
[2025-11-06 16:24:17,696][322896] Avg episode reward: [(0, '905.290')]
[2025-11-06 16:24:22,799][322896] Fps is (10 sec: 4865.0, 60 sec: 3817.3, 300 sec: 3665.2). Total num frames: 5619712. Throughput: 0: 3614.8. Samples: 5619712. Policy #0 lag: (min: 0.0, avg: 3.0, max: 64.0)
[2025-11-06 16:24:22,799][322896] Avg episode reward: [(0, '886.520')]
[2025-11-06 16:24:27,726][322896] Fps is (10 sec: 4083.7, 60 sec: 3694.2, 300 sec: 3665.7). Total num frames: 5636096. Throughput: 0: 3621.1. Samples: 5629952. Policy #0 lag: (min: 0.0, avg: 3.0, max: 64.0)
[2025-11-06 16:24:27,726][322896] Avg episode reward: [(0, '896.122')]
[2025-11-06 16:24:32,736][322896] Fps is (10 sec: 3297.5, 60 sec: 3551.6, 300 sec: 3612.7). Total num frames: 5652480. Throughput: 0: 3630.0. Samples: 5652480. Policy #0 lag: (min: 6.0, avg: 9.0, max: 70.0)
[2025-11-06 16:24:32,736][322896] Avg episode reward: [(0, '926.389')]
[2025-11-06 16:24:32,861][322896] Saving new best policy, reward=926.389!
[2025-11-06 16:24:37,716][322896] Fps is (10 sec: 3280.1, 60 sec: 3552.3, 300 sec: 3610.9). Total num frames: 5668864. Throughput: 0: 3643.0. Samples: 5672960. Policy #0 lag: (min: 6.0, avg: 9.0, max: 70.0)
[2025-11-06 16:24:37,717][322896] Avg episode reward: [(0, '886.333')]
[2025-11-06 16:24:42,786][322896] Fps is (10 sec: 3260.5, 60 sec: 3548.5, 300 sec: 3609.9). Total num frames: 5685248. Throughput: 0: 3640.9. Samples: 5685248. Policy #0 lag: (min: 6.0, avg: 9.0, max: 70.0)
[2025-11-06 16:24:42,786][322896] Avg episode reward: [(0, '853.264')]
[2025-11-06 16:24:47,726][322896] Fps is (10 sec: 3273.5, 60 sec: 3550.8, 300 sec: 3610.7). Total num frames: 5701632. Throughput: 0: 3645.5. Samples: 5705728. Policy #0 lag: (min: 6.0, avg: 9.0, max: 70.0)
[2025-11-06 16:24:47,727][322896] Avg episode reward: [(0, '908.409')]
[2025-11-06 16:24:52,753][322896] Fps is (10 sec: 3287.5, 60 sec: 3549.2, 300 sec: 3610.3). Total num frames: 5718016. Throughput: 0: 3625.2. Samples: 5728256. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:24:52,754][322896] Avg episode reward: [(0, '967.468')]
[2025-11-06 16:24:52,882][322896] Saving new best policy, reward=967.468!
[2025-11-06 16:24:57,748][322896] Fps is (10 sec: 3269.7, 60 sec: 3552.1, 300 sec: 3609.4). Total num frames: 5734400. Throughput: 0: 3625.3. Samples: 5738496. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:24:57,748][322896] Avg episode reward: [(0, '924.426')]
[2025-11-06 16:24:57,999][322896] Signal inference workers to stop experience collection... (1050 times)
[2025-11-06 16:24:58,372][322896] InferenceWorker_p0-w0: stopping experience collection (1050 times)
[2025-11-06 16:24:58,377][322896] Signal inference workers to resume experience collection... (1050 times)
[2025-11-06 16:24:58,504][322896] InferenceWorker_p0-w0: resuming experience collection (1050 times)
[2025-11-06 16:25:03,028][322896] Fps is (10 sec: 3986.5, 60 sec: 3671.5, 300 sec: 3634.9). Total num frames: 5758976. Throughput: 0: 3580.3. Samples: 5760000. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:25:03,028][322896] Avg episode reward: [(0, '919.538')]
[2025-11-06 16:25:07,932][322896] Fps is (10 sec: 4826.4, 60 sec: 3808.2, 300 sec: 3662.5). Total num frames: 5783552. Throughput: 0: 3596.1. Samples: 5782016. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:25:07,932][322896] Avg episode reward: [(0, '907.663')]
[2025-11-06 16:25:12,734][322896] Fps is (10 sec: 4220.0, 60 sec: 3820.5, 300 sec: 3640.6). Total num frames: 5799936. Throughput: 0: 3594.7. Samples: 5791744. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:25:12,734][322896] Avg episode reward: [(0, '902.670')]
[2025-11-06 16:25:17,683][322896] Fps is (10 sec: 3360.4, 60 sec: 3687.2, 300 sec: 3610.2). Total num frames: 5816320. Throughput: 0: 3588.2. Samples: 5813760. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:25:17,683][322896] Avg episode reward: [(0, '892.594')]
[2025-11-06 16:25:22,737][322896] Fps is (10 sec: 3275.7, 60 sec: 3553.5, 300 sec: 3609.4). Total num frames: 5832704. Throughput: 0: 3571.0. Samples: 5833728. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:25:22,738][322896] Avg episode reward: [(0, '950.604')]
[2025-11-06 16:25:27,772][322896] Fps is (10 sec: 3248.0, 60 sec: 3547.2, 300 sec: 3609.2). Total num frames: 5849088. Throughput: 0: 3562.4. Samples: 5845504. Policy #0 lag: (min: 5.0, avg: 8.0, max: 69.0)
[2025-11-06 16:25:27,772][322896] Avg episode reward: [(0, '959.090')]
[2025-11-06 16:25:32,696][322896] Fps is (10 sec: 3290.4, 60 sec: 3552.3, 300 sec: 3610.4). Total num frames: 5865472. Throughput: 0: 3575.0. Samples: 5866496. Policy #0 lag: (min: 5.0, avg: 8.0, max: 69.0)
[2025-11-06 16:25:32,696][322896] Avg episode reward: [(0, '921.155')]
[2025-11-06 16:25:37,722][322896] Fps is (10 sec: 3293.1, 60 sec: 3549.5, 300 sec: 3610.6). Total num frames: 5881856. Throughput: 0: 3529.5. Samples: 5886976. Policy #0 lag: (min: 5.0, avg: 8.0, max: 69.0)
[2025-11-06 16:25:37,723][322896] Avg episode reward: [(0, '881.180')]
[2025-11-06 16:25:42,739][322896] Fps is (10 sec: 3262.6, 60 sec: 3552.6, 300 sec: 3609.6). Total num frames: 5898240. Throughput: 0: 3550.5. Samples: 5898240. Policy #0 lag: (min: 5.0, avg: 8.0, max: 69.0)
[2025-11-06 16:25:42,740][322896] Avg episode reward: [(0, '880.162')]
[2025-11-06 16:25:47,734][322896] Fps is (10 sec: 3273.0, 60 sec: 3549.4, 300 sec: 3609.6). Total num frames: 5914624. Throughput: 0: 3538.8. Samples: 5918208. Policy #0 lag: (min: 0.0, avg: 3.0, max: 64.0)
[2025-11-06 16:25:47,734][322896] Avg episode reward: [(0, '921.219')]
[2025-11-06 16:25:52,686][322896] Fps is (10 sec: 3294.2, 60 sec: 3553.8, 300 sec: 3585.8). Total num frames: 5931008. Throughput: 0: 3523.6. Samples: 5939712. Policy #0 lag: (min: 0.0, avg: 3.0, max: 64.0)
[2025-11-06 16:25:52,687][322896] Avg episode reward: [(0, '928.707')]
[2025-11-06 16:25:57,724][322896] Fps is (10 sec: 3280.0, 60 sec: 3551.3, 300 sec: 3554.7). Total num frames: 5947392. Throughput: 0: 3527.9. Samples: 5950464. Policy #0 lag: (min: 0.0, avg: 3.0, max: 64.0)
[2025-11-06 16:25:57,725][322896] Avg episode reward: [(0, '902.049')]
[2025-11-06 16:25:57,868][322896] Saving /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_lidar_policy2_acc_yaw_sp/checkpoint_p0/checkpoint_000023232_5947392.pth...
[2025-11-06 16:25:57,872][322896] Removing /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_lidar_policy2_acc_yaw_sp/checkpoint_p0/checkpoint_000019904_5095424.pth
[2025-11-06 16:26:02,753][322896] Fps is (10 sec: 3255.2, 60 sec: 3429.1, 300 sec: 3553.6). Total num frames: 5963776. Throughput: 0: 3510.3. Samples: 5971968. Policy #0 lag: (min: 0.0, avg: 3.0, max: 64.0)
[2025-11-06 16:26:02,753][322896] Avg episode reward: [(0, '934.460')]
[2025-11-06 16:26:07,701][322896] Fps is (10 sec: 3284.4, 60 sec: 3289.5, 300 sec: 3554.9). Total num frames: 5980160. Throughput: 0: 3552.7. Samples: 5993472. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:26:07,701][322896] Avg episode reward: [(0, '947.843')]
[2025-11-06 16:26:12,602][322896] Signal inference workers to stop experience collection... (1100 times)
[2025-11-06 16:26:12,957][322896] InferenceWorker_p0-w0: stopping experience collection (1100 times)
[2025-11-06 16:26:12,957][322896] Signal inference workers to resume experience collection... (1100 times)
[2025-11-06 16:26:12,958][322896] Fps is (10 sec: 4816.5, 60 sec: 3536.7, 300 sec: 3607.1). Total num frames: 6012928. Throughput: 0: 3490.0. Samples: 6003200. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:26:12,958][322896] Avg episode reward: [(0, '950.038')]
[2025-11-06 16:26:12,958][322896] InferenceWorker_p0-w0: resuming experience collection (1100 times)
[2025-11-06 16:26:17,778][322896] Fps is (10 sec: 4877.6, 60 sec: 3544.2, 300 sec: 3610.2). Total num frames: 6029312. Throughput: 0: 3520.7. Samples: 6025216. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:26:17,779][322896] Avg episode reward: [(0, '938.700')]
[2025-11-06 16:26:22,679][322896] Fps is (10 sec: 3370.6, 60 sec: 3553.3, 300 sec: 3611.4). Total num frames: 6045696. Throughput: 0: 3553.3. Samples: 6046720. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:26:22,680][322896] Avg episode reward: [(0, '973.625')]
[2025-11-06 16:26:22,815][322896] Saving new best policy, reward=973.625!
[2025-11-06 16:26:27,761][322896] Fps is (10 sec: 3282.6, 60 sec: 3550.5, 300 sec: 3610.4). Total num frames: 6062080. Throughput: 0: 3525.4. Samples: 6056960. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:26:27,761][322896] Avg episode reward: [(0, '963.864')]
[2025-11-06 16:26:32,696][322896] Fps is (10 sec: 3271.2, 60 sec: 3549.8, 300 sec: 3610.0). Total num frames: 6078464. Throughput: 0: 3564.2. Samples: 6078464. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:26:32,697][322896] Avg episode reward: [(0, '952.128')]
[2025-11-06 16:26:37,683][322896] Fps is (10 sec: 3302.6, 60 sec: 3552.2, 300 sec: 3586.1). Total num frames: 6094848. Throughput: 0: 3527.4. Samples: 6098432. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:26:37,683][322896] Avg episode reward: [(0, '950.208')]
[2025-11-06 16:26:42,771][322896] Fps is (10 sec: 3252.4, 60 sec: 3548.0, 300 sec: 3555.6). Total num frames: 6111232. Throughput: 0: 3546.2. Samples: 6110208. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:26:42,772][322896] Avg episode reward: [(0, '920.039')]
[2025-11-06 16:26:47,696][322896] Fps is (10 sec: 3272.3, 60 sec: 3552.1, 300 sec: 3554.8). Total num frames: 6127616. Throughput: 0: 3508.8. Samples: 6129664. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:26:47,696][322896] Avg episode reward: [(0, '946.844')]
[2025-11-06 16:26:52,679][322896] Fps is (10 sec: 3307.4, 60 sec: 3550.3, 300 sec: 3554.4). Total num frames: 6144000. Throughput: 0: 3517.5. Samples: 6151680. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:26:52,679][322896] Avg episode reward: [(0, '962.581')]
[2025-11-06 16:26:57,731][322896] Fps is (10 sec: 3265.4, 60 sec: 3549.5, 300 sec: 3554.4). Total num frames: 6160384. Throughput: 0: 3533.5. Samples: 6161408. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:26:57,732][322896] Avg episode reward: [(0, '982.528')]
[2025-11-06 16:26:57,856][322896] Saving new best policy, reward=982.528!
[2025-11-06 16:27:02,684][322896] Fps is (10 sec: 3275.3, 60 sec: 3554.0, 300 sec: 3555.2). Total num frames: 6176768. Throughput: 0: 3534.6. Samples: 6183936. Policy #0 lag: (min: 9.0, avg: 12.0, max: 73.0)
[2025-11-06 16:27:02,684][322896] Avg episode reward: [(0, '975.478')]
[2025-11-06 16:27:07,673][322896] Fps is (10 sec: 3295.9, 60 sec: 3551.5, 300 sec: 3555.7). Total num frames: 6193152. Throughput: 0: 3527.6. Samples: 6205440. Policy #0 lag: (min: 9.0, avg: 12.0, max: 73.0)
[2025-11-06 16:27:07,674][322896] Avg episode reward: [(0, '941.654')]
[2025-11-06 16:27:12,823][322896] Fps is (10 sec: 4039.6, 60 sec: 3421.0, 300 sec: 3582.0). Total num frames: 6217728. Throughput: 0: 3522.2. Samples: 6215680. Policy #0 lag: (min: 9.0, avg: 12.0, max: 73.0)
[2025-11-06 16:27:12,823][322896] Avg episode reward: [(0, '953.082')]
[2025-11-06 16:27:17,874][322896] Fps is (10 sec: 4818.7, 60 sec: 3544.2, 300 sec: 3608.0). Total num frames: 6242304. Throughput: 0: 3524.6. Samples: 6237696. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:27:17,874][322896] Avg episode reward: [(0, '951.330')]
[2025-11-06 16:27:22,780][322896] Fps is (10 sec: 4113.8, 60 sec: 3543.9, 300 sec: 3609.4). Total num frames: 6258688. Throughput: 0: 3553.6. Samples: 6258688. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:27:22,780][322896] Avg episode reward: [(0, '988.447')]
[2025-11-06 16:27:22,903][322896] Saving new best policy, reward=988.447!
[2025-11-06 16:27:27,694][322896] Fps is (10 sec: 3336.8, 60 sec: 3553.8, 300 sec: 3585.3). Total num frames: 6275072. Throughput: 0: 3544.6. Samples: 6269440. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:27:27,694][322896] Avg episode reward: [(0, '994.193')]
[2025-11-06 16:27:27,821][322896] Saving new best policy, reward=994.193!
[2025-11-06 16:27:31,270][322896] Signal inference workers to stop experience collection... (1150 times)
[2025-11-06 16:27:31,271][322896] Signal inference workers to resume experience collection... (1150 times)
[2025-11-06 16:27:31,537][322896] InferenceWorker_p0-w0: stopping experience collection (1150 times)
[2025-11-06 16:27:31,537][322896] InferenceWorker_p0-w0: resuming experience collection (1150 times)
[2025-11-06 16:27:32,701][322896] Fps is (10 sec: 3302.9, 60 sec: 3549.6, 300 sec: 3582.4). Total num frames: 6291456. Throughput: 0: 3595.0. Samples: 6291456. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:27:32,701][322896] Avg episode reward: [(0, '974.466')]
[2025-11-06 16:27:37,729][322896] Fps is (10 sec: 3265.3, 60 sec: 3547.1, 300 sec: 3554.9). Total num frames: 6307840. Throughput: 0: 3545.9. Samples: 6311424. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:27:37,729][322896] Avg episode reward: [(0, '998.677')]
[2025-11-06 16:27:37,856][322896] Saving new best policy, reward=998.677!
[2025-11-06 16:27:42,737][322896] Fps is (10 sec: 3265.1, 60 sec: 3551.9, 300 sec: 3554.2). Total num frames: 6324224. Throughput: 0: 3606.3. Samples: 6323712. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:27:42,737][322896] Avg episode reward: [(0, '1006.089')]
[2025-11-06 16:27:42,866][322896] Saving new best policy, reward=1006.089!
[2025-11-06 16:27:47,775][322896] Fps is (10 sec: 3261.9, 60 sec: 3545.2, 300 sec: 3554.7). Total num frames: 6340608. Throughput: 0: 3554.0. Samples: 6344192. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:27:47,775][322896] Avg episode reward: [(0, '1006.219')]
[2025-11-06 16:27:47,916][322896] Saving new best policy, reward=1006.219!
[2025-11-06 16:27:52,788][322896] Fps is (10 sec: 3260.0, 60 sec: 3543.4, 300 sec: 3553.8). Total num frames: 6356992. Throughput: 0: 3540.8. Samples: 6365184. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:27:52,788][322896] Avg episode reward: [(0, '1023.366')]
[2025-11-06 16:27:52,933][322896] Saving new best policy, reward=1023.366!
[2025-11-06 16:27:57,731][322896] Fps is (10 sec: 3291.2, 60 sec: 3549.9, 300 sec: 3553.8). Total num frames: 6373376. Throughput: 0: 3534.3. Samples: 6374400. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:27:57,731][322896] Avg episode reward: [(0, '1011.899')]
[2025-11-06 16:27:57,863][322896] Saving /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_lidar_policy2_acc_yaw_sp/checkpoint_p0/checkpoint_000024896_6373376.pth...
[2025-11-06 16:27:57,866][322896] Removing /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_lidar_policy2_acc_yaw_sp/checkpoint_p0/checkpoint_000021568_5521408.pth
[2025-11-06 16:28:02,789][322896] Fps is (10 sec: 3276.4, 60 sec: 3543.6, 300 sec: 3553.2). Total num frames: 6389760. Throughput: 0: 3545.1. Samples: 6396928. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:28:02,790][322896] Avg episode reward: [(0, '1021.787')]
[2025-11-06 16:28:07,681][322896] Fps is (10 sec: 3293.4, 60 sec: 3549.4, 300 sec: 3555.7). Total num frames: 6406144. Throughput: 0: 3557.7. Samples: 6418432. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:28:07,681][322896] Avg episode reward: [(0, '1070.760')]
[2025-11-06 16:28:07,812][322896] Saving new best policy, reward=1070.760!
[2025-11-06 16:28:12,699][322896] Fps is (10 sec: 3306.9, 60 sec: 3420.4, 300 sec: 3554.2). Total num frames: 6422528. Throughput: 0: 3526.7. Samples: 6428160. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:28:12,699][322896] Avg episode reward: [(0, '1037.087')]
[2025-11-06 16:28:17,902][322896] Fps is (10 sec: 4007.1, 60 sec: 3411.7, 300 sec: 3579.9). Total num frames: 6447104. Throughput: 0: 3488.7. Samples: 6449152. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:28:17,903][322896] Avg episode reward: [(0, '1004.448')]
[2025-11-06 16:28:22,736][322896] Fps is (10 sec: 4080.8, 60 sec: 3415.8, 300 sec: 3555.9). Total num frames: 6463488. Throughput: 0: 3515.2. Samples: 6469632. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:28:22,736][322896] Avg episode reward: [(0, '971.365')]
[2025-11-06 16:28:27,682][322896] Fps is (10 sec: 4188.3, 60 sec: 3550.6, 300 sec: 3555.5). Total num frames: 6488064. Throughput: 0: 3463.1. Samples: 6479360. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:28:27,682][322896] Avg episode reward: [(0, '1003.545')]
[2025-11-06 16:28:32,702][322896] Fps is (10 sec: 4109.9, 60 sec: 3549.8, 300 sec: 3555.2). Total num frames: 6504448. Throughput: 0: 3498.6. Samples: 6501376. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:28:32,702][322896] Avg episode reward: [(0, '1027.870')]
[2025-11-06 16:28:37,697][322896] Fps is (10 sec: 3271.9, 60 sec: 3551.8, 300 sec: 3555.3). Total num frames: 6520832. Throughput: 0: 3488.7. Samples: 6521856. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:28:37,697][322896] Avg episode reward: [(0, '1012.156')]
[2025-11-06 16:28:42,716][322896] Fps is (10 sec: 3272.1, 60 sec: 3551.1, 300 sec: 3554.8). Total num frames: 6537216. Throughput: 0: 3528.3. Samples: 6533120. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:28:42,717][322896] Avg episode reward: [(0, '989.866')]
[2025-11-06 16:28:47,736][322896] Fps is (10 sec: 3263.9, 60 sec: 3552.1, 300 sec: 3554.6). Total num frames: 6553600. Throughput: 0: 3508.5. Samples: 6554624. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:28:47,737][322896] Avg episode reward: [(0, '976.032')]
[2025-11-06 16:28:50,152][322896] Signal inference workers to stop experience collection... (1200 times)
[2025-11-06 16:28:50,512][322896] InferenceWorker_p0-w0: stopping experience collection (1200 times)
[2025-11-06 16:28:50,514][322896] Signal inference workers to resume experience collection... (1200 times)
[2025-11-06 16:28:50,632][322896] InferenceWorker_p0-w0: resuming experience collection (1200 times)
[2025-11-06 16:28:52,813][322896] Fps is (10 sec: 3245.3, 60 sec: 3548.4, 300 sec: 3554.2). Total num frames: 6569984. Throughput: 0: 3460.0. Samples: 6574592. Policy #0 lag: (min: 0.0, avg: 3.0, max: 64.0)
[2025-11-06 16:28:52,814][322896] Avg episode reward: [(0, '1030.533')]
[2025-11-06 16:28:57,771][322896] Fps is (10 sec: 3265.4, 60 sec: 3547.5, 300 sec: 3554.6). Total num frames: 6586368. Throughput: 0: 3498.7. Samples: 6585856. Policy #0 lag: (min: 0.0, avg: 3.0, max: 64.0)
[2025-11-06 16:28:57,772][322896] Avg episode reward: [(0, '961.028')]
[2025-11-06 16:29:02,748][322896] Fps is (10 sec: 3298.4, 60 sec: 3552.3, 300 sec: 3553.9). Total num frames: 6602752. Throughput: 0: 3516.4. Samples: 6606848. Policy #0 lag: (min: 0.0, avg: 3.0, max: 64.0)
[2025-11-06 16:29:02,748][322896] Avg episode reward: [(0, '958.742')]
[2025-11-06 16:29:07,750][322896] Fps is (10 sec: 3283.8, 60 sec: 3545.8, 300 sec: 3553.8). Total num frames: 6619136. Throughput: 0: 3537.4. Samples: 6628864. Policy #0 lag: (min: 0.0, avg: 3.0, max: 64.0)
[2025-11-06 16:29:07,750][322896] Avg episode reward: [(0, '957.320')]
[2025-11-06 16:29:12,702][322896] Fps is (10 sec: 3291.9, 60 sec: 3549.7, 300 sec: 3526.7). Total num frames: 6635520. Throughput: 0: 3548.3. Samples: 6639104. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:29:12,702][322896] Avg episode reward: [(0, '1038.862')]
[2025-11-06 16:29:17,752][322896] Fps is (10 sec: 4095.1, 60 sec: 3558.8, 300 sec: 3527.3). Total num frames: 6660096. Throughput: 0: 3568.6. Samples: 6662144. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:29:17,753][322896] Avg episode reward: [(0, '991.833')]
[2025-11-06 16:29:22,800][322896] Fps is (10 sec: 4867.5, 60 sec: 3682.5, 300 sec: 3553.6). Total num frames: 6684672. Throughput: 0: 3609.9. Samples: 6684672. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:29:22,800][322896] Avg episode reward: [(0, '1011.498')]
[2025-11-06 16:29:27,780][322896] Fps is (10 sec: 4084.6, 60 sec: 3544.1, 300 sec: 3554.0). Total num frames: 6701056. Throughput: 0: 3590.3. Samples: 6694912. Policy #0 lag: (min: 10.0, avg: 13.0, max: 74.0)
[2025-11-06 16:29:27,780][322896] Avg episode reward: [(0, '988.485')]
[2025-11-06 16:29:32,699][322896] Fps is (10 sec: 3310.3, 60 sec: 3550.1, 300 sec: 3554.7). Total num frames: 6717440. Throughput: 0: 3609.8. Samples: 6716928. Policy #0 lag: (min: 10.0, avg: 13.0, max: 74.0)
[2025-11-06 16:29:32,699][322896] Avg episode reward: [(0, '1006.323')]
[2025-11-06 16:29:37,673][322896] Fps is (10 sec: 3312.2, 60 sec: 3551.3, 300 sec: 3555.9). Total num frames: 6733824. Throughput: 0: 3640.8. Samples: 6737920. Policy #0 lag: (min: 10.0, avg: 13.0, max: 74.0)
[2025-11-06 16:29:37,674][322896] Avg episode reward: [(0, '983.901')]
[2025-11-06 16:29:42,701][322896] Fps is (10 sec: 3275.9, 60 sec: 3550.8, 300 sec: 3554.8). Total num frames: 6750208. Throughput: 0: 3646.6. Samples: 6749696. Policy #0 lag: (min: 10.0, avg: 13.0, max: 74.0)
[2025-11-06 16:29:42,702][322896] Avg episode reward: [(0, '963.306')]
[2025-11-06 16:29:47,740][322896] Fps is (10 sec: 3255.0, 60 sec: 3549.6, 300 sec: 3554.7). Total num frames: 6766592. Throughput: 0: 3641.5. Samples: 6770688. Policy #0 lag: (min: 6.0, avg: 9.0, max: 70.0)
[2025-11-06 16:29:47,741][322896] Avg episode reward: [(0, '949.377')]
[2025-11-06 16:29:52,769][322896] Fps is (10 sec: 3254.7, 60 sec: 3552.5, 300 sec: 3554.2). Total num frames: 6782976. Throughput: 0: 3662.1. Samples: 6793728. Policy #0 lag: (min: 6.0, avg: 9.0, max: 70.0)
[2025-11-06 16:29:52,770][322896] Avg episode reward: [(0, '968.517')]
[2025-11-06 16:29:58,017][322896] Fps is (10 sec: 3985.6, 60 sec: 3671.4, 300 sec: 3554.6). Total num frames: 6807552. Throughput: 0: 3649.5. Samples: 6804480. Policy #0 lag: (min: 6.0, avg: 9.0, max: 70.0)
[2025-11-06 16:29:58,018][322896] Avg episode reward: [(0, '1030.201')]
[2025-11-06 16:29:58,366][322896] Saving /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_lidar_policy2_acc_yaw_sp/checkpoint_p0/checkpoint_000026624_6815744.pth...
[2025-11-06 16:29:58,370][322896] Removing /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_lidar_policy2_acc_yaw_sp/checkpoint_p0/checkpoint_000023232_5947392.pth
[2025-11-06 16:30:02,433][322896] Signal inference workers to stop experience collection... (1250 times)
[2025-11-06 16:30:02,785][322896] InferenceWorker_p0-w0: stopping experience collection (1250 times)
[2025-11-06 16:30:02,786][322896] Signal inference workers to resume experience collection... (1250 times)
[2025-11-06 16:30:02,786][322896] Fps is (10 sec: 4907.1, 60 sec: 3820.5, 300 sec: 3556.3). Total num frames: 6832128. Throughput: 0: 3660.9. Samples: 6827008. Policy #0 lag: (min: 11.0, avg: 14.0, max: 75.0)
[2025-11-06 16:30:02,786][322896] Avg episode reward: [(0, '1045.390')]
[2025-11-06 16:30:02,786][322896] InferenceWorker_p0-w0: resuming experience collection (1250 times)
[2025-11-06 16:30:07,764][322896] Fps is (10 sec: 4202.5, 60 sec: 3822.0, 300 sec: 3554.1). Total num frames: 6848512. Throughput: 0: 3666.6. Samples: 6849536. Policy #0 lag: (min: 11.0, avg: 14.0, max: 75.0)
[2025-11-06 16:30:07,764][322896] Avg episode reward: [(0, '1049.423')]
[2025-11-06 16:30:12,742][322896] Fps is (10 sec: 3291.4, 60 sec: 3820.4, 300 sec: 3553.8). Total num frames: 6864896. Throughput: 0: 3678.2. Samples: 6860288. Policy #0 lag: (min: 11.0, avg: 14.0, max: 75.0)
[2025-11-06 16:30:12,742][322896] Avg episode reward: [(0, '1022.398')]
[2025-11-06 16:30:17,728][322896] Fps is (10 sec: 3288.6, 60 sec: 3687.9, 300 sec: 3554.6). Total num frames: 6881280. Throughput: 0: 3672.6. Samples: 6882304. Policy #0 lag: (min: 11.0, avg: 14.0, max: 75.0)
[2025-11-06 16:30:17,728][322896] Avg episode reward: [(0, '1041.161')]
[2025-11-06 16:30:22,767][322896] Fps is (10 sec: 3268.6, 60 sec: 3551.9, 300 sec: 3554.6). Total num frames: 6897664. Throughput: 0: 3656.1. Samples: 6902784. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:30:22,767][322896] Avg episode reward: [(0, '1025.669')]
[2025-11-06 16:30:27,714][322896] Fps is (10 sec: 3281.2, 60 sec: 3553.8, 300 sec: 3554.3). Total num frames: 6914048. Throughput: 0: 3662.6. Samples: 6914560. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:30:27,715][322896] Avg episode reward: [(0, '1057.268')]
[2025-11-06 16:30:32,697][322896] Fps is (10 sec: 3299.9, 60 sec: 3550.0, 300 sec: 3554.8). Total num frames: 6930432. Throughput: 0: 3633.0. Samples: 6934016. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:30:32,697][322896] Avg episode reward: [(0, '1051.248')]
[2025-11-06 16:30:37,740][322896] Fps is (10 sec: 3268.6, 60 sec: 3546.0, 300 sec: 3554.5). Total num frames: 6946816. Throughput: 0: 3631.9. Samples: 6957056. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:30:37,740][322896] Avg episode reward: [(0, '1102.521')]
[2025-11-06 16:30:37,867][322896] Saving new best policy, reward=1102.521!
[2025-11-06 16:30:42,709][322896] Fps is (10 sec: 3272.9, 60 sec: 3549.4, 300 sec: 3554.8). Total num frames: 6963200. Throughput: 0: 3643.1. Samples: 6967296. Policy #0 lag: (min: 0.0, avg: 3.0, max: 64.0)
[2025-11-06 16:30:42,709][322896] Avg episode reward: [(0, '1082.380')]
[2025-11-06 16:30:47,985][322896] Fps is (10 sec: 4797.4, 60 sec: 3807.4, 300 sec: 3606.4). Total num frames: 6995968. Throughput: 0: 3613.5. Samples: 6990336. Policy #0 lag: (min: 0.0, avg: 3.0, max: 64.0)
[2025-11-06 16:30:47,985][322896] Avg episode reward: [(0, '1056.354')]
[2025-11-06 16:30:52,790][322896] Fps is (10 sec: 4875.3, 60 sec: 3821.6, 300 sec: 3609.2). Total num frames: 7012352. Throughput: 0: 3627.4. Samples: 7012864. Policy #0 lag: (min: 0.0, avg: 3.0, max: 64.0)
[2025-11-06 16:30:52,791][322896] Avg episode reward: [(0, '1019.151')]
[2025-11-06 16:30:57,737][322896] Fps is (10 sec: 3360.1, 60 sec: 3703.7, 300 sec: 3610.2). Total num frames: 7028736. Throughput: 0: 3595.7. Samples: 7022080. Policy #0 lag: (min: 11.0, avg: 14.0, max: 75.0)
[2025-11-06 16:30:57,738][322896] Avg episode reward: [(0, '983.265')]
[2025-11-06 16:31:02,758][322896] Fps is (10 sec: 3287.3, 60 sec: 3551.5, 300 sec: 3609.3). Total num frames: 7045120. Throughput: 0: 3604.3. Samples: 7044608. Policy #0 lag: (min: 11.0, avg: 14.0, max: 75.0)
[2025-11-06 16:31:02,758][322896] Avg episode reward: [(0, '986.679')]
[2025-11-06 16:31:07,782][322896] Fps is (10 sec: 3262.3, 60 sec: 3548.8, 300 sec: 3556.6). Total num frames: 7061504. Throughput: 0: 3605.5. Samples: 7065088. Policy #0 lag: (min: 11.0, avg: 14.0, max: 75.0)
[2025-11-06 16:31:07,782][322896] Avg episode reward: [(0, '950.321')]
[2025-11-06 16:31:12,732][322896] Fps is (10 sec: 3285.5, 60 sec: 3550.5, 300 sec: 3555.1). Total num frames: 7077888. Throughput: 0: 3594.0. Samples: 7076352. Policy #0 lag: (min: 11.0, avg: 14.0, max: 75.0)
[2025-11-06 16:31:12,732][322896] Avg episode reward: [(0, '1001.530')]
[2025-11-06 16:31:17,717][322896] Fps is (10 sec: 3298.2, 60 sec: 3550.5, 300 sec: 3554.0). Total num frames: 7094272. Throughput: 0: 3605.1. Samples: 7096320. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:31:17,717][322896] Avg episode reward: [(0, '1051.083')]
[2025-11-06 16:31:19,904][322896] Signal inference workers to stop experience collection... (1300 times)
[2025-11-06 16:31:19,904][322896] Signal inference workers to resume experience collection... (1300 times)
[2025-11-06 16:31:20,164][322896] InferenceWorker_p0-w0: stopping experience collection (1300 times)
[2025-11-06 16:31:20,164][322896] InferenceWorker_p0-w0: resuming experience collection (1300 times)
[2025-11-06 16:31:22,783][322896] Fps is (10 sec: 3259.9, 60 sec: 3548.9, 300 sec: 3554.2). Total num frames: 7110656. Throughput: 0: 3569.1. Samples: 7117824. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:31:22,784][322896] Avg episode reward: [(0, '1038.883')]
[2025-11-06 16:31:27,737][322896] Fps is (10 sec: 3270.2, 60 sec: 3548.5, 300 sec: 3554.0). Total num frames: 7127040. Throughput: 0: 3570.4. Samples: 7128064. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:31:27,737][322896] Avg episode reward: [(0, '1037.005')]
[2025-11-06 16:31:32,691][322896] Fps is (10 sec: 3307.4, 60 sec: 3550.2, 300 sec: 3554.4). Total num frames: 7143424. Throughput: 0: 3550.3. Samples: 7149056. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:31:32,691][322896] Avg episode reward: [(0, '1054.149')]
[2025-11-06 16:31:37,752][322896] Fps is (10 sec: 3272.0, 60 sec: 3549.2, 300 sec: 3554.7). Total num frames: 7159808. Throughput: 0: 3518.8. Samples: 7171072. Policy #0 lag: (min: 1.0, avg: 4.0, max: 65.0)
[2025-11-06 16:31:37,752][322896] Avg episode reward: [(0, '1074.498')]
[2025-11-06 16:31:42,973][322896] Fps is (10 sec: 3983.7, 60 sec: 3670.2, 300 sec: 3578.9). Total num frames: 7184384. Throughput: 0: 3520.1. Samples: 7181312. Policy #0 lag: (min: 1.0, avg: 4.0, max: 65.0)
[2025-11-06 16:31:42,973][322896] Avg episode reward: [(0, '1088.330')]
[2025-11-06 16:31:47,937][322896] Fps is (10 sec: 4825.8, 60 sec: 3552.7, 300 sec: 3606.9). Total num frames: 7208960. Throughput: 0: 3524.5. Samples: 7203840. Policy #0 lag: (min: 1.0, avg: 4.0, max: 65.0)
[2025-11-06 16:31:47,937][322896] Avg episode reward: [(0, '1043.449')]
[2025-11-06 16:31:52,788][322896] Fps is (10 sec: 4173.3, 60 sec: 3550.0, 300 sec: 3609.3). Total num frames: 7225344. Throughput: 0: 3560.8. Samples: 7225344. Policy #0 lag: (min: 31.0, avg: 34.0, max: 95.0)
[2025-11-06 16:31:52,788][322896] Avg episode reward: [(0, '1047.054')]
[2025-11-06 16:31:57,738][322896] Fps is (10 sec: 3343.4, 60 sec: 3549.8, 300 sec: 3609.4). Total num frames: 7241728. Throughput: 0: 3538.0. Samples: 7235584. Policy #0 lag: (min: 31.0, avg: 34.0, max: 95.0)
[2025-11-06 16:31:57,738][322896] Avg episode reward: [(0, '1042.633')]
[2025-11-06 16:31:57,873][322896] Saving /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_lidar_policy2_acc_yaw_sp/checkpoint_p0/checkpoint_000028288_7241728.pth...
[2025-11-06 16:31:57,877][322896] Removing /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_lidar_policy2_acc_yaw_sp/checkpoint_p0/checkpoint_000024896_6373376.pth
[2025-11-06 16:32:02,751][322896] Fps is (10 sec: 3288.7, 60 sec: 3550.3, 300 sec: 3609.1). Total num frames: 7258112. Throughput: 0: 3581.2. Samples: 7257600. Policy #0 lag: (min: 31.0, avg: 34.0, max: 95.0)
[2025-11-06 16:32:02,752][322896] Avg episode reward: [(0, '1099.603')]
[2025-11-06 16:32:07,674][322896] Fps is (10 sec: 3297.9, 60 sec: 3556.3, 300 sec: 3584.1). Total num frames: 7274496. Throughput: 0: 3592.8. Samples: 7279104. Policy #0 lag: (min: 31.0, avg: 34.0, max: 95.0)
[2025-11-06 16:32:07,674][322896] Avg episode reward: [(0, '1090.287')]
[2025-11-06 16:32:12,719][322896] Fps is (10 sec: 3287.5, 60 sec: 3550.6, 300 sec: 3556.4). Total num frames: 7290880. Throughput: 0: 3619.6. Samples: 7290880. Policy #0 lag: (min: 31.0, avg: 34.0, max: 95.0)
[2025-11-06 16:32:12,719][322896] Avg episode reward: [(0, '1126.764')]
[2025-11-06 16:32:12,844][322896] Saving new best policy, reward=1126.764!
[2025-11-06 16:32:17,696][322896] Fps is (10 sec: 3269.5, 60 sec: 3551.1, 300 sec: 3555.5). Total num frames: 7307264. Throughput: 0: 3606.4. Samples: 7311360. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:32:17,696][322896] Avg episode reward: [(0, '1099.075')]
[2025-11-06 16:32:22,769][322896] Fps is (10 sec: 3260.4, 60 sec: 3550.7, 300 sec: 3553.6). Total num frames: 7323648. Throughput: 0: 3628.1. Samples: 7334400. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:32:22,769][322896] Avg episode reward: [(0, '1098.724')]
[2025-11-06 16:32:27,782][322896] Fps is (10 sec: 3248.8, 60 sec: 3547.2, 300 sec: 3553.5). Total num frames: 7340032. Throughput: 0: 3645.0. Samples: 7344640. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:32:27,782][322896] Avg episode reward: [(0, '1134.085')]
[2025-11-06 16:32:28,144][322896] Saving new best policy, reward=1134.085!
[2025-11-06 16:32:32,949][322896] Fps is (10 sec: 4828.6, 60 sec: 3806.6, 300 sec: 3607.3). Total num frames: 7372800. Throughput: 0: 3628.6. Samples: 7367168. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:32:32,949][322896] Avg episode reward: [(0, '1097.130')]
[2025-11-06 16:32:36,743][322896] Signal inference workers to stop experience collection... (1350 times)
[2025-11-06 16:32:37,096][322896] InferenceWorker_p0-w0: stopping experience collection (1350 times)
[2025-11-06 16:32:37,097][322896] Signal inference workers to resume experience collection... (1350 times)
[2025-11-06 16:32:37,215][322896] InferenceWorker_p0-w0: resuming experience collection (1350 times)
[2025-11-06 16:32:37,679][322896] Fps is (10 sec: 4966.4, 60 sec: 3827.6, 300 sec: 3610.7). Total num frames: 7389184. Throughput: 0: 3661.1. Samples: 7389696. Policy #0 lag: (min: 0.0, avg: 3.0, max: 64.0)
[2025-11-06 16:32:37,679][322896] Avg episode reward: [(0, '1035.346')]
[2025-11-06 16:32:42,793][322896] Fps is (10 sec: 3328.6, 60 sec: 3697.5, 300 sec: 3609.8). Total num frames: 7405568. Throughput: 0: 3647.8. Samples: 7399936. Policy #0 lag: (min: 0.0, avg: 3.0, max: 64.0)
[2025-11-06 16:32:42,793][322896] Avg episode reward: [(0, '1037.976')]
[2025-11-06 16:32:47,764][322896] Fps is (10 sec: 3249.2, 60 sec: 3560.1, 300 sec: 3610.3). Total num frames: 7421952. Throughput: 0: 3674.0. Samples: 7422976. Policy #0 lag: (min: 0.0, avg: 3.0, max: 64.0)
[2025-11-06 16:32:47,764][322896] Avg episode reward: [(0, '1059.399')]
[2025-11-06 16:32:52,709][322896] Fps is (10 sec: 3304.6, 60 sec: 3554.5, 300 sec: 3610.3). Total num frames: 7438336. Throughput: 0: 3649.4. Samples: 7443456. Policy #0 lag: (min: 0.0, avg: 3.0, max: 64.0)
[2025-11-06 16:32:52,709][322896] Avg episode reward: [(0, '1069.532')]
[2025-11-06 16:32:57,793][322896] Fps is (10 sec: 3267.3, 60 sec: 3546.6, 300 sec: 3610.0). Total num frames: 7454720. Throughput: 0: 3646.3. Samples: 7455232. Policy #0 lag: (min: 0.0, avg: 3.0, max: 64.0)
[2025-11-06 16:32:57,793][322896] Avg episode reward: [(0, '1087.456')]
[2025-11-06 16:33:02,687][322896] Fps is (10 sec: 3284.2, 60 sec: 3553.7, 300 sec: 3610.0). Total num frames: 7471104. Throughput: 0: 3653.0. Samples: 7475712. Policy #0 lag: (min: 4.0, avg: 7.0, max: 68.0)
[2025-11-06 16:33:02,687][322896] Avg episode reward: [(0, '1067.184')]
[2025-11-06 16:33:07,720][322896] Fps is (10 sec: 3300.9, 60 sec: 3547.1, 300 sec: 3609.8). Total num frames: 7487488. Throughput: 0: 3633.5. Samples: 7497728. Policy #0 lag: (min: 4.0, avg: 7.0, max: 68.0)
[2025-11-06 16:33:07,720][322896] Avg episode reward: [(0, '1079.755')]
[2025-11-06 16:33:12,702][322896] Fps is (10 sec: 3271.8, 60 sec: 3550.9, 300 sec: 3584.7). Total num frames: 7503872. Throughput: 0: 3636.0. Samples: 7507968. Policy #0 lag: (min: 4.0, avg: 7.0, max: 68.0)
[2025-11-06 16:33:12,702][322896] Avg episode reward: [(0, '1103.302')]
[2025-11-06 16:33:17,806][322896] Fps is (10 sec: 4061.0, 60 sec: 3679.6, 300 sec: 3609.2). Total num frames: 7528448. Throughput: 0: 3641.0. Samples: 7530496. Policy #0 lag: (min: 4.0, avg: 7.0, max: 68.0)
[2025-11-06 16:33:17,806][322896] Avg episode reward: [(0, '1121.264')]
[2025-11-06 16:33:22,704][322896] Fps is (10 sec: 4914.3, 60 sec: 3827.1, 300 sec: 3609.8). Total num frames: 7553024. Throughput: 0: 3627.5. Samples: 7553024. Policy #0 lag: (min: 5.0, avg: 8.0, max: 69.0)
[2025-11-06 16:33:22,704][322896] Avg episode reward: [(0, '1169.184')]
[2025-11-06 16:33:22,834][322896] Saving new best policy, reward=1169.184!
[2025-11-06 16:33:27,720][322896] Fps is (10 sec: 4131.5, 60 sec: 3826.9, 300 sec: 3609.8). Total num frames: 7569408. Throughput: 0: 3635.4. Samples: 7563264. Policy #0 lag: (min: 5.0, avg: 8.0, max: 69.0)
[2025-11-06 16:33:27,721][322896] Avg episode reward: [(0, '1199.209')]
[2025-11-06 16:33:27,855][322896] Saving new best policy, reward=1199.209!
[2025-11-06 16:33:32,710][322896] Fps is (10 sec: 3274.7, 60 sec: 3564.0, 300 sec: 3609.9). Total num frames: 7585792. Throughput: 0: 3622.5. Samples: 7585792. Policy #0 lag: (min: 5.0, avg: 8.0, max: 69.0)
[2025-11-06 16:33:32,710][322896] Avg episode reward: [(0, '1167.586')]
[2025-11-06 16:33:37,715][322896] Fps is (10 sec: 3278.7, 60 sec: 3547.8, 300 sec: 3610.1). Total num frames: 7602176. Throughput: 0: 3617.7. Samples: 7606272. Policy #0 lag: (min: 5.0, avg: 8.0, max: 69.0)
[2025-11-06 16:33:37,715][322896] Avg episode reward: [(0, '1121.267')]
[2025-11-06 16:33:42,739][322896] Fps is (10 sec: 3267.3, 60 sec: 3553.1, 300 sec: 3610.0). Total num frames: 7618560. Throughput: 0: 3633.8. Samples: 7618560. Policy #0 lag: (min: 5.0, avg: 8.0, max: 69.0)
[2025-11-06 16:33:42,740][322896] Avg episode reward: [(0, '1125.837')]
[2025-11-06 16:33:47,754][322896] Fps is (10 sec: 3263.9, 60 sec: 3550.5, 300 sec: 3610.8). Total num frames: 7634944. Throughput: 0: 3635.5. Samples: 7639552. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:33:47,754][322896] Avg episode reward: [(0, '1181.609')]
[2025-11-06 16:33:49,194][322896] Signal inference workers to stop experience collection... (1400 times)
[2025-11-06 16:33:49,529][322896] InferenceWorker_p0-w0: stopping experience collection (1400 times)
[2025-11-06 16:33:49,529][322896] Signal inference workers to resume experience collection... (1400 times)
[2025-11-06 16:33:49,529][322896] InferenceWorker_p0-w0: resuming experience collection (1400 times)
[2025-11-06 16:33:52,692][322896] Fps is (10 sec: 3292.3, 60 sec: 3550.9, 300 sec: 3611.0). Total num frames: 7651328. Throughput: 0: 3643.1. Samples: 7661568. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:33:52,692][322896] Avg episode reward: [(0, '1188.771')]
[2025-11-06 16:33:57,746][322896] Fps is (10 sec: 3279.4, 60 sec: 3552.6, 300 sec: 3610.1). Total num frames: 7667712. Throughput: 0: 3626.0. Samples: 7671296. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:33:57,746][322896] Avg episode reward: [(0, '1119.991')]
[2025-11-06 16:33:57,872][322896] Saving /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_lidar_policy2_acc_yaw_sp/checkpoint_p0/checkpoint_000029952_7667712.pth...
[2025-11-06 16:33:57,877][322896] Removing /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_lidar_policy2_acc_yaw_sp/checkpoint_p0/checkpoint_000026624_6815744.pth
[2025-11-06 16:34:02,796][322896] Fps is (10 sec: 4054.1, 60 sec: 3679.7, 300 sec: 3637.2). Total num frames: 7692288. Throughput: 0: 3630.4. Samples: 7693824. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:34:02,796][322896] Avg episode reward: [(0, '1119.511')]
[2025-11-06 16:34:07,697][322896] Fps is (10 sec: 4939.5, 60 sec: 3824.4, 300 sec: 3665.6). Total num frames: 7716864. Throughput: 0: 3641.5. Samples: 7716864. Policy #0 lag: (min: 5.0, avg: 8.0, max: 69.0)
[2025-11-06 16:34:07,697][322896] Avg episode reward: [(0, '1146.417')]
[2025-11-06 16:34:12,749][322896] Fps is (10 sec: 4115.1, 60 sec: 3819.9, 300 sec: 3637.8). Total num frames: 7733248. Throughput: 0: 3638.6. Samples: 7727104. Policy #0 lag: (min: 5.0, avg: 8.0, max: 69.0)
[2025-11-06 16:34:12,749][322896] Avg episode reward: [(0, '1093.195')]
[2025-11-06 16:34:17,763][322896] Fps is (10 sec: 3255.2, 60 sec: 3689.0, 300 sec: 3610.5). Total num frames: 7749632. Throughput: 0: 3636.6. Samples: 7749632. Policy #0 lag: (min: 5.0, avg: 8.0, max: 69.0)
[2025-11-06 16:34:17,763][322896] Avg episode reward: [(0, '1178.661')]
[2025-11-06 16:34:22,740][322896] Fps is (10 sec: 3279.8, 60 sec: 3547.7, 300 sec: 3610.5). Total num frames: 7766016. Throughput: 0: 3638.8. Samples: 7770112. Policy #0 lag: (min: 5.0, avg: 8.0, max: 69.0)
[2025-11-06 16:34:22,740][322896] Avg episode reward: [(0, '1179.324')]
[2025-11-06 16:34:27,723][322896] Fps is (10 sec: 3290.2, 60 sec: 3549.7, 300 sec: 3609.7). Total num frames: 7782400. Throughput: 0: 3642.2. Samples: 7782400. Policy #0 lag: (min: 5.0, avg: 8.0, max: 69.0)
[2025-11-06 16:34:27,723][322896] Avg episode reward: [(0, '1135.430')]
[2025-11-06 16:34:32,758][322896] Fps is (10 sec: 3270.8, 60 sec: 3547.0, 300 sec: 3609.0). Total num frames: 7798784. Throughput: 0: 3640.5. Samples: 7803392. Policy #0 lag: (min: 9.0, avg: 12.0, max: 73.0)
[2025-11-06 16:34:32,759][322896] Avg episode reward: [(0, '1144.310')]
[2025-11-06 16:34:37,720][322896] Fps is (10 sec: 3277.5, 60 sec: 3549.5, 300 sec: 3609.8). Total num frames: 7815168. Throughput: 0: 3650.0. Samples: 7825920. Policy #0 lag: (min: 9.0, avg: 12.0, max: 73.0)
[2025-11-06 16:34:37,721][322896] Avg episode reward: [(0, '1141.063')]
[2025-11-06 16:34:42,991][322896] Fps is (10 sec: 4002.8, 60 sec: 3671.0, 300 sec: 3634.7). Total num frames: 7839744. Throughput: 0: 3655.1. Samples: 7836672. Policy #0 lag: (min: 9.0, avg: 12.0, max: 73.0)
[2025-11-06 16:34:42,991][322896] Avg episode reward: [(0, '1221.054')]
[2025-11-06 16:34:43,336][322896] Saving new best policy, reward=1221.054!
[2025-11-06 16:34:47,901][322896] Fps is (10 sec: 4828.3, 60 sec: 3813.6, 300 sec: 3663.9). Total num frames: 7864320. Throughput: 0: 3666.5. Samples: 7859200. Policy #0 lag: (min: 9.0, avg: 12.0, max: 73.0)
[2025-11-06 16:34:47,901][322896] Avg episode reward: [(0, '1248.837')]
[2025-11-06 16:34:47,902][322896] Saving new best policy, reward=1248.837!
[2025-11-06 16:34:52,733][322896] Fps is (10 sec: 4204.6, 60 sec: 3820.3, 300 sec: 3641.3). Total num frames: 7880704. Throughput: 0: 3660.7. Samples: 7881728. Policy #0 lag: (min: 14.0, avg: 17.0, max: 78.0)
[2025-11-06 16:34:52,733][322896] Avg episode reward: [(0, '1245.689')]
[2025-11-06 16:34:57,706][322896] Fps is (10 sec: 3342.0, 60 sec: 3825.5, 300 sec: 3611.0). Total num frames: 7897088. Throughput: 0: 3667.2. Samples: 7891968. Policy #0 lag: (min: 14.0, avg: 17.0, max: 78.0)
[2025-11-06 16:34:57,706][322896] Avg episode reward: [(0, '1160.955')]
[2025-11-06 16:35:02,689][322896] Fps is (10 sec: 3291.4, 60 sec: 3693.0, 300 sec: 3611.0). Total num frames: 7913472. Throughput: 0: 3669.7. Samples: 7914496. Policy #0 lag: (min: 14.0, avg: 17.0, max: 78.0)
[2025-11-06 16:35:02,689][322896] Avg episode reward: [(0, '1152.885')]
[2025-11-06 16:35:05,435][322896] Signal inference workers to stop experience collection... (1450 times)
[2025-11-06 16:35:05,435][322896] Signal inference workers to resume experience collection... (1450 times)
[2025-11-06 16:35:05,669][322896] InferenceWorker_p0-w0: stopping experience collection (1450 times)
[2025-11-06 16:35:05,669][322896] InferenceWorker_p0-w0: resuming experience collection (1450 times)
[2025-11-06 16:35:07,686][322896] Fps is (10 sec: 3283.2, 60 sec: 3550.5, 300 sec: 3610.7). Total num frames: 7929856. Throughput: 0: 3679.4. Samples: 7935488. Policy #0 lag: (min: 14.0, avg: 17.0, max: 78.0)
[2025-11-06 16:35:07,686][322896] Avg episode reward: [(0, '1168.415')]
[2025-11-06 16:35:12,787][322896] Fps is (10 sec: 3244.8, 60 sec: 3547.6, 300 sec: 3609.3). Total num frames: 7946240. Throughput: 0: 3647.0. Samples: 7946752. Policy #0 lag: (min: 14.0, avg: 17.0, max: 78.0)
[2025-11-06 16:35:12,787][322896] Avg episode reward: [(0, '1167.221')]
[2025-11-06 16:35:17,811][322896] Fps is (10 sec: 3236.4, 60 sec: 3547.1, 300 sec: 3609.5). Total num frames: 7962624. Throughput: 0: 3625.3. Samples: 7966720. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:35:17,811][322896] Avg episode reward: [(0, '1166.883')]
[2025-11-06 16:35:22,682][322896] Fps is (10 sec: 3311.8, 60 sec: 3553.3, 300 sec: 3610.4). Total num frames: 7979008. Throughput: 0: 3598.5. Samples: 7987712. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:35:22,682][322896] Avg episode reward: [(0, '1179.988')]
[2025-11-06 16:35:27,779][322896] Fps is (10 sec: 3287.3, 60 sec: 3546.5, 300 sec: 3609.0). Total num frames: 7995392. Throughput: 0: 3589.6. Samples: 7997440. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:35:27,779][322896] Avg episode reward: [(0, '1136.223')]
[2025-11-06 16:35:32,787][322896] Fps is (10 sec: 3242.7, 60 sec: 3548.2, 300 sec: 3609.5). Total num frames: 8011776. Throughput: 0: 3581.7. Samples: 8019968. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:35:32,787][322896] Avg episode reward: [(0, '1164.357')]
[2025-11-06 16:35:37,951][322896] Fps is (10 sec: 4026.8, 60 sec: 3672.3, 300 sec: 3634.8). Total num frames: 8036352. Throughput: 0: 3544.1. Samples: 8041984. Policy #0 lag: (min: 5.0, avg: 8.0, max: 69.0)
[2025-11-06 16:35:37,951][322896] Avg episode reward: [(0, '1198.717')]
[2025-11-06 16:35:42,714][322896] Fps is (10 sec: 4951.1, 60 sec: 3703.5, 300 sec: 3613.4). Total num frames: 8060928. Throughput: 0: 3560.6. Samples: 8052224. Policy #0 lag: (min: 5.0, avg: 8.0, max: 69.0)
[2025-11-06 16:35:42,714][322896] Avg episode reward: [(0, '1203.951')]
[2025-11-06 16:35:47,758][322896] Fps is (10 sec: 4176.2, 60 sec: 3558.3, 300 sec: 3610.4). Total num frames: 8077312. Throughput: 0: 3555.7. Samples: 8074752. Policy #0 lag: (min: 5.0, avg: 8.0, max: 69.0)
[2025-11-06 16:35:47,759][322896] Avg episode reward: [(0, '1206.843')]
[2025-11-06 16:35:52,674][322896] Fps is (10 sec: 3289.9, 60 sec: 3553.3, 300 sec: 3610.8). Total num frames: 8093696. Throughput: 0: 3562.2. Samples: 8095744. Policy #0 lag: (min: 5.0, avg: 8.0, max: 69.0)
[2025-11-06 16:35:52,675][322896] Avg episode reward: [(0, '1188.985')]
[2025-11-06 16:35:57,753][322896] Fps is (10 sec: 3278.6, 60 sec: 3547.1, 300 sec: 3610.1). Total num frames: 8110080. Throughput: 0: 3575.3. Samples: 8107520. Policy #0 lag: (min: 5.0, avg: 8.0, max: 69.0)
[2025-11-06 16:35:57,753][322896] Avg episode reward: [(0, '1249.594')]
[2025-11-06 16:35:57,888][322896] Saving /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_lidar_policy2_acc_yaw_sp/checkpoint_p0/checkpoint_000031680_8110080.pth...
[2025-11-06 16:35:57,891][322896] Removing /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_lidar_policy2_acc_yaw_sp/checkpoint_p0/checkpoint_000028288_7241728.pth
[2025-11-06 16:35:57,892][322896] Saving new best policy, reward=1249.594!
[2025-11-06 16:36:02,783][322896] Fps is (10 sec: 3241.5, 60 sec: 3544.3, 300 sec: 3610.0). Total num frames: 8126464. Throughput: 0: 3597.6. Samples: 8128512. Policy #0 lag: (min: 3.0, avg: 6.0, max: 67.0)
[2025-11-06 16:36:02,784][322896] Avg episode reward: [(0, '1227.087')]
[2025-11-06 16:36:07,705][322896] Fps is (10 sec: 3292.7, 60 sec: 3548.8, 300 sec: 3610.4). Total num frames: 8142848. Throughput: 0: 3604.9. Samples: 8150016. Policy #0 lag: (min: 3.0, avg: 6.0, max: 67.0)
[2025-11-06 16:36:07,705][322896] Avg episode reward: [(0, '1223.162')]
[2025-11-06 16:36:12,746][322896] Fps is (10 sec: 3289.2, 60 sec: 3552.3, 300 sec: 3609.7). Total num frames: 8159232. Throughput: 0: 3620.8. Samples: 8160256. Policy #0 lag: (min: 3.0, avg: 6.0, max: 67.0)
[2025-11-06 16:36:12,746][322896] Avg episode reward: [(0, '1180.534')]
[2025-11-06 16:36:17,677][322896] Fps is (10 sec: 3286.0, 60 sec: 3557.8, 300 sec: 3611.3). Total num frames: 8175616. Throughput: 0: 3604.2. Samples: 8181760. Policy #0 lag: (min: 3.0, avg: 6.0, max: 67.0)
[2025-11-06 16:36:17,677][322896] Avg episode reward: [(0, '1172.352')]
[2025-11-06 16:36:22,720][322896] Signal inference workers to stop experience collection... (1500 times)
[2025-11-06 16:36:22,720][322896] Fps is (10 sec: 3285.1, 60 sec: 3547.6, 300 sec: 3610.2). Total num frames: 8192000. Throughput: 0: 3636.7. Samples: 8204800. Policy #0 lag: (min: 3.0, avg: 6.0, max: 67.0)
[2025-11-06 16:36:22,721][322896] Avg episode reward: [(0, '1193.658')]
[2025-11-06 16:36:23,066][322896] InferenceWorker_p0-w0: stopping experience collection (1500 times)
[2025-11-06 16:36:23,068][322896] Signal inference workers to resume experience collection... (1500 times)
[2025-11-06 16:36:23,191][322896] InferenceWorker_p0-w0: resuming experience collection (1500 times)
[2025-11-06 16:36:27,945][322896] Fps is (10 sec: 4786.5, 60 sec: 3812.3, 300 sec: 3662.4). Total num frames: 8224768. Throughput: 0: 3599.6. Samples: 8215040. Policy #0 lag: (min: 8.0, avg: 11.0, max: 72.0)
[2025-11-06 16:36:27,946][322896] Avg episode reward: [(0, '1195.060')]
[2025-11-06 16:36:32,800][322896] Fps is (10 sec: 4876.6, 60 sec: 3822.1, 300 sec: 3665.0). Total num frames: 8241152. Throughput: 0: 3626.2. Samples: 8238080. Policy #0 lag: (min: 8.0, avg: 11.0, max: 72.0)
[2025-11-06 16:36:32,800][322896] Avg episode reward: [(0, '1228.900')]
[2025-11-06 16:36:37,785][322896] Fps is (10 sec: 3330.2, 60 sec: 3696.6, 300 sec: 3640.1). Total num frames: 8257536. Throughput: 0: 3609.3. Samples: 8258560. Policy #0 lag: (min: 8.0, avg: 11.0, max: 72.0)
[2025-11-06 16:36:37,785][322896] Avg episode reward: [(0, '1195.953')]
[2025-11-06 16:36:42,717][322896] Fps is (10 sec: 3304.2, 60 sec: 3549.7, 300 sec: 3612.7). Total num frames: 8273920. Throughput: 0: 3609.7. Samples: 8269824. Policy #0 lag: (min: 8.0, avg: 11.0, max: 72.0)
[2025-11-06 16:36:42,717][322896] Avg episode reward: [(0, '1164.569')]
[2025-11-06 16:36:47,681][322896] Fps is (10 sec: 3311.4, 60 sec: 3554.5, 300 sec: 3611.3). Total num frames: 8290304. Throughput: 0: 3626.4. Samples: 8291328. Policy #0 lag: (min: 10.0, avg: 13.0, max: 74.0)
[2025-11-06 16:36:47,681][322896] Avg episode reward: [(0, '1116.743')]
[2025-11-06 16:36:52,692][322896] Fps is (10 sec: 3284.7, 60 sec: 3548.8, 300 sec: 3610.6). Total num frames: 8306688. Throughput: 0: 3630.5. Samples: 8313344. Policy #0 lag: (min: 10.0, avg: 13.0, max: 74.0)
[2025-11-06 16:36:52,693][322896] Avg episode reward: [(0, '1174.506')]
[2025-11-06 16:36:57,773][322896] Fps is (10 sec: 3246.8, 60 sec: 3548.7, 300 sec: 3609.8). Total num frames: 8323072. Throughput: 0: 3638.7. Samples: 8324096. Policy #0 lag: (min: 10.0, avg: 13.0, max: 74.0)
[2025-11-06 16:36:57,773][322896] Avg episode reward: [(0, '1237.863')]
[2025-11-06 16:37:02,778][322896] Fps is (10 sec: 3248.9, 60 sec: 3550.2, 300 sec: 3608.8). Total num frames: 8339456. Throughput: 0: 3644.0. Samples: 8346112. Policy #0 lag: (min: 10.0, avg: 13.0, max: 74.0)
[2025-11-06 16:37:02,779][322896] Avg episode reward: [(0, '1234.563')]
[2025-11-06 16:37:07,787][322896] Fps is (10 sec: 3272.2, 60 sec: 3545.0, 300 sec: 3609.2). Total num frames: 8355840. Throughput: 0: 3635.5. Samples: 8368640. Policy #0 lag: (min: 10.0, avg: 13.0, max: 74.0)
[2025-11-06 16:37:07,787][322896] Avg episode reward: [(0, '1146.429')]
[2025-11-06 16:37:12,906][322896] Fps is (10 sec: 4853.1, 60 sec: 3812.7, 300 sec: 3663.0). Total num frames: 8388608. Throughput: 0: 3644.1. Samples: 8378880. Policy #0 lag: (min: 3.0, avg: 6.0, max: 67.0)
[2025-11-06 16:37:12,907][322896] Avg episode reward: [(0, '1117.178')]
[2025-11-06 16:37:17,706][322896] Fps is (10 sec: 4955.6, 60 sec: 3821.1, 300 sec: 3666.4). Total num frames: 8404992. Throughput: 0: 3637.1. Samples: 8401408. Policy #0 lag: (min: 3.0, avg: 6.0, max: 67.0)
[2025-11-06 16:37:17,706][322896] Avg episode reward: [(0, '1115.316')]
[2025-11-06 16:37:22,727][322896] Fps is (10 sec: 3336.7, 60 sec: 3822.5, 300 sec: 3666.3). Total num frames: 8421376. Throughput: 0: 3645.6. Samples: 8422400. Policy #0 lag: (min: 3.0, avg: 6.0, max: 67.0)
[2025-11-06 16:37:22,727][322896] Avg episode reward: [(0, '1137.448')]
[2025-11-06 16:37:27,737][322896] Fps is (10 sec: 3266.5, 60 sec: 3562.2, 300 sec: 3612.6). Total num frames: 8437760. Throughput: 0: 3605.1. Samples: 8432128. Policy #0 lag: (min: 3.0, avg: 6.0, max: 67.0)
[2025-11-06 16:37:27,737][322896] Avg episode reward: [(0, '1125.003')]
[2025-11-06 16:37:32,697][322896] Fps is (10 sec: 3286.5, 60 sec: 3555.9, 300 sec: 3609.8). Total num frames: 8454144. Throughput: 0: 3628.2. Samples: 8454656. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:37:32,698][322896] Avg episode reward: [(0, '1175.667')]
[2025-11-06 16:37:35,627][322896] Signal inference workers to stop experience collection... (1550 times)
[2025-11-06 16:37:35,976][322896] InferenceWorker_p0-w0: stopping experience collection (1550 times)
[2025-11-06 16:37:35,977][322896] Signal inference workers to resume experience collection... (1550 times)
[2025-11-06 16:37:35,977][322896] InferenceWorker_p0-w0: resuming experience collection (1550 times)
[2025-11-06 16:37:37,744][322896] Fps is (10 sec: 3274.6, 60 sec: 3552.3, 300 sec: 3610.6). Total num frames: 8470528. Throughput: 0: 3591.3. Samples: 8475136. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:37:37,744][322896] Avg episode reward: [(0, '1160.179')]
[2025-11-06 16:37:42,716][322896] Fps is (10 sec: 3270.7, 60 sec: 3549.9, 300 sec: 3610.6). Total num frames: 8486912. Throughput: 0: 3634.1. Samples: 8487424. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:37:42,716][322896] Avg episode reward: [(0, '1105.820')]
[2025-11-06 16:37:47,760][322896] Fps is (10 sec: 3271.3, 60 sec: 3545.1, 300 sec: 3609.4). Total num frames: 8503296. Throughput: 0: 3596.8. Samples: 8507904. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:37:47,761][322896] Avg episode reward: [(0, '1041.558')]
[2025-11-06 16:37:52,775][322896] Fps is (10 sec: 3257.7, 60 sec: 3545.0, 300 sec: 3610.3). Total num frames: 8519680. Throughput: 0: 3585.0. Samples: 8529920. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:37:52,775][322896] Avg episode reward: [(0, '1195.653')]
[2025-11-06 16:37:57,674][322896] Fps is (10 sec: 3305.5, 60 sec: 3555.8, 300 sec: 3610.2). Total num frames: 8536064. Throughput: 0: 3602.6. Samples: 8540160. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:37:57,674][322896] Avg episode reward: [(0, '1201.619')]
[2025-11-06 16:37:57,799][322896] Saving /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_lidar_policy2_acc_yaw_sp/checkpoint_p0/checkpoint_000033344_8536064.pth...
[2025-11-06 16:37:57,803][322896] Removing /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_lidar_policy2_acc_yaw_sp/checkpoint_p0/checkpoint_000029952_7667712.pth
[2025-11-06 16:38:02,828][322896] Fps is (10 sec: 4074.2, 60 sec: 3683.3, 300 sec: 3636.5). Total num frames: 8560640. Throughput: 0: 3562.9. Samples: 8562176. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:38:02,828][322896] Avg episode reward: [(0, '1174.742')]
[2025-11-06 16:38:07,774][322896] Fps is (10 sec: 4866.2, 60 sec: 3823.7, 300 sec: 3664.7). Total num frames: 8585216. Throughput: 0: 3603.0. Samples: 8584704. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:38:07,775][322896] Avg episode reward: [(0, '1153.961')]
[2025-11-06 16:38:12,701][322896] Fps is (10 sec: 4148.9, 60 sec: 3562.1, 300 sec: 3639.1). Total num frames: 8601600. Throughput: 0: 3632.4. Samples: 8595456. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:38:12,701][322896] Avg episode reward: [(0, '1177.674')]
[2025-11-06 16:38:17,751][322896] Fps is (10 sec: 3284.3, 60 sec: 3547.2, 300 sec: 3609.5). Total num frames: 8617984. Throughput: 0: 3602.4. Samples: 8616960. Policy #0 lag: (min: 1.0, avg: 4.0, max: 65.0)
[2025-11-06 16:38:17,752][322896] Avg episode reward: [(0, '1145.183')]
[2025-11-06 16:38:22,784][322896] Fps is (10 sec: 3249.6, 60 sec: 3546.5, 300 sec: 3609.2). Total num frames: 8634368. Throughput: 0: 3603.5. Samples: 8637440. Policy #0 lag: (min: 1.0, avg: 4.0, max: 65.0)
[2025-11-06 16:38:22,785][322896] Avg episode reward: [(0, '1184.760')]
[2025-11-06 16:38:27,715][322896] Fps is (10 sec: 3288.9, 60 sec: 3551.2, 300 sec: 3610.0). Total num frames: 8650752. Throughput: 0: 3595.5. Samples: 8649216. Policy #0 lag: (min: 1.0, avg: 4.0, max: 65.0)
[2025-11-06 16:38:27,715][322896] Avg episode reward: [(0, '1161.807')]
[2025-11-06 16:38:32,765][322896] Fps is (10 sec: 3283.3, 60 sec: 3545.9, 300 sec: 3609.4). Total num frames: 8667136. Throughput: 0: 3583.7. Samples: 8669184. Policy #0 lag: (min: 1.0, avg: 4.0, max: 65.0)
[2025-11-06 16:38:32,765][322896] Avg episode reward: [(0, '1161.282')]
[2025-11-06 16:38:37,727][322896] Fps is (10 sec: 3272.7, 60 sec: 3550.8, 300 sec: 3610.2). Total num frames: 8683520. Throughput: 0: 3576.4. Samples: 8690688. Policy #0 lag: (min: 1.0, avg: 4.0, max: 65.0)
[2025-11-06 16:38:37,728][322896] Avg episode reward: [(0, '1160.786')]
[2025-11-06 16:38:42,705][322896] Fps is (10 sec: 3296.5, 60 sec: 3550.5, 300 sec: 3610.6). Total num frames: 8699904. Throughput: 0: 3570.1. Samples: 8700928. Policy #0 lag: (min: 8.0, avg: 11.0, max: 72.0)
[2025-11-06 16:38:42,705][322896] Avg episode reward: [(0, '1156.273')]
[2025-11-06 16:38:47,779][322896] Fps is (10 sec: 3259.8, 60 sec: 3548.8, 300 sec: 3609.0). Total num frames: 8716288. Throughput: 0: 3599.3. Samples: 8723968. Policy #0 lag: (min: 8.0, avg: 11.0, max: 72.0)
[2025-11-06 16:38:47,780][322896] Avg episode reward: [(0, '1158.875')]
[2025-11-06 16:38:52,803][322896] Signal inference workers to stop experience collection... (1600 times)
[2025-11-06 16:38:52,803][322896] Signal inference workers to resume experience collection... (1600 times)
[2025-11-06 16:38:52,803][322896] Fps is (10 sec: 4056.3, 60 sec: 3684.7, 300 sec: 3637.1). Total num frames: 8740864. Throughput: 0: 3593.1. Samples: 8746496. Policy #0 lag: (min: 8.0, avg: 11.0, max: 72.0)
[2025-11-06 16:38:52,803][322896] Avg episode reward: [(0, '1188.472')]
[2025-11-06 16:38:53,048][322896] InferenceWorker_p0-w0: stopping experience collection (1600 times)
[2025-11-06 16:38:53,049][322896] InferenceWorker_p0-w0: resuming experience collection (1600 times)
[2025-11-06 16:38:57,725][322896] Fps is (10 sec: 4942.1, 60 sec: 3819.7, 300 sec: 3638.7). Total num frames: 8765440. Throughput: 0: 3593.4. Samples: 8757248. Policy #0 lag: (min: 8.0, avg: 11.0, max: 72.0)
[2025-11-06 16:38:57,725][322896] Avg episode reward: [(0, '1181.679')]
[2025-11-06 16:39:02,691][322896] Fps is (10 sec: 4142.4, 60 sec: 3694.8, 300 sec: 3610.1). Total num frames: 8781824. Throughput: 0: 3623.0. Samples: 8779776. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:39:02,691][322896] Avg episode reward: [(0, '1213.386')]
[2025-11-06 16:39:07,791][322896] Fps is (10 sec: 3255.2, 60 sec: 3548.9, 300 sec: 3609.5). Total num frames: 8798208. Throughput: 0: 3629.0. Samples: 8800768. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:39:07,792][322896] Avg episode reward: [(0, '1156.924')]
[2025-11-06 16:39:12,698][322896] Fps is (10 sec: 3274.6, 60 sec: 3550.0, 300 sec: 3610.8). Total num frames: 8814592. Throughput: 0: 3642.3. Samples: 8813056. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:39:12,698][322896] Avg episode reward: [(0, '1178.601')]
[2025-11-06 16:39:17,696][322896] Fps is (10 sec: 3308.2, 60 sec: 3553.1, 300 sec: 3610.6). Total num frames: 8830976. Throughput: 0: 3669.2. Samples: 8834048. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:39:17,697][322896] Avg episode reward: [(0, '1175.381')]
[2025-11-06 16:39:22,769][322896] Fps is (10 sec: 3253.6, 60 sec: 3550.8, 300 sec: 3609.5). Total num frames: 8847360. Throughput: 0: 3694.3. Samples: 8857088. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:39:22,769][322896] Avg episode reward: [(0, '1204.523')]
[2025-11-06 16:39:27,779][322896] Fps is (10 sec: 3250.0, 60 sec: 3546.1, 300 sec: 3609.8). Total num frames: 8863744. Throughput: 0: 3691.7. Samples: 8867328. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:39:27,779][322896] Avg episode reward: [(0, '1233.346')]
[2025-11-06 16:39:32,861][322896] Fps is (10 sec: 4058.7, 60 sec: 3680.5, 300 sec: 3636.1). Total num frames: 8888320. Throughput: 0: 3679.7. Samples: 8889856. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:39:32,861][322896] Avg episode reward: [(0, '1155.343')]
[2025-11-06 16:39:37,780][322896] Fps is (10 sec: 4914.6, 60 sec: 3819.6, 300 sec: 3640.4). Total num frames: 8912896. Throughput: 0: 3688.3. Samples: 8912384. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:39:37,781][322896] Avg episode reward: [(0, '1142.302')]
[2025-11-06 16:39:42,725][322896] Fps is (10 sec: 4152.3, 60 sec: 3821.7, 300 sec: 3612.2). Total num frames: 8929280. Throughput: 0: 3686.4. Samples: 8923136. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:39:42,726][322896] Avg episode reward: [(0, '1245.681')]
[2025-11-06 16:39:47,746][322896] Fps is (10 sec: 3288.0, 60 sec: 3825.0, 300 sec: 3609.9). Total num frames: 8945664. Throughput: 0: 3681.9. Samples: 8945664. Policy #0 lag: (min: 31.0, avg: 34.0, max: 95.0)
[2025-11-06 16:39:47,747][322896] Avg episode reward: [(0, '1281.663')]
[2025-11-06 16:39:47,881][322896] Saving new best policy, reward=1281.663!
[2025-11-06 16:39:52,708][322896] Fps is (10 sec: 3282.6, 60 sec: 3692.3, 300 sec: 3610.0). Total num frames: 8962048. Throughput: 0: 3693.3. Samples: 8966656. Policy #0 lag: (min: 31.0, avg: 34.0, max: 95.0)
[2025-11-06 16:39:52,708][322896] Avg episode reward: [(0, '1216.256')]
[2025-11-06 16:39:57,707][322896] Fps is (10 sec: 3289.6, 60 sec: 3550.9, 300 sec: 3609.8). Total num frames: 8978432. Throughput: 0: 3685.6. Samples: 8978944. Policy #0 lag: (min: 31.0, avg: 34.0, max: 95.0)
[2025-11-06 16:39:57,708][322896] Avg episode reward: [(0, '1275.567')]
[2025-11-06 16:39:57,835][322896] Saving /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_lidar_policy2_acc_yaw_sp/checkpoint_p0/checkpoint_000035072_8978432.pth...
[2025-11-06 16:39:57,839][322896] Removing /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_lidar_policy2_acc_yaw_sp/checkpoint_p0/checkpoint_000031680_8110080.pth
[2025-11-06 16:40:02,762][322896] Fps is (10 sec: 3259.0, 60 sec: 3545.7, 300 sec: 3609.1). Total num frames: 8994816. Throughput: 0: 3692.4. Samples: 9000448. Policy #0 lag: (min: 31.0, avg: 34.0, max: 95.0)
[2025-11-06 16:40:02,762][322896] Avg episode reward: [(0, '1262.374')]
[2025-11-06 16:40:07,767][322896] Fps is (10 sec: 3257.2, 60 sec: 3551.3, 300 sec: 3610.3). Total num frames: 9011200. Throughput: 0: 3686.5. Samples: 9022976. Policy #0 lag: (min: 31.0, avg: 34.0, max: 95.0)
[2025-11-06 16:40:07,768][322896] Avg episode reward: [(0, '1233.065')]
[2025-11-06 16:40:08,019][322896] Signal inference workers to stop experience collection... (1650 times)
[2025-11-06 16:40:08,389][322896] InferenceWorker_p0-w0: stopping experience collection (1650 times)
[2025-11-06 16:40:08,391][322896] Signal inference workers to resume experience collection... (1650 times)
[2025-11-06 16:40:08,512][322896] InferenceWorker_p0-w0: resuming experience collection (1650 times)
[2025-11-06 16:40:12,817][322896] Fps is (10 sec: 4073.6, 60 sec: 3679.1, 300 sec: 3637.7). Total num frames: 9035776. Throughput: 0: 3683.3. Samples: 9033216. Policy #0 lag: (min: 58.0, avg: 61.0, max: 122.0)
[2025-11-06 16:40:12,817][322896] Avg episode reward: [(0, '1247.940')]
[2025-11-06 16:40:17,715][322896] Fps is (10 sec: 4941.3, 60 sec: 3821.8, 300 sec: 3665.2). Total num frames: 9060352. Throughput: 0: 3709.8. Samples: 9056256. Policy #0 lag: (min: 58.0, avg: 61.0, max: 122.0)
[2025-11-06 16:40:17,715][322896] Avg episode reward: [(0, '1257.479')]
[2025-11-06 16:40:22,678][322896] Fps is (10 sec: 4153.8, 60 sec: 3828.8, 300 sec: 3666.8). Total num frames: 9076736. Throughput: 0: 3683.4. Samples: 9077760. Policy #0 lag: (min: 58.0, avg: 61.0, max: 122.0)
[2025-11-06 16:40:22,678][322896] Avg episode reward: [(0, '1239.707')]
[2025-11-06 16:40:27,730][322896] Fps is (10 sec: 3271.9, 60 sec: 3826.1, 300 sec: 3666.3). Total num frames: 9093120. Throughput: 0: 3697.4. Samples: 9089536. Policy #0 lag: (min: 58.0, avg: 61.0, max: 122.0)
[2025-11-06 16:40:27,730][322896] Avg episode reward: [(0, '1242.936')]
[2025-11-06 16:40:32,782][322896] Fps is (10 sec: 3243.1, 60 sec: 3691.3, 300 sec: 3639.9). Total num frames: 9109504. Throughput: 0: 3660.8. Samples: 9110528. Policy #0 lag: (min: 58.0, avg: 61.0, max: 122.0)
[2025-11-06 16:40:32,782][322896] Avg episode reward: [(0, '1242.948')]
[2025-11-06 16:40:37,728][322896] Fps is (10 sec: 3277.2, 60 sec: 3552.9, 300 sec: 3609.9). Total num frames: 9125888. Throughput: 0: 3696.1. Samples: 9133056. Policy #0 lag: (min: 2.0, avg: 5.0, max: 66.0)
[2025-11-06 16:40:37,729][322896] Avg episode reward: [(0, '1272.930')]
[2025-11-06 16:40:42,762][322896] Fps is (10 sec: 3283.2, 60 sec: 3547.7, 300 sec: 3610.0). Total num frames: 9142272. Throughput: 0: 3647.8. Samples: 9143296. Policy #0 lag: (min: 2.0, avg: 5.0, max: 66.0)
[2025-11-06 16:40:42,763][322896] Avg episode reward: [(0, '1299.553')]
[2025-11-06 16:40:42,898][322896] Saving new best policy, reward=1299.553!
[2025-11-06 16:40:47,679][322896] Fps is (10 sec: 3293.1, 60 sec: 3553.9, 300 sec: 3610.0). Total num frames: 9158656. Throughput: 0: 3693.2. Samples: 9166336. Policy #0 lag: (min: 2.0, avg: 5.0, max: 66.0)
[2025-11-06 16:40:47,679][322896] Avg episode reward: [(0, '1306.370')]
[2025-11-06 16:40:47,815][322896] Saving new best policy, reward=1306.370!
[2025-11-06 16:40:52,898][322896] Fps is (10 sec: 4041.0, 60 sec: 3674.7, 300 sec: 3636.0). Total num frames: 9183232. Throughput: 0: 3675.7. Samples: 9188864. Policy #0 lag: (min: 2.0, avg: 5.0, max: 66.0)
[2025-11-06 16:40:52,899][322896] Avg episode reward: [(0, '1279.173')]
[2025-11-06 16:40:57,771][322896] Fps is (10 sec: 4870.4, 60 sec: 3818.9, 300 sec: 3665.7). Total num frames: 9207808. Throughput: 0: 3690.2. Samples: 9199104. Policy #0 lag: (min: 2.0, avg: 5.0, max: 66.0)
[2025-11-06 16:40:57,771][322896] Avg episode reward: [(0, '1202.415')]
[2025-11-06 16:41:02,719][322896] Fps is (10 sec: 4171.0, 60 sec: 3825.7, 300 sec: 3665.4). Total num frames: 9224192. Throughput: 0: 3686.1. Samples: 9222144. Policy #0 lag: (min: 14.0, avg: 17.0, max: 78.0)
[2025-11-06 16:41:02,719][322896] Avg episode reward: [(0, '1235.669')]
[2025-11-06 16:41:07,735][322896] Fps is (10 sec: 3288.6, 60 sec: 3825.0, 300 sec: 3665.7). Total num frames: 9240576. Throughput: 0: 3670.4. Samples: 9243136. Policy #0 lag: (min: 14.0, avg: 17.0, max: 78.0)
[2025-11-06 16:41:07,735][322896] Avg episode reward: [(0, '1243.938')]
[2025-11-06 16:41:12,747][322896] Fps is (10 sec: 3267.6, 60 sec: 3690.7, 300 sec: 3664.7). Total num frames: 9256960. Throughput: 0: 3685.0. Samples: 9255424. Policy #0 lag: (min: 14.0, avg: 17.0, max: 78.0)
[2025-11-06 16:41:12,747][322896] Avg episode reward: [(0, '1254.462')]
[2025-11-06 16:41:17,696][322896] Fps is (10 sec: 3289.7, 60 sec: 3551.0, 300 sec: 3665.9). Total num frames: 9273344. Throughput: 0: 3682.1. Samples: 9275904. Policy #0 lag: (min: 14.0, avg: 17.0, max: 78.0)
[2025-11-06 16:41:17,696][322896] Avg episode reward: [(0, '1300.329')]
[2025-11-06 16:41:19,563][322896] Signal inference workers to stop experience collection... (1700 times)
[2025-11-06 16:41:19,911][322896] InferenceWorker_p0-w0: stopping experience collection (1700 times)
[2025-11-06 16:41:19,911][322896] Signal inference workers to resume experience collection... (1700 times)
[2025-11-06 16:41:19,912][322896] InferenceWorker_p0-w0: resuming experience collection (1700 times)
[2025-11-06 16:41:22,675][322896] Fps is (10 sec: 3300.5, 60 sec: 3550.0, 300 sec: 3613.3). Total num frames: 9289728. Throughput: 0: 3690.8. Samples: 9298944. Policy #0 lag: (min: 14.0, avg: 17.0, max: 78.0)
[2025-11-06 16:41:22,675][322896] Avg episode reward: [(0, '1266.737')]
[2025-11-06 16:41:27,712][322896] Fps is (10 sec: 3271.4, 60 sec: 3550.9, 300 sec: 3611.1). Total num frames: 9306112. Throughput: 0: 3690.5. Samples: 9309184. Policy #0 lag: (min: 14.0, avg: 17.0, max: 78.0)
[2025-11-06 16:41:27,713][322896] Avg episode reward: [(0, '1258.134')]
[2025-11-06 16:41:32,830][322896] Fps is (10 sec: 4033.5, 60 sec: 3683.5, 300 sec: 3637.3). Total num frames: 9330688. Throughput: 0: 3674.1. Samples: 9332224. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:41:32,830][322896] Avg episode reward: [(0, '1300.210')]
[2025-11-06 16:41:37,719][322896] Fps is (10 sec: 4912.0, 60 sec: 3823.5, 300 sec: 3665.5). Total num frames: 9355264. Throughput: 0: 3712.6. Samples: 9355264. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:41:37,719][322896] Avg episode reward: [(0, '1299.047')]
[2025-11-06 16:41:42,702][322896] Fps is (10 sec: 4149.0, 60 sec: 3826.8, 300 sec: 3665.3). Total num frames: 9371648. Throughput: 0: 3703.4. Samples: 9365504. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:41:42,702][322896] Avg episode reward: [(0, '1315.110')]
[2025-11-06 16:41:42,824][322896] Saving new best policy, reward=1315.110!
[2025-11-06 16:41:47,747][322896] Fps is (10 sec: 3267.7, 60 sec: 3818.6, 300 sec: 3664.9). Total num frames: 9388032. Throughput: 0: 3695.5. Samples: 9388544. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:41:47,747][322896] Avg episode reward: [(0, '1384.018')]
[2025-11-06 16:41:47,876][322896] Saving new best policy, reward=1384.018!
[2025-11-06 16:41:52,725][322896] Fps is (10 sec: 3269.2, 60 sec: 3697.1, 300 sec: 3666.2). Total num frames: 9404416. Throughput: 0: 3687.2. Samples: 9409024. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:41:52,726][322896] Avg episode reward: [(0, '1387.540')]
[2025-11-06 16:41:52,859][322896] Saving new best policy, reward=1387.540!
[2025-11-06 16:41:57,697][322896] Fps is (10 sec: 3293.2, 60 sec: 3554.3, 300 sec: 3666.6). Total num frames: 9420800. Throughput: 0: 3690.5. Samples: 9421312. Policy #0 lag: (min: 5.0, avg: 8.0, max: 69.0)
[2025-11-06 16:41:57,697][322896] Avg episode reward: [(0, '1286.124')]
[2025-11-06 16:41:57,829][322896] Saving /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_lidar_policy2_acc_yaw_sp/checkpoint_p0/checkpoint_000036800_9420800.pth...
[2025-11-06 16:41:57,833][322896] Removing /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_lidar_policy2_acc_yaw_sp/checkpoint_p0/checkpoint_000033344_8536064.pth
[2025-11-06 16:42:02,756][322896] Fps is (10 sec: 3266.8, 60 sec: 3547.7, 300 sec: 3666.0). Total num frames: 9437184. Throughput: 0: 3692.8. Samples: 9442304. Policy #0 lag: (min: 5.0, avg: 8.0, max: 69.0)
[2025-11-06 16:42:02,756][322896] Avg episode reward: [(0, '1261.058')]
[2025-11-06 16:42:07,716][322896] Fps is (10 sec: 3270.7, 60 sec: 3551.0, 300 sec: 3612.4). Total num frames: 9453568. Throughput: 0: 3683.1. Samples: 9464832. Policy #0 lag: (min: 5.0, avg: 8.0, max: 69.0)
[2025-11-06 16:42:07,716][322896] Avg episode reward: [(0, '1311.259')]
[2025-11-06 16:42:12,893][322896] Fps is (10 sec: 4040.6, 60 sec: 3677.4, 300 sec: 3635.5). Total num frames: 9478144. Throughput: 0: 3683.0. Samples: 9475584. Policy #0 lag: (min: 5.0, avg: 8.0, max: 69.0)
[2025-11-06 16:42:12,893][322896] Avg episode reward: [(0, '1344.889')]
[2025-11-06 16:42:17,771][322896] Fps is (10 sec: 4888.2, 60 sec: 3818.2, 300 sec: 3665.0). Total num frames: 9502720. Throughput: 0: 3691.3. Samples: 9498112. Policy #0 lag: (min: 5.0, avg: 8.0, max: 69.0)
[2025-11-06 16:42:17,771][322896] Avg episode reward: [(0, '1345.969')]
[2025-11-06 16:42:22,729][322896] Fps is (10 sec: 4164.1, 60 sec: 3819.5, 300 sec: 3665.7). Total num frames: 9519104. Throughput: 0: 3662.8. Samples: 9520128. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:42:22,730][322896] Avg episode reward: [(0, '1285.762')]
[2025-11-06 16:42:27,752][322896] Fps is (10 sec: 3283.0, 60 sec: 3820.4, 300 sec: 3664.9). Total num frames: 9535488. Throughput: 0: 3670.9. Samples: 9530880. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:42:27,752][322896] Avg episode reward: [(0, '1304.210')]
[2025-11-06 16:42:32,730][322896] Fps is (10 sec: 3276.6, 60 sec: 3692.6, 300 sec: 3665.7). Total num frames: 9551872. Throughput: 0: 3653.6. Samples: 9552896. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:42:32,730][322896] Avg episode reward: [(0, '1376.351')]
[2025-11-06 16:42:35,178][322896] Signal inference workers to stop experience collection... (1750 times)
[2025-11-06 16:42:35,178][322896] Signal inference workers to resume experience collection... (1750 times)
[2025-11-06 16:42:35,419][322896] InferenceWorker_p0-w0: stopping experience collection (1750 times)
[2025-11-06 16:42:35,419][322896] InferenceWorker_p0-w0: resuming experience collection (1750 times)
[2025-11-06 16:42:37,684][322896] Fps is (10 sec: 3299.3, 60 sec: 3551.9, 300 sec: 3666.0). Total num frames: 9568256. Throughput: 0: 3689.8. Samples: 9574912. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:42:37,684][322896] Avg episode reward: [(0, '1372.877')]
[2025-11-06 16:42:42,704][322896] Fps is (10 sec: 3285.4, 60 sec: 3549.8, 300 sec: 3666.3). Total num frames: 9584640. Throughput: 0: 3651.7. Samples: 9585664. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:42:42,704][322896] Avg episode reward: [(0, '1357.729')]
[2025-11-06 16:42:47,704][322896] Fps is (10 sec: 3270.4, 60 sec: 3552.4, 300 sec: 3666.5). Total num frames: 9601024. Throughput: 0: 3679.3. Samples: 9607680. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:42:47,704][322896] Avg episode reward: [(0, '1410.720')]
[2025-11-06 16:42:47,842][322896] Saving new best policy, reward=1410.720!
[2025-11-06 16:42:52,970][322896] Fps is (10 sec: 3989.8, 60 sec: 3671.4, 300 sec: 3689.6). Total num frames: 9625600. Throughput: 0: 3665.7. Samples: 9630720. Policy #0 lag: (min: 6.0, avg: 9.0, max: 70.0)
[2025-11-06 16:42:52,970][322896] Avg episode reward: [(0, '1445.272')]
[2025-11-06 16:42:53,318][322896] Saving new best policy, reward=1445.272!
[2025-11-06 16:42:57,743][322896] Fps is (10 sec: 4896.1, 60 sec: 3820.0, 300 sec: 3694.4). Total num frames: 9650176. Throughput: 0: 3687.3. Samples: 9640960. Policy #0 lag: (min: 6.0, avg: 9.0, max: 70.0)
[2025-11-06 16:42:57,743][322896] Avg episode reward: [(0, '1372.695')]
[2025-11-06 16:43:02,766][322896] Fps is (10 sec: 4181.2, 60 sec: 3822.3, 300 sec: 3665.7). Total num frames: 9666560. Throughput: 0: 3686.8. Samples: 9664000. Policy #0 lag: (min: 6.0, avg: 9.0, max: 70.0)
[2025-11-06 16:43:02,766][322896] Avg episode reward: [(0, '1426.656')]
[2025-11-06 16:43:07,711][322896] Fps is (10 sec: 3287.1, 60 sec: 3823.2, 300 sec: 3665.4). Total num frames: 9682944. Throughput: 0: 3665.1. Samples: 9684992. Policy #0 lag: (min: 6.0, avg: 9.0, max: 70.0)
[2025-11-06 16:43:07,711][322896] Avg episode reward: [(0, '1460.307')]
[2025-11-06 16:43:07,842][322896] Saving new best policy, reward=1460.307!
[2025-11-06 16:43:12,765][322896] Fps is (10 sec: 3277.3, 60 sec: 3694.3, 300 sec: 3665.4). Total num frames: 9699328. Throughput: 0: 3696.7. Samples: 9697280. Policy #0 lag: (min: 6.0, avg: 9.0, max: 70.0)
[2025-11-06 16:43:12,765][322896] Avg episode reward: [(0, '1448.793')]
[2025-11-06 16:43:17,772][322896] Fps is (10 sec: 3257.0, 60 sec: 3549.8, 300 sec: 3665.7). Total num frames: 9715712. Throughput: 0: 3671.6. Samples: 9718272. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:43:17,772][322896] Avg episode reward: [(0, '1323.259')]
[2025-11-06 16:43:22,703][322896] Fps is (10 sec: 3297.3, 60 sec: 3551.5, 300 sec: 3665.7). Total num frames: 9732096. Throughput: 0: 3684.9. Samples: 9740800. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:43:22,703][322896] Avg episode reward: [(0, '1333.291')]
[2025-11-06 16:43:27,735][322896] Fps is (10 sec: 3288.8, 60 sec: 3550.8, 300 sec: 3665.9). Total num frames: 9748480. Throughput: 0: 3683.8. Samples: 9751552. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:43:27,736][322896] Avg episode reward: [(0, '1297.245')]
[2025-11-06 16:43:32,933][322896] Fps is (10 sec: 4003.9, 60 sec: 3674.0, 300 sec: 3690.8). Total num frames: 9773056. Throughput: 0: 3690.4. Samples: 9774592. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:43:32,933][322896] Avg episode reward: [(0, '1259.261')]
[2025-11-06 16:43:37,752][322896] Fps is (10 sec: 4907.1, 60 sec: 3818.6, 300 sec: 3720.5). Total num frames: 9797632. Throughput: 0: 3715.8. Samples: 9797120. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:43:37,752][322896] Avg episode reward: [(0, '1247.290')]
[2025-11-06 16:43:42,709][322896] Fps is (10 sec: 4189.7, 60 sec: 3822.6, 300 sec: 3722.0). Total num frames: 9814016. Throughput: 0: 3700.5. Samples: 9807360. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:43:42,709][322896] Avg episode reward: [(0, '1283.308')]
[2025-11-06 16:43:47,743][322896] Fps is (10 sec: 3279.7, 60 sec: 3820.4, 300 sec: 3694.1). Total num frames: 9830400. Throughput: 0: 3688.3. Samples: 9829888. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:43:47,743][322896] Avg episode reward: [(0, '1375.021')]
[2025-11-06 16:43:50,491][322896] Signal inference workers to stop experience collection... (1800 times)
[2025-11-06 16:43:50,841][322896] InferenceWorker_p0-w0: stopping experience collection (1800 times)
[2025-11-06 16:43:50,843][322896] Signal inference workers to resume experience collection... (1800 times)
[2025-11-06 16:43:50,963][322896] InferenceWorker_p0-w0: resuming experience collection (1800 times)
[2025-11-06 16:43:52,707][322896] Fps is (10 sec: 3277.4, 60 sec: 3702.6, 300 sec: 3665.8). Total num frames: 9846784. Throughput: 0: 3675.4. Samples: 9850368. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:43:52,707][322896] Avg episode reward: [(0, '1357.606')]
[2025-11-06 16:43:57,725][322896] Fps is (10 sec: 3282.7, 60 sec: 3550.9, 300 sec: 3665.1). Total num frames: 9863168. Throughput: 0: 3689.6. Samples: 9863168. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:43:57,725][322896] Avg episode reward: [(0, '1372.777')]
[2025-11-06 16:43:57,861][322896] Saving /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_lidar_policy2_acc_yaw_sp/checkpoint_p0/checkpoint_000038528_9863168.pth...
[2025-11-06 16:43:57,865][322896] Removing /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_lidar_policy2_acc_yaw_sp/checkpoint_p0/checkpoint_000035072_8978432.pth
[2025-11-06 16:44:02,758][322896] Fps is (10 sec: 3260.1, 60 sec: 3550.3, 300 sec: 3666.0). Total num frames: 9879552. Throughput: 0: 3687.5. Samples: 9884160. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:44:02,758][322896] Avg episode reward: [(0, '1478.056')]
[2025-11-06 16:44:02,884][322896] Saving new best policy, reward=1478.056!
[2025-11-06 16:44:07,707][322896] Fps is (10 sec: 3282.8, 60 sec: 3550.1, 300 sec: 3665.5). Total num frames: 9895936. Throughput: 0: 3686.0. Samples: 9906688. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:44:07,707][322896] Avg episode reward: [(0, '1519.220')]
[2025-11-06 16:44:07,842][322896] Saving new best policy, reward=1519.220!
[2025-11-06 16:44:12,979][322896] Fps is (10 sec: 4007.4, 60 sec: 3673.3, 300 sec: 3689.8). Total num frames: 9920512. Throughput: 0: 3666.5. Samples: 9917440. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:44:12,979][322896] Avg episode reward: [(0, '1513.834')]
[2025-11-06 16:44:17,725][322896] Fps is (10 sec: 4906.1, 60 sec: 3825.9, 300 sec: 3721.7). Total num frames: 9945088. Throughput: 0: 3703.4. Samples: 9940480. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:44:17,726][322896] Avg episode reward: [(0, '1431.210')]
[2025-11-06 16:44:22,766][322896] Fps is (10 sec: 4185.2, 60 sec: 3818.9, 300 sec: 3721.3). Total num frames: 9961472. Throughput: 0: 3673.9. Samples: 9962496. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:44:22,766][322896] Avg episode reward: [(0, '1357.932')]
[2025-11-06 16:44:27,682][322896] Fps is (10 sec: 3291.0, 60 sec: 3826.3, 300 sec: 3695.6). Total num frames: 9977856. Throughput: 0: 3688.6. Samples: 9973248. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:44:27,682][322896] Avg episode reward: [(0, '1293.042')]
[2025-11-06 16:44:32,733][322896] Fps is (10 sec: 3287.6, 60 sec: 3698.7, 300 sec: 3666.2). Total num frames: 9994240. Throughput: 0: 3675.8. Samples: 9995264. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:44:32,733][322896] Avg episode reward: [(0, '1343.026')]
[2025-11-06 16:44:37,789][322896] Fps is (10 sec: 3242.3, 60 sec: 3547.7, 300 sec: 3664.8). Total num frames: 10010624. Throughput: 0: 3702.4. Samples: 10017280. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:44:37,789][322896] Avg episode reward: [(0, '1460.952')]
[2025-11-06 16:44:42,711][322896] Fps is (10 sec: 3284.2, 60 sec: 3549.8, 300 sec: 3666.0). Total num frames: 10027008. Throughput: 0: 3664.8. Samples: 10028032. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:44:42,711][322896] Avg episode reward: [(0, '1492.369')]
[2025-11-06 16:44:47,690][322896] Fps is (10 sec: 3309.4, 60 sec: 3553.0, 300 sec: 3665.8). Total num frames: 10043392. Throughput: 0: 3703.4. Samples: 10050560. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:44:47,691][322896] Avg episode reward: [(0, '1435.217')]
[2025-11-06 16:44:52,697][322896] Fps is (10 sec: 3281.2, 60 sec: 3550.5, 300 sec: 3665.7). Total num frames: 10059776. Throughput: 0: 3698.6. Samples: 10073088. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:44:52,697][322896] Avg episode reward: [(0, '1386.946')]
[2025-11-06 16:44:57,758][322896] Fps is (10 sec: 4882.3, 60 sec: 3820.9, 300 sec: 3721.2). Total num frames: 10092544. Throughput: 0: 3704.6. Samples: 10083328. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:44:57,758][322896] Avg episode reward: [(0, '1372.632')]
[2025-11-06 16:45:01,892][322896] Signal inference workers to stop experience collection... (1850 times)
[2025-11-06 16:45:02,236][322896] InferenceWorker_p0-w0: stopping experience collection (1850 times)
[2025-11-06 16:45:02,237][322896] Signal inference workers to resume experience collection... (1850 times)
[2025-11-06 16:45:02,237][322896] InferenceWorker_p0-w0: resuming experience collection (1850 times)
[2025-11-06 16:45:02,738][322896] Fps is (10 sec: 4895.0, 60 sec: 3824.2, 300 sec: 3721.5). Total num frames: 10108928. Throughput: 0: 3685.3. Samples: 10106368. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:45:02,739][322896] Avg episode reward: [(0, '1389.268')]
[2025-11-06 16:45:07,758][322896] Fps is (10 sec: 3276.6, 60 sec: 3819.7, 300 sec: 3694.1). Total num frames: 10125312. Throughput: 0: 3664.3. Samples: 10127360. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:45:07,758][322896] Avg episode reward: [(0, '1438.677')]
[2025-11-06 16:45:12,688][322896] Fps is (10 sec: 3293.3, 60 sec: 3704.4, 300 sec: 3665.9). Total num frames: 10141696. Throughput: 0: 3697.3. Samples: 10139648. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:45:12,688][322896] Avg episode reward: [(0, '1431.779')]
[2025-11-06 16:45:17,719][322896] Fps is (10 sec: 3289.7, 60 sec: 3550.2, 300 sec: 3665.1). Total num frames: 10158080. Throughput: 0: 3676.2. Samples: 10160640. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:45:17,719][322896] Avg episode reward: [(0, '1430.100')]
[2025-11-06 16:45:22,674][322896] Fps is (10 sec: 3281.4, 60 sec: 3555.3, 300 sec: 3666.3). Total num frames: 10174464. Throughput: 0: 3707.2. Samples: 10183680. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:45:22,674][322896] Avg episode reward: [(0, '1421.488')]
[2025-11-06 16:45:27,691][322896] Fps is (10 sec: 3285.9, 60 sec: 3549.3, 300 sec: 3666.7). Total num frames: 10190848. Throughput: 0: 3688.0. Samples: 10193920. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:45:27,691][322896] Avg episode reward: [(0, '1431.356')]
[2025-11-06 16:45:32,803][322896] Fps is (10 sec: 4044.0, 60 sec: 3682.1, 300 sec: 3692.4). Total num frames: 10215424. Throughput: 0: 3688.6. Samples: 10216960. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:45:32,803][322896] Avg episode reward: [(0, '1477.491')]
[2025-11-06 16:45:37,742][322896] Fps is (10 sec: 4890.5, 60 sec: 3825.9, 300 sec: 3721.4). Total num frames: 10240000. Throughput: 0: 3694.1. Samples: 10239488. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:45:37,742][322896] Avg episode reward: [(0, '1455.151')]
[2025-11-06 16:45:42,681][322896] Fps is (10 sec: 4146.3, 60 sec: 3824.8, 300 sec: 3721.1). Total num frames: 10256384. Throughput: 0: 3715.5. Samples: 10250240. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:45:42,682][322896] Avg episode reward: [(0, '1511.540')]
[2025-11-06 16:45:47,771][322896] Fps is (10 sec: 3267.2, 60 sec: 3817.8, 300 sec: 3694.9). Total num frames: 10272768. Throughput: 0: 3695.1. Samples: 10272768. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:45:47,771][322896] Avg episode reward: [(0, '1479.163')]
[2025-11-06 16:45:52,758][322896] Fps is (10 sec: 3251.8, 60 sec: 3819.0, 300 sec: 3665.7). Total num frames: 10289152. Throughput: 0: 3697.8. Samples: 10293760. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:45:52,759][322896] Avg episode reward: [(0, '1456.689')]
[2025-11-06 16:45:57,769][322896] Fps is (10 sec: 3277.6, 60 sec: 3549.2, 300 sec: 3665.0). Total num frames: 10305536. Throughput: 0: 3691.2. Samples: 10306048. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:45:57,769][322896] Avg episode reward: [(0, '1474.873')]
[2025-11-06 16:45:57,890][322896] Saving /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_lidar_policy2_acc_yaw_sp/checkpoint_p0/checkpoint_000040256_10305536.pth...
[2025-11-06 16:45:57,894][322896] Removing /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_lidar_policy2_acc_yaw_sp/checkpoint_p0/checkpoint_000036800_9420800.pth
[2025-11-06 16:46:02,684][322896] Fps is (10 sec: 3301.4, 60 sec: 3553.1, 300 sec: 3666.2). Total num frames: 10321920. Throughput: 0: 3700.7. Samples: 10327040. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:46:02,684][322896] Avg episode reward: [(0, '1460.853')]
[2025-11-06 16:46:07,679][322896] Fps is (10 sec: 3306.4, 60 sec: 3554.6, 300 sec: 3666.4). Total num frames: 10338304. Throughput: 0: 3697.4. Samples: 10350080. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:46:07,679][322896] Avg episode reward: [(0, '1484.661')]
[2025-11-06 16:46:12,806][322896] Fps is (10 sec: 4046.7, 60 sec: 3679.2, 300 sec: 3692.0). Total num frames: 10362880. Throughput: 0: 3688.4. Samples: 10360320. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:46:12,806][322896] Avg episode reward: [(0, '1488.217')]
[2025-11-06 16:46:17,262][322896] Signal inference workers to stop experience collection... (1900 times)
[2025-11-06 16:46:17,262][322896] Signal inference workers to resume experience collection... (1900 times)
[2025-11-06 16:46:17,510][322896] InferenceWorker_p0-w0: stopping experience collection (1900 times)
[2025-11-06 16:46:17,510][322896] InferenceWorker_p0-w0: resuming experience collection (1900 times)
[2025-11-06 16:46:17,744][322896] Fps is (10 sec: 4883.4, 60 sec: 3821.3, 300 sec: 3720.2). Total num frames: 10387456. Throughput: 0: 3702.6. Samples: 10383360. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:46:17,745][322896] Avg episode reward: [(0, '1501.568')]
[2025-11-06 16:46:22,715][322896] Fps is (10 sec: 4133.5, 60 sec: 3820.3, 300 sec: 3721.1). Total num frames: 10403840. Throughput: 0: 3677.2. Samples: 10404864. Policy #0 lag: (min: 3.0, avg: 6.0, max: 67.0)
[2025-11-06 16:46:22,715][322896] Avg episode reward: [(0, '1510.590')]
[2025-11-06 16:46:27,697][322896] Fps is (10 sec: 3292.2, 60 sec: 3822.5, 300 sec: 3695.0). Total num frames: 10420224. Throughput: 0: 3685.1. Samples: 10416128. Policy #0 lag: (min: 3.0, avg: 6.0, max: 67.0)
[2025-11-06 16:46:27,698][322896] Avg episode reward: [(0, '1435.119')]
[2025-11-06 16:46:32,736][322896] Fps is (10 sec: 3269.9, 60 sec: 3690.5, 300 sec: 3665.4). Total num frames: 10436608. Throughput: 0: 3666.5. Samples: 10437632. Policy #0 lag: (min: 3.0, avg: 6.0, max: 67.0)
[2025-11-06 16:46:32,736][322896] Avg episode reward: [(0, '1408.224')]
[2025-11-06 16:46:37,792][322896] Fps is (10 sec: 3246.1, 60 sec: 3546.9, 300 sec: 3664.5). Total num frames: 10452992. Throughput: 0: 3683.6. Samples: 10459648. Policy #0 lag: (min: 3.0, avg: 6.0, max: 67.0)
[2025-11-06 16:46:37,792][322896] Avg episode reward: [(0, '1416.422')]
[2025-11-06 16:46:42,726][322896] Fps is (10 sec: 3280.0, 60 sec: 3547.2, 300 sec: 3665.8). Total num frames: 10469376. Throughput: 0: 3655.7. Samples: 10470400. Policy #0 lag: (min: 3.0, avg: 6.0, max: 67.0)
[2025-11-06 16:46:42,727][322896] Avg episode reward: [(0, '1453.199')]
[2025-11-06 16:46:47,689][322896] Fps is (10 sec: 3310.9, 60 sec: 3554.7, 300 sec: 3666.0). Total num frames: 10485760. Throughput: 0: 3686.0. Samples: 10492928. Policy #0 lag: (min: 3.0, avg: 6.0, max: 67.0)
[2025-11-06 16:46:47,689][322896] Avg episode reward: [(0, '1427.404')]
[2025-11-06 16:46:52,917][322896] Fps is (10 sec: 4019.5, 60 sec: 3676.7, 300 sec: 3690.6). Total num frames: 10510336. Throughput: 0: 3655.7. Samples: 10515456. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:46:52,917][322896] Avg episode reward: [(0, '1358.112')]
[2025-11-06 16:46:57,703][322896] Fps is (10 sec: 4908.2, 60 sec: 3827.1, 300 sec: 3721.8). Total num frames: 10534912. Throughput: 0: 3694.8. Samples: 10526208. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:46:57,704][322896] Avg episode reward: [(0, '1336.027')]
[2025-11-06 16:47:02,769][322896] Fps is (10 sec: 4157.5, 60 sec: 3817.5, 300 sec: 3720.4). Total num frames: 10551296. Throughput: 0: 3673.0. Samples: 10548736. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:47:02,769][322896] Avg episode reward: [(0, '1360.888')]
[2025-11-06 16:47:07,705][322896] Fps is (10 sec: 3276.4, 60 sec: 3821.3, 300 sec: 3695.7). Total num frames: 10567680. Throughput: 0: 3664.5. Samples: 10569728. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:47:07,705][322896] Avg episode reward: [(0, '1441.780')]
[2025-11-06 16:47:12,740][322896] Fps is (10 sec: 3286.3, 60 sec: 3690.5, 300 sec: 3666.0). Total num frames: 10584064. Throughput: 0: 3682.9. Samples: 10582016. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:47:12,740][322896] Avg episode reward: [(0, '1485.065')]
[2025-11-06 16:47:17,786][322896] Fps is (10 sec: 3250.4, 60 sec: 3547.4, 300 sec: 3664.9). Total num frames: 10600448. Throughput: 0: 3671.0. Samples: 10603008. Policy #0 lag: (min: 11.0, avg: 14.0, max: 75.0)
[2025-11-06 16:47:17,786][322896] Avg episode reward: [(0, '1456.310')]
[2025-11-06 16:47:22,728][322896] Fps is (10 sec: 3280.7, 60 sec: 3549.1, 300 sec: 3665.9). Total num frames: 10616832. Throughput: 0: 3703.1. Samples: 10626048. Policy #0 lag: (min: 11.0, avg: 14.0, max: 75.0)
[2025-11-06 16:47:22,728][322896] Avg episode reward: [(0, '1436.371')]
[2025-11-06 16:47:27,768][322896] Fps is (10 sec: 3282.7, 60 sec: 3545.7, 300 sec: 3665.1). Total num frames: 10633216. Throughput: 0: 3694.4. Samples: 10636800. Policy #0 lag: (min: 11.0, avg: 14.0, max: 75.0)
[2025-11-06 16:47:27,768][322896] Avg episode reward: [(0, '1523.728')]
[2025-11-06 16:47:27,896][322896] Saving new best policy, reward=1523.728!
[2025-11-06 16:47:32,445][322896] Signal inference workers to stop experience collection... (1950 times)
[2025-11-06 16:47:32,796][322896] InferenceWorker_p0-w0: stopping experience collection (1950 times)
[2025-11-06 16:47:32,798][322896] Signal inference workers to resume experience collection... (1950 times)
[2025-11-06 16:47:32,799][322896] Fps is (10 sec: 4067.0, 60 sec: 3682.5, 300 sec: 3691.9). Total num frames: 10657792. Throughput: 0: 3700.1. Samples: 10659840. Policy #0 lag: (min: 11.0, avg: 14.0, max: 75.0)
[2025-11-06 16:47:32,799][322896] Avg episode reward: [(0, '1512.606')]
[2025-11-06 16:47:32,932][322896] InferenceWorker_p0-w0: resuming experience collection (1950 times)
[2025-11-06 16:47:37,720][322896] Fps is (10 sec: 4938.6, 60 sec: 3827.5, 300 sec: 3720.9). Total num frames: 10682368. Throughput: 0: 3725.4. Samples: 10682368. Policy #0 lag: (min: 11.0, avg: 14.0, max: 75.0)
[2025-11-06 16:47:37,721][322896] Avg episode reward: [(0, '1488.543')]
[2025-11-06 16:47:42,766][322896] Fps is (10 sec: 4109.4, 60 sec: 3820.4, 300 sec: 3720.3). Total num frames: 10698752. Throughput: 0: 3692.6. Samples: 10692608. Policy #0 lag: (min: 14.0, avg: 17.0, max: 78.0)
[2025-11-06 16:47:42,767][322896] Avg episode reward: [(0, '1444.875')]
[2025-11-06 16:47:47,792][322896] Fps is (10 sec: 3253.4, 60 sec: 3816.4, 300 sec: 3695.6). Total num frames: 10715136. Throughput: 0: 3695.8. Samples: 10715136. Policy #0 lag: (min: 14.0, avg: 17.0, max: 78.0)
[2025-11-06 16:47:47,792][322896] Avg episode reward: [(0, '1421.310')]
[2025-11-06 16:47:52,741][322896] Fps is (10 sec: 3285.2, 60 sec: 3697.2, 300 sec: 3665.6). Total num frames: 10731520. Throughput: 0: 3694.8. Samples: 10736128. Policy #0 lag: (min: 14.0, avg: 17.0, max: 78.0)
[2025-11-06 16:47:52,741][322896] Avg episode reward: [(0, '1429.302')]
[2025-11-06 16:47:57,752][322896] Fps is (10 sec: 3290.0, 60 sec: 3547.0, 300 sec: 3665.8). Total num frames: 10747904. Throughput: 0: 3696.8. Samples: 10748416. Policy #0 lag: (min: 14.0, avg: 17.0, max: 78.0)
[2025-11-06 16:47:57,752][322896] Avg episode reward: [(0, '1417.434')]
[2025-11-06 16:47:57,887][322896] Saving /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_lidar_policy2_acc_yaw_sp/checkpoint_p0/checkpoint_000041984_10747904.pth...
[2025-11-06 16:47:57,891][322896] Removing /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_lidar_policy2_acc_yaw_sp/checkpoint_p0/checkpoint_000038528_9863168.pth
[2025-11-06 16:48:02,687][322896] Fps is (10 sec: 3294.6, 60 sec: 3554.7, 300 sec: 3665.9). Total num frames: 10764288. Throughput: 0: 3705.9. Samples: 10769408. Policy #0 lag: (min: 14.0, avg: 17.0, max: 78.0)
[2025-11-06 16:48:02,687][322896] Avg episode reward: [(0, '1458.216')]
[2025-11-06 16:48:07,730][322896] Fps is (10 sec: 3284.0, 60 sec: 3548.4, 300 sec: 3666.0). Total num frames: 10780672. Throughput: 0: 3697.6. Samples: 10792448. Policy #0 lag: (min: 14.0, avg: 17.0, max: 78.0)
[2025-11-06 16:48:07,730][322896] Avg episode reward: [(0, '1427.929')]
[2025-11-06 16:48:12,794][322896] Fps is (10 sec: 4052.5, 60 sec: 3683.1, 300 sec: 3693.1). Total num frames: 10805248. Throughput: 0: 3684.2. Samples: 10802688. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:48:12,794][322896] Avg episode reward: [(0, '1459.508')]
[2025-11-06 16:48:17,683][322896] Fps is (10 sec: 4938.5, 60 sec: 3829.5, 300 sec: 3721.4). Total num frames: 10829824. Throughput: 0: 3695.9. Samples: 10825728. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:48:17,683][322896] Avg episode reward: [(0, '1443.554')]
[2025-11-06 16:48:22,724][322896] Fps is (10 sec: 4125.1, 60 sec: 3823.2, 300 sec: 3721.3). Total num frames: 10846208. Throughput: 0: 3663.4. Samples: 10847232. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:48:22,724][322896] Avg episode reward: [(0, '1427.499')]
[2025-11-06 16:48:27,680][322896] Fps is (10 sec: 3277.7, 60 sec: 3828.5, 300 sec: 3696.5). Total num frames: 10862592. Throughput: 0: 3704.9. Samples: 10859008. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:48:27,680][322896] Avg episode reward: [(0, '1440.796')]
[2025-11-06 16:48:32,778][322896] Fps is (10 sec: 3259.1, 60 sec: 3687.7, 300 sec: 3665.3). Total num frames: 10878976. Throughput: 0: 3664.8. Samples: 10880000. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:48:32,778][322896] Avg episode reward: [(0, '1451.020')]
[2025-11-06 16:48:37,728][322896] Fps is (10 sec: 3261.3, 60 sec: 3549.4, 300 sec: 3665.3). Total num frames: 10895360. Throughput: 0: 3698.9. Samples: 10902528. Policy #0 lag: (min: 24.0, avg: 27.0, max: 88.0)
[2025-11-06 16:48:37,728][322896] Avg episode reward: [(0, '1401.540')]
[2025-11-06 16:48:42,692][322896] Fps is (10 sec: 3305.1, 60 sec: 3554.3, 300 sec: 3666.2). Total num frames: 10911744. Throughput: 0: 3657.1. Samples: 10912768. Policy #0 lag: (min: 24.0, avg: 27.0, max: 88.0)
[2025-11-06 16:48:42,693][322896] Avg episode reward: [(0, '1391.579')]
[2025-11-06 16:48:44,172][322896] Signal inference workers to stop experience collection... (2000 times)
[2025-11-06 16:48:44,512][322896] InferenceWorker_p0-w0: stopping experience collection (2000 times)
[2025-11-06 16:48:44,512][322896] Signal inference workers to resume experience collection... (2000 times)
[2025-11-06 16:48:44,513][322896] InferenceWorker_p0-w0: resuming experience collection (2000 times)
[2025-11-06 16:48:47,720][322896] Fps is (10 sec: 3279.2, 60 sec: 3554.1, 300 sec: 3665.4). Total num frames: 10928128. Throughput: 0: 3672.3. Samples: 10934784. Policy #0 lag: (min: 24.0, avg: 27.0, max: 88.0)
[2025-11-06 16:48:47,720][322896] Avg episode reward: [(0, '1458.372')]
[2025-11-06 16:48:52,689][322896] Fps is (10 sec: 3278.1, 60 sec: 3553.0, 300 sec: 3666.0). Total num frames: 10944512. Throughput: 0: 3655.6. Samples: 10956800. Policy #0 lag: (min: 24.0, avg: 27.0, max: 88.0)
[2025-11-06 16:48:52,689][322896] Avg episode reward: [(0, '1410.048')]
[2025-11-06 16:48:57,918][322896] Fps is (10 sec: 4819.8, 60 sec: 3812.4, 300 sec: 3719.1). Total num frames: 10977280. Throughput: 0: 3653.6. Samples: 10967552. Policy #0 lag: (min: 24.0, avg: 27.0, max: 88.0)
[2025-11-06 16:48:57,918][322896] Avg episode reward: [(0, '1439.840')]
[2025-11-06 16:49:02,685][322896] Fps is (10 sec: 4916.7, 60 sec: 3823.0, 300 sec: 3721.4). Total num frames: 10993664. Throughput: 0: 3663.4. Samples: 10990592. Policy #0 lag: (min: 29.0, avg: 32.0, max: 93.0)
[2025-11-06 16:49:02,686][322896] Avg episode reward: [(0, '1514.620')]
[2025-11-06 16:49:07,710][322896] Fps is (10 sec: 3346.6, 60 sec: 3824.2, 300 sec: 3696.7). Total num frames: 11010048. Throughput: 0: 3642.0. Samples: 11011072. Policy #0 lag: (min: 29.0, avg: 32.0, max: 93.0)
[2025-11-06 16:49:07,710][322896] Avg episode reward: [(0, '1491.067')]
[2025-11-06 16:49:12,764][322896] Fps is (10 sec: 3251.3, 60 sec: 3688.3, 300 sec: 3665.1). Total num frames: 11026432. Throughput: 0: 3656.8. Samples: 11023872. Policy #0 lag: (min: 29.0, avg: 32.0, max: 93.0)
[2025-11-06 16:49:12,764][322896] Avg episode reward: [(0, '1475.511')]
[2025-11-06 16:49:17,772][322896] Fps is (10 sec: 3256.6, 60 sec: 3544.6, 300 sec: 3665.5). Total num frames: 11042816. Throughput: 0: 3675.5. Samples: 11045376. Policy #0 lag: (min: 29.0, avg: 32.0, max: 93.0)
[2025-11-06 16:49:17,772][322896] Avg episode reward: [(0, '1483.925')]
[2025-11-06 16:49:22,725][322896] Fps is (10 sec: 3289.5, 60 sec: 3549.8, 300 sec: 3665.0). Total num frames: 11059200. Throughput: 0: 3675.2. Samples: 11067904. Policy #0 lag: (min: 29.0, avg: 32.0, max: 93.0)
[2025-11-06 16:49:22,726][322896] Avg episode reward: [(0, '1515.286')]
[2025-11-06 16:49:27,706][322896] Fps is (10 sec: 3298.6, 60 sec: 3548.4, 300 sec: 3665.9). Total num frames: 11075584. Throughput: 0: 3685.3. Samples: 11078656. Policy #0 lag: (min: 29.0, avg: 32.0, max: 93.0)
[2025-11-06 16:49:27,706][322896] Avg episode reward: [(0, '1497.095')]
[2025-11-06 16:49:32,938][322896] Fps is (10 sec: 4010.7, 60 sec: 3676.6, 300 sec: 3691.5). Total num frames: 11100160. Throughput: 0: 3680.0. Samples: 11101184. Policy #0 lag: (min: 2.0, avg: 5.0, max: 66.0)
[2025-11-06 16:49:32,938][322896] Avg episode reward: [(0, '1393.748')]
[2025-11-06 16:49:37,794][322896] Fps is (10 sec: 4872.2, 60 sec: 3818.7, 300 sec: 3720.1). Total num frames: 11124736. Throughput: 0: 3700.5. Samples: 11123712. Policy #0 lag: (min: 2.0, avg: 5.0, max: 66.0)
[2025-11-06 16:49:37,794][322896] Avg episode reward: [(0, '1459.378')]
[2025-11-06 16:49:42,785][322896] Fps is (10 sec: 4159.6, 60 sec: 3817.0, 300 sec: 3719.9). Total num frames: 11141120. Throughput: 0: 3720.2. Samples: 11134464. Policy #0 lag: (min: 2.0, avg: 5.0, max: 66.0)
[2025-11-06 16:49:42,785][322896] Avg episode reward: [(0, '1451.683')]
[2025-11-06 16:49:47,701][322896] Fps is (10 sec: 3307.6, 60 sec: 3824.2, 300 sec: 3721.1). Total num frames: 11157504. Throughput: 0: 3707.9. Samples: 11157504. Policy #0 lag: (min: 2.0, avg: 5.0, max: 66.0)
[2025-11-06 16:49:47,701][322896] Avg episode reward: [(0, '1500.289')]
[2025-11-06 16:49:52,772][322896] Fps is (10 sec: 3281.0, 60 sec: 3817.6, 300 sec: 3665.4). Total num frames: 11173888. Throughput: 0: 3715.4. Samples: 11178496. Policy #0 lag: (min: 2.0, avg: 5.0, max: 66.0)
[2025-11-06 16:49:52,772][322896] Avg episode reward: [(0, '1519.421')]
[2025-11-06 16:49:57,750][322896] Fps is (10 sec: 3260.7, 60 sec: 3559.8, 300 sec: 3665.4). Total num frames: 11190272. Throughput: 0: 3710.3. Samples: 11190784. Policy #0 lag: (min: 2.0, avg: 5.0, max: 66.0)
[2025-11-06 16:49:57,750][322896] Avg episode reward: [(0, '1535.974')]
[2025-11-06 16:49:57,879][322896] Saving /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_lidar_policy2_acc_yaw_sp/checkpoint_p0/checkpoint_000043712_11190272.pth...
[2025-11-06 16:49:57,883][322896] Removing /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_lidar_policy2_acc_yaw_sp/checkpoint_p0/checkpoint_000040256_10305536.pth
[2025-11-06 16:49:57,883][322896] Saving new best policy, reward=1535.974!
[2025-11-06 16:49:59,596][322896] Signal inference workers to stop experience collection... (2050 times)
[2025-11-06 16:49:59,596][322896] Signal inference workers to resume experience collection... (2050 times)
[2025-11-06 16:49:59,842][322896] InferenceWorker_p0-w0: stopping experience collection (2050 times)
[2025-11-06 16:49:59,842][322896] InferenceWorker_p0-w0: resuming experience collection (2050 times)
[2025-11-06 16:50:02,733][322896] Fps is (10 sec: 3289.5, 60 sec: 3547.0, 300 sec: 3665.9). Total num frames: 11206656. Throughput: 0: 3689.5. Samples: 11211264. Policy #0 lag: (min: 2.0, avg: 5.0, max: 66.0)
[2025-11-06 16:50:02,734][322896] Avg episode reward: [(0, '1505.702')]
[2025-11-06 16:50:07,673][322896] Fps is (10 sec: 3302.2, 60 sec: 3552.0, 300 sec: 3665.8). Total num frames: 11223040. Throughput: 0: 3690.7. Samples: 11233792. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:50:07,673][322896] Avg episode reward: [(0, '1551.407')]
[2025-11-06 16:50:07,798][322896] Saving new best policy, reward=1551.407!
[2025-11-06 16:50:12,947][322896] Fps is (10 sec: 4010.2, 60 sec: 3675.2, 300 sec: 3690.5). Total num frames: 11247616. Throughput: 0: 3666.7. Samples: 11244544. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:50:12,948][322896] Avg episode reward: [(0, '1538.447')]
[2025-11-06 16:50:17,678][322896] Fps is (10 sec: 4912.8, 60 sec: 3828.9, 300 sec: 3721.1). Total num frames: 11272192. Throughput: 0: 3719.3. Samples: 11267584. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:50:17,678][322896] Avg episode reward: [(0, '1474.656')]
[2025-11-06 16:50:22,701][322896] Fps is (10 sec: 4199.6, 60 sec: 3824.5, 300 sec: 3721.0). Total num frames: 11288576. Throughput: 0: 3694.0. Samples: 11289600. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:50:22,701][322896] Avg episode reward: [(0, '1403.722')]
[2025-11-06 16:50:27,681][322896] Fps is (10 sec: 3275.8, 60 sec: 3824.5, 300 sec: 3694.9). Total num frames: 11304960. Throughput: 0: 3694.9. Samples: 11300352. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:50:27,681][322896] Avg episode reward: [(0, '1430.201')]
[2025-11-06 16:50:32,725][322896] Fps is (10 sec: 3269.0, 60 sec: 3699.6, 300 sec: 3665.8). Total num frames: 11321344. Throughput: 0: 3661.7. Samples: 11322368. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:50:32,725][322896] Avg episode reward: [(0, '1510.306')]
[2025-11-06 16:50:37,679][322896] Fps is (10 sec: 3277.6, 60 sec: 3556.7, 300 sec: 3665.6). Total num frames: 11337728. Throughput: 0: 3682.7. Samples: 11343872. Policy #0 lag: (min: 10.0, avg: 13.0, max: 74.0)
[2025-11-06 16:50:37,679][322896] Avg episode reward: [(0, '1630.048')]
[2025-11-06 16:50:37,803][322896] Saving new best policy, reward=1630.048!
[2025-11-06 16:50:42,774][322896] Fps is (10 sec: 3260.5, 60 sec: 3550.5, 300 sec: 3665.5). Total num frames: 11354112. Throughput: 0: 3650.3. Samples: 11355136. Policy #0 lag: (min: 10.0, avg: 13.0, max: 74.0)
[2025-11-06 16:50:42,775][322896] Avg episode reward: [(0, '1612.947')]
[2025-11-06 16:50:47,685][322896] Fps is (10 sec: 3274.8, 60 sec: 3550.8, 300 sec: 3666.5). Total num frames: 11370496. Throughput: 0: 3701.8. Samples: 11377664. Policy #0 lag: (min: 10.0, avg: 13.0, max: 74.0)
[2025-11-06 16:50:47,685][322896] Avg episode reward: [(0, '1492.944')]
[2025-11-06 16:50:52,713][322896] Fps is (10 sec: 3297.2, 60 sec: 3553.4, 300 sec: 3666.3). Total num frames: 11386880. Throughput: 0: 3694.5. Samples: 11400192. Policy #0 lag: (min: 10.0, avg: 13.0, max: 74.0)
[2025-11-06 16:50:52,713][322896] Avg episode reward: [(0, '1483.276')]
[2025-11-06 16:50:57,793][322896] Fps is (10 sec: 4862.6, 60 sec: 3820.2, 300 sec: 3719.7). Total num frames: 11419648. Throughput: 0: 3699.1. Samples: 11410432. Policy #0 lag: (min: 10.0, avg: 13.0, max: 74.0)
[2025-11-06 16:50:57,794][322896] Avg episode reward: [(0, '1464.406')]
[2025-11-06 16:51:02,720][322896] Fps is (10 sec: 4911.7, 60 sec: 3823.8, 300 sec: 3720.6). Total num frames: 11436032. Throughput: 0: 3683.0. Samples: 11433472. Policy #0 lag: (min: 10.0, avg: 13.0, max: 74.0)
[2025-11-06 16:51:02,720][322896] Avg episode reward: [(0, '1504.218')]
[2025-11-06 16:51:07,793][322896] Fps is (10 sec: 3276.9, 60 sec: 3815.3, 300 sec: 3693.5). Total num frames: 11452416. Throughput: 0: 3656.2. Samples: 11454464. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:51:07,793][322896] Avg episode reward: [(0, '1496.796')]
[2025-11-06 16:51:12,785][322896] Fps is (10 sec: 3255.6, 60 sec: 3696.4, 300 sec: 3665.1). Total num frames: 11468800. Throughput: 0: 3677.9. Samples: 11466240. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:51:12,785][322896] Avg episode reward: [(0, '1516.595')]
[2025-11-06 16:51:14,905][322896] Signal inference workers to stop experience collection... (2100 times)
[2025-11-06 16:51:15,244][322896] InferenceWorker_p0-w0: stopping experience collection (2100 times)
[2025-11-06 16:51:15,246][322896] Signal inference workers to resume experience collection... (2100 times)
[2025-11-06 16:51:15,365][322896] InferenceWorker_p0-w0: resuming experience collection (2100 times)
[2025-11-06 16:51:17,681][322896] Fps is (10 sec: 3314.0, 60 sec: 3549.7, 300 sec: 3666.0). Total num frames: 11485184. Throughput: 0: 3667.2. Samples: 11487232. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:51:17,681][322896] Avg episode reward: [(0, '1535.723')]
[2025-11-06 16:51:22,762][322896] Fps is (10 sec: 3284.2, 60 sec: 3546.2, 300 sec: 3664.8). Total num frames: 11501568. Throughput: 0: 3690.9. Samples: 11510272. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:51:22,763][322896] Avg episode reward: [(0, '1615.886')]
[2025-11-06 16:51:27,683][322896] Fps is (10 sec: 3276.0, 60 sec: 3549.7, 300 sec: 3666.2). Total num frames: 11517952. Throughput: 0: 3682.5. Samples: 11520512. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:51:27,684][322896] Avg episode reward: [(0, '1644.537')]
[2025-11-06 16:51:27,819][322896] Saving new best policy, reward=1644.537!
[2025-11-06 16:51:32,922][322896] Fps is (10 sec: 4031.4, 60 sec: 3674.3, 300 sec: 3691.7). Total num frames: 11542528. Throughput: 0: 3667.1. Samples: 11543552. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:51:32,923][322896] Avg episode reward: [(0, '1528.786')]
[2025-11-06 16:51:37,786][322896] Fps is (10 sec: 4865.5, 60 sec: 3816.1, 300 sec: 3720.4). Total num frames: 11567104. Throughput: 0: 3691.8. Samples: 11566592. Policy #0 lag: (min: 7.0, avg: 10.0, max: 71.0)
[2025-11-06 16:51:37,786][322896] Avg episode reward: [(0, '1524.852')]
[2025-11-06 16:51:42,777][322896] Fps is (10 sec: 4156.6, 60 sec: 3822.8, 300 sec: 3720.0). Total num frames: 11583488. Throughput: 0: 3710.5. Samples: 11577344. Policy #0 lag: (min: 7.0, avg: 10.0, max: 71.0)
[2025-11-06 16:51:42,777][322896] Avg episode reward: [(0, '1569.149')]
[2025-11-06 16:51:47,698][322896] Fps is (10 sec: 3305.9, 60 sec: 3822.1, 300 sec: 3696.1). Total num frames: 11599872. Throughput: 0: 3699.6. Samples: 11599872. Policy #0 lag: (min: 7.0, avg: 10.0, max: 71.0)
[2025-11-06 16:51:47,698][322896] Avg episode reward: [(0, '1543.484')]
[2025-11-06 16:51:52,737][322896] Fps is (10 sec: 3289.7, 60 sec: 3821.4, 300 sec: 3665.1). Total num frames: 11616256. Throughput: 0: 3702.3. Samples: 11620864. Policy #0 lag: (min: 7.0, avg: 10.0, max: 71.0)
[2025-11-06 16:51:52,738][322896] Avg episode reward: [(0, '1566.543')]
[2025-11-06 16:51:57,739][322896] Fps is (10 sec: 3263.2, 60 sec: 3553.1, 300 sec: 3665.9). Total num frames: 11632640. Throughput: 0: 3712.9. Samples: 11633152. Policy #0 lag: (min: 7.0, avg: 10.0, max: 71.0)
[2025-11-06 16:51:57,739][322896] Avg episode reward: [(0, '1529.005')]
[2025-11-06 16:51:57,881][322896] Saving /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_lidar_policy2_acc_yaw_sp/checkpoint_p0/checkpoint_000045440_11632640.pth...
[2025-11-06 16:51:57,885][322896] Removing /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_lidar_policy2_acc_yaw_sp/checkpoint_p0/checkpoint_000041984_10747904.pth
[2025-11-06 16:52:02,726][322896] Fps is (10 sec: 3280.4, 60 sec: 3549.5, 300 sec: 3665.3). Total num frames: 11649024. Throughput: 0: 3694.0. Samples: 11653632. Policy #0 lag: (min: 7.0, avg: 10.0, max: 71.0)
[2025-11-06 16:52:02,727][322896] Avg episode reward: [(0, '1513.531')]
[2025-11-06 16:52:07,747][322896] Fps is (10 sec: 3274.2, 60 sec: 3552.6, 300 sec: 3665.5). Total num frames: 11665408. Throughput: 0: 3699.0. Samples: 11676672. Policy #0 lag: (min: 7.0, avg: 10.0, max: 71.0)
[2025-11-06 16:52:07,747][322896] Avg episode reward: [(0, '1538.749')]
[2025-11-06 16:52:12,909][322896] Fps is (10 sec: 4022.5, 60 sec: 3678.8, 300 sec: 3691.8). Total num frames: 11689984. Throughput: 0: 3679.3. Samples: 11686912. Policy #0 lag: (min: 2.0, avg: 5.0, max: 66.0)
[2025-11-06 16:52:12,909][322896] Avg episode reward: [(0, '1486.175')]
[2025-11-06 16:52:17,760][322896] Fps is (10 sec: 4908.9, 60 sec: 3817.9, 300 sec: 3720.7). Total num frames: 11714560. Throughput: 0: 3711.2. Samples: 11709952. Policy #0 lag: (min: 2.0, avg: 5.0, max: 66.0)
[2025-11-06 16:52:17,760][322896] Avg episode reward: [(0, '1470.814')]
[2025-11-06 16:52:22,795][322896] Fps is (10 sec: 4143.4, 60 sec: 3820.9, 300 sec: 3720.8). Total num frames: 11730944. Throughput: 0: 3674.3. Samples: 11731968. Policy #0 lag: (min: 2.0, avg: 5.0, max: 66.0)
[2025-11-06 16:52:22,795][322896] Avg episode reward: [(0, '1506.367')]
[2025-11-06 16:52:26,287][322896] Signal inference workers to stop experience collection... (2150 times)
[2025-11-06 16:52:26,616][322896] InferenceWorker_p0-w0: stopping experience collection (2150 times)
[2025-11-06 16:52:26,616][322896] Signal inference workers to resume experience collection... (2150 times)
[2025-11-06 16:52:26,616][322896] InferenceWorker_p0-w0: resuming experience collection (2150 times)
[2025-11-06 16:52:27,759][322896] Fps is (10 sec: 3277.0, 60 sec: 3818.1, 300 sec: 3693.8). Total num frames: 11747328. Throughput: 0: 3676.4. Samples: 11742720. Policy #0 lag: (min: 2.0, avg: 5.0, max: 66.0)
[2025-11-06 16:52:27,760][322896] Avg episode reward: [(0, '1530.793')]
[2025-11-06 16:52:32,772][322896] Fps is (10 sec: 3284.3, 60 sec: 3695.7, 300 sec: 3664.9). Total num frames: 11763712. Throughput: 0: 3657.6. Samples: 11764736. Policy #0 lag: (min: 2.0, avg: 5.0, max: 66.0)
[2025-11-06 16:52:32,772][322896] Avg episode reward: [(0, '1530.500')]
[2025-11-06 16:52:37,729][322896] Fps is (10 sec: 3286.9, 60 sec: 3553.2, 300 sec: 3666.0). Total num frames: 11780096. Throughput: 0: 3687.1. Samples: 11786752. Policy #0 lag: (min: 2.0, avg: 5.0, max: 66.0)
[2025-11-06 16:52:37,729][322896] Avg episode reward: [(0, '1532.106')]
[2025-11-06 16:52:42,775][322896] Fps is (10 sec: 3275.9, 60 sec: 3550.0, 300 sec: 3665.8). Total num frames: 11796480. Throughput: 0: 3649.4. Samples: 11797504. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:52:42,775][322896] Avg episode reward: [(0, '1489.231')]
[2025-11-06 16:52:47,711][322896] Fps is (10 sec: 3282.7, 60 sec: 3549.1, 300 sec: 3665.9). Total num frames: 11812864. Throughput: 0: 3699.1. Samples: 11820032. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:52:47,711][322896] Avg episode reward: [(0, '1577.710')]
[2025-11-06 16:52:52,891][322896] Fps is (10 sec: 4049.2, 60 sec: 3677.0, 300 sec: 3691.6). Total num frames: 11837440. Throughput: 0: 3686.0. Samples: 11843072. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:52:52,891][322896] Avg episode reward: [(0, '1544.275')]
[2025-11-06 16:52:57,764][322896] Fps is (10 sec: 4889.0, 60 sec: 3821.3, 300 sec: 3720.1). Total num frames: 11862016. Throughput: 0: 3709.7. Samples: 11853312. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:52:57,764][322896] Avg episode reward: [(0, '1571.242')]
[2025-11-06 16:53:02,675][322896] Fps is (10 sec: 4186.1, 60 sec: 3826.2, 300 sec: 3721.8). Total num frames: 11878400. Throughput: 0: 3704.8. Samples: 11876352. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:53:02,675][322896] Avg episode reward: [(0, '1571.452')]
[2025-11-06 16:53:07,737][322896] Fps is (10 sec: 3285.9, 60 sec: 3823.6, 300 sec: 3694.1). Total num frames: 11894784. Throughput: 0: 3679.8. Samples: 11897344. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:53:07,737][322896] Avg episode reward: [(0, '1567.187')]
[2025-11-06 16:53:12,745][322896] Fps is (10 sec: 3254.0, 60 sec: 3696.5, 300 sec: 3664.8). Total num frames: 11911168. Throughput: 0: 3710.3. Samples: 11909632. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:53:12,745][322896] Avg episode reward: [(0, '1526.568')]
[2025-11-06 16:53:17,752][322896] Fps is (10 sec: 3271.9, 60 sec: 3550.4, 300 sec: 3665.2). Total num frames: 11927552. Throughput: 0: 3688.1. Samples: 11930624. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:53:17,752][322896] Avg episode reward: [(0, '1537.619')]
[2025-11-06 16:53:22,717][322896] Fps is (10 sec: 3286.0, 60 sec: 3554.5, 300 sec: 3665.1). Total num frames: 11943936. Throughput: 0: 3698.7. Samples: 11953152. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:53:22,718][322896] Avg episode reward: [(0, '1522.946')]
[2025-11-06 16:53:27,743][322896] Fps is (10 sec: 3279.7, 60 sec: 3550.8, 300 sec: 3666.0). Total num frames: 11960320. Throughput: 0: 3700.4. Samples: 11963904. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:53:27,743][322896] Avg episode reward: [(0, '1580.698')]
[2025-11-06 16:53:32,757][322896] Fps is (10 sec: 4079.7, 60 sec: 3687.3, 300 sec: 3693.0). Total num frames: 11984896. Throughput: 0: 3705.3. Samples: 11986944. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:53:32,758][322896] Avg episode reward: [(0, '1525.135')]
[2025-11-06 16:53:37,729][322896] Fps is (10 sec: 4922.2, 60 sec: 3822.9, 300 sec: 3720.7). Total num frames: 12009472. Throughput: 0: 3711.1. Samples: 12009472. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:53:37,729][322896] Avg episode reward: [(0, '1571.590')]
[2025-11-06 16:53:41,635][322896] Signal inference workers to stop experience collection... (2200 times)
[2025-11-06 16:53:41,637][322896] Signal inference workers to resume experience collection... (2200 times)
[2025-11-06 16:53:41,870][322896] InferenceWorker_p0-w0: stopping experience collection (2200 times)
[2025-11-06 16:53:41,870][322896] InferenceWorker_p0-w0: resuming experience collection (2200 times)
[2025-11-06 16:53:42,731][322896] Fps is (10 sec: 4107.0, 60 sec: 3825.8, 300 sec: 3721.0). Total num frames: 12025856. Throughput: 0: 3700.5. Samples: 12019712. Policy #0 lag: (min: 12.0, avg: 15.0, max: 76.0)
[2025-11-06 16:53:42,731][322896] Avg episode reward: [(0, '1569.803')]
[2025-11-06 16:53:47,729][322896] Fps is (10 sec: 3276.8, 60 sec: 3821.8, 300 sec: 3720.6). Total num frames: 12042240. Throughput: 0: 3693.4. Samples: 12042752. Policy #0 lag: (min: 12.0, avg: 15.0, max: 76.0)
[2025-11-06 16:53:47,729][322896] Avg episode reward: [(0, '1560.374')]
[2025-11-06 16:53:52,785][322896] Fps is (10 sec: 3259.2, 60 sec: 3692.9, 300 sec: 3667.2). Total num frames: 12058624. Throughput: 0: 3682.5. Samples: 12063232. Policy #0 lag: (min: 12.0, avg: 15.0, max: 76.0)
[2025-11-06 16:53:52,785][322896] Avg episode reward: [(0, '1490.570')]
[2025-11-06 16:53:57,706][322896] Fps is (10 sec: 3284.4, 60 sec: 3553.3, 300 sec: 3665.3). Total num frames: 12075008. Throughput: 0: 3689.7. Samples: 12075520. Policy #0 lag: (min: 12.0, avg: 15.0, max: 76.0)
[2025-11-06 16:53:57,706][322896] Avg episode reward: [(0, '1529.582')]
[2025-11-06 16:53:57,843][322896] Saving /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_lidar_policy2_acc_yaw_sp/checkpoint_p0/checkpoint_000047168_12075008.pth...
[2025-11-06 16:53:57,846][322896] Removing /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_lidar_policy2_acc_yaw_sp/checkpoint_p0/checkpoint_000043712_11190272.pth
[2025-11-06 16:54:02,775][322896] Fps is (10 sec: 3280.0, 60 sec: 3544.0, 300 sec: 3664.8). Total num frames: 12091392. Throughput: 0: 3684.5. Samples: 12096512. Policy #0 lag: (min: 12.0, avg: 15.0, max: 76.0)
[2025-11-06 16:54:02,775][322896] Avg episode reward: [(0, '1520.118')]
[2025-11-06 16:54:07,792][322896] Fps is (10 sec: 3248.6, 60 sec: 3546.6, 300 sec: 3665.2). Total num frames: 12107776. Throughput: 0: 3703.0. Samples: 12120064. Policy #0 lag: (min: 12.0, avg: 15.0, max: 76.0)
[2025-11-06 16:54:07,793][322896] Avg episode reward: [(0, '1510.853')]
[2025-11-06 16:54:12,709][322896] Fps is (10 sec: 4123.2, 60 sec: 3688.6, 300 sec: 3694.1). Total num frames: 12132352. Throughput: 0: 3700.6. Samples: 12130304. Policy #0 lag: (min: 6.0, avg: 9.0, max: 70.0)
[2025-11-06 16:54:12,709][322896] Avg episode reward: [(0, '1594.080')]
[2025-11-06 16:54:17,728][322896] Fps is (10 sec: 4946.9, 60 sec: 3824.4, 300 sec: 3721.1). Total num frames: 12156928. Throughput: 0: 3700.2. Samples: 12153344. Policy #0 lag: (min: 6.0, avg: 9.0, max: 70.0)
[2025-11-06 16:54:17,728][322896] Avg episode reward: [(0, '1684.818')]
[2025-11-06 16:54:17,878][322896] Saving new best policy, reward=1684.818!
[2025-11-06 16:54:22,756][322896] Fps is (10 sec: 4076.9, 60 sec: 3820.5, 300 sec: 3720.5). Total num frames: 12173312. Throughput: 0: 3661.4. Samples: 12174336. Policy #0 lag: (min: 6.0, avg: 9.0, max: 70.0)
[2025-11-06 16:54:22,756][322896] Avg episode reward: [(0, '1656.583')]
[2025-11-06 16:54:27,784][322896] Fps is (10 sec: 3258.5, 60 sec: 3820.3, 300 sec: 3695.3). Total num frames: 12189696. Throughput: 0: 3693.4. Samples: 12186112. Policy #0 lag: (min: 6.0, avg: 9.0, max: 70.0)
[2025-11-06 16:54:27,785][322896] Avg episode reward: [(0, '1628.322')]
[2025-11-06 16:54:32,756][322896] Fps is (10 sec: 3276.8, 60 sec: 3686.5, 300 sec: 3666.0). Total num frames: 12206080. Throughput: 0: 3650.1. Samples: 12207104. Policy #0 lag: (min: 6.0, avg: 9.0, max: 70.0)
[2025-11-06 16:54:32,756][322896] Avg episode reward: [(0, '1624.058')]
[2025-11-06 16:54:37,696][322896] Fps is (10 sec: 3305.9, 60 sec: 3551.8, 300 sec: 3666.7). Total num frames: 12222464. Throughput: 0: 3705.0. Samples: 12229632. Policy #0 lag: (min: 6.0, avg: 9.0, max: 70.0)
[2025-11-06 16:54:37,696][322896] Avg episode reward: [(0, '1653.756')]
[2025-11-06 16:54:42,673][322896] Fps is (10 sec: 3304.2, 60 sec: 3553.3, 300 sec: 3665.9). Total num frames: 12238848. Throughput: 0: 3654.9. Samples: 12239872. Policy #0 lag: (min: 6.0, avg: 9.0, max: 70.0)
[2025-11-06 16:54:42,673][322896] Avg episode reward: [(0, '1688.569')]
[2025-11-06 16:54:42,808][322896] Saving new best policy, reward=1688.569!
[2025-11-06 16:54:47,766][322896] Fps is (10 sec: 3254.2, 60 sec: 3547.7, 300 sec: 3665.7). Total num frames: 12255232. Throughput: 0: 3709.9. Samples: 12263424. Policy #0 lag: (min: 12.0, avg: 15.0, max: 76.0)
[2025-11-06 16:54:47,766][322896] Avg episode reward: [(0, '1769.510')]
[2025-11-06 16:54:47,896][322896] Saving new best policy, reward=1769.510!
[2025-11-06 16:54:52,724][322896] Fps is (10 sec: 4075.2, 60 sec: 3690.1, 300 sec: 3693.7). Total num frames: 12279808. Throughput: 0: 3692.0. Samples: 12285952. Policy #0 lag: (min: 12.0, avg: 15.0, max: 76.0)
[2025-11-06 16:54:52,724][322896] Avg episode reward: [(0, '1787.449')]
[2025-11-06 16:54:53,068][322896] Saving new best policy, reward=1787.449!
[2025-11-06 16:54:56,750][322896] Signal inference workers to stop experience collection... (2250 times)
[2025-11-06 16:54:57,122][322896] InferenceWorker_p0-w0: stopping experience collection (2250 times)
[2025-11-06 16:54:57,124][322896] Signal inference workers to resume experience collection... (2250 times)
[2025-11-06 16:54:57,261][322896] InferenceWorker_p0-w0: resuming experience collection (2250 times)
[2025-11-06 16:54:57,731][322896] Fps is (10 sec: 4932.2, 60 sec: 3821.3, 300 sec: 3721.1). Total num frames: 12304384. Throughput: 0: 3695.9. Samples: 12296704. Policy #0 lag: (min: 12.0, avg: 15.0, max: 76.0)
[2025-11-06 16:54:57,731][322896] Avg episode reward: [(0, '1786.164')]
[2025-11-06 16:55:02,762][322896] Fps is (10 sec: 4080.3, 60 sec: 3823.7, 300 sec: 3720.0). Total num frames: 12320768. Throughput: 0: 3683.6. Samples: 12319232. Policy #0 lag: (min: 12.0, avg: 15.0, max: 76.0)
[2025-11-06 16:55:02,763][322896] Avg episode reward: [(0, '1731.415')]
[2025-11-06 16:55:07,677][322896] Fps is (10 sec: 3294.7, 60 sec: 3830.3, 300 sec: 3696.7). Total num frames: 12337152. Throughput: 0: 3704.3. Samples: 12340736. Policy #0 lag: (min: 12.0, avg: 15.0, max: 76.0)
[2025-11-06 16:55:07,677][322896] Avg episode reward: [(0, '1708.751')]
[2025-11-06 16:55:12,743][322896] Fps is (10 sec: 3283.2, 60 sec: 3684.3, 300 sec: 3664.8). Total num frames: 12353536. Throughput: 0: 3701.2. Samples: 12352512. Policy #0 lag: (min: 12.0, avg: 15.0, max: 76.0)
[2025-11-06 16:55:12,743][322896] Avg episode reward: [(0, '1704.269')]
[2025-11-06 16:55:17,709][322896] Fps is (10 sec: 3266.3, 60 sec: 3551.0, 300 sec: 3665.5). Total num frames: 12369920. Throughput: 0: 3713.0. Samples: 12374016. Policy #0 lag: (min: 11.0, avg: 14.0, max: 75.0)
[2025-11-06 16:55:17,709][322896] Avg episode reward: [(0, '1762.592')]
[2025-11-06 16:55:22,676][322896] Fps is (10 sec: 3299.0, 60 sec: 3554.6, 300 sec: 3665.6). Total num frames: 12386304. Throughput: 0: 3710.8. Samples: 12396544. Policy #0 lag: (min: 11.0, avg: 14.0, max: 75.0)
[2025-11-06 16:55:22,676][322896] Avg episode reward: [(0, '1780.649')]
[2025-11-06 16:55:27,698][322896] Fps is (10 sec: 3280.4, 60 sec: 3555.0, 300 sec: 3665.9). Total num frames: 12402688. Throughput: 0: 3707.1. Samples: 12406784. Policy #0 lag: (min: 11.0, avg: 14.0, max: 75.0)
[2025-11-06 16:55:27,698][322896] Avg episode reward: [(0, '1704.709')]
[2025-11-06 16:55:32,959][322896] Fps is (10 sec: 4779.8, 60 sec: 3810.0, 300 sec: 3717.6). Total num frames: 12435456. Throughput: 0: 3682.0. Samples: 12429824. Policy #0 lag: (min: 11.0, avg: 14.0, max: 75.0)
[2025-11-06 16:55:32,959][322896] Avg episode reward: [(0, '1721.225')]
[2025-11-06 16:55:37,730][322896] Fps is (10 sec: 4899.7, 60 sec: 3820.8, 300 sec: 3721.7). Total num frames: 12451840. Throughput: 0: 3708.7. Samples: 12452864. Policy #0 lag: (min: 11.0, avg: 14.0, max: 75.0)
[2025-11-06 16:55:37,730][322896] Avg episode reward: [(0, '1723.975')]
[2025-11-06 16:55:42,773][322896] Fps is (10 sec: 3339.1, 60 sec: 3816.6, 300 sec: 3720.0). Total num frames: 12468224. Throughput: 0: 3694.4. Samples: 12463104. Policy #0 lag: (min: 11.0, avg: 14.0, max: 75.0)
[2025-11-06 16:55:42,773][322896] Avg episode reward: [(0, '1678.214')]
[2025-11-06 16:55:47,726][322896] Fps is (10 sec: 3278.1, 60 sec: 3825.5, 300 sec: 3720.9). Total num frames: 12484608. Throughput: 0: 3700.8. Samples: 12485632. Policy #0 lag: (min: 14.0, avg: 17.0, max: 78.0)
[2025-11-06 16:55:47,726][322896] Avg episode reward: [(0, '1664.953')]
[2025-11-06 16:55:52,713][322896] Fps is (10 sec: 3296.6, 60 sec: 3687.1, 300 sec: 3666.6). Total num frames: 12500992. Throughput: 0: 3694.8. Samples: 12507136. Policy #0 lag: (min: 14.0, avg: 17.0, max: 78.0)
[2025-11-06 16:55:52,713][322896] Avg episode reward: [(0, '1693.136')]
[2025-11-06 16:55:57,753][322896] Fps is (10 sec: 3268.0, 60 sec: 3548.6, 300 sec: 3665.2). Total num frames: 12517376. Throughput: 0: 3685.6. Samples: 12518400. Policy #0 lag: (min: 14.0, avg: 17.0, max: 78.0)
[2025-11-06 16:55:57,753][322896] Avg episode reward: [(0, '1719.879')]
[2025-11-06 16:55:57,888][322896] Saving /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_lidar_policy2_acc_yaw_sp/checkpoint_p0/checkpoint_000048896_12517376.pth...
[2025-11-06 16:55:57,891][322896] Removing /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_lidar_policy2_acc_yaw_sp/checkpoint_p0/checkpoint_000045440_11632640.pth
[2025-11-06 16:56:02,793][322896] Fps is (10 sec: 3250.6, 60 sec: 3548.0, 300 sec: 3665.6). Total num frames: 12533760. Throughput: 0: 3679.5. Samples: 12539904. Policy #0 lag: (min: 14.0, avg: 17.0, max: 78.0)
[2025-11-06 16:56:02,794][322896] Avg episode reward: [(0, '1709.994')]
[2025-11-06 16:56:07,767][322896] Fps is (10 sec: 3272.3, 60 sec: 3544.6, 300 sec: 3665.8). Total num frames: 12550144. Throughput: 0: 3690.3. Samples: 12562944. Policy #0 lag: (min: 14.0, avg: 17.0, max: 78.0)
[2025-11-06 16:56:07,767][322896] Avg episode reward: [(0, '1723.217')]
[2025-11-06 16:56:08,118][322896] Signal inference workers to stop experience collection... (2300 times)
[2025-11-06 16:56:08,464][322896] InferenceWorker_p0-w0: stopping experience collection (2300 times)
[2025-11-06 16:56:08,464][322896] Signal inference workers to resume experience collection... (2300 times)
[2025-11-06 16:56:08,464][322896] InferenceWorker_p0-w0: resuming experience collection (2300 times)
[2025-11-06 16:56:12,921][322896] Fps is (10 sec: 4853.1, 60 sec: 3811.6, 300 sec: 3718.1). Total num frames: 12582912. Throughput: 0: 3679.5. Samples: 12573184. Policy #0 lag: (min: 14.0, avg: 17.0, max: 78.0)
[2025-11-06 16:56:12,922][322896] Avg episode reward: [(0, '1797.295')]
[2025-11-06 16:56:12,922][322896] Saving new best policy, reward=1797.295!
[2025-11-06 16:56:17,761][322896] Fps is (10 sec: 4918.1, 60 sec: 3819.7, 300 sec: 3721.1). Total num frames: 12599296. Throughput: 0: 3714.2. Samples: 12596224. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:56:17,761][322896] Avg episode reward: [(0, '1745.287')]
[2025-11-06 16:56:22,785][322896] Fps is (10 sec: 3322.0, 60 sec: 3816.0, 300 sec: 3719.8). Total num frames: 12615680. Throughput: 0: 3636.4. Samples: 12616704. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:56:22,786][322896] Avg episode reward: [(0, '1732.930')]
[2025-11-06 16:56:27,786][322896] Fps is (10 sec: 3268.7, 60 sec: 3817.4, 300 sec: 3695.1). Total num frames: 12632064. Throughput: 0: 3674.0. Samples: 12628480. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:56:27,786][322896] Avg episode reward: [(0, '1728.925')]
[2025-11-06 16:56:32,717][322896] Fps is (10 sec: 3299.4, 60 sec: 3564.3, 300 sec: 3666.4). Total num frames: 12648448. Throughput: 0: 3641.6. Samples: 12649472. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:56:32,717][322896] Avg episode reward: [(0, '1737.592')]
[2025-11-06 16:56:37,681][322896] Fps is (10 sec: 3311.5, 60 sec: 3552.8, 300 sec: 3666.8). Total num frames: 12664832. Throughput: 0: 3677.6. Samples: 12672512. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:56:37,681][322896] Avg episode reward: [(0, '1758.614')]
[2025-11-06 16:56:42,764][322896] Fps is (10 sec: 3261.3, 60 sec: 3550.4, 300 sec: 3664.7). Total num frames: 12681216. Throughput: 0: 3640.0. Samples: 12682240. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:56:42,765][322896] Avg episode reward: [(0, '1768.313')]
[2025-11-06 16:56:47,743][322896] Fps is (10 sec: 3256.5, 60 sec: 3548.9, 300 sec: 3665.5). Total num frames: 12697600. Throughput: 0: 3679.1. Samples: 12705280. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:56:47,743][322896] Avg episode reward: [(0, '1776.176')]
[2025-11-06 16:56:52,829][322896] Fps is (10 sec: 4069.5, 60 sec: 3679.2, 300 sec: 3692.2). Total num frames: 12722176. Throughput: 0: 3658.5. Samples: 12727808. Policy #0 lag: (min: 2.0, avg: 5.0, max: 66.0)
[2025-11-06 16:56:52,830][322896] Avg episode reward: [(0, '1734.196')]
[2025-11-06 16:56:57,691][322896] Fps is (10 sec: 4941.1, 60 sec: 3826.9, 300 sec: 3721.6). Total num frames: 12746752. Throughput: 0: 3682.5. Samples: 12738048. Policy #0 lag: (min: 2.0, avg: 5.0, max: 66.0)
[2025-11-06 16:56:57,691][322896] Avg episode reward: [(0, '1725.489')]
[2025-11-06 16:57:02,757][322896] Fps is (10 sec: 4126.0, 60 sec: 3825.3, 300 sec: 3721.0). Total num frames: 12763136. Throughput: 0: 3664.0. Samples: 12761088. Policy #0 lag: (min: 2.0, avg: 5.0, max: 66.0)
[2025-11-06 16:57:02,757][322896] Avg episode reward: [(0, '1633.428')]
[2025-11-06 16:57:07,768][322896] Fps is (10 sec: 3251.6, 60 sec: 3822.8, 300 sec: 3695.1). Total num frames: 12779520. Throughput: 0: 3676.4. Samples: 12782080. Policy #0 lag: (min: 2.0, avg: 5.0, max: 66.0)
[2025-11-06 16:57:07,768][322896] Avg episode reward: [(0, '1622.047')]
[2025-11-06 16:57:12,734][322896] Fps is (10 sec: 3284.1, 60 sec: 3561.0, 300 sec: 3665.9). Total num frames: 12795904. Throughput: 0: 3690.6. Samples: 12794368. Policy #0 lag: (min: 2.0, avg: 5.0, max: 66.0)
[2025-11-06 16:57:12,735][322896] Avg episode reward: [(0, '1732.354')]
[2025-11-06 16:57:17,681][322896] Fps is (10 sec: 3305.7, 60 sec: 3554.6, 300 sec: 3667.0). Total num frames: 12812288. Throughput: 0: 3678.0. Samples: 12814848. Policy #0 lag: (min: 2.0, avg: 5.0, max: 66.0)
[2025-11-06 16:57:17,681][322896] Avg episode reward: [(0, '1737.937')]
[2025-11-06 16:57:22,794][322896] Fps is (10 sec: 3257.4, 60 sec: 3549.3, 300 sec: 3665.1). Total num frames: 12828672. Throughput: 0: 3665.8. Samples: 12837888. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:57:22,794][322896] Avg episode reward: [(0, '1789.469')]
[2025-11-06 16:57:24,026][322896] Signal inference workers to stop experience collection... (2350 times)
[2025-11-06 16:57:24,027][322896] Signal inference workers to resume experience collection... (2350 times)
[2025-11-06 16:57:24,260][322896] InferenceWorker_p0-w0: stopping experience collection (2350 times)
[2025-11-06 16:57:24,260][322896] InferenceWorker_p0-w0: resuming experience collection (2350 times)
[2025-11-06 16:57:27,717][322896] Fps is (10 sec: 3264.8, 60 sec: 3553.9, 300 sec: 3666.3). Total num frames: 12845056. Throughput: 0: 3690.2. Samples: 12848128. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:57:27,718][322896] Avg episode reward: [(0, '1797.538')]
[2025-11-06 16:57:27,847][322896] Saving new best policy, reward=1797.538!
[2025-11-06 16:57:32,881][322896] Fps is (10 sec: 4060.8, 60 sec: 3676.4, 300 sec: 3691.4). Total num frames: 12869632. Throughput: 0: 3675.2. Samples: 12871168. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:57:32,881][322896] Avg episode reward: [(0, '1835.487')]
[2025-11-06 16:57:33,218][322896] Saving new best policy, reward=1835.487!
[2025-11-06 16:57:37,706][322896] Fps is (10 sec: 4920.8, 60 sec: 3821.3, 300 sec: 3722.0). Total num frames: 12894208. Throughput: 0: 3696.5. Samples: 12893696. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:57:37,706][322896] Avg episode reward: [(0, '1697.277')]
[2025-11-06 16:57:42,678][322896] Fps is (10 sec: 4180.6, 60 sec: 3828.4, 300 sec: 3721.5). Total num frames: 12910592. Throughput: 0: 3687.4. Samples: 12903936. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:57:42,679][322896] Avg episode reward: [(0, '1644.367')]
[2025-11-06 16:57:47,795][322896] Fps is (10 sec: 3248.0, 60 sec: 3819.6, 300 sec: 3694.5). Total num frames: 12926976. Throughput: 0: 3671.9. Samples: 12926464. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:57:47,795][322896] Avg episode reward: [(0, '1676.304')]
[2025-11-06 16:57:52,741][322896] Fps is (10 sec: 3256.3, 60 sec: 3691.8, 300 sec: 3665.9). Total num frames: 12943360. Throughput: 0: 3677.2. Samples: 12947456. Policy #0 lag: (min: 40.0, avg: 43.0, max: 104.0)
[2025-11-06 16:57:52,742][322896] Avg episode reward: [(0, '1732.089')]
[2025-11-06 16:57:57,682][322896] Fps is (10 sec: 3314.1, 60 sec: 3550.4, 300 sec: 3665.5). Total num frames: 12959744. Throughput: 0: 3679.3. Samples: 12959744. Policy #0 lag: (min: 40.0, avg: 43.0, max: 104.0)
[2025-11-06 16:57:57,683][322896] Avg episode reward: [(0, '1702.157')]
[2025-11-06 16:57:57,814][322896] Saving /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_lidar_policy2_acc_yaw_sp/checkpoint_p0/checkpoint_000050624_12959744.pth...
[2025-11-06 16:57:57,818][322896] Removing /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_lidar_policy2_acc_yaw_sp/checkpoint_p0/checkpoint_000047168_12075008.pth
[2025-11-06 16:58:02,773][322896] Fps is (10 sec: 3266.5, 60 sec: 3548.9, 300 sec: 3665.1). Total num frames: 12976128. Throughput: 0: 3678.9. Samples: 12980736. Policy #0 lag: (min: 40.0, avg: 43.0, max: 104.0)
[2025-11-06 16:58:02,773][322896] Avg episode reward: [(0, '1599.946')]
[2025-11-06 16:58:07,687][322896] Fps is (10 sec: 3275.2, 60 sec: 3554.6, 300 sec: 3666.3). Total num frames: 12992512. Throughput: 0: 3683.8. Samples: 13003264. Policy #0 lag: (min: 40.0, avg: 43.0, max: 104.0)
[2025-11-06 16:58:07,688][322896] Avg episode reward: [(0, '1620.680')]
[2025-11-06 16:58:13,022][322896] Fps is (10 sec: 3197.0, 60 sec: 3532.9, 300 sec: 3662.2). Total num frames: 13008896. Throughput: 0: 3661.6. Samples: 13014016. Policy #0 lag: (min: 40.0, avg: 43.0, max: 104.0)
[2025-11-06 16:58:13,023][322896] Avg episode reward: [(0, '1723.120')]
[2025-11-06 16:58:17,900][322896] Fps is (10 sec: 4812.8, 60 sec: 3809.0, 300 sec: 3718.8). Total num frames: 13041664. Throughput: 0: 3673.4. Samples: 13036544. Policy #0 lag: (min: 40.0, avg: 43.0, max: 104.0)
[2025-11-06 16:58:17,900][322896] Avg episode reward: [(0, '1711.956')]
[2025-11-06 16:58:22,713][322896] Fps is (10 sec: 5072.1, 60 sec: 3828.1, 300 sec: 3721.5). Total num frames: 13058048. Throughput: 0: 3674.5. Samples: 13059072. Policy #0 lag: (min: 40.0, avg: 43.0, max: 104.0)
[2025-11-06 16:58:22,713][322896] Avg episode reward: [(0, '1747.205')]
[2025-11-06 16:58:27,736][322896] Fps is (10 sec: 3331.5, 60 sec: 3821.7, 300 sec: 3693.6). Total num frames: 13074432. Throughput: 0: 3670.3. Samples: 13069312. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:58:27,736][322896] Avg episode reward: [(0, '1674.196')]
[2025-11-06 16:58:32,742][322896] Fps is (10 sec: 3267.3, 60 sec: 3694.9, 300 sec: 3665.4). Total num frames: 13090816. Throughput: 0: 3667.9. Samples: 13091328. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:58:32,742][322896] Avg episode reward: [(0, '1610.167')]
[2025-11-06 16:58:37,704][322896] Fps is (10 sec: 3287.5, 60 sec: 3550.0, 300 sec: 3665.9). Total num frames: 13107200. Throughput: 0: 3666.7. Samples: 13112320. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:58:37,704][322896] Avg episode reward: [(0, '1586.316')]
[2025-11-06 16:58:39,590][322896] Signal inference workers to stop experience collection... (2400 times)
[2025-11-06 16:58:39,939][322896] InferenceWorker_p0-w0: stopping experience collection (2400 times)
[2025-11-06 16:58:39,941][322896] Signal inference workers to resume experience collection... (2400 times)
[2025-11-06 16:58:40,071][322896] InferenceWorker_p0-w0: resuming experience collection (2400 times)
[2025-11-06 16:58:42,772][322896] Fps is (10 sec: 3267.2, 60 sec: 3544.4, 300 sec: 3665.0). Total num frames: 13123584. Throughput: 0: 3656.4. Samples: 13124608. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:58:42,772][322896] Avg episode reward: [(0, '1595.620')]
[2025-11-06 16:58:47,761][322896] Fps is (10 sec: 3258.0, 60 sec: 3551.9, 300 sec: 3665.9). Total num frames: 13139968. Throughput: 0: 3664.6. Samples: 13145600. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:58:47,761][322896] Avg episode reward: [(0, '1697.727')]
[2025-11-06 16:58:52,793][322896] Fps is (10 sec: 3269.9, 60 sec: 3546.8, 300 sec: 3664.5). Total num frames: 13156352. Throughput: 0: 3666.4. Samples: 13168640. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:58:52,793][322896] Avg episode reward: [(0, '1775.092')]
[2025-11-06 16:58:57,676][322896] Fps is (10 sec: 4131.1, 60 sec: 3686.8, 300 sec: 3694.6). Total num frames: 13180928. Throughput: 0: 3692.0. Samples: 13178880. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:58:57,677][322896] Avg episode reward: [(0, '1751.526')]
[2025-11-06 16:59:02,753][322896] Fps is (10 sec: 4934.7, 60 sec: 3824.2, 300 sec: 3721.6). Total num frames: 13205504. Throughput: 0: 3687.1. Samples: 13201920. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:59:02,753][322896] Avg episode reward: [(0, '1799.871')]
[2025-11-06 16:59:07,738][322896] Fps is (10 sec: 4071.0, 60 sec: 3819.7, 300 sec: 3693.0). Total num frames: 13221888. Throughput: 0: 3638.9. Samples: 13222912. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:59:07,738][322896] Avg episode reward: [(0, '1807.680')]
[2025-11-06 16:59:12,714][322896] Fps is (10 sec: 3289.9, 60 sec: 3842.7, 300 sec: 3665.8). Total num frames: 13238272. Throughput: 0: 3688.2. Samples: 13235200. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:59:12,714][322896] Avg episode reward: [(0, '1733.160')]
[2025-11-06 16:59:17,685][322896] Fps is (10 sec: 3294.1, 60 sec: 3562.6, 300 sec: 3666.4). Total num frames: 13254656. Throughput: 0: 3656.9. Samples: 13255680. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:59:17,685][322896] Avg episode reward: [(0, '1728.934')]
[2025-11-06 16:59:22,788][322896] Fps is (10 sec: 3252.6, 60 sec: 3545.4, 300 sec: 3665.5). Total num frames: 13271040. Throughput: 0: 3679.5. Samples: 13278208. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:59:22,788][322896] Avg episode reward: [(0, '1764.400')]
[2025-11-06 16:59:27,709][322896] Fps is (10 sec: 3268.9, 60 sec: 3551.4, 300 sec: 3666.1). Total num frames: 13287424. Throughput: 0: 3645.9. Samples: 13288448. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:59:27,710][322896] Avg episode reward: [(0, '1745.790')]
[2025-11-06 16:59:32,747][322896] Fps is (10 sec: 3290.3, 60 sec: 3549.6, 300 sec: 3664.9). Total num frames: 13303808. Throughput: 0: 3699.0. Samples: 13312000. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:59:32,747][322896] Avg episode reward: [(0, '1801.745')]
[2025-11-06 16:59:37,680][322896] Fps is (10 sec: 4108.2, 60 sec: 3687.9, 300 sec: 3693.3). Total num frames: 13328384. Throughput: 0: 3695.7. Samples: 13334528. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:59:37,680][322896] Avg episode reward: [(0, '1728.917')]
[2025-11-06 16:59:42,714][322896] Fps is (10 sec: 4931.4, 60 sec: 3826.6, 300 sec: 3721.8). Total num frames: 13352960. Throughput: 0: 3694.7. Samples: 13345280. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:59:42,714][322896] Avg episode reward: [(0, '1663.146')]
[2025-11-06 16:59:47,790][322896] Fps is (10 sec: 4051.5, 60 sec: 3821.1, 300 sec: 3692.5). Total num frames: 13369344. Throughput: 0: 3683.4. Samples: 13367808. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:59:47,790][322896] Avg episode reward: [(0, '1639.516')]
[2025-11-06 16:59:51,102][322896] Signal inference workers to stop experience collection... (2450 times)
[2025-11-06 16:59:51,485][322896] InferenceWorker_p0-w0: stopping experience collection (2450 times)
[2025-11-06 16:59:51,485][322896] Signal inference workers to resume experience collection... (2450 times)
[2025-11-06 16:59:51,485][322896] InferenceWorker_p0-w0: resuming experience collection (2450 times)
[2025-11-06 16:59:52,737][322896] Fps is (10 sec: 3269.3, 60 sec: 3826.5, 300 sec: 3665.5). Total num frames: 13385728. Throughput: 0: 3675.1. Samples: 13388288. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:59:52,737][322896] Avg episode reward: [(0, '1708.782')]
[2025-11-06 16:59:57,794][322896] Fps is (10 sec: 3275.3, 60 sec: 3679.2, 300 sec: 3665.2). Total num frames: 13402112. Throughput: 0: 3668.4. Samples: 13400576. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 16:59:57,794][322896] Avg episode reward: [(0, '1758.422')]
[2025-11-06 16:59:57,927][322896] Saving /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_lidar_policy2_acc_yaw_sp/checkpoint_p0/checkpoint_000052352_13402112.pth...
[2025-11-06 16:59:57,931][322896] Removing /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_lidar_policy2_acc_yaw_sp/checkpoint_p0/checkpoint_000048896_12517376.pth
[2025-11-06 17:00:02,699][322896] Fps is (10 sec: 3289.5, 60 sec: 3553.1, 300 sec: 3665.3). Total num frames: 13418496. Throughput: 0: 3685.3. Samples: 13421568. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 17:00:02,699][322896] Avg episode reward: [(0, '1735.601')]
[2025-11-06 17:00:07,770][322896] Fps is (10 sec: 3284.9, 60 sec: 3548.0, 300 sec: 3665.2). Total num frames: 13434880. Throughput: 0: 3699.3. Samples: 13444608. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 17:00:07,770][322896] Avg episode reward: [(0, '1674.451')]
[2025-11-06 17:00:12,684][322896] Fps is (10 sec: 3281.4, 60 sec: 3551.6, 300 sec: 3665.9). Total num frames: 13451264. Throughput: 0: 3711.2. Samples: 13455360. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 17:00:12,685][322896] Avg episode reward: [(0, '1616.583')]
[2025-11-06 17:00:17,736][322896] Fps is (10 sec: 4109.9, 60 sec: 3683.3, 300 sec: 3692.6). Total num frames: 13475840. Throughput: 0: 3687.3. Samples: 13477888. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 17:00:17,736][322896] Avg episode reward: [(0, '1616.265')]
[2025-11-06 17:00:22,731][322896] Fps is (10 sec: 4892.6, 60 sec: 3826.6, 300 sec: 3720.7). Total num frames: 13500416. Throughput: 0: 3682.2. Samples: 13500416. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 17:00:22,731][322896] Avg episode reward: [(0, '1647.130')]
[2025-11-06 17:00:27,698][322896] Fps is (10 sec: 4111.5, 60 sec: 3823.7, 300 sec: 3668.8). Total num frames: 13516800. Throughput: 0: 3676.3. Samples: 13510656. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 17:00:27,698][322896] Avg episode reward: [(0, '1623.740')]
[2025-11-06 17:00:32,763][322896] Fps is (10 sec: 3266.3, 60 sec: 3821.9, 300 sec: 3665.2). Total num frames: 13533184. Throughput: 0: 3677.2. Samples: 13533184. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 17:00:32,763][322896] Avg episode reward: [(0, '1612.723')]
[2025-11-06 17:00:37,788][322896] Fps is (10 sec: 3247.5, 60 sec: 3679.7, 300 sec: 3665.4). Total num frames: 13549568. Throughput: 0: 3693.6. Samples: 13554688. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 17:00:37,789][322896] Avg episode reward: [(0, '1678.254')]
[2025-11-06 17:00:42,740][322896] Fps is (10 sec: 3284.5, 60 sec: 3548.4, 300 sec: 3665.4). Total num frames: 13565952. Throughput: 0: 3690.9. Samples: 13566464. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 17:00:42,740][322896] Avg episode reward: [(0, '1579.249')]
[2025-11-06 17:00:47,701][322896] Fps is (10 sec: 3305.8, 60 sec: 3555.1, 300 sec: 3665.7). Total num frames: 13582336. Throughput: 0: 3697.6. Samples: 13587968. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 17:00:47,701][322896] Avg episode reward: [(0, '1640.994')]
[2025-11-06 17:00:52,784][322896] Fps is (10 sec: 3262.3, 60 sec: 3547.1, 300 sec: 3665.2). Total num frames: 13598720. Throughput: 0: 3685.2. Samples: 13610496. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 17:00:52,784][322896] Avg episode reward: [(0, '1583.525')]
[2025-11-06 17:00:57,870][322896] Fps is (10 sec: 4027.7, 60 sec: 3681.7, 300 sec: 3692.4). Total num frames: 13623296. Throughput: 0: 3659.9. Samples: 13620736. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 17:00:57,870][322896] Avg episode reward: [(0, '1636.466')]
[2025-11-06 17:01:02,754][322896] Fps is (10 sec: 4929.9, 60 sec: 3819.4, 300 sec: 3721.3). Total num frames: 13647872. Throughput: 0: 3673.5. Samples: 13643264. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 17:01:02,754][322896] Avg episode reward: [(0, '1648.975')]
[2025-11-06 17:01:06,717][322896] Signal inference workers to stop experience collection... (2500 times)
[2025-11-06 17:01:06,717][322896] Signal inference workers to resume experience collection... (2500 times)
[2025-11-06 17:01:06,951][322896] InferenceWorker_p0-w0: stopping experience collection (2500 times)
[2025-11-06 17:01:06,951][322896] InferenceWorker_p0-w0: resuming experience collection (2500 times)
[2025-11-06 17:01:07,704][322896] Fps is (10 sec: 4165.1, 60 sec: 3827.1, 300 sec: 3668.3). Total num frames: 13664256. Throughput: 0: 3665.8. Samples: 13665280. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 17:01:07,704][322896] Avg episode reward: [(0, '1645.261')]
[2025-11-06 17:01:12,704][322896] Fps is (10 sec: 3293.1, 60 sec: 3821.7, 300 sec: 3666.3). Total num frames: 13680640. Throughput: 0: 3685.9. Samples: 13676544. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 17:01:12,705][322896] Avg episode reward: [(0, '1691.934')]
[2025-11-06 17:01:17,730][322896] Fps is (10 sec: 3268.5, 60 sec: 3686.8, 300 sec: 3666.3). Total num frames: 13697024. Throughput: 0: 3666.4. Samples: 13698048. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 17:01:17,730][322896] Avg episode reward: [(0, '1672.199')]
[2025-11-06 17:01:22,708][322896] Fps is (10 sec: 3275.8, 60 sec: 3551.2, 300 sec: 3666.5). Total num frames: 13713408. Throughput: 0: 3693.0. Samples: 13720576. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 17:01:22,708][322896] Avg episode reward: [(0, '1704.660')]
[2025-11-06 17:01:27,693][322896] Fps is (10 sec: 3288.7, 60 sec: 3550.1, 300 sec: 3665.9). Total num frames: 13729792. Throughput: 0: 3656.0. Samples: 13730816. Policy #0 lag: (min: 11.0, avg: 14.0, max: 75.0)
[2025-11-06 17:01:27,694][322896] Avg episode reward: [(0, '1695.755')]
[2025-11-06 17:01:32,752][322896] Fps is (10 sec: 3262.4, 60 sec: 3550.5, 300 sec: 3664.7). Total num frames: 13746176. Throughput: 0: 3670.9. Samples: 13753344. Policy #0 lag: (min: 11.0, avg: 14.0, max: 75.0)
[2025-11-06 17:01:32,752][322896] Avg episode reward: [(0, '1682.764')]
[2025-11-06 17:01:37,944][322896] Fps is (10 sec: 3995.8, 60 sec: 3676.9, 300 sec: 3691.1). Total num frames: 13770752. Throughput: 0: 3662.0. Samples: 13775872. Policy #0 lag: (min: 11.0, avg: 14.0, max: 75.0)
[2025-11-06 17:01:37,944][322896] Avg episode reward: [(0, '1621.816')]
[2025-11-06 17:01:42,684][322896] Fps is (10 sec: 4948.6, 60 sec: 3826.5, 300 sec: 3721.9). Total num frames: 13795328. Throughput: 0: 3701.7. Samples: 13786624. Policy #0 lag: (min: 11.0, avg: 14.0, max: 75.0)
[2025-11-06 17:01:42,684][322896] Avg episode reward: [(0, '1708.062')]
[2025-11-06 17:01:47,797][322896] Fps is (10 sec: 4157.3, 60 sec: 3816.8, 300 sec: 3693.8). Total num frames: 13811712. Throughput: 0: 3682.9. Samples: 13809152. Policy #0 lag: (min: 11.0, avg: 14.0, max: 75.0)
[2025-11-06 17:01:47,797][322896] Avg episode reward: [(0, '1691.597')]
[2025-11-06 17:01:52,763][322896] Fps is (10 sec: 3251.2, 60 sec: 3824.3, 300 sec: 3664.7). Total num frames: 13828096. Throughput: 0: 3658.9. Samples: 13830144. Policy #0 lag: (min: 11.0, avg: 14.0, max: 75.0)
[2025-11-06 17:01:52,763][322896] Avg episode reward: [(0, '1681.157')]
[2025-11-06 17:01:57,717][322896] Fps is (10 sec: 3303.2, 60 sec: 3695.9, 300 sec: 3666.1). Total num frames: 13844480. Throughput: 0: 3685.4. Samples: 13842432. Policy #0 lag: (min: 11.0, avg: 14.0, max: 75.0)
[2025-11-06 17:01:57,717][322896] Avg episode reward: [(0, '1721.436')]
[2025-11-06 17:01:57,859][322896] Saving /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_lidar_policy2_acc_yaw_sp/checkpoint_p0/checkpoint_000054080_13844480.pth...
[2025-11-06 17:01:57,863][322896] Removing /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_lidar_policy2_acc_yaw_sp/checkpoint_p0/checkpoint_000050624_12959744.pth
[2025-11-06 17:02:02,697][322896] Fps is (10 sec: 3298.7, 60 sec: 3553.3, 300 sec: 3666.5). Total num frames: 13860864. Throughput: 0: 3666.3. Samples: 13862912. Policy #0 lag: (min: 10.0, avg: 13.0, max: 74.0)
[2025-11-06 17:02:02,697][322896] Avg episode reward: [(0, '1703.381')]
[2025-11-06 17:02:07,736][322896] Fps is (10 sec: 3270.5, 60 sec: 3548.0, 300 sec: 3665.6). Total num frames: 13877248. Throughput: 0: 3672.7. Samples: 13885952. Policy #0 lag: (min: 10.0, avg: 13.0, max: 74.0)
[2025-11-06 17:02:07,736][322896] Avg episode reward: [(0, '1773.963')]
[2025-11-06 17:02:12,778][322896] Fps is (10 sec: 3250.3, 60 sec: 3545.5, 300 sec: 3664.4). Total num frames: 13893632. Throughput: 0: 3679.5. Samples: 13896704. Policy #0 lag: (min: 10.0, avg: 13.0, max: 74.0)
[2025-11-06 17:02:12,778][322896] Avg episode reward: [(0, '1787.718')]
[2025-11-06 17:02:17,932][322896] Fps is (10 sec: 4017.2, 60 sec: 3674.0, 300 sec: 3691.6). Total num frames: 13918208. Throughput: 0: 3671.7. Samples: 13919232. Policy #0 lag: (min: 10.0, avg: 13.0, max: 74.0)
[2025-11-06 17:02:17,932][322896] Avg episode reward: [(0, '1722.523')]
[2025-11-06 17:02:21,997][322896] Signal inference workers to stop experience collection... (2550 times)
[2025-11-06 17:02:22,338][322896] InferenceWorker_p0-w0: stopping experience collection (2550 times)
[2025-11-06 17:02:22,340][322896] Signal inference workers to resume experience collection... (2550 times)
[2025-11-06 17:02:22,468][322896] InferenceWorker_p0-w0: resuming experience collection (2550 times)
[2025-11-06 17:02:22,692][322896] Fps is (10 sec: 4957.9, 60 sec: 3823.9, 300 sec: 3721.4). Total num frames: 13942784. Throughput: 0: 3718.6. Samples: 13942272. Policy #0 lag: (min: 10.0, avg: 13.0, max: 74.0)
[2025-11-06 17:02:22,692][322896] Avg episode reward: [(0, '1717.543')]
[2025-11-06 17:02:27,715][322896] Fps is (10 sec: 4186.8, 60 sec: 3821.5, 300 sec: 3695.4). Total num frames: 13959168. Throughput: 0: 3683.9. Samples: 13952512. Policy #0 lag: (min: 10.0, avg: 13.0, max: 74.0)
[2025-11-06 17:02:27,715][322896] Avg episode reward: [(0, '1773.655')]
[2025-11-06 17:02:32,769][322896] Fps is (10 sec: 3251.9, 60 sec: 3821.8, 300 sec: 3664.8). Total num frames: 13975552. Throughput: 0: 3688.7. Samples: 13975040. Policy #0 lag: (min: 10.0, avg: 13.0, max: 74.0)
[2025-11-06 17:02:32,769][322896] Avg episode reward: [(0, '1801.294')]
[2025-11-06 17:02:37,805][322896] Fps is (10 sec: 3247.7, 60 sec: 3695.0, 300 sec: 3664.0). Total num frames: 13991936. Throughput: 0: 3683.0. Samples: 13996032. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 17:02:37,805][322896] Avg episode reward: [(0, '1727.458')]
[2025-11-06 17:02:42,732][322896] Fps is (10 sec: 3288.9, 60 sec: 3547.0, 300 sec: 3666.4). Total num frames: 14008320. Throughput: 0: 3696.5. Samples: 14008832. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 17:02:42,732][322896] Avg episode reward: [(0, '1710.053')]
[2025-11-06 17:02:47,786][322896] Fps is (10 sec: 3282.8, 60 sec: 3550.5, 300 sec: 3665.0). Total num frames: 14024704. Throughput: 0: 3690.4. Samples: 14029312. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 17:02:47,786][322896] Avg episode reward: [(0, '1721.658')]
[2025-11-06 17:02:52,707][322896] Fps is (10 sec: 3285.0, 60 sec: 3553.2, 300 sec: 3665.3). Total num frames: 14041088. Throughput: 0: 3688.8. Samples: 14051840. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 17:02:52,707][322896] Avg episode reward: [(0, '1706.139')]
[2025-11-06 17:02:57,947][322896] Fps is (10 sec: 4031.1, 60 sec: 3672.3, 300 sec: 3691.2). Total num frames: 14065664. Throughput: 0: 3672.6. Samples: 14062592. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 17:02:57,947][322896] Avg episode reward: [(0, '1713.902')]
[2025-11-06 17:03:02,696][322896] Fps is (10 sec: 4920.3, 60 sec: 3822.9, 300 sec: 3721.0). Total num frames: 14090240. Throughput: 0: 3717.2. Samples: 14085632. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 17:03:02,697][322896] Avg episode reward: [(0, '1842.016')]
[2025-11-06 17:03:02,697][322896] Saving new best policy, reward=1842.016!
[2025-11-06 17:03:07,736][322896] Fps is (10 sec: 4184.4, 60 sec: 3822.9, 300 sec: 3724.7). Total num frames: 14106624. Throughput: 0: 3671.4. Samples: 14107648. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 17:03:07,736][322896] Avg episode reward: [(0, '1778.597')]
[2025-11-06 17:03:12,713][322896] Fps is (10 sec: 3271.3, 60 sec: 3827.1, 300 sec: 3667.9). Total num frames: 14123008. Throughput: 0: 3697.9. Samples: 14118912. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 17:03:12,713][322896] Avg episode reward: [(0, '1707.791')]
[2025-11-06 17:03:17,742][322896] Fps is (10 sec: 3274.7, 60 sec: 3698.1, 300 sec: 3665.2). Total num frames: 14139392. Throughput: 0: 3677.2. Samples: 14140416. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 17:03:17,743][322896] Avg episode reward: [(0, '1668.818')]
[2025-11-06 17:03:22,793][322896] Fps is (10 sec: 3250.8, 60 sec: 3543.9, 300 sec: 3664.9). Total num frames: 14155776. Throughput: 0: 3698.7. Samples: 14162432. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 17:03:22,793][322896] Avg episode reward: [(0, '1709.574')]
[2025-11-06 17:03:27,674][322896] Fps is (10 sec: 3299.3, 60 sec: 3552.3, 300 sec: 3666.4). Total num frames: 14172160. Throughput: 0: 3657.0. Samples: 14173184. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 17:03:27,674][322896] Avg episode reward: [(0, '1624.069')]
[2025-11-06 17:03:32,733][322896] Fps is (10 sec: 3296.5, 60 sec: 3552.0, 300 sec: 3665.2). Total num frames: 14188544. Throughput: 0: 3690.7. Samples: 14195200. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 17:03:32,734][322896] Avg episode reward: [(0, '1568.620')]
[2025-11-06 17:03:33,573][322896] Signal inference workers to stop experience collection... (2600 times)
[2025-11-06 17:03:33,924][322896] InferenceWorker_p0-w0: stopping experience collection (2600 times)
[2025-11-06 17:03:33,924][322896] Signal inference workers to resume experience collection... (2600 times)
[2025-11-06 17:03:33,925][322896] InferenceWorker_p0-w0: resuming experience collection (2600 times)
[2025-11-06 17:03:37,962][322896] Fps is (10 sec: 3981.2, 60 sec: 3676.7, 300 sec: 3691.0). Total num frames: 14213120. Throughput: 0: 3676.9. Samples: 14218240. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 17:03:37,963][322896] Avg episode reward: [(0, '1605.341')]
[2025-11-06 17:03:42,755][322896] Fps is (10 sec: 4904.7, 60 sec: 3821.5, 300 sec: 3721.2). Total num frames: 14237696. Throughput: 0: 3702.2. Samples: 14228480. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 17:03:42,755][322896] Avg episode reward: [(0, '1687.468')]
[2025-11-06 17:03:47,708][322896] Fps is (10 sec: 4202.8, 60 sec: 3827.9, 300 sec: 3722.2). Total num frames: 14254080. Throughput: 0: 3685.4. Samples: 14251520. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 17:03:47,708][322896] Avg episode reward: [(0, '1742.254')]
[2025-11-06 17:03:52,779][322896] Fps is (10 sec: 3268.9, 60 sec: 3818.3, 300 sec: 3692.1). Total num frames: 14270464. Throughput: 0: 3660.1. Samples: 14272512. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 17:03:52,779][322896] Avg episode reward: [(0, '1734.712')]
[2025-11-06 17:03:57,730][322896] Fps is (10 sec: 3269.6, 60 sec: 3699.8, 300 sec: 3665.9). Total num frames: 14286848. Throughput: 0: 3673.6. Samples: 14284288. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 17:03:57,730][322896] Avg episode reward: [(0, '1719.177')]
[2025-11-06 17:03:57,865][322896] Saving /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_lidar_policy2_acc_yaw_sp/checkpoint_p0/checkpoint_000055808_14286848.pth...
[2025-11-06 17:03:57,869][322896] Removing /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_lidar_policy2_acc_yaw_sp/checkpoint_p0/checkpoint_000052352_13402112.pth
[2025-11-06 17:04:02,681][322896] Fps is (10 sec: 3309.2, 60 sec: 3550.8, 300 sec: 3666.3). Total num frames: 14303232. Throughput: 0: 3680.0. Samples: 14305792. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 17:04:02,681][322896] Avg episode reward: [(0, '1740.667')]
[2025-11-06 17:04:07,783][322896] Fps is (10 sec: 3259.4, 60 sec: 3547.1, 300 sec: 3664.7). Total num frames: 14319616. Throughput: 0: 3687.2. Samples: 14328320. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 17:04:07,784][322896] Avg episode reward: [(0, '1726.293')]
[2025-11-06 17:04:12,717][322896] Fps is (10 sec: 3265.0, 60 sec: 3549.6, 300 sec: 3665.2). Total num frames: 14336000. Throughput: 0: 3671.5. Samples: 14338560. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 17:04:12,718][322896] Avg episode reward: [(0, '1751.432')]
[2025-11-06 17:04:17,994][322896] Fps is (10 sec: 4011.6, 60 sec: 3671.0, 300 sec: 3690.8). Total num frames: 14360576. Throughput: 0: 3676.5. Samples: 14361600. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 17:04:17,994][322896] Avg episode reward: [(0, '1773.917')]
[2025-11-06 17:04:22,870][322896] Fps is (10 sec: 4841.3, 60 sec: 3818.0, 300 sec: 3719.1). Total num frames: 14385152. Throughput: 0: 3694.0. Samples: 14384128. Policy #0 lag: (min: 10.0, avg: 13.0, max: 74.0)
[2025-11-06 17:04:22,870][322896] Avg episode reward: [(0, '1771.410')]
[2025-11-06 17:04:27,680][322896] Fps is (10 sec: 4228.7, 60 sec: 3822.6, 300 sec: 3722.0). Total num frames: 14401536. Throughput: 0: 3692.5. Samples: 14394368. Policy #0 lag: (min: 10.0, avg: 13.0, max: 74.0)
[2025-11-06 17:04:27,680][322896] Avg episode reward: [(0, '1748.546')]
[2025-11-06 17:04:32,710][322896] Fps is (10 sec: 3330.3, 60 sec: 3824.4, 300 sec: 3693.0). Total num frames: 14417920. Throughput: 0: 3674.9. Samples: 14416896. Policy #0 lag: (min: 10.0, avg: 13.0, max: 74.0)
[2025-11-06 17:04:32,710][322896] Avg episode reward: [(0, '1750.873')]
[2025-11-06 17:04:37,740][322896] Fps is (10 sec: 3257.2, 60 sec: 3700.1, 300 sec: 3665.2). Total num frames: 14434304. Throughput: 0: 3678.2. Samples: 14437888. Policy #0 lag: (min: 10.0, avg: 13.0, max: 74.0)
[2025-11-06 17:04:37,740][322896] Avg episode reward: [(0, '1776.624')]
[2025-11-06 17:04:42,673][322896] Fps is (10 sec: 3288.7, 60 sec: 3554.7, 300 sec: 3667.0). Total num frames: 14450688. Throughput: 0: 3691.1. Samples: 14450176. Policy #0 lag: (min: 10.0, avg: 13.0, max: 74.0)
[2025-11-06 17:04:42,674][322896] Avg episode reward: [(0, '1725.811')]
[2025-11-06 17:04:47,741][322896] Fps is (10 sec: 3276.4, 60 sec: 3547.9, 300 sec: 3665.5). Total num frames: 14467072. Throughput: 0: 3670.1. Samples: 14471168. Policy #0 lag: (min: 10.0, avg: 13.0, max: 74.0)
[2025-11-06 17:04:47,742][322896] Avg episode reward: [(0, '1729.754')]
[2025-11-06 17:04:49,264][322896] Signal inference workers to stop experience collection... (2650 times)
[2025-11-06 17:04:49,264][322896] Signal inference workers to resume experience collection... (2650 times)
[2025-11-06 17:04:49,517][322896] InferenceWorker_p0-w0: stopping experience collection (2650 times)
[2025-11-06 17:04:49,517][322896] InferenceWorker_p0-w0: resuming experience collection (2650 times)
[2025-11-06 17:04:52,679][322896] Fps is (10 sec: 3274.9, 60 sec: 3555.8, 300 sec: 3667.0). Total num frames: 14483456. Throughput: 0: 3683.6. Samples: 14493696. Policy #0 lag: (min: 10.0, avg: 13.0, max: 74.0)
[2025-11-06 17:04:52,679][322896] Avg episode reward: [(0, '1637.032')]
[2025-11-06 17:04:57,741][322896] Fps is (10 sec: 3276.8, 60 sec: 3549.2, 300 sec: 3665.0). Total num frames: 14499840. Throughput: 0: 3673.1. Samples: 14503936. Policy #0 lag: (min: 10.0, avg: 13.0, max: 74.0)
[2025-11-06 17:04:57,742][322896] Avg episode reward: [(0, '1651.171')]
[2025-11-06 17:05:02,963][322896] Fps is (10 sec: 4779.5, 60 sec: 3805.1, 300 sec: 3718.7). Total num frames: 14532608. Throughput: 0: 3677.5. Samples: 14526976. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 17:05:02,963][322896] Avg episode reward: [(0, '1724.995')]
[2025-11-06 17:05:07,760][322896] Fps is (10 sec: 4906.3, 60 sec: 3824.5, 300 sec: 3720.2). Total num frames: 14548992. Throughput: 0: 3684.1. Samples: 14549504. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 17:05:07,760][322896] Avg episode reward: [(0, '1745.656')]
[2025-11-06 17:05:12,673][322896] Fps is (10 sec: 3374.6, 60 sec: 3825.7, 300 sec: 3694.1). Total num frames: 14565376. Throughput: 0: 3686.9. Samples: 14560256. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 17:05:12,674][322896] Avg episode reward: [(0, '1784.524')]
[2025-11-06 17:05:17,719][322896] Fps is (10 sec: 3290.0, 60 sec: 3703.3, 300 sec: 3665.7). Total num frames: 14581760. Throughput: 0: 3685.6. Samples: 14582784. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 17:05:17,720][322896] Avg episode reward: [(0, '1696.000')]
[2025-11-06 17:05:22,745][322896] Fps is (10 sec: 3253.4, 60 sec: 3557.3, 300 sec: 3665.0). Total num frames: 14598144. Throughput: 0: 3686.0. Samples: 14603776. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 17:05:22,745][322896] Avg episode reward: [(0, '1656.434')]
[2025-11-06 17:05:27,716][322896] Fps is (10 sec: 3277.9, 60 sec: 3547.7, 300 sec: 3666.2). Total num frames: 14614528. Throughput: 0: 3671.5. Samples: 14615552. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 17:05:27,716][322896] Avg episode reward: [(0, '1732.122')]
[2025-11-06 17:05:32,757][322896] Fps is (10 sec: 3273.1, 60 sec: 3547.1, 300 sec: 3666.0). Total num frames: 14630912. Throughput: 0: 3685.2. Samples: 14637056. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 17:05:32,757][322896] Avg episode reward: [(0, '1769.882')]
[2025-11-06 17:05:37,693][322896] Fps is (10 sec: 3284.3, 60 sec: 3552.6, 300 sec: 3666.1). Total num frames: 14647296. Throughput: 0: 3685.2. Samples: 14659584. Policy #0 lag: (min: 8.0, avg: 11.0, max: 72.0)
[2025-11-06 17:05:37,694][322896] Avg episode reward: [(0, '1805.064')]
[2025-11-06 17:05:42,944][322896] Fps is (10 sec: 4824.9, 60 sec: 3805.8, 300 sec: 3718.0). Total num frames: 14680064. Throughput: 0: 3681.2. Samples: 14670336. Policy #0 lag: (min: 8.0, avg: 11.0, max: 72.0)
[2025-11-06 17:05:42,944][322896] Avg episode reward: [(0, '1943.732')]
[2025-11-06 17:05:42,944][322896] Saving new best policy, reward=1943.732!
[2025-11-06 17:05:47,746][322896] Fps is (10 sec: 4889.6, 60 sec: 3822.7, 300 sec: 3721.6). Total num frames: 14696448. Throughput: 0: 3704.3. Samples: 14692864. Policy #0 lag: (min: 8.0, avg: 11.0, max: 72.0)
[2025-11-06 17:05:47,746][322896] Avg episode reward: [(0, '1964.974')]
[2025-11-06 17:05:47,873][322896] Saving new best policy, reward=1964.974!
[2025-11-06 17:05:52,706][322896] Fps is (10 sec: 3356.5, 60 sec: 3821.2, 300 sec: 3695.4). Total num frames: 14712832. Throughput: 0: 3656.6. Samples: 14713856. Policy #0 lag: (min: 8.0, avg: 11.0, max: 72.0)
[2025-11-06 17:05:52,707][322896] Avg episode reward: [(0, '1884.358')]
[2025-11-06 17:05:57,723][322896] Fps is (10 sec: 3284.1, 60 sec: 3824.1, 300 sec: 3666.0). Total num frames: 14729216. Throughput: 0: 3682.3. Samples: 14726144. Policy #0 lag: (min: 8.0, avg: 11.0, max: 72.0)
[2025-11-06 17:05:57,724][322896] Avg episode reward: [(0, '1807.399')]
[2025-11-06 17:05:57,862][322896] Saving /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_lidar_policy2_acc_yaw_sp/checkpoint_p0/checkpoint_000057536_14729216.pth...
[2025-11-06 17:05:57,866][322896] Removing /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_lidar_policy2_acc_yaw_sp/checkpoint_p0/checkpoint_000054080_13844480.pth
[2025-11-06 17:06:02,767][322896] Fps is (10 sec: 3257.1, 60 sec: 3561.5, 300 sec: 3664.8). Total num frames: 14745600. Throughput: 0: 3637.1. Samples: 14746624. Policy #0 lag: (min: 8.0, avg: 11.0, max: 72.0)
[2025-11-06 17:06:02,767][322896] Avg episode reward: [(0, '1798.247')]
[2025-11-06 17:06:04,637][322896] Signal inference workers to stop experience collection... (2700 times)
[2025-11-06 17:06:04,993][322896] InferenceWorker_p0-w0: stopping experience collection (2700 times)
[2025-11-06 17:06:04,995][322896] Signal inference workers to resume experience collection... (2700 times)
[2025-11-06 17:06:05,121][322896] InferenceWorker_p0-w0: resuming experience collection (2700 times)
[2025-11-06 17:06:07,693][322896] Fps is (10 sec: 3286.9, 60 sec: 3553.8, 300 sec: 3665.7). Total num frames: 14761984. Throughput: 0: 3679.3. Samples: 14769152. Policy #0 lag: (min: 8.0, avg: 11.0, max: 72.0)
[2025-11-06 17:06:07,693][322896] Avg episode reward: [(0, '1745.419')]
[2025-11-06 17:06:12,785][322896] Fps is (10 sec: 3271.0, 60 sec: 3543.3, 300 sec: 3664.9). Total num frames: 14778368. Throughput: 0: 3635.4. Samples: 14779392. Policy #0 lag: (min: 13.0, avg: 16.0, max: 77.0)
[2025-11-06 17:06:12,785][322896] Avg episode reward: [(0, '1749.769')]
[2025-11-06 17:06:17,749][322896] Fps is (10 sec: 3258.4, 60 sec: 3548.1, 300 sec: 3665.1). Total num frames: 14794752. Throughput: 0: 3675.6. Samples: 14802432. Policy #0 lag: (min: 13.0, avg: 16.0, max: 77.0)
[2025-11-06 17:06:17,749][322896] Avg episode reward: [(0, '1703.348')]
[2025-11-06 17:06:22,798][322896] Fps is (10 sec: 4090.5, 60 sec: 3683.2, 300 sec: 3692.0). Total num frames: 14819328. Throughput: 0: 3677.8. Samples: 14825472. Policy #0 lag: (min: 13.0, avg: 16.0, max: 77.0)
[2025-11-06 17:06:22,798][322896] Avg episode reward: [(0, '1731.378')]
[2025-11-06 17:06:27,737][322896] Fps is (10 sec: 4921.1, 60 sec: 3821.6, 300 sec: 3721.3). Total num frames: 14843904. Throughput: 0: 3680.5. Samples: 14835200. Policy #0 lag: (min: 13.0, avg: 16.0, max: 77.0)
[2025-11-06 17:06:27,737][322896] Avg episode reward: [(0, '1761.401')]
[2025-11-06 17:06:32,788][322896] Fps is (10 sec: 4100.3, 60 sec: 3821.0, 300 sec: 3695.3). Total num frames: 14860288. Throughput: 0: 3660.2. Samples: 14857728. Policy #0 lag: (min: 13.0, avg: 16.0, max: 77.0)
[2025-11-06 17:06:32,788][322896] Avg episode reward: [(0, '1774.276')]
[2025-11-06 17:06:37,779][322896] Fps is (10 sec: 3263.2, 60 sec: 3817.5, 300 sec: 3664.4). Total num frames: 14876672. Throughput: 0: 3657.8. Samples: 14878720. Policy #0 lag: (min: 13.0, avg: 16.0, max: 77.0)
[2025-11-06 17:06:37,779][322896] Avg episode reward: [(0, '1751.524')]
[2025-11-06 17:06:42,749][322896] Fps is (10 sec: 3289.6, 60 sec: 3561.4, 300 sec: 3666.2). Total num frames: 14893056. Throughput: 0: 3661.6. Samples: 14891008. Policy #0 lag: (min: 13.0, avg: 16.0, max: 77.0)
[2025-11-06 17:06:42,749][322896] Avg episode reward: [(0, '1801.098')]
[2025-11-06 17:06:47,806][322896] Fps is (10 sec: 3267.9, 60 sec: 3546.3, 300 sec: 3665.0). Total num frames: 14909440. Throughput: 0: 3671.8. Samples: 14912000. Policy #0 lag: (min: 31.0, avg: 34.0, max: 95.0)
[2025-11-06 17:06:47,806][322896] Avg episode reward: [(0, '1845.370')]
[2025-11-06 17:06:52,771][322896] Fps is (10 sec: 3269.3, 60 sec: 3546.0, 300 sec: 3664.9). Total num frames: 14925824. Throughput: 0: 3668.6. Samples: 14934528. Policy #0 lag: (min: 31.0, avg: 34.0, max: 95.0)
[2025-11-06 17:06:52,772][322896] Avg episode reward: [(0, '1787.788')]
[2025-11-06 17:06:57,683][322896] Fps is (10 sec: 3317.5, 60 sec: 3552.2, 300 sec: 3665.7). Total num frames: 14942208. Throughput: 0: 3683.3. Samples: 14944768. Policy #0 lag: (min: 31.0, avg: 34.0, max: 95.0)
[2025-11-06 17:06:57,684][322896] Avg episode reward: [(0, '1877.807')]
[2025-11-06 17:07:02,985][322896] Fps is (10 sec: 4010.5, 60 sec: 3673.1, 300 sec: 3690.2). Total num frames: 14966784. Throughput: 0: 3655.9. Samples: 14967808. Policy #0 lag: (min: 31.0, avg: 34.0, max: 95.0)
[2025-11-06 17:07:02,985][322896] Avg episode reward: [(0, '1895.002')]
[2025-11-06 17:07:07,837][322896] Fps is (10 sec: 4840.9, 60 sec: 3813.8, 300 sec: 3720.4). Total num frames: 14991360. Throughput: 0: 3660.5. Samples: 14990336. Policy #0 lag: (min: 31.0, avg: 34.0, max: 95.0)
[2025-11-06 17:07:07,837][322896] Avg episode reward: [(0, '1893.682')]
[2025-11-06 17:07:12,738][322896] Fps is (10 sec: 4199.5, 60 sec: 3825.9, 300 sec: 3695.8). Total num frames: 15007744. Throughput: 0: 3675.0. Samples: 15000576. Policy #0 lag: (min: 31.0, avg: 34.0, max: 95.0)
[2025-11-06 17:07:12,738][322896] Avg episode reward: [(0, '1820.651')]
[2025-11-06 17:07:16,378][322896] Signal inference workers to stop experience collection... (2750 times)
[2025-11-06 17:07:16,722][322896] InferenceWorker_p0-w0: stopping experience collection (2750 times)
[2025-11-06 17:07:16,722][322896] Signal inference workers to resume experience collection... (2750 times)
[2025-11-06 17:07:16,722][322896] InferenceWorker_p0-w0: resuming experience collection (2750 times)
[2025-11-06 17:07:17,729][322896] Fps is (10 sec: 3312.5, 60 sec: 3824.2, 300 sec: 3665.1). Total num frames: 15024128. Throughput: 0: 3691.2. Samples: 15023616. Policy #0 lag: (min: 31.0, avg: 34.0, max: 95.0)
[2025-11-06 17:07:17,729][322896] Avg episode reward: [(0, '1697.605')]
[2025-11-06 17:07:22,734][322896] Fps is (10 sec: 3278.2, 60 sec: 3690.3, 300 sec: 3665.3). Total num frames: 15040512. Throughput: 0: 3678.7. Samples: 15044096. Policy #0 lag: (min: 31.0, avg: 34.0, max: 95.0)
[2025-11-06 17:07:22,734][322896] Avg episode reward: [(0, '1729.096')]
[2025-11-06 17:07:27,684][322896] Fps is (10 sec: 3291.7, 60 sec: 3553.0, 300 sec: 3666.6). Total num frames: 15056896. Throughput: 0: 3680.3. Samples: 15056384. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 17:07:27,684][322896] Avg episode reward: [(0, '1766.074')]
[2025-11-06 17:07:32,756][322896] Fps is (10 sec: 3269.6, 60 sec: 3551.7, 300 sec: 3666.2). Total num frames: 15073280. Throughput: 0: 3679.1. Samples: 15077376. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 17:07:32,756][322896] Avg episode reward: [(0, '1773.891')]
[2025-11-06 17:07:37,691][322896] Fps is (10 sec: 3274.5, 60 sec: 3555.1, 300 sec: 3666.1). Total num frames: 15089664. Throughput: 0: 3681.6. Samples: 15099904. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 17:07:37,691][322896] Avg episode reward: [(0, '1816.507')]
[2025-11-06 17:07:42,731][322896] Fps is (10 sec: 3284.9, 60 sec: 3550.9, 300 sec: 3666.3). Total num frames: 15106048. Throughput: 0: 3682.5. Samples: 15110656. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 17:07:42,732][322896] Avg episode reward: [(0, '1900.527')]
[2025-11-06 17:07:47,924][322896] Fps is (10 sec: 4803.3, 60 sec: 3815.4, 300 sec: 3718.4). Total num frames: 15138816. Throughput: 0: 3680.0. Samples: 15133184. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 17:07:47,924][322896] Avg episode reward: [(0, '1871.263')]
[2025-11-06 17:07:52,747][322896] Fps is (10 sec: 4907.5, 60 sec: 3824.5, 300 sec: 3695.8). Total num frames: 15155200. Throughput: 0: 3693.8. Samples: 15156224. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 17:07:52,747][322896] Avg episode reward: [(0, '1752.348')]
[2025-11-06 17:07:57,772][322896] Fps is (10 sec: 3327.4, 60 sec: 3817.3, 300 sec: 3664.6). Total num frames: 15171584. Throughput: 0: 3683.6. Samples: 15166464. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 17:07:57,772][322896] Avg episode reward: [(0, '1712.559')]
[2025-11-06 17:07:57,896][322896] Saving /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_lidar_policy2_acc_yaw_sp/checkpoint_p0/checkpoint_000059264_15171584.pth...
[2025-11-06 17:07:57,900][322896] Removing /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_lidar_policy2_acc_yaw_sp/checkpoint_p0/checkpoint_000055808_14286848.pth
[2025-11-06 17:08:02,724][322896] Fps is (10 sec: 3284.3, 60 sec: 3702.5, 300 sec: 3665.7). Total num frames: 15187968. Throughput: 0: 3675.4. Samples: 15188992. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 17:08:02,725][322896] Avg episode reward: [(0, '1785.131')]
[2025-11-06 17:08:07,700][322896] Fps is (10 sec: 3300.5, 60 sec: 3558.0, 300 sec: 3665.7). Total num frames: 15204352. Throughput: 0: 3689.2. Samples: 15209984. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 17:08:07,700][322896] Avg episode reward: [(0, '1785.515')]
[2025-11-06 17:08:12,777][322896] Fps is (10 sec: 3259.6, 60 sec: 3547.5, 300 sec: 3665.1). Total num frames: 15220736. Throughput: 0: 3667.4. Samples: 15221760. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 17:08:12,778][322896] Avg episode reward: [(0, '1722.941')]
[2025-11-06 17:08:17,783][322896] Fps is (10 sec: 3249.8, 60 sec: 3546.7, 300 sec: 3665.7). Total num frames: 15237120. Throughput: 0: 3684.2. Samples: 15243264. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 17:08:17,783][322896] Avg episode reward: [(0, '1780.660')]
[2025-11-06 17:08:22,742][322896] Fps is (10 sec: 3288.6, 60 sec: 3549.4, 300 sec: 3664.7). Total num frames: 15253504. Throughput: 0: 3682.2. Samples: 15265792. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 17:08:22,742][322896] Avg episode reward: [(0, '1802.790')]
[2025-11-06 17:08:27,913][322896] Fps is (10 sec: 4852.0, 60 sec: 3808.4, 300 sec: 3718.8). Total num frames: 15286272. Throughput: 0: 3671.6. Samples: 15276544. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 17:08:27,913][322896] Avg episode reward: [(0, '1854.390')]
[2025-11-06 17:08:32,039][322896] Signal inference workers to stop experience collection... (2800 times)
[2025-11-06 17:08:32,039][322896] Signal inference workers to resume experience collection... (2800 times)
[2025-11-06 17:08:32,278][322896] InferenceWorker_p0-w0: stopping experience collection (2800 times)
[2025-11-06 17:08:32,279][322896] InferenceWorker_p0-w0: resuming experience collection (2800 times)
[2025-11-06 17:08:32,772][322896] Fps is (10 sec: 4900.4, 60 sec: 3821.9, 300 sec: 3695.7). Total num frames: 15302656. Throughput: 0: 3698.9. Samples: 15299072. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 17:08:32,772][322896] Avg episode reward: [(0, '1875.576')]
[2025-11-06 17:08:37,691][322896] Fps is (10 sec: 3351.2, 60 sec: 3822.9, 300 sec: 3666.4). Total num frames: 15319040. Throughput: 0: 3645.4. Samples: 15320064. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 17:08:37,691][322896] Avg episode reward: [(0, '1828.134')]
[2025-11-06 17:08:42,789][322896] Fps is (10 sec: 3271.3, 60 sec: 3819.3, 300 sec: 3664.6). Total num frames: 15335424. Throughput: 0: 3685.0. Samples: 15332352. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2025-11-06 17:08:42,789][322896] Avg episode reward: [(0, '1733.946')]
[2025-11-06 17:08:47,753][322896] Fps is (10 sec: 3256.6, 60 sec: 3560.0, 300 sec: 3665.9). Total num frames: 15351808. Throughput: 0: 3638.6. Samples: 15352832. Policy #0 lag: (min: 2.0, avg: 5.0, max: 66.0)
[2025-11-06 17:08:47,753][322896] Avg episode reward: [(0, '1676.405')]
[2025-11-06 17:08:52,691][322896] Fps is (10 sec: 3309.2, 60 sec: 3553.2, 300 sec: 3666.1). Total num frames: 15368192. Throughput: 0: 3675.8. Samples: 15375360. Policy #0 lag: (min: 2.0, avg: 5.0, max: 66.0)
[2025-11-06 17:08:52,691][322896] Avg episode reward: [(0, '1807.924')]
[2025-11-06 17:08:57,687][322896] Fps is (10 sec: 3298.7, 60 sec: 3554.9, 300 sec: 3665.5). Total num frames: 15384576. Throughput: 0: 3648.2. Samples: 15385600. Policy #0 lag: (min: 2.0, avg: 5.0, max: 66.0)
[2025-11-06 17:08:57,687][322896] Avg episode reward: [(0, '1818.353')]
[2025-11-06 17:09:02,789][322896] Fps is (10 sec: 3244.9, 60 sec: 3546.0, 300 sec: 3665.5). Total num frames: 15400960. Throughput: 0: 3640.4. Samples: 15407104. Policy #0 lag: (min: 2.0, avg: 5.0, max: 66.0)
[2025-11-06 17:09:02,789][322896] Avg episode reward: [(0, '1770.171')]
[2025-11-06 17:09:07,785][322896] Fps is (10 sec: 3245.0, 60 sec: 3544.8, 300 sec: 3664.7). Total num frames: 15417344. Throughput: 0: 3626.0. Samples: 15429120. Policy #0 lag: (min: 2.0, avg: 5.0, max: 66.0)
[2025-11-06 17:09:07,785][322896] Avg episode reward: [(0, '1697.931')]
[2025-11-06 17:09:12,983][322896] Fps is (10 sec: 4018.0, 60 sec: 3673.8, 300 sec: 3665.7). Total num frames: 15441920. Throughput: 0: 3612.5. Samples: 15439360. Policy #0 lag: (min: 2.0, avg: 5.0, max: 66.0)
[2025-11-06 17:09:12,983][322896] Avg episode reward: [(0, '1596.137')]
[2025-11-06 17:09:17,888][322896] Fps is (10 sec: 4865.3, 60 sec: 3816.3, 300 sec: 3665.4). Total num frames: 15466496. Throughput: 0: 3597.5. Samples: 15461376. Policy #0 lag: (min: 2.0, avg: 5.0, max: 66.0)
[2025-11-06 17:09:17,888][322896] Avg episode reward: [(0, '1652.396')]
[2025-11-06 17:09:22,722][322896] Fps is (10 sec: 4205.7, 60 sec: 3824.2, 300 sec: 3665.0). Total num frames: 15482880. Throughput: 0: 3627.0. Samples: 15483392. Policy #0 lag: (min: 58.0, avg: 61.0, max: 122.0)
[2025-11-06 17:09:22,723][322896] Avg episode reward: [(0, '1750.776')]
