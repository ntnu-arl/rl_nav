[2026-02-02 12:07:09,026][93050] Saving configuration to /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_accel_policy2_aggressive_magpie_adp_nullified_02022026/config.json...
[2026-02-02 12:07:09,063][93050] Using GPUs [0] for process 0 (actually maps to GPUs [0])
[2026-02-02 12:07:09,063][93050] Rollout worker 0 uses device cuda:0
[2026-02-02 12:07:09,082][93050] Using GPUs [0] for process 0 (actually maps to GPUs [0])
[2026-02-02 12:07:09,082][93050] InferenceWorker_p0-w0: min num requests: 1
[2026-02-02 12:07:09,082][93050] Using GPUs [0] for process 0 (actually maps to GPUs [0])
[2026-02-02 12:07:09,082][93050] Starting seed is not provided
[2026-02-02 12:07:09,083][93050] Using GPUs [0] for process 0 (actually maps to GPUs [0])
[2026-02-02 12:07:09,083][93050] Initializing actor-critic model on device cuda:0
[2026-02-02 12:07:09,084][93050] RunningMeanStd input shape: (337,)
[2026-02-02 12:07:09,084][93050] RunningMeanStd input shape: (1,)
[2026-02-02 12:07:09,092][93050] Created Actor Critic model with architecture:
[2026-02-02 12:07:09,092][93050] ActorCriticSharedWeights(
  (obs_normalizer): ObservationNormalizer(
    (running_mean_std): RunningMeanStdDictInPlace(
      (running_mean_std): ModuleDict(
        (observations): RunningMeanStdInPlace()
      )
    )
  )
  (returns_normalizer): RecursiveScriptModule(original_name=RunningMeanStdInPlace)
  (encoder): CustomEncoder(
    (encoders): ModuleDict(
      (obs_image): Sequential(
        (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): ELU(alpha=1.0)
        (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
        (3): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (4): ELU(alpha=1.0)
        (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
        (6): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (7): ELU(alpha=1.0)
        (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        (9): Flatten(start_dim=1, end_dim=-1)
      )
    )
    (mlp_head_custom): Sequential(
      (0): Linear(in_features=145, out_features=256, bias=True)
      (1): ELU(alpha=1.0)
      (2): Linear(in_features=256, out_features=128, bias=True)
      (3): ELU(alpha=1.0)
      (4): Linear(in_features=128, out_features=64, bias=True)
      (5): ELU(alpha=1.0)
    )
  )
  (core): ModelCoreRNN(
    (core): GRU(64, 128)
  )
  (decoder): MlpDecoder(
    (mlp): Identity()
  )
  (critic_linear): Linear(in_features=128, out_features=1, bias=True)
  (action_parameterization): ActionParameterizationDefault(
    (distribution_linear): Linear(in_features=128, out_features=8, bias=True)
  )
)
[2026-02-02 12:07:09,456][93050] Using optimizer <class 'torch.optim.adam.Adam'>
[2026-02-02 12:07:09,456][93050] No checkpoints found
[2026-02-02 12:07:09,456][93050] Did not load from checkpoint, starting from scratch!
[2026-02-02 12:07:09,456][93050] Initialized policy 0 weights for model version 0
[2026-02-02 12:07:09,456][93050] LearnerWorker_p0 finished initialization!
[2026-02-02 12:07:09,457][93050] Using GPUs [0] for process 0 (actually maps to GPUs [0])
[2026-02-02 12:07:09,462][93050] Fps is (10 sec: nan, 60 sec: nan, 300 sec: nan). Total num frames: 0. Throughput: 0: nan. Samples: 0. Policy #0 lag: (min: -1.0, avg: -1.0, max: -1.0)
[2026-02-02 12:07:09,462][93050] Inference worker 0-0 is ready!
[2026-02-02 12:07:09,462][93050] All inference workers are ready! Signal rollout workers to start!
[2026-02-02 12:07:09,462][93050] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 0.0). Total num frames: 0. Throughput: 0: 0.0. Samples: 0. Policy #0 lag: (min: -1.0, avg: -1.0, max: -1.0)
[2026-02-02 12:07:09,463][93050] EnvRunner 0-0 uses policy 0
[2026-02-02 12:07:22,537][93050] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 0.0). Total num frames: 0. Throughput: 0: 0.0. Samples: 0. Policy #0 lag: (min: -1.0, avg: -1.0, max: -1.0)
[2026-02-02 12:07:27,178][93050] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 0.0). Total num frames: 0. Throughput: 0: 0.0. Samples: 0. Policy #0 lag: (min: -1.0, avg: -1.0, max: -1.0)
[2026-02-02 12:07:27,281][93050] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 0.0). Total num frames: 0. Throughput: 0: 28.7. Samples: 512. Policy #0 lag: (min: -1.0, avg: -1.0, max: -1.0)
[2026-02-02 12:07:27,281][93050] Avg episode reward: [(0, '-10.000')]
[2026-02-02 12:07:28,711][93050] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 0.0). Total num frames: 0. Throughput: 0: 53.2. Samples: 1024. Policy #0 lag: (min: -1.0, avg: -1.0, max: -1.0)
[2026-02-02 12:07:28,711][93050] Avg episode reward: [(0, '-10.000')]
[2026-02-02 12:07:29,272][93050] Heartbeat connected on Batcher_0
[2026-02-02 12:07:29,272][93050] Heartbeat connected on LearnerWorker_p0
[2026-02-02 12:07:29,272][93050] Heartbeat connected on InferenceWorker_p0-w0
[2026-02-02 12:07:29,272][93050] Heartbeat connected on RolloutWorker_w0
[2026-02-02 12:07:32,538][93050] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 0.0). Total num frames: 0. Throughput: 0: 310.6. Samples: 7168. Policy #0 lag: (min: -1.0, avg: -1.0, max: -1.0)
[2026-02-02 12:07:32,538][93050] Avg episode reward: [(0, '-11.827')]
[2026-02-02 12:07:33,547][93050] Signal inference workers to stop experience collection...
[2026-02-02 12:07:34,801][93050] InferenceWorker_p0-w0: stopping experience collection
[2026-02-02 12:07:34,803][93050] Signal inference workers to resume experience collection...
[2026-02-02 12:07:34,975][93050] InferenceWorker_p0-w0: resuming experience collection
[2026-02-02 12:07:37,532][93050] Fps is (10 sec: 1857.3, 60 sec: 583.7, 300 sec: 583.7). Total num frames: 16384. Throughput: 0: 802.6. Samples: 22528. Policy #0 lag: (min: 7.0, avg: 7.0, max: 7.0)
[2026-02-02 12:07:37,533][93050] Avg episode reward: [(0, '-25.677')]
[2026-02-02 12:07:42,592][93050] Fps is (10 sec: 3259.1, 60 sec: 989.1, 300 sec: 989.1). Total num frames: 32768. Throughput: 0: 973.6. Samples: 32256. Policy #0 lag: (min: 13.0, avg: 16.0, max: 77.0)
[2026-02-02 12:07:42,592][93050] Avg episode reward: [(0, '-37.952')]
[2026-02-02 12:07:48,056][93050] Fps is (10 sec: 3113.7, 60 sec: 1273.6, 300 sec: 1273.6). Total num frames: 49152. Throughput: 0: 1326.6. Samples: 51200. Policy #0 lag: (min: 2.0, avg: 5.0, max: 66.0)
[2026-02-02 12:07:48,056][93050] Avg episode reward: [(0, '-166.407')]
[2026-02-02 12:07:52,567][93050] Fps is (10 sec: 3285.1, 60 sec: 1520.4, 300 sec: 1520.4). Total num frames: 65536. Throughput: 0: 1591.7. Samples: 68608. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:07:52,567][93050] Avg episode reward: [(0, '-167.790')]
[2026-02-02 12:07:57,544][93050] Fps is (10 sec: 3453.6, 60 sec: 1703.8, 300 sec: 1703.8). Total num frames: 81920. Throughput: 0: 2266.9. Samples: 79360. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:07:57,544][93050] Avg episode reward: [(0, '-155.490')]
[2026-02-02 12:08:02,545][93050] Fps is (10 sec: 3283.9, 60 sec: 1851.9, 300 sec: 1851.9). Total num frames: 98304. Throughput: 0: 2808.5. Samples: 99328. Policy #0 lag: (min: 11.0, avg: 14.0, max: 75.0)
[2026-02-02 12:08:02,545][93050] Avg episode reward: [(0, '-112.662')]
[2026-02-02 12:08:07,551][93050] Fps is (10 sec: 3274.6, 60 sec: 1974.4, 300 sec: 1974.4). Total num frames: 114688. Throughput: 0: 2886.1. Samples: 116736. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:08:07,551][93050] Avg episode reward: [(0, '-129.200')]
[2026-02-02 12:08:07,694][93050] Saving new best policy, reward=-129.200!
[2026-02-02 12:08:12,488][93050] Fps is (10 sec: 3295.8, 60 sec: 2624.0, 300 sec: 2079.7). Total num frames: 131072. Throughput: 0: 2888.9. Samples: 127488. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:08:12,488][93050] Avg episode reward: [(0, '-130.420')]
[2026-02-02 12:08:17,490][93050] Fps is (10 sec: 3297.0, 60 sec: 2930.8, 300 sec: 2167.6). Total num frames: 147456. Throughput: 0: 3109.4. Samples: 146944. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:08:17,490][93050] Avg episode reward: [(0, '-92.664')]
[2026-02-02 12:08:17,635][93050] Saving new best policy, reward=-92.664!
[2026-02-02 12:08:22,551][93050] Fps is (10 sec: 3256.2, 60 sec: 2964.4, 300 sec: 2241.7). Total num frames: 163840. Throughput: 0: 3195.8. Samples: 166400. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:08:22,551][93050] Avg episode reward: [(0, '-66.567')]
[2026-02-02 12:08:22,688][93050] Saving new best policy, reward=-66.567!
[2026-02-02 12:08:27,537][93050] Fps is (10 sec: 3261.3, 60 sec: 3063.7, 300 sec: 2308.3). Total num frames: 180224. Throughput: 0: 3212.4. Samples: 176640. Policy #0 lag: (min: 1.0, avg: 4.0, max: 65.0)
[2026-02-02 12:08:27,537][93050] Avg episode reward: [(0, '-69.250')]
[2026-02-02 12:08:32,557][93050] Fps is (10 sec: 3274.6, 60 sec: 3275.7, 300 sec: 2366.1). Total num frames: 196608. Throughput: 0: 3256.0. Samples: 196096. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:08:32,558][93050] Avg episode reward: [(0, '-65.908')]
[2026-02-02 12:08:32,713][93050] Saving new best policy, reward=-65.908!
[2026-02-02 12:08:37,525][93050] Fps is (10 sec: 3280.9, 60 sec: 3277.2, 300 sec: 2418.6). Total num frames: 212992. Throughput: 0: 3234.3. Samples: 214016. Policy #0 lag: (min: 4.0, avg: 7.0, max: 68.0)
[2026-02-02 12:08:37,525][93050] Avg episode reward: [(0, '-53.465')]
[2026-02-02 12:08:37,678][93050] Saving new best policy, reward=-53.465!
[2026-02-02 12:08:42,605][93050] Fps is (10 sec: 3261.4, 60 sec: 3276.1, 300 sec: 2462.6). Total num frames: 229376. Throughput: 0: 3227.0. Samples: 224768. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:08:42,605][93050] Avg episode reward: [(0, '-47.533')]
[2026-02-02 12:08:42,760][93050] Saving new best policy, reward=-47.533!
[2026-02-02 12:08:47,568][93050] Fps is (10 sec: 3262.8, 60 sec: 3303.7, 300 sec: 2505.1). Total num frames: 245760. Throughput: 0: 3195.6. Samples: 243200. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:08:47,568][93050] Avg episode reward: [(0, '-38.740')]
[2026-02-02 12:08:47,716][93050] Saving new best policy, reward=-38.740!
[2026-02-02 12:08:52,597][93050] Fps is (10 sec: 3279.3, 60 sec: 3275.1, 300 sec: 2541.8). Total num frames: 262144. Throughput: 0: 3228.0. Samples: 262144. Policy #0 lag: (min: 10.0, avg: 13.0, max: 74.0)
[2026-02-02 12:08:52,597][93050] Avg episode reward: [(0, '-30.444')]
[2026-02-02 12:08:52,755][93050] Saving /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_accel_policy2_aggressive_magpie_adp_nullified_02022026/checkpoint_p0/checkpoint_000001024_262144.pth...
[2026-02-02 12:08:52,759][93050] Saving new best policy, reward=-30.444!
[2026-02-02 12:08:57,456][93050] Signal inference workers to stop experience collection... (50 times)
[2026-02-02 12:08:57,824][93050] InferenceWorker_p0-w0: stopping experience collection (50 times)
[2026-02-02 12:08:57,824][93050] Signal inference workers to resume experience collection... (50 times)
[2026-02-02 12:08:57,824][93050] Fps is (10 sec: 3194.9, 60 sec: 3261.6, 300 sec: 2570.3). Total num frames: 278528. Throughput: 0: 3150.8. Samples: 270336. Policy #0 lag: (min: 5.0, avg: 8.0, max: 69.0)
[2026-02-02 12:08:57,824][93050] Avg episode reward: [(0, '-20.842')]
[2026-02-02 12:08:57,825][93050] InferenceWorker_p0-w0: resuming experience collection (50 times)
[2026-02-02 12:08:57,825][93050] Saving new best policy, reward=-20.842!
[2026-02-02 12:09:02,826][93050] Fps is (10 sec: 2402.5, 60 sec: 3125.6, 300 sec: 2529.2). Total num frames: 286720. Throughput: 0: 3128.2. Samples: 288768. Policy #0 lag: (min: 11.0, avg: 14.0, max: 75.0)
[2026-02-02 12:09:02,827][93050] Avg episode reward: [(0, '-9.827')]
[2026-02-02 12:09:03,200][93050] Saving new best policy, reward=-9.827!
[2026-02-02 12:09:07,605][93050] Fps is (10 sec: 1675.1, 60 sec: 3001.0, 300 sec: 2496.2). Total num frames: 294912. Throughput: 0: 3125.1. Samples: 307200. Policy #0 lag: (min: 11.0, avg: 14.0, max: 75.0)
[2026-02-02 12:09:07,605][93050] Avg episode reward: [(0, '-0.858')]
[2026-02-02 12:09:07,772][93050] Saving new best policy, reward=-0.858!
[2026-02-02 12:09:12,570][93050] Fps is (10 sec: 2522.3, 60 sec: 2999.6, 300 sec: 2528.6). Total num frames: 311296. Throughput: 0: 3081.1. Samples: 315392. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:09:12,570][93050] Avg episode reward: [(0, '8.365')]
[2026-02-02 12:09:12,733][93050] Saving new best policy, reward=8.365!
[2026-02-02 12:09:17,534][93050] Fps is (10 sec: 3300.1, 60 sec: 3001.5, 300 sec: 2558.6). Total num frames: 327680. Throughput: 0: 3062.2. Samples: 333824. Policy #0 lag: (min: 8.0, avg: 11.0, max: 72.0)
[2026-02-02 12:09:17,534][93050] Avg episode reward: [(0, '19.847')]
[2026-02-02 12:09:17,695][93050] Saving new best policy, reward=19.847!
[2026-02-02 12:09:22,589][93050] Fps is (10 sec: 3270.4, 60 sec: 3001.8, 300 sec: 2584.5). Total num frames: 344064. Throughput: 0: 3056.2. Samples: 351744. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:09:22,590][93050] Avg episode reward: [(0, '31.905')]
[2026-02-02 12:09:22,754][93050] Saving new best policy, reward=31.905!
[2026-02-02 12:09:27,492][93050] Fps is (10 sec: 3290.5, 60 sec: 3006.0, 300 sec: 2611.4). Total num frames: 360448. Throughput: 0: 3045.5. Samples: 361472. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:09:27,493][93050] Avg episode reward: [(0, '45.470')]
[2026-02-02 12:09:27,652][93050] Saving new best policy, reward=45.470!
[2026-02-02 12:09:32,490][93050] Fps is (10 sec: 3309.7, 60 sec: 3007.1, 300 sec: 2634.7). Total num frames: 376832. Throughput: 0: 3020.3. Samples: 378880. Policy #0 lag: (min: 5.0, avg: 8.0, max: 69.0)
[2026-02-02 12:09:32,490][93050] Avg episode reward: [(0, '52.923')]
[2026-02-02 12:09:32,653][93050] Saving new best policy, reward=52.923!
[2026-02-02 12:09:37,580][93050] Fps is (10 sec: 3248.4, 60 sec: 3001.0, 300 sec: 2654.8). Total num frames: 393216. Throughput: 0: 3004.9. Samples: 397312. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:09:37,580][93050] Avg episode reward: [(0, '68.173')]
[2026-02-02 12:09:37,737][93050] Saving new best policy, reward=68.173!
[2026-02-02 12:09:42,544][93050] Fps is (10 sec: 3259.2, 60 sec: 3006.8, 300 sec: 2675.7). Total num frames: 409600. Throughput: 0: 3068.3. Samples: 407552. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:09:42,544][93050] Avg episode reward: [(0, '79.092')]
[2026-02-02 12:09:42,701][93050] Saving new best policy, reward=79.092!
[2026-02-02 12:09:47,610][93050] Fps is (10 sec: 3266.9, 60 sec: 3001.6, 300 sec: 2693.6). Total num frames: 425984. Throughput: 0: 3052.5. Samples: 425472. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:09:47,610][93050] Avg episode reward: [(0, '87.178')]
[2026-02-02 12:09:47,767][93050] Saving new best policy, reward=87.178!
[2026-02-02 12:09:52,510][93050] Fps is (10 sec: 3288.0, 60 sec: 3008.1, 300 sec: 2713.1). Total num frames: 442368. Throughput: 0: 3032.9. Samples: 443392. Policy #0 lag: (min: 10.0, avg: 13.0, max: 74.0)
[2026-02-02 12:09:52,510][93050] Avg episode reward: [(0, '91.880')]
[2026-02-02 12:09:52,669][93050] Saving new best policy, reward=91.880!
[2026-02-02 12:09:57,601][93050] Fps is (10 sec: 3279.8, 60 sec: 3014.9, 300 sec: 2728.4). Total num frames: 458752. Throughput: 0: 3047.1. Samples: 452608. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:09:57,601][93050] Avg episode reward: [(0, '99.468')]
[2026-02-02 12:09:57,760][93050] Saving new best policy, reward=99.468!
[2026-02-02 12:10:02,714][93050] Fps is (10 sec: 3211.3, 60 sec: 3146.2, 300 sec: 2742.5). Total num frames: 475136. Throughput: 0: 3037.1. Samples: 471040. Policy #0 lag: (min: 9.0, avg: 12.0, max: 73.0)
[2026-02-02 12:10:02,714][93050] Avg episode reward: [(0, '105.504')]
[2026-02-02 12:10:02,716][93050] Saving new best policy, reward=105.504!
[2026-02-02 12:10:07,681][93050] Fps is (10 sec: 2438.2, 60 sec: 3136.3, 300 sec: 2712.0). Total num frames: 483328. Throughput: 0: 3054.4. Samples: 489472. Policy #0 lag: (min: 12.0, avg: 15.0, max: 76.0)
[2026-02-02 12:10:07,681][93050] Avg episode reward: [(0, '112.694')]
[2026-02-02 12:10:08,061][93050] Saving new best policy, reward=112.694!
[2026-02-02 12:10:12,617][93050] Fps is (10 sec: 1654.5, 60 sec: 3001.4, 300 sec: 2683.6). Total num frames: 491520. Throughput: 0: 3245.1. Samples: 507904. Policy #0 lag: (min: 12.0, avg: 15.0, max: 76.0)
[2026-02-02 12:10:12,617][93050] Avg episode reward: [(0, '112.869')]
[2026-02-02 12:10:13,006][93050] Saving new best policy, reward=112.869!
[2026-02-02 12:10:17,574][93050] Fps is (10 sec: 2484.1, 60 sec: 3001.7, 300 sec: 2700.0). Total num frames: 507904. Throughput: 0: 3054.9. Samples: 516608. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:10:17,575][93050] Avg episode reward: [(0, '124.159')]
[2026-02-02 12:10:17,735][93050] Saving new best policy, reward=124.159!
[2026-02-02 12:10:22,517][93050] Fps is (10 sec: 3309.9, 60 sec: 3007.4, 300 sec: 2715.7). Total num frames: 524288. Throughput: 0: 3064.9. Samples: 535040. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:10:22,517][93050] Avg episode reward: [(0, '133.000')]
[2026-02-02 12:10:22,674][93050] Saving new best policy, reward=133.000!
[2026-02-02 12:10:27,586][93050] Fps is (10 sec: 3272.9, 60 sec: 2999.0, 300 sec: 2729.0). Total num frames: 540672. Throughput: 0: 3012.3. Samples: 543232. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:10:27,586][93050] Avg episode reward: [(0, '144.685')]
[2026-02-02 12:10:27,745][93050] Saving new best policy, reward=144.685!
[2026-02-02 12:10:29,193][93050] Signal inference workers to stop experience collection... (100 times)
[2026-02-02 12:10:29,195][93050] Signal inference workers to resume experience collection... (100 times)
[2026-02-02 12:10:29,459][93050] InferenceWorker_p0-w0: stopping experience collection (100 times)
[2026-02-02 12:10:29,460][93050] InferenceWorker_p0-w0: resuming experience collection (100 times)
[2026-02-02 12:10:32,511][93050] Fps is (10 sec: 3278.8, 60 sec: 3002.7, 300 sec: 2743.5). Total num frames: 557056. Throughput: 0: 3033.2. Samples: 561664. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:10:32,511][93050] Avg episode reward: [(0, '152.036')]
[2026-02-02 12:10:32,669][93050] Saving new best policy, reward=152.036!
[2026-02-02 12:10:37,539][93050] Fps is (10 sec: 3292.2, 60 sec: 3005.8, 300 sec: 2755.9). Total num frames: 573440. Throughput: 0: 3035.9. Samples: 580096. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:10:37,540][93050] Avg episode reward: [(0, '153.352')]
[2026-02-02 12:10:37,694][93050] Saving new best policy, reward=153.352!
[2026-02-02 12:10:42,470][93050] Fps is (10 sec: 3290.1, 60 sec: 3007.4, 300 sec: 2769.0). Total num frames: 589824. Throughput: 0: 3069.5. Samples: 590336. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:10:42,471][93050] Avg episode reward: [(0, '156.852')]
[2026-02-02 12:10:42,628][93050] Saving new best policy, reward=156.852!
[2026-02-02 12:10:47,567][93050] Fps is (10 sec: 3267.8, 60 sec: 3005.9, 300 sec: 2779.4). Total num frames: 606208. Throughput: 0: 3036.4. Samples: 607232. Policy #0 lag: (min: 12.0, avg: 15.0, max: 76.0)
[2026-02-02 12:10:47,567][93050] Avg episode reward: [(0, '157.827')]
[2026-02-02 12:10:47,731][93050] Saving new best policy, reward=157.827!
[2026-02-02 12:10:52,489][93050] Fps is (10 sec: 3270.6, 60 sec: 3004.8, 300 sec: 2791.6). Total num frames: 622592. Throughput: 0: 3039.4. Samples: 625664. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:10:52,489][93050] Avg episode reward: [(0, '158.888')]
[2026-02-02 12:10:52,650][93050] Saving /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_accel_policy2_aggressive_magpie_adp_nullified_02022026/checkpoint_p0/checkpoint_000002432_622592.pth...
[2026-02-02 12:10:52,654][93050] Saving new best policy, reward=158.888!
[2026-02-02 12:10:57,531][93050] Fps is (10 sec: 3288.7, 60 sec: 3007.3, 300 sec: 2801.7). Total num frames: 638976. Throughput: 0: 2838.5. Samples: 635392. Policy #0 lag: (min: 7.0, avg: 10.0, max: 71.0)
[2026-02-02 12:10:57,531][93050] Avg episode reward: [(0, '169.213')]
[2026-02-02 12:10:57,692][93050] Saving new best policy, reward=169.213!
[2026-02-02 12:11:02,475][93050] Fps is (10 sec: 3281.5, 60 sec: 3015.8, 300 sec: 2812.5). Total num frames: 655360. Throughput: 0: 3056.0. Samples: 653824. Policy #0 lag: (min: 3.0, avg: 6.0, max: 67.0)
[2026-02-02 12:11:02,475][93050] Avg episode reward: [(0, '165.474')]
[2026-02-02 12:11:07,579][93050] Fps is (10 sec: 3261.1, 60 sec: 3145.6, 300 sec: 2821.1). Total num frames: 671744. Throughput: 0: 3045.0. Samples: 672256. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:11:07,579][93050] Avg episode reward: [(0, '177.769')]
[2026-02-02 12:11:07,744][93050] Saving new best policy, reward=177.769!
[2026-02-02 12:11:12,618][93050] Fps is (10 sec: 3230.6, 60 sec: 3276.8, 300 sec: 2830.0). Total num frames: 688128. Throughput: 0: 3058.5. Samples: 680960. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:11:12,618][93050] Avg episode reward: [(0, '176.758')]
[2026-02-02 12:11:17,586][93050] Fps is (10 sec: 2455.9, 60 sec: 3139.7, 300 sec: 2806.3). Total num frames: 696320. Throughput: 0: 3055.5. Samples: 699392. Policy #0 lag: (min: 5.0, avg: 8.0, max: 69.0)
[2026-02-02 12:11:17,586][93050] Avg episode reward: [(0, '182.922')]
[2026-02-02 12:11:17,966][93050] Saving new best policy, reward=182.922!
[2026-02-02 12:11:22,609][93050] Fps is (10 sec: 1639.8, 60 sec: 2999.1, 300 sec: 2783.0). Total num frames: 704512. Throughput: 0: 3055.9. Samples: 717824. Policy #0 lag: (min: 5.0, avg: 8.0, max: 69.0)
[2026-02-02 12:11:22,609][93050] Avg episode reward: [(0, '184.801')]
[2026-02-02 12:11:22,990][93050] Saving new best policy, reward=184.801!
[2026-02-02 12:11:27,507][93050] Fps is (10 sec: 2477.0, 60 sec: 3007.7, 300 sec: 2793.7). Total num frames: 720896. Throughput: 0: 3024.0. Samples: 726528. Policy #0 lag: (min: 10.0, avg: 13.0, max: 74.0)
[2026-02-02 12:11:27,508][93050] Avg episode reward: [(0, '193.185')]
[2026-02-02 12:11:27,661][93050] Saving new best policy, reward=193.185!
[2026-02-02 12:11:32,558][93050] Fps is (10 sec: 3293.7, 60 sec: 3001.4, 300 sec: 2802.3). Total num frames: 737280. Throughput: 0: 3061.2. Samples: 744960. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:11:32,558][93050] Avg episode reward: [(0, '201.740')]
[2026-02-02 12:11:32,719][93050] Saving new best policy, reward=201.740!
[2026-02-02 12:11:37,496][93050] Fps is (10 sec: 3280.5, 60 sec: 3005.9, 300 sec: 2811.8). Total num frames: 753664. Throughput: 0: 3060.2. Samples: 763392. Policy #0 lag: (min: 8.0, avg: 11.0, max: 72.0)
[2026-02-02 12:11:37,496][93050] Avg episode reward: [(0, '208.878')]
[2026-02-02 12:11:37,655][93050] Saving new best policy, reward=208.878!
[2026-02-02 12:11:42,605][93050] Fps is (10 sec: 3261.4, 60 sec: 2997.0, 300 sec: 2819.2). Total num frames: 770048. Throughput: 0: 3010.1. Samples: 771072. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:11:42,605][93050] Avg episode reward: [(0, '209.165')]
[2026-02-02 12:11:42,770][93050] Saving new best policy, reward=209.165!
[2026-02-02 12:11:47,559][93050] Fps is (10 sec: 3256.3, 60 sec: 3004.1, 300 sec: 2827.9). Total num frames: 786432. Throughput: 0: 3020.8. Samples: 790016. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:11:47,559][93050] Avg episode reward: [(0, '215.959')]
[2026-02-02 12:11:47,714][93050] Saving new best policy, reward=215.959!
[2026-02-02 12:11:52,578][93050] Fps is (10 sec: 3285.8, 60 sec: 2999.3, 300 sec: 2835.6). Total num frames: 802816. Throughput: 0: 3026.6. Samples: 808448. Policy #0 lag: (min: 13.0, avg: 16.0, max: 77.0)
[2026-02-02 12:11:52,578][93050] Avg episode reward: [(0, '225.213')]
[2026-02-02 12:11:52,745][93050] Saving new best policy, reward=225.213!
[2026-02-02 12:11:57,530][93050] Fps is (10 sec: 3286.3, 60 sec: 3003.8, 300 sec: 2843.8). Total num frames: 819200. Throughput: 0: 3066.6. Samples: 818688. Policy #0 lag: (min: 9.0, avg: 12.0, max: 73.0)
[2026-02-02 12:11:57,530][93050] Avg episode reward: [(0, '232.744')]
[2026-02-02 12:11:57,688][93050] Saving new best policy, reward=232.744!
[2026-02-02 12:12:00,345][93050] Signal inference workers to stop experience collection... (150 times)
[2026-02-02 12:12:00,744][93050] InferenceWorker_p0-w0: stopping experience collection (150 times)
[2026-02-02 12:12:00,746][93050] Signal inference workers to resume experience collection... (150 times)
[2026-02-02 12:12:00,918][93050] InferenceWorker_p0-w0: resuming experience collection (150 times)
[2026-02-02 12:12:02,500][93050] Fps is (10 sec: 3302.3, 60 sec: 3002.4, 300 sec: 2851.5). Total num frames: 835584. Throughput: 0: 3055.0. Samples: 836608. Policy #0 lag: (min: 2.0, avg: 5.0, max: 66.0)
[2026-02-02 12:12:02,501][93050] Avg episode reward: [(0, '240.823')]
[2026-02-02 12:12:02,659][93050] Saving new best policy, reward=240.823!
[2026-02-02 12:12:07,546][93050] Fps is (10 sec: 3271.7, 60 sec: 3005.4, 300 sec: 2989.3). Total num frames: 851968. Throughput: 0: 3008.0. Samples: 852992. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:12:07,546][93050] Avg episode reward: [(0, '239.224')]
[2026-02-02 12:12:12,477][93050] Fps is (10 sec: 3284.4, 60 sec: 3010.8, 300 sec: 3043.6). Total num frames: 868352. Throughput: 0: 3051.3. Samples: 863744. Policy #0 lag: (min: 8.0, avg: 11.0, max: 72.0)
[2026-02-02 12:12:12,478][93050] Avg episode reward: [(0, '243.790')]
[2026-02-02 12:12:12,646][93050] Saving new best policy, reward=243.790!
[2026-02-02 12:12:17,611][93050] Fps is (10 sec: 3255.3, 60 sec: 3138.9, 300 sec: 3047.3). Total num frames: 884736. Throughput: 0: 3034.3. Samples: 881664. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:12:17,612][93050] Avg episode reward: [(0, '250.089')]
[2026-02-02 12:12:17,767][93050] Saving new best policy, reward=250.089!
[2026-02-02 12:12:22,660][93050] Fps is (10 sec: 3218.1, 60 sec: 3274.0, 300 sec: 3065.6). Total num frames: 901120. Throughput: 0: 3026.9. Samples: 900096. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:12:22,660][93050] Avg episode reward: [(0, '255.912')]
[2026-02-02 12:12:22,662][93050] Saving new best policy, reward=255.912!
[2026-02-02 12:12:27,686][93050] Fps is (10 sec: 2439.4, 60 sec: 3130.9, 300 sec: 3080.9). Total num frames: 909312. Throughput: 0: 3055.1. Samples: 908800. Policy #0 lag: (min: 2.0, avg: 5.0, max: 66.0)
[2026-02-02 12:12:27,686][93050] Avg episode reward: [(0, '266.931')]
[2026-02-02 12:12:28,057][93050] Saving new best policy, reward=266.931!
[2026-02-02 12:12:32,584][93050] Fps is (10 sec: 1650.9, 60 sec: 3002.4, 300 sec: 3054.1). Total num frames: 917504. Throughput: 0: 3047.5. Samples: 927232. Policy #0 lag: (min: 2.0, avg: 5.0, max: 66.0)
[2026-02-02 12:12:32,584][93050] Avg episode reward: [(0, '280.792')]
[2026-02-02 12:12:32,761][93050] Saving new best policy, reward=280.792!
[2026-02-02 12:12:37,567][93050] Fps is (10 sec: 2487.2, 60 sec: 3000.2, 300 sec: 3054.9). Total num frames: 933888. Throughput: 0: 3038.6. Samples: 945152. Policy #0 lag: (min: 11.0, avg: 14.0, max: 75.0)
[2026-02-02 12:12:37,567][93050] Avg episode reward: [(0, '289.606')]
[2026-02-02 12:12:37,729][93050] Saving new best policy, reward=289.606!
[2026-02-02 12:12:42,576][93050] Fps is (10 sec: 3279.4, 60 sec: 3005.2, 300 sec: 3059.6). Total num frames: 950272. Throughput: 0: 2989.3. Samples: 953344. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:12:42,576][93050] Avg episode reward: [(0, '290.066')]
[2026-02-02 12:12:42,737][93050] Saving new best policy, reward=290.066!
[2026-02-02 12:12:47,505][93050] Fps is (10 sec: 3297.1, 60 sec: 3006.4, 300 sec: 3055.3). Total num frames: 966656. Throughput: 0: 3003.4. Samples: 971776. Policy #0 lag: (min: 4.0, avg: 7.0, max: 68.0)
[2026-02-02 12:12:47,506][93050] Avg episode reward: [(0, '277.751')]
[2026-02-02 12:12:52,534][93050] Fps is (10 sec: 3290.5, 60 sec: 3005.9, 300 sec: 3054.7). Total num frames: 983040. Throughput: 0: 3050.0. Samples: 990208. Policy #0 lag: (min: 0.0, avg: 3.0, max: 64.0)
[2026-02-02 12:12:52,535][93050] Avg episode reward: [(0, '279.519')]
[2026-02-02 12:12:52,696][93050] Saving /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_accel_policy2_aggressive_magpie_adp_nullified_02022026/checkpoint_p0/checkpoint_000003840_983040.pth...
[2026-02-02 12:12:52,700][93050] Removing /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_accel_policy2_aggressive_magpie_adp_nullified_02022026/checkpoint_p0/checkpoint_000001024_262144.pth
[2026-02-02 12:12:57,586][93050] Fps is (10 sec: 3250.7, 60 sec: 3000.9, 300 sec: 3054.2). Total num frames: 999424. Throughput: 0: 3030.6. Samples: 1000448. Policy #0 lag: (min: 12.0, avg: 15.0, max: 76.0)
[2026-02-02 12:12:57,586][93050] Avg episode reward: [(0, '288.542')]
[2026-02-02 12:13:02,545][93050] Fps is (10 sec: 3273.2, 60 sec: 3001.5, 300 sec: 3054.7). Total num frames: 1015808. Throughput: 0: 3008.2. Samples: 1016832. Policy #0 lag: (min: 11.0, avg: 14.0, max: 75.0)
[2026-02-02 12:13:02,545][93050] Avg episode reward: [(0, '306.036')]
[2026-02-02 12:13:02,705][93050] Saving new best policy, reward=306.036!
[2026-02-02 12:13:07,510][93050] Fps is (10 sec: 3302.0, 60 sec: 3005.5, 300 sec: 3054.4). Total num frames: 1032192. Throughput: 0: 3025.2. Samples: 1035776. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:13:07,510][93050] Avg episode reward: [(0, '319.723')]
[2026-02-02 12:13:07,663][93050] Saving new best policy, reward=319.723!
[2026-02-02 12:13:12,567][93050] Fps is (10 sec: 3269.7, 60 sec: 2999.3, 300 sec: 3053.8). Total num frames: 1048576. Throughput: 0: 3045.9. Samples: 1045504. Policy #0 lag: (min: 9.0, avg: 12.0, max: 73.0)
[2026-02-02 12:13:12,567][93050] Avg episode reward: [(0, '321.609')]
[2026-02-02 12:13:12,735][93050] Saving new best policy, reward=321.609!
[2026-02-02 12:13:17,470][93050] Fps is (10 sec: 3289.8, 60 sec: 3010.8, 300 sec: 3055.5). Total num frames: 1064960. Throughput: 0: 3045.6. Samples: 1063936. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:13:17,470][93050] Avg episode reward: [(0, '323.916')]
[2026-02-02 12:13:17,625][93050] Saving new best policy, reward=323.916!
[2026-02-02 12:13:22,532][93050] Fps is (10 sec: 3288.4, 60 sec: 3010.2, 300 sec: 3054.7). Total num frames: 1081344. Throughput: 0: 3051.6. Samples: 1082368. Policy #0 lag: (min: 5.0, avg: 8.0, max: 69.0)
[2026-02-02 12:13:22,532][93050] Avg episode reward: [(0, '324.435')]
[2026-02-02 12:13:22,696][93050] Saving new best policy, reward=324.435!
[2026-02-02 12:13:27,106][93050] Signal inference workers to stop experience collection... (200 times)
[2026-02-02 12:13:27,481][93050] InferenceWorker_p0-w0: stopping experience collection (200 times)
[2026-02-02 12:13:27,481][93050] Signal inference workers to resume experience collection... (200 times)
[2026-02-02 12:13:27,481][93050] Fps is (10 sec: 3273.0, 60 sec: 3151.0, 300 sec: 3055.4). Total num frames: 1097728. Throughput: 0: 3067.1. Samples: 1091072. Policy #0 lag: (min: 11.0, avg: 14.0, max: 75.0)
[2026-02-02 12:13:27,481][93050] Avg episode reward: [(0, '324.856')]
[2026-02-02 12:13:27,482][93050] InferenceWorker_p0-w0: resuming experience collection (200 times)
[2026-02-02 12:13:27,482][93050] Saving new best policy, reward=324.856!
[2026-02-02 12:13:32,564][93050] Fps is (10 sec: 2449.6, 60 sec: 3141.3, 300 sec: 3026.5). Total num frames: 1105920. Throughput: 0: 3056.6. Samples: 1109504. Policy #0 lag: (min: 10.0, avg: 13.0, max: 74.0)
[2026-02-02 12:13:32,565][93050] Avg episode reward: [(0, '325.878')]
[2026-02-02 12:13:32,953][93050] Saving new best policy, reward=325.878!
[2026-02-02 12:13:37,529][93050] Fps is (10 sec: 1630.6, 60 sec: 3005.6, 300 sec: 2999.9). Total num frames: 1114112. Throughput: 0: 3038.2. Samples: 1126912. Policy #0 lag: (min: 10.0, avg: 13.0, max: 74.0)
[2026-02-02 12:13:37,530][93050] Avg episode reward: [(0, '344.240')]
[2026-02-02 12:13:37,687][93050] Saving new best policy, reward=344.240!
[2026-02-02 12:13:42,616][93050] Fps is (10 sec: 2445.0, 60 sec: 3001.7, 300 sec: 2998.6). Total num frames: 1130496. Throughput: 0: 3217.8. Samples: 1145344. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:13:42,616][93050] Avg episode reward: [(0, '360.675')]
[2026-02-02 12:13:42,775][93050] Saving new best policy, reward=360.675!
[2026-02-02 12:13:47,530][93050] Fps is (10 sec: 3276.5, 60 sec: 3002.5, 300 sec: 2999.8). Total num frames: 1146880. Throughput: 0: 3050.3. Samples: 1154048. Policy #0 lag: (min: 14.0, avg: 17.0, max: 78.0)
[2026-02-02 12:13:47,530][93050] Avg episode reward: [(0, '363.036')]
[2026-02-02 12:13:47,692][93050] Saving new best policy, reward=363.036!
[2026-02-02 12:13:52,498][93050] Fps is (10 sec: 3316.0, 60 sec: 3005.6, 300 sec: 3002.4). Total num frames: 1163264. Throughput: 0: 3038.7. Samples: 1172480. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:13:52,498][93050] Avg episode reward: [(0, '368.280')]
[2026-02-02 12:13:52,669][93050] Saving new best policy, reward=368.280!
[2026-02-02 12:13:57,498][93050] Fps is (10 sec: 3287.3, 60 sec: 3008.1, 300 sec: 3030.2). Total num frames: 1179648. Throughput: 0: 3008.3. Samples: 1180672. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:13:57,498][93050] Avg episode reward: [(0, '367.338')]
[2026-02-02 12:14:02,565][93050] Fps is (10 sec: 3254.8, 60 sec: 3002.7, 300 sec: 3055.1). Total num frames: 1196032. Throughput: 0: 2997.4. Samples: 1199104. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:14:02,566][93050] Avg episode reward: [(0, '364.703')]
[2026-02-02 12:14:07,612][93050] Fps is (10 sec: 3239.8, 60 sec: 2998.6, 300 sec: 3054.2). Total num frames: 1212416. Throughput: 0: 2998.4. Samples: 1217536. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:14:07,612][93050] Avg episode reward: [(0, '358.733')]
[2026-02-02 12:14:12,569][93050] Fps is (10 sec: 3275.7, 60 sec: 3003.7, 300 sec: 3054.3). Total num frames: 1228800. Throughput: 0: 3020.6. Samples: 1227264. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:14:12,569][93050] Avg episode reward: [(0, '360.549')]
[2026-02-02 12:14:17,554][93050] Fps is (10 sec: 3296.1, 60 sec: 2999.5, 300 sec: 3055.0). Total num frames: 1245184. Throughput: 0: 3027.2. Samples: 1245696. Policy #0 lag: (min: 14.0, avg: 17.0, max: 78.0)
[2026-02-02 12:14:17,554][93050] Avg episode reward: [(0, '356.330')]
[2026-02-02 12:14:22,612][93050] Fps is (10 sec: 3262.7, 60 sec: 2999.7, 300 sec: 3053.4). Total num frames: 1261568. Throughput: 0: 3009.6. Samples: 1262592. Policy #0 lag: (min: 13.0, avg: 16.0, max: 77.0)
[2026-02-02 12:14:22,612][93050] Avg episode reward: [(0, '361.747')]
[2026-02-02 12:14:27,517][93050] Fps is (10 sec: 3288.8, 60 sec: 3001.9, 300 sec: 3054.4). Total num frames: 1277952. Throughput: 0: 2839.3. Samples: 1272832. Policy #0 lag: (min: 0.0, avg: 3.0, max: 64.0)
[2026-02-02 12:14:27,518][93050] Avg episode reward: [(0, '365.971')]
[2026-02-02 12:14:32,477][93050] Fps is (10 sec: 3321.7, 60 sec: 3144.9, 300 sec: 3055.7). Total num frames: 1294336. Throughput: 0: 3052.9. Samples: 1291264. Policy #0 lag: (min: 0.0, avg: 3.0, max: 64.0)
[2026-02-02 12:14:32,477][93050] Avg episode reward: [(0, '382.289')]
[2026-02-02 12:14:32,478][93050] Saving new best policy, reward=382.289!
[2026-02-02 12:14:37,476][93050] Fps is (10 sec: 2467.8, 60 sec: 3143.1, 300 sec: 3027.6). Total num frames: 1302528. Throughput: 0: 3039.3. Samples: 1309184. Policy #0 lag: (min: 10.0, avg: 13.0, max: 74.0)
[2026-02-02 12:14:37,476][93050] Avg episode reward: [(0, '378.214')]
[2026-02-02 12:14:42,812][93050] Fps is (10 sec: 2377.8, 60 sec: 3130.0, 300 sec: 3024.8). Total num frames: 1318912. Throughput: 0: 3028.1. Samples: 1317888. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:14:42,812][93050] Avg episode reward: [(0, '385.172')]
[2026-02-02 12:14:43,185][93050] Saving new best policy, reward=385.172!
[2026-02-02 12:14:47,514][93050] Fps is (10 sec: 2448.3, 60 sec: 3004.6, 300 sec: 2999.1). Total num frames: 1327104. Throughput: 0: 3052.7. Samples: 1336320. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:14:47,514][93050] Avg episode reward: [(0, '389.021')]
[2026-02-02 12:14:47,667][93050] Saving new best policy, reward=389.021!
[2026-02-02 12:14:52,594][93050] Fps is (10 sec: 2512.3, 60 sec: 2998.9, 300 sec: 2999.2). Total num frames: 1343488. Throughput: 0: 3050.5. Samples: 1354752. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:14:52,594][93050] Avg episode reward: [(0, '390.075')]
[2026-02-02 12:14:52,751][93050] Saving /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_accel_policy2_aggressive_magpie_adp_nullified_02022026/checkpoint_p0/checkpoint_000005248_1343488.pth...
[2026-02-02 12:14:52,755][93050] Removing /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_accel_policy2_aggressive_magpie_adp_nullified_02022026/checkpoint_p0/checkpoint_000002432_622592.pth
[2026-02-02 12:14:52,755][93050] Saving new best policy, reward=390.075!
[2026-02-02 12:14:57,536][93050] Fps is (10 sec: 3269.5, 60 sec: 3001.8, 300 sec: 3000.9). Total num frames: 1359872. Throughput: 0: 3028.7. Samples: 1363456. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:14:57,536][93050] Avg episode reward: [(0, '405.025')]
[2026-02-02 12:14:57,695][93050] Saving new best policy, reward=405.025!
[2026-02-02 12:14:58,992][93050] Signal inference workers to stop experience collection... (250 times)
[2026-02-02 12:14:58,995][93050] Signal inference workers to resume experience collection... (250 times)
[2026-02-02 12:14:59,260][93050] InferenceWorker_p0-w0: stopping experience collection (250 times)
[2026-02-02 12:14:59,260][93050] InferenceWorker_p0-w0: resuming experience collection (250 times)
[2026-02-02 12:15:02,623][93050] Fps is (10 sec: 3267.3, 60 sec: 3000.8, 300 sec: 3027.5). Total num frames: 1376256. Throughput: 0: 3010.5. Samples: 1381376. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:15:02,623][93050] Avg episode reward: [(0, '404.960')]
[2026-02-02 12:15:07,583][93050] Fps is (10 sec: 3261.5, 60 sec: 3005.2, 300 sec: 3055.0). Total num frames: 1392640. Throughput: 0: 3051.2. Samples: 1399808. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:15:07,583][93050] Avg episode reward: [(0, '395.068')]
[2026-02-02 12:15:12,499][93050] Fps is (10 sec: 3318.1, 60 sec: 3007.2, 300 sec: 3055.4). Total num frames: 1409024. Throughput: 0: 3050.5. Samples: 1410048. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:15:12,499][93050] Avg episode reward: [(0, '387.028')]
[2026-02-02 12:15:17,565][93050] Fps is (10 sec: 3282.9, 60 sec: 3003.2, 300 sec: 3054.1). Total num frames: 1425408. Throughput: 0: 2997.9. Samples: 1426432. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:15:17,565][93050] Avg episode reward: [(0, '384.333')]
[2026-02-02 12:15:22,613][93050] Fps is (10 sec: 3239.6, 60 sec: 3003.7, 300 sec: 3054.4). Total num frames: 1441792. Throughput: 0: 3017.3. Samples: 1445376. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:15:22,614][93050] Avg episode reward: [(0, '397.225')]
[2026-02-02 12:15:27,539][93050] Fps is (10 sec: 3285.4, 60 sec: 3002.7, 300 sec: 3054.4). Total num frames: 1458176. Throughput: 0: 3079.3. Samples: 1455616. Policy #0 lag: (min: 17.0, avg: 20.0, max: 81.0)
[2026-02-02 12:15:27,539][93050] Avg episode reward: [(0, '405.429')]
[2026-02-02 12:15:27,699][93050] Saving new best policy, reward=405.429!
[2026-02-02 12:15:32,574][93050] Fps is (10 sec: 3289.6, 60 sec: 2998.8, 300 sec: 3054.3). Total num frames: 1474560. Throughput: 0: 3056.5. Samples: 1474048. Policy #0 lag: (min: 31.0, avg: 34.0, max: 95.0)
[2026-02-02 12:15:32,575][93050] Avg episode reward: [(0, '420.943')]
[2026-02-02 12:15:32,742][93050] Saving new best policy, reward=420.943!
[2026-02-02 12:15:37,579][93050] Fps is (10 sec: 3263.6, 60 sec: 3134.9, 300 sec: 3053.5). Total num frames: 1490944. Throughput: 0: 3050.3. Samples: 1491968. Policy #0 lag: (min: 47.0, avg: 50.0, max: 111.0)
[2026-02-02 12:15:37,579][93050] Avg episode reward: [(0, '418.753')]
[2026-02-02 12:15:42,491][93050] Fps is (10 sec: 3304.4, 60 sec: 3157.2, 300 sec: 3055.4). Total num frames: 1507328. Throughput: 0: 3063.7. Samples: 1501184. Policy #0 lag: (min: 47.0, avg: 50.0, max: 111.0)
[2026-02-02 12:15:42,491][93050] Avg episode reward: [(0, '427.048')]
[2026-02-02 12:15:42,653][93050] Saving new best policy, reward=427.048!
[2026-02-02 12:15:47,777][93050] Fps is (10 sec: 3213.2, 60 sec: 3262.5, 300 sec: 3051.7). Total num frames: 1523712. Throughput: 0: 3061.5. Samples: 1519616. Policy #0 lag: (min: 13.0, avg: 16.0, max: 77.0)
[2026-02-02 12:15:47,777][93050] Avg episode reward: [(0, '435.173')]
[2026-02-02 12:15:47,777][93050] Saving new best policy, reward=435.173!
[2026-02-02 12:15:52,755][93050] Fps is (10 sec: 2394.5, 60 sec: 3131.9, 300 sec: 3024.6). Total num frames: 1531904. Throughput: 0: 3049.0. Samples: 1537536. Policy #0 lag: (min: 13.0, avg: 16.0, max: 77.0)
[2026-02-02 12:15:52,755][93050] Avg episode reward: [(0, '442.278')]
[2026-02-02 12:15:53,130][93050] Saving new best policy, reward=442.278!
[2026-02-02 12:15:57,586][93050] Fps is (10 sec: 1670.2, 60 sec: 3001.2, 300 sec: 2998.0). Total num frames: 1540096. Throughput: 0: 3020.6. Samples: 1546240. Policy #0 lag: (min: 47.0, avg: 50.0, max: 111.0)
[2026-02-02 12:15:57,587][93050] Avg episode reward: [(0, '443.797')]
[2026-02-02 12:15:57,749][93050] Saving new best policy, reward=443.797!
[2026-02-02 12:16:02,516][93050] Fps is (10 sec: 2517.7, 60 sec: 3009.1, 300 sec: 2999.7). Total num frames: 1556480. Throughput: 0: 3075.3. Samples: 1564672. Policy #0 lag: (min: 47.0, avg: 50.0, max: 111.0)
[2026-02-02 12:16:02,516][93050] Avg episode reward: [(0, '452.271')]
[2026-02-02 12:16:02,676][93050] Saving new best policy, reward=452.271!
[2026-02-02 12:16:07,611][93050] Fps is (10 sec: 3268.6, 60 sec: 3002.3, 300 sec: 2999.2). Total num frames: 1572864. Throughput: 0: 3060.8. Samples: 1583104. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:16:07,612][93050] Avg episode reward: [(0, '452.670')]
[2026-02-02 12:16:07,781][93050] Saving new best policy, reward=452.670!
[2026-02-02 12:16:12,555][93050] Fps is (10 sec: 3264.1, 60 sec: 3000.9, 300 sec: 3027.2). Total num frames: 1589248. Throughput: 0: 3014.0. Samples: 1591296. Policy #0 lag: (min: 44.0, avg: 47.0, max: 108.0)
[2026-02-02 12:16:12,555][93050] Avg episode reward: [(0, '459.222')]
[2026-02-02 12:16:12,730][93050] Saving new best policy, reward=459.222!
[2026-02-02 12:16:17,513][93050] Fps is (10 sec: 3309.3, 60 sec: 3006.3, 300 sec: 3055.6). Total num frames: 1605632. Throughput: 0: 3019.2. Samples: 1609728. Policy #0 lag: (min: 44.0, avg: 47.0, max: 108.0)
[2026-02-02 12:16:17,513][93050] Avg episode reward: [(0, '468.338')]
[2026-02-02 12:16:17,670][93050] Saving new best policy, reward=468.338!
[2026-02-02 12:16:22,494][93050] Fps is (10 sec: 3296.8, 60 sec: 3009.7, 300 sec: 3054.8). Total num frames: 1622016. Throughput: 0: 3032.2. Samples: 1628160. Policy #0 lag: (min: 5.0, avg: 8.0, max: 69.0)
[2026-02-02 12:16:22,494][93050] Avg episode reward: [(0, '465.008')]
[2026-02-02 12:16:27,471][93050] Fps is (10 sec: 3290.6, 60 sec: 3007.1, 300 sec: 3055.5). Total num frames: 1638400. Throughput: 0: 3039.2. Samples: 1637888. Policy #0 lag: (min: 32.0, avg: 35.0, max: 96.0)
[2026-02-02 12:16:27,472][93050] Avg episode reward: [(0, '475.177')]
[2026-02-02 12:16:27,624][93050] Saving new best policy, reward=475.177!
[2026-02-02 12:16:30,198][93050] Signal inference workers to stop experience collection... (300 times)
[2026-02-02 12:16:30,575][93050] InferenceWorker_p0-w0: stopping experience collection (300 times)
[2026-02-02 12:16:30,577][93050] Signal inference workers to resume experience collection... (300 times)
[2026-02-02 12:16:30,730][93050] InferenceWorker_p0-w0: resuming experience collection (300 times)
[2026-02-02 12:16:32,517][93050] Fps is (10 sec: 3269.2, 60 sec: 3006.6, 300 sec: 3054.4). Total num frames: 1654784. Throughput: 0: 3044.1. Samples: 1655808. Policy #0 lag: (min: 32.0, avg: 35.0, max: 96.0)
[2026-02-02 12:16:32,517][93050] Avg episode reward: [(0, '462.183')]
[2026-02-02 12:16:37,479][93050] Fps is (10 sec: 3274.2, 60 sec: 3008.7, 300 sec: 3055.9). Total num frames: 1671168. Throughput: 0: 3033.7. Samples: 1673216. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:16:37,480][93050] Avg episode reward: [(0, '461.408')]
[2026-02-02 12:16:42,528][93050] Fps is (10 sec: 3273.3, 60 sec: 3001.9, 300 sec: 3055.0). Total num frames: 1687552. Throughput: 0: 3041.8. Samples: 1682944. Policy #0 lag: (min: 47.0, avg: 50.0, max: 111.0)
[2026-02-02 12:16:42,528][93050] Avg episode reward: [(0, '466.020')]
[2026-02-02 12:16:47,596][93050] Fps is (10 sec: 3238.9, 60 sec: 3012.8, 300 sec: 3054.5). Total num frames: 1703936. Throughput: 0: 3021.1. Samples: 1700864. Policy #0 lag: (min: 47.0, avg: 50.0, max: 111.0)
[2026-02-02 12:16:47,597][93050] Avg episode reward: [(0, '465.720')]
[2026-02-02 12:16:52,800][93050] Fps is (10 sec: 3189.9, 60 sec: 3137.9, 300 sec: 3051.8). Total num frames: 1720320. Throughput: 0: 3013.9. Samples: 1719296. Policy #0 lag: (min: 4.0, avg: 7.0, max: 68.0)
[2026-02-02 12:16:52,800][93050] Avg episode reward: [(0, '462.417')]
[2026-02-02 12:16:52,802][93050] Saving /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_accel_policy2_aggressive_magpie_adp_nullified_02022026/checkpoint_p0/checkpoint_000006720_1720320.pth...
[2026-02-02 12:16:52,806][93050] Removing /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_accel_policy2_aggressive_magpie_adp_nullified_02022026/checkpoint_p0/checkpoint_000003840_983040.pth
[2026-02-02 12:16:57,792][93050] Fps is (10 sec: 2410.4, 60 sec: 3129.5, 300 sec: 3023.9). Total num frames: 1728512. Throughput: 0: 3010.6. Samples: 1727488. Policy #0 lag: (min: 4.0, avg: 7.0, max: 68.0)
[2026-02-02 12:16:57,792][93050] Avg episode reward: [(0, '457.020')]
[2026-02-02 12:17:02,481][93050] Fps is (10 sec: 1692.4, 60 sec: 3005.5, 300 sec: 2999.8). Total num frames: 1736704. Throughput: 0: 3028.7. Samples: 1745920. Policy #0 lag: (min: 4.0, avg: 7.0, max: 68.0)
[2026-02-02 12:17:02,481][93050] Avg episode reward: [(0, '467.951')]
[2026-02-02 12:17:07,577][93050] Fps is (10 sec: 2511.6, 60 sec: 3005.5, 300 sec: 2998.1). Total num frames: 1753088. Throughput: 0: 3020.9. Samples: 1764352. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:17:07,577][93050] Avg episode reward: [(0, '481.434')]
[2026-02-02 12:17:07,734][93050] Saving new best policy, reward=481.434!
[2026-02-02 12:17:12,580][93050] Fps is (10 sec: 3244.8, 60 sec: 3002.5, 300 sec: 2999.4). Total num frames: 1769472. Throughput: 0: 2996.5. Samples: 1773056. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:17:12,580][93050] Avg episode reward: [(0, '495.353')]
[2026-02-02 12:17:12,743][93050] Saving new best policy, reward=495.353!
[2026-02-02 12:17:17,563][93050] Fps is (10 sec: 3281.3, 60 sec: 3001.2, 300 sec: 3000.1). Total num frames: 1785856. Throughput: 0: 3000.7. Samples: 1790976. Policy #0 lag: (min: 5.0, avg: 8.0, max: 69.0)
[2026-02-02 12:17:17,566][93050] Avg episode reward: [(0, '502.221')]
[2026-02-02 12:17:17,725][93050] Saving new best policy, reward=502.221!
[2026-02-02 12:17:22,600][93050] Fps is (10 sec: 3270.2, 60 sec: 2998.4, 300 sec: 3027.8). Total num frames: 1802240. Throughput: 0: 3018.4. Samples: 1809408. Policy #0 lag: (min: 5.0, avg: 8.0, max: 69.0)
[2026-02-02 12:17:22,600][93050] Avg episode reward: [(0, '494.602')]
[2026-02-02 12:17:27,484][93050] Fps is (10 sec: 3302.9, 60 sec: 3003.1, 300 sec: 3055.7). Total num frames: 1818624. Throughput: 0: 3040.8. Samples: 1819648. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:17:27,484][93050] Avg episode reward: [(0, '496.700')]
[2026-02-02 12:17:32,576][93050] Fps is (10 sec: 3284.7, 60 sec: 3000.8, 300 sec: 3054.6). Total num frames: 1835008. Throughput: 0: 3005.1. Samples: 1836032. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:17:32,576][93050] Avg episode reward: [(0, '514.565')]
[2026-02-02 12:17:32,740][93050] Saving new best policy, reward=514.565!
[2026-02-02 12:17:37,559][93050] Fps is (10 sec: 3252.4, 60 sec: 2999.7, 300 sec: 3054.8). Total num frames: 1851392. Throughput: 0: 3031.3. Samples: 1854976. Policy #0 lag: (min: 13.0, avg: 16.0, max: 77.0)
[2026-02-02 12:17:37,560][93050] Avg episode reward: [(0, '532.576')]
[2026-02-02 12:17:37,718][93050] Saving new best policy, reward=532.576!
[2026-02-02 12:17:42,519][93050] Fps is (10 sec: 3295.6, 60 sec: 3004.2, 300 sec: 3054.5). Total num frames: 1867776. Throughput: 0: 3067.9. Samples: 1864704. Policy #0 lag: (min: 13.0, avg: 16.0, max: 77.0)
[2026-02-02 12:17:42,519][93050] Avg episode reward: [(0, '539.300')]
[2026-02-02 12:17:42,677][93050] Saving new best policy, reward=539.300!
[2026-02-02 12:17:47,551][93050] Fps is (10 sec: 3279.6, 60 sec: 3006.0, 300 sec: 3054.5). Total num frames: 1884160. Throughput: 0: 3021.8. Samples: 1882112. Policy #0 lag: (min: 6.0, avg: 9.0, max: 70.0)
[2026-02-02 12:17:47,551][93050] Avg episode reward: [(0, '518.472')]
[2026-02-02 12:17:52,540][93050] Fps is (10 sec: 3269.9, 60 sec: 3016.8, 300 sec: 3055.1). Total num frames: 1900544. Throughput: 0: 3029.0. Samples: 1900544. Policy #0 lag: (min: 6.0, avg: 9.0, max: 70.0)
[2026-02-02 12:17:52,540][93050] Avg episode reward: [(0, '534.445')]
[2026-02-02 12:17:57,588][93050] Signal inference workers to stop experience collection... (350 times)
[2026-02-02 12:17:57,588][93050] Fps is (10 sec: 2448.4, 60 sec: 3014.0, 300 sec: 3026.4). Total num frames: 1908736. Throughput: 0: 3014.5. Samples: 1908736. Policy #0 lag: (min: 13.0, avg: 16.0, max: 77.0)
[2026-02-02 12:17:57,588][93050] Avg episode reward: [(0, '530.009')]
[2026-02-02 12:17:57,966][93050] InferenceWorker_p0-w0: stopping experience collection (350 times)
[2026-02-02 12:17:57,966][93050] Signal inference workers to resume experience collection... (350 times)
[2026-02-02 12:17:57,966][93050] InferenceWorker_p0-w0: resuming experience collection (350 times)
[2026-02-02 12:18:02,580][93050] Fps is (10 sec: 1631.8, 60 sec: 2998.8, 300 sec: 2998.4). Total num frames: 1916928. Throughput: 0: 3025.3. Samples: 1927168. Policy #0 lag: (min: 13.0, avg: 16.0, max: 77.0)
[2026-02-02 12:18:02,581][93050] Avg episode reward: [(0, '547.346')]
[2026-02-02 12:18:02,973][93050] Saving new best policy, reward=547.346!
[2026-02-02 12:18:07,488][93050] Fps is (10 sec: 2482.4, 60 sec: 3008.2, 300 sec: 2999.9). Total num frames: 1933312. Throughput: 0: 3034.0. Samples: 1945600. Policy #0 lag: (min: 13.0, avg: 16.0, max: 77.0)
[2026-02-02 12:18:07,489][93050] Avg episode reward: [(0, '535.162')]
[2026-02-02 12:18:12,618][93050] Fps is (10 sec: 3264.4, 60 sec: 3001.8, 300 sec: 2997.6). Total num frames: 1949696. Throughput: 0: 3187.7. Samples: 1963520. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:18:12,618][93050] Avg episode reward: [(0, '538.750')]
[2026-02-02 12:18:17,485][93050] Fps is (10 sec: 3278.1, 60 sec: 3007.7, 300 sec: 2999.6). Total num frames: 1966080. Throughput: 0: 3032.6. Samples: 1972224. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:18:17,485][93050] Avg episode reward: [(0, '557.029')]
[2026-02-02 12:18:17,642][93050] Saving new best policy, reward=557.029!
[2026-02-02 12:18:22,564][93050] Fps is (10 sec: 3294.8, 60 sec: 3005.5, 300 sec: 2998.3). Total num frames: 1982464. Throughput: 0: 3014.8. Samples: 1990656. Policy #0 lag: (min: 8.0, avg: 11.0, max: 72.0)
[2026-02-02 12:18:22,564][93050] Avg episode reward: [(0, '564.296')]
[2026-02-02 12:18:22,726][93050] Saving new best policy, reward=564.296!
[2026-02-02 12:18:27,485][93050] Fps is (10 sec: 3276.7, 60 sec: 3003.7, 300 sec: 3027.7). Total num frames: 1998848. Throughput: 0: 3006.0. Samples: 1999872. Policy #0 lag: (min: 8.0, avg: 11.0, max: 72.0)
[2026-02-02 12:18:27,485][93050] Avg episode reward: [(0, '576.785')]
[2026-02-02 12:18:27,658][93050] Saving new best policy, reward=576.785!
[2026-02-02 12:18:32,625][93050] Fps is (10 sec: 3256.8, 60 sec: 3001.3, 300 sec: 3053.7). Total num frames: 2015232. Throughput: 0: 2998.8. Samples: 2017280. Policy #0 lag: (min: 7.0, avg: 10.0, max: 71.0)
[2026-02-02 12:18:32,625][93050] Avg episode reward: [(0, '581.229')]
[2026-02-02 12:18:32,790][93050] Saving new best policy, reward=581.229!
[2026-02-02 12:18:37,610][93050] Fps is (10 sec: 3236.2, 60 sec: 3001.2, 300 sec: 3054.7). Total num frames: 2031616. Throughput: 0: 2987.7. Samples: 2035200. Policy #0 lag: (min: 7.0, avg: 10.0, max: 71.0)
[2026-02-02 12:18:37,611][93050] Avg episode reward: [(0, '566.417')]
[2026-02-02 12:18:42,591][93050] Fps is (10 sec: 3288.0, 60 sec: 3000.1, 300 sec: 3054.0). Total num frames: 2048000. Throughput: 0: 3037.7. Samples: 2045440. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:18:42,591][93050] Avg episode reward: [(0, '562.623')]
[2026-02-02 12:18:47,563][93050] Fps is (10 sec: 3292.4, 60 sec: 3003.1, 300 sec: 3054.0). Total num frames: 2064384. Throughput: 0: 3027.7. Samples: 2063360. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:18:47,563][93050] Avg episode reward: [(0, '574.938')]
[2026-02-02 12:18:52,524][93050] Fps is (10 sec: 3298.8, 60 sec: 3004.5, 300 sec: 3054.4). Total num frames: 2080768. Throughput: 0: 3024.1. Samples: 2081792. Policy #0 lag: (min: 10.0, avg: 13.0, max: 74.0)
[2026-02-02 12:18:52,524][93050] Avg episode reward: [(0, '574.963')]
[2026-02-02 12:18:52,687][93050] Saving /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_accel_policy2_aggressive_magpie_adp_nullified_02022026/checkpoint_p0/checkpoint_000008128_2080768.pth...
[2026-02-02 12:18:52,691][93050] Removing /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_accel_policy2_aggressive_magpie_adp_nullified_02022026/checkpoint_p0/checkpoint_000005248_1343488.pth
[2026-02-02 12:18:57,626][93050] Fps is (10 sec: 3256.3, 60 sec: 3138.3, 300 sec: 3054.0). Total num frames: 2097152. Throughput: 0: 2809.8. Samples: 2089984. Policy #0 lag: (min: 10.0, avg: 13.0, max: 74.0)
[2026-02-02 12:18:57,626][93050] Avg episode reward: [(0, '606.230')]
[2026-02-02 12:18:57,633][93050] Saving new best policy, reward=606.230!
[2026-02-02 12:19:02,632][93050] Fps is (10 sec: 2431.4, 60 sec: 3137.6, 300 sec: 3026.7). Total num frames: 2105344. Throughput: 0: 3016.6. Samples: 2108416. Policy #0 lag: (min: 10.0, avg: 13.0, max: 74.0)
[2026-02-02 12:19:02,632][93050] Avg episode reward: [(0, '606.066')]
[2026-02-02 12:19:07,520][93050] Fps is (10 sec: 1655.9, 60 sec: 3002.1, 300 sec: 2999.6). Total num frames: 2113536. Throughput: 0: 3029.4. Samples: 2126848. Policy #0 lag: (min: 10.0, avg: 13.0, max: 74.0)
[2026-02-02 12:19:07,521][93050] Avg episode reward: [(0, '594.183')]
[2026-02-02 12:19:12,611][93050] Fps is (10 sec: 2462.8, 60 sec: 3004.1, 300 sec: 2998.5). Total num frames: 2129920. Throughput: 0: 2995.3. Samples: 2135040. Policy #0 lag: (min: 10.0, avg: 13.0, max: 74.0)
[2026-02-02 12:19:12,611][93050] Avg episode reward: [(0, '596.033')]
[2026-02-02 12:19:17,601][93050] Fps is (10 sec: 3250.7, 60 sec: 2997.9, 300 sec: 2999.2). Total num frames: 2146304. Throughput: 0: 3028.1. Samples: 2153472. Policy #0 lag: (min: 5.0, avg: 8.0, max: 69.0)
[2026-02-02 12:19:17,601][93050] Avg episode reward: [(0, '583.752')]
[2026-02-02 12:19:22,595][93050] Fps is (10 sec: 3281.9, 60 sec: 3002.1, 300 sec: 2998.3). Total num frames: 2162688. Throughput: 0: 3027.5. Samples: 2171392. Policy #0 lag: (min: 5.0, avg: 8.0, max: 69.0)
[2026-02-02 12:19:22,596][93050] Avg episode reward: [(0, '597.953')]
[2026-02-02 12:19:27,561][93050] Fps is (10 sec: 3290.0, 60 sec: 2999.9, 300 sec: 2998.3). Total num frames: 2179072. Throughput: 0: 2994.4. Samples: 2180096. Policy #0 lag: (min: 13.0, avg: 16.0, max: 77.0)
[2026-02-02 12:19:27,561][93050] Avg episode reward: [(0, '580.854')]
[2026-02-02 12:19:29,809][93050] Signal inference workers to stop experience collection... (400 times)
[2026-02-02 12:19:29,809][93050] Signal inference workers to resume experience collection... (400 times)
[2026-02-02 12:19:30,086][93050] InferenceWorker_p0-w0: stopping experience collection (400 times)
[2026-02-02 12:19:30,086][93050] InferenceWorker_p0-w0: resuming experience collection (400 times)
[2026-02-02 12:19:32,525][93050] Fps is (10 sec: 3300.1, 60 sec: 3008.8, 300 sec: 3026.4). Total num frames: 2195456. Throughput: 0: 2994.9. Samples: 2198016. Policy #0 lag: (min: 13.0, avg: 16.0, max: 77.0)
[2026-02-02 12:19:32,525][93050] Avg episode reward: [(0, '588.514')]
[2026-02-02 12:19:37,633][93050] Fps is (10 sec: 3253.3, 60 sec: 3002.6, 300 sec: 3028.7). Total num frames: 2211840. Throughput: 0: 2985.1. Samples: 2216448. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:19:37,633][93050] Avg episode reward: [(0, '607.121')]
[2026-02-02 12:19:37,635][93050] Saving new best policy, reward=607.121!
[2026-02-02 12:19:42,582][93050] Fps is (10 sec: 3258.0, 60 sec: 3004.2, 300 sec: 3053.9). Total num frames: 2228224. Throughput: 0: 3029.4. Samples: 2226176. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:19:42,583][93050] Avg episode reward: [(0, '616.263')]
[2026-02-02 12:19:42,747][93050] Saving new best policy, reward=616.263!
[2026-02-02 12:19:47,531][93050] Fps is (10 sec: 3310.6, 60 sec: 3005.3, 300 sec: 3055.3). Total num frames: 2244608. Throughput: 0: 3033.3. Samples: 2244608. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:19:47,531][93050] Avg episode reward: [(0, '619.064')]
[2026-02-02 12:19:47,697][93050] Saving new best policy, reward=619.064!
[2026-02-02 12:19:52,529][93050] Fps is (10 sec: 3294.5, 60 sec: 3003.5, 300 sec: 3054.7). Total num frames: 2260992. Throughput: 0: 3003.2. Samples: 2262016. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:19:52,529][93050] Avg episode reward: [(0, '635.418')]
[2026-02-02 12:19:52,695][93050] Saving new best policy, reward=635.418!
[2026-02-02 12:19:57,624][93050] Fps is (10 sec: 3246.6, 60 sec: 3003.8, 300 sec: 3054.6). Total num frames: 2277376. Throughput: 0: 3207.6. Samples: 2279424. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:19:57,624][93050] Avg episode reward: [(0, '634.011')]
[2026-02-02 12:20:02,765][93050] Fps is (10 sec: 3201.2, 60 sec: 3133.3, 300 sec: 3052.8). Total num frames: 2293760. Throughput: 0: 3004.1. Samples: 2289152. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:20:02,765][93050] Avg episode reward: [(0, '630.131')]
[2026-02-02 12:20:07,792][93050] Fps is (10 sec: 2416.9, 60 sec: 3126.1, 300 sec: 3023.9). Total num frames: 2301952. Throughput: 0: 3024.6. Samples: 2308096. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:20:07,793][93050] Avg episode reward: [(0, '605.778')]
[2026-02-02 12:20:12,478][93050] Fps is (10 sec: 1686.8, 60 sec: 3010.4, 300 sec: 3000.0). Total num frames: 2310144. Throughput: 0: 3032.1. Samples: 2316288. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:20:12,478][93050] Avg episode reward: [(0, '607.077')]
[2026-02-02 12:20:17,560][93050] Fps is (10 sec: 2516.1, 60 sec: 3005.8, 300 sec: 2999.7). Total num frames: 2326528. Throughput: 0: 3035.5. Samples: 2334720. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:20:17,560][93050] Avg episode reward: [(0, '612.200')]
[2026-02-02 12:20:22,617][93050] Fps is (10 sec: 3231.9, 60 sec: 3002.7, 300 sec: 2998.3). Total num frames: 2342912. Throughput: 0: 3027.6. Samples: 2352640. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:20:22,617][93050] Avg episode reward: [(0, '623.504')]
[2026-02-02 12:20:27,574][93050] Fps is (10 sec: 3272.2, 60 sec: 3003.1, 300 sec: 2999.1). Total num frames: 2359296. Throughput: 0: 2981.6. Samples: 2360320. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:20:27,574][93050] Avg episode reward: [(0, '638.283')]
[2026-02-02 12:20:27,727][93050] Saving new best policy, reward=638.283!
[2026-02-02 12:20:32,620][93050] Fps is (10 sec: 3275.9, 60 sec: 2999.0, 300 sec: 2998.7). Total num frames: 2375680. Throughput: 0: 2986.5. Samples: 2379264. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:20:32,620][93050] Avg episode reward: [(0, '652.493')]
[2026-02-02 12:20:32,783][93050] Saving new best policy, reward=652.493!
[2026-02-02 12:20:37,571][93050] Fps is (10 sec: 3277.8, 60 sec: 3006.8, 300 sec: 2998.3). Total num frames: 2392064. Throughput: 0: 3012.3. Samples: 2397696. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:20:37,571][93050] Avg episode reward: [(0, '640.317')]
[2026-02-02 12:20:42,572][93050] Fps is (10 sec: 3292.5, 60 sec: 3004.3, 300 sec: 3001.2). Total num frames: 2408448. Throughput: 0: 2847.8. Samples: 2407424. Policy #0 lag: (min: 11.0, avg: 14.0, max: 75.0)
[2026-02-02 12:20:42,572][93050] Avg episode reward: [(0, '683.720')]
[2026-02-02 12:20:42,736][93050] Saving new best policy, reward=683.720!
[2026-02-02 12:20:47,471][93050] Fps is (10 sec: 3309.9, 60 sec: 3006.8, 300 sec: 3029.8). Total num frames: 2424832. Throughput: 0: 3057.9. Samples: 2425856. Policy #0 lag: (min: 11.0, avg: 14.0, max: 75.0)
[2026-02-02 12:20:47,471][93050] Avg episode reward: [(0, '693.521')]
[2026-02-02 12:20:47,636][93050] Saving new best policy, reward=693.521!
[2026-02-02 12:20:52,619][93050] Fps is (10 sec: 3261.5, 60 sec: 2999.2, 300 sec: 3054.3). Total num frames: 2441216. Throughput: 0: 2992.5. Samples: 2442240. Policy #0 lag: (min: 12.0, avg: 15.0, max: 76.0)
[2026-02-02 12:20:52,619][93050] Avg episode reward: [(0, '710.128')]
[2026-02-02 12:20:52,788][93050] Saving /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_accel_policy2_aggressive_magpie_adp_nullified_02022026/checkpoint_p0/checkpoint_000009536_2441216.pth...
[2026-02-02 12:20:52,792][93050] Removing /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_accel_policy2_aggressive_magpie_adp_nullified_02022026/checkpoint_p0/checkpoint_000006720_1720320.pth
[2026-02-02 12:20:52,792][93050] Saving new best policy, reward=710.128!
[2026-02-02 12:20:57,559][93050] Fps is (10 sec: 3248.2, 60 sec: 3007.0, 300 sec: 3054.2). Total num frames: 2457600. Throughput: 0: 3009.7. Samples: 2451968. Policy #0 lag: (min: 12.0, avg: 15.0, max: 76.0)
[2026-02-02 12:20:57,559][93050] Avg episode reward: [(0, '729.509')]
[2026-02-02 12:20:57,724][93050] Saving new best policy, reward=729.509!
[2026-02-02 12:21:01,761][93050] Signal inference workers to stop experience collection... (450 times)
[2026-02-02 12:21:02,144][93050] InferenceWorker_p0-w0: stopping experience collection (450 times)
[2026-02-02 12:21:02,146][93050] Signal inference workers to resume experience collection... (450 times)
[2026-02-02 12:21:02,312][93050] InferenceWorker_p0-w0: resuming experience collection (450 times)
[2026-02-02 12:21:02,556][93050] Fps is (10 sec: 3297.3, 60 sec: 3014.2, 300 sec: 3055.2). Total num frames: 2473984. Throughput: 0: 3015.3. Samples: 2470400. Policy #0 lag: (min: 7.0, avg: 10.0, max: 71.0)
[2026-02-02 12:21:02,557][93050] Avg episode reward: [(0, '732.359')]
[2026-02-02 12:21:02,558][93050] Saving new best policy, reward=732.359!
[2026-02-02 12:21:07,558][93050] Fps is (10 sec: 2457.7, 60 sec: 3015.5, 300 sec: 3026.8). Total num frames: 2482176. Throughput: 0: 3030.4. Samples: 2488832. Policy #0 lag: (min: 7.0, avg: 10.0, max: 71.0)
[2026-02-02 12:21:07,559][93050] Avg episode reward: [(0, '737.679')]
[2026-02-02 12:21:07,953][93050] Saving new best policy, reward=737.679!
[2026-02-02 12:21:12,575][93050] Fps is (10 sec: 1635.4, 60 sec: 2998.9, 300 sec: 2998.5). Total num frames: 2490368. Throughput: 0: 3037.8. Samples: 2497024. Policy #0 lag: (min: 7.0, avg: 10.0, max: 71.0)
[2026-02-02 12:21:12,575][93050] Avg episode reward: [(0, '709.990')]
[2026-02-02 12:21:17,537][93050] Fps is (10 sec: 2463.0, 60 sec: 3004.9, 300 sec: 2998.7). Total num frames: 2506752. Throughput: 0: 3032.1. Samples: 2515456. Policy #0 lag: (min: 6.0, avg: 9.0, max: 70.0)
[2026-02-02 12:21:17,537][93050] Avg episode reward: [(0, '656.018')]
[2026-02-02 12:21:22,590][93050] Fps is (10 sec: 3272.0, 60 sec: 3005.1, 300 sec: 2997.9). Total num frames: 2523136. Throughput: 0: 3013.9. Samples: 2533376. Policy #0 lag: (min: 6.0, avg: 9.0, max: 70.0)
[2026-02-02 12:21:22,590][93050] Avg episode reward: [(0, '673.488')]
[2026-02-02 12:21:27,521][93050] Fps is (10 sec: 3281.8, 60 sec: 3006.4, 300 sec: 2999.1). Total num frames: 2539520. Throughput: 0: 2995.7. Samples: 2542080. Policy #0 lag: (min: 6.0, avg: 9.0, max: 70.0)
[2026-02-02 12:21:27,521][93050] Avg episode reward: [(0, '693.599')]
[2026-02-02 12:21:32,471][93050] Fps is (10 sec: 3316.2, 60 sec: 3011.2, 300 sec: 2999.2). Total num frames: 2555904. Throughput: 0: 2981.0. Samples: 2560000. Policy #0 lag: (min: 6.0, avg: 9.0, max: 70.0)
[2026-02-02 12:21:32,471][93050] Avg episode reward: [(0, '733.108')]
[2026-02-02 12:21:37,623][93050] Fps is (10 sec: 3243.8, 60 sec: 3001.1, 300 sec: 2998.1). Total num frames: 2572288. Throughput: 0: 3026.2. Samples: 2578432. Policy #0 lag: (min: 14.0, avg: 17.0, max: 78.0)
[2026-02-02 12:21:37,623][93050] Avg episode reward: [(0, '756.801')]
[2026-02-02 12:21:37,795][93050] Saving new best policy, reward=756.801!
[2026-02-02 12:21:42,482][93050] Fps is (10 sec: 3273.1, 60 sec: 3008.2, 300 sec: 3000.3). Total num frames: 2588672. Throughput: 0: 3031.7. Samples: 2588160. Policy #0 lag: (min: 14.0, avg: 17.0, max: 78.0)
[2026-02-02 12:21:42,482][93050] Avg episode reward: [(0, '748.047')]
[2026-02-02 12:21:47,560][93050] Fps is (10 sec: 3297.7, 60 sec: 2999.3, 300 sec: 3001.6). Total num frames: 2605056. Throughput: 0: 3014.9. Samples: 2606080. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:21:47,560][93050] Avg episode reward: [(0, '723.026')]
[2026-02-02 12:21:52,490][93050] Fps is (10 sec: 3274.1, 60 sec: 3010.2, 300 sec: 3030.0). Total num frames: 2621440. Throughput: 0: 2996.9. Samples: 2623488. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:21:52,490][93050] Avg episode reward: [(0, '723.157')]
[2026-02-02 12:21:57,474][93050] Fps is (10 sec: 3305.2, 60 sec: 3008.0, 300 sec: 3054.7). Total num frames: 2637824. Throughput: 0: 3033.3. Samples: 2633216. Policy #0 lag: (min: 4.0, avg: 7.0, max: 68.0)
[2026-02-02 12:21:57,474][93050] Avg episode reward: [(0, '729.311')]
[2026-02-02 12:22:02,516][93050] Fps is (10 sec: 3268.1, 60 sec: 3005.7, 300 sec: 3055.3). Total num frames: 2654208. Throughput: 0: 3016.5. Samples: 2651136. Policy #0 lag: (min: 4.0, avg: 7.0, max: 68.0)
[2026-02-02 12:22:02,517][93050] Avg episode reward: [(0, '736.081')]
[2026-02-02 12:22:07,787][93050] Fps is (10 sec: 3177.2, 60 sec: 3128.3, 300 sec: 3052.5). Total num frames: 2670592. Throughput: 0: 3013.3. Samples: 2669568. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:22:07,787][93050] Avg episode reward: [(0, '756.569')]
[2026-02-02 12:22:12,809][93050] Fps is (10 sec: 2387.9, 60 sec: 3128.1, 300 sec: 3024.4). Total num frames: 2678784. Throughput: 0: 2996.0. Samples: 2677760. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:22:12,809][93050] Avg episode reward: [(0, '755.612')]
[2026-02-02 12:22:17,577][93050] Fps is (10 sec: 1673.7, 60 sec: 3001.7, 300 sec: 2999.3). Total num frames: 2686976. Throughput: 0: 3019.4. Samples: 2696192. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:22:17,577][93050] Avg episode reward: [(0, '746.141')]
[2026-02-02 12:22:22,571][93050] Fps is (10 sec: 2517.4, 60 sec: 3004.7, 300 sec: 2998.2). Total num frames: 2703360. Throughput: 0: 3018.6. Samples: 2714112. Policy #0 lag: (min: 13.0, avg: 16.0, max: 77.0)
[2026-02-02 12:22:22,571][93050] Avg episode reward: [(0, '751.784')]
[2026-02-02 12:22:27,504][93050] Fps is (10 sec: 3300.6, 60 sec: 3004.6, 300 sec: 2999.8). Total num frames: 2719744. Throughput: 0: 2990.8. Samples: 2722816. Policy #0 lag: (min: 13.0, avg: 16.0, max: 77.0)
[2026-02-02 12:22:27,509][93050] Avg episode reward: [(0, '752.379')]
[2026-02-02 12:22:29,178][93050] Signal inference workers to stop experience collection... (500 times)
[2026-02-02 12:22:29,567][93050] InferenceWorker_p0-w0: stopping experience collection (500 times)
[2026-02-02 12:22:29,567][93050] Signal inference workers to resume experience collection... (500 times)
[2026-02-02 12:22:29,567][93050] InferenceWorker_p0-w0: resuming experience collection (500 times)
[2026-02-02 12:22:32,586][93050] Fps is (10 sec: 3272.0, 60 sec: 2998.0, 300 sec: 2998.8). Total num frames: 2736128. Throughput: 0: 2990.6. Samples: 2740736. Policy #0 lag: (min: 1.0, avg: 4.0, max: 65.0)
[2026-02-02 12:22:32,586][93050] Avg episode reward: [(0, '762.948')]
[2026-02-02 12:22:32,752][93050] Saving new best policy, reward=762.948!
[2026-02-02 12:22:37,615][93050] Fps is (10 sec: 3240.8, 60 sec: 3004.1, 300 sec: 2998.1). Total num frames: 2752512. Throughput: 0: 2995.4. Samples: 2758656. Policy #0 lag: (min: 1.0, avg: 4.0, max: 65.0)
[2026-02-02 12:22:37,616][93050] Avg episode reward: [(0, '778.615')]
[2026-02-02 12:22:37,773][93050] Saving new best policy, reward=778.615!
[2026-02-02 12:22:42,557][93050] Fps is (10 sec: 3286.2, 60 sec: 3000.0, 300 sec: 2999.0). Total num frames: 2768896. Throughput: 0: 2998.2. Samples: 2768384. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:22:42,557][93050] Avg episode reward: [(0, '796.509')]
[2026-02-02 12:22:42,719][93050] Saving new best policy, reward=796.509!
[2026-02-02 12:22:47,495][93050] Fps is (10 sec: 3316.9, 60 sec: 3007.0, 300 sec: 2999.6). Total num frames: 2785280. Throughput: 0: 3005.2. Samples: 2786304. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:22:47,495][93050] Avg episode reward: [(0, '799.495')]
[2026-02-02 12:22:47,653][93050] Saving new best policy, reward=799.495!
[2026-02-02 12:22:52,529][93050] Fps is (10 sec: 3285.9, 60 sec: 3001.8, 300 sec: 3027.5). Total num frames: 2801664. Throughput: 0: 2998.2. Samples: 2803712. Policy #0 lag: (min: 6.0, avg: 9.0, max: 70.0)
[2026-02-02 12:22:52,530][93050] Avg episode reward: [(0, '814.747')]
[2026-02-02 12:22:52,689][93050] Saving /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_accel_policy2_aggressive_magpie_adp_nullified_02022026/checkpoint_p0/checkpoint_000010944_2801664.pth...
[2026-02-02 12:22:52,693][93050] Removing /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_accel_policy2_aggressive_magpie_adp_nullified_02022026/checkpoint_p0/checkpoint_000008128_2080768.pth
[2026-02-02 12:22:52,693][93050] Saving new best policy, reward=814.747!
[2026-02-02 12:22:57,547][93050] Fps is (10 sec: 3259.7, 60 sec: 3000.1, 300 sec: 3055.0). Total num frames: 2818048. Throughput: 0: 3021.3. Samples: 2812928. Policy #0 lag: (min: 6.0, avg: 9.0, max: 70.0)
[2026-02-02 12:22:57,547][93050] Avg episode reward: [(0, '829.914')]
[2026-02-02 12:22:57,716][93050] Saving new best policy, reward=829.914!
[2026-02-02 12:23:02,623][93050] Fps is (10 sec: 3246.4, 60 sec: 2998.4, 300 sec: 3053.3). Total num frames: 2834432. Throughput: 0: 3000.6. Samples: 2831360. Policy #0 lag: (min: 8.0, avg: 11.0, max: 72.0)
[2026-02-02 12:23:02,623][93050] Avg episode reward: [(0, '841.581')]
[2026-02-02 12:23:02,790][93050] Saving new best policy, reward=841.581!
[2026-02-02 12:23:07,593][93050] Fps is (10 sec: 2446.4, 60 sec: 2876.5, 300 sec: 3027.1). Total num frames: 2842624. Throughput: 0: 3002.3. Samples: 2849280. Policy #0 lag: (min: 8.0, avg: 11.0, max: 72.0)
[2026-02-02 12:23:07,593][93050] Avg episode reward: [(0, '851.506')]
[2026-02-02 12:23:07,974][93050] Saving new best policy, reward=851.506!
[2026-02-02 12:23:12,567][93050] Fps is (10 sec: 1647.7, 60 sec: 2878.8, 300 sec: 2998.3). Total num frames: 2850816. Throughput: 0: 2988.2. Samples: 2857472. Policy #0 lag: (min: 8.0, avg: 11.0, max: 72.0)
[2026-02-02 12:23:12,567][93050] Avg episode reward: [(0, '815.037')]
[2026-02-02 12:23:17,591][93050] Fps is (10 sec: 2458.0, 60 sec: 3003.0, 300 sec: 2998.8). Total num frames: 2867200. Throughput: 0: 2980.6. Samples: 2874880. Policy #0 lag: (min: 14.0, avg: 17.0, max: 78.0)
[2026-02-02 12:23:17,591][93050] Avg episode reward: [(0, '795.877')]
[2026-02-02 12:23:22,522][93050] Fps is (10 sec: 3291.5, 60 sec: 3006.2, 300 sec: 2998.7). Total num frames: 2883584. Throughput: 0: 2998.6. Samples: 2893312. Policy #0 lag: (min: 14.0, avg: 17.0, max: 78.0)
[2026-02-02 12:23:22,522][93050] Avg episode reward: [(0, '793.473')]
[2026-02-02 12:23:27,472][93050] Fps is (10 sec: 3316.3, 60 sec: 3005.4, 300 sec: 3000.7). Total num frames: 2899968. Throughput: 0: 2952.4. Samples: 2900992. Policy #0 lag: (min: 10.0, avg: 13.0, max: 74.0)
[2026-02-02 12:23:27,472][93050] Avg episode reward: [(0, '808.240')]
[2026-02-02 12:23:32,517][93050] Fps is (10 sec: 3278.6, 60 sec: 3007.2, 300 sec: 3000.1). Total num frames: 2916352. Throughput: 0: 2968.1. Samples: 2919936. Policy #0 lag: (min: 10.0, avg: 13.0, max: 74.0)
[2026-02-02 12:23:32,517][93050] Avg episode reward: [(0, '829.621')]
[2026-02-02 12:23:37,513][93050] Fps is (10 sec: 3263.5, 60 sec: 3008.9, 300 sec: 2999.9). Total num frames: 2932736. Throughput: 0: 2982.1. Samples: 2937856. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:23:37,513][93050] Avg episode reward: [(0, '871.583')]
[2026-02-02 12:23:37,681][93050] Saving new best policy, reward=871.583!
[2026-02-02 12:23:42,497][93050] Fps is (10 sec: 3283.3, 60 sec: 3006.8, 300 sec: 2999.8). Total num frames: 2949120. Throughput: 0: 2995.7. Samples: 2947584. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:23:42,497][93050] Avg episode reward: [(0, '896.244')]
[2026-02-02 12:23:42,662][93050] Saving new best policy, reward=896.244!
[2026-02-02 12:23:47,570][93050] Fps is (10 sec: 3257.9, 60 sec: 2999.9, 300 sec: 2998.6). Total num frames: 2965504. Throughput: 0: 2984.5. Samples: 2965504. Policy #0 lag: (min: 1.0, avg: 4.0, max: 65.0)
[2026-02-02 12:23:47,571][93050] Avg episode reward: [(0, '911.321')]
[2026-02-02 12:23:47,732][93050] Saving new best policy, reward=911.321!
[2026-02-02 12:23:52,575][93050] Fps is (10 sec: 3251.3, 60 sec: 3001.4, 300 sec: 2999.6). Total num frames: 2981888. Throughput: 0: 2970.8. Samples: 2982912. Policy #0 lag: (min: 1.0, avg: 4.0, max: 65.0)
[2026-02-02 12:23:52,575][93050] Avg episode reward: [(0, '899.986')]
[2026-02-02 12:23:57,520][93050] Fps is (10 sec: 3293.2, 60 sec: 3005.1, 300 sec: 3028.0). Total num frames: 2998272. Throughput: 0: 2995.4. Samples: 2992128. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:23:57,521][93050] Avg episode reward: [(0, '876.992')]
[2026-02-02 12:24:02,454][93050] Signal inference workers to stop experience collection... (550 times)
[2026-02-02 12:24:02,454][93050] Signal inference workers to resume experience collection... (550 times)
[2026-02-02 12:24:02,730][93050] InferenceWorker_p0-w0: stopping experience collection (550 times)
[2026-02-02 12:24:02,730][93050] InferenceWorker_p0-w0: resuming experience collection (550 times)
[2026-02-02 12:24:02,844][93050] Fps is (10 sec: 3191.0, 60 sec: 2992.7, 300 sec: 3051.3). Total num frames: 3014656. Throughput: 0: 2987.0. Samples: 3010048. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:24:02,844][93050] Avg episode reward: [(0, '887.995')]
[2026-02-02 12:24:07,569][93050] Fps is (10 sec: 1630.4, 60 sec: 2868.3, 300 sec: 2999.5). Total num frames: 3014656. Throughput: 0: 2989.2. Samples: 3027968. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:24:07,570][93050] Avg episode reward: [(0, '920.656')]
[2026-02-02 12:24:07,964][93050] Saving new best policy, reward=920.656!
[2026-02-02 12:24:12,553][93050] Fps is (10 sec: 1687.5, 60 sec: 3004.4, 300 sec: 2999.6). Total num frames: 3031040. Throughput: 0: 3009.7. Samples: 3036672. Policy #0 lag: (min: 6.0, avg: 9.0, max: 70.0)
[2026-02-02 12:24:12,553][93050] Avg episode reward: [(0, '921.651')]
[2026-02-02 12:24:12,722][93050] Saving new best policy, reward=921.651!
[2026-02-02 12:24:17,585][93050] Fps is (10 sec: 3271.6, 60 sec: 3004.0, 300 sec: 2999.2). Total num frames: 3047424. Throughput: 0: 2987.8. Samples: 3054592. Policy #0 lag: (min: 6.0, avg: 9.0, max: 70.0)
[2026-02-02 12:24:17,586][93050] Avg episode reward: [(0, '936.986')]
[2026-02-02 12:24:17,747][93050] Saving new best policy, reward=936.986!
[2026-02-02 12:24:22,619][93050] Fps is (10 sec: 3255.2, 60 sec: 2998.9, 300 sec: 2998.5). Total num frames: 3063808. Throughput: 0: 2985.3. Samples: 3072512. Policy #0 lag: (min: 1.0, avg: 4.0, max: 65.0)
[2026-02-02 12:24:22,619][93050] Avg episode reward: [(0, '942.952')]
[2026-02-02 12:24:22,779][93050] Saving new best policy, reward=942.952!
[2026-02-02 12:24:27,567][93050] Fps is (10 sec: 3282.9, 60 sec: 2999.0, 300 sec: 2998.7). Total num frames: 3080192. Throughput: 0: 2965.0. Samples: 3081216. Policy #0 lag: (min: 1.0, avg: 4.0, max: 65.0)
[2026-02-02 12:24:27,567][93050] Avg episode reward: [(0, '937.692')]
[2026-02-02 12:24:32,556][93050] Fps is (10 sec: 3297.7, 60 sec: 3001.8, 300 sec: 2999.9). Total num frames: 3096576. Throughput: 0: 2970.6. Samples: 3099136. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:24:32,556][93050] Avg episode reward: [(0, '966.812')]
[2026-02-02 12:24:32,720][93050] Saving new best policy, reward=966.812!
[2026-02-02 12:24:37,530][93050] Fps is (10 sec: 3289.0, 60 sec: 3002.9, 300 sec: 2999.6). Total num frames: 3112960. Throughput: 0: 2995.4. Samples: 3117568. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:24:37,530][93050] Avg episode reward: [(0, '975.880')]
[2026-02-02 12:24:37,706][93050] Saving new best policy, reward=975.880!
[2026-02-02 12:24:42,590][93050] Fps is (10 sec: 3265.6, 60 sec: 2999.1, 300 sec: 2998.5). Total num frames: 3129344. Throughput: 0: 2999.1. Samples: 3127296. Policy #0 lag: (min: 0.0, avg: 3.0, max: 64.0)
[2026-02-02 12:24:42,590][93050] Avg episode reward: [(0, '967.891')]
[2026-02-02 12:24:47,545][93050] Fps is (10 sec: 3271.6, 60 sec: 3005.0, 300 sec: 2998.9). Total num frames: 3145728. Throughput: 0: 3023.8. Samples: 3145216. Policy #0 lag: (min: 0.0, avg: 3.0, max: 64.0)
[2026-02-02 12:24:47,546][93050] Avg episode reward: [(0, '966.266')]
[2026-02-02 12:24:52,522][93050] Fps is (10 sec: 3299.3, 60 sec: 3006.4, 300 sec: 3000.1). Total num frames: 3162112. Throughput: 0: 3006.9. Samples: 3163136. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:24:52,522][93050] Avg episode reward: [(0, '944.710')]
[2026-02-02 12:24:52,680][93050] Saving /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_accel_policy2_aggressive_magpie_adp_nullified_02022026/checkpoint_p0/checkpoint_000012352_3162112.pth...
[2026-02-02 12:24:52,684][93050] Removing /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_accel_policy2_aggressive_magpie_adp_nullified_02022026/checkpoint_p0/checkpoint_000009536_2441216.pth
[2026-02-02 12:24:57,504][93050] Fps is (10 sec: 3290.5, 60 sec: 3004.6, 300 sec: 3001.8). Total num frames: 3178496. Throughput: 0: 3007.0. Samples: 3171840. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:24:57,504][93050] Avg episode reward: [(0, '954.138')]
[2026-02-02 12:25:02,562][93050] Fps is (10 sec: 2447.8, 60 sec: 2880.7, 300 sec: 3001.5). Total num frames: 3186688. Throughput: 0: 3005.3. Samples: 3189760. Policy #0 lag: (min: 11.0, avg: 14.0, max: 75.0)
[2026-02-02 12:25:02,562][93050] Avg episode reward: [(0, '954.931')]
[2026-02-02 12:25:07,604][93050] Fps is (10 sec: 1622.1, 60 sec: 3002.0, 300 sec: 2997.8). Total num frames: 3194880. Throughput: 0: 3016.1. Samples: 3208192. Policy #0 lag: (min: 11.0, avg: 14.0, max: 75.0)
[2026-02-02 12:25:07,604][93050] Avg episode reward: [(0, '960.568')]
[2026-02-02 12:25:12,560][93050] Fps is (10 sec: 2458.0, 60 sec: 3003.4, 300 sec: 2999.1). Total num frames: 3211264. Throughput: 0: 3015.5. Samples: 3216896. Policy #0 lag: (min: 11.0, avg: 14.0, max: 75.0)
[2026-02-02 12:25:12,560][93050] Avg episode reward: [(0, '971.931')]
[2026-02-02 12:25:17,482][93050] Fps is (10 sec: 3317.3, 60 sec: 3008.9, 300 sec: 3000.5). Total num frames: 3227648. Throughput: 0: 3020.1. Samples: 3234816. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:25:17,482][93050] Avg episode reward: [(0, '932.836')]
[2026-02-02 12:25:22,603][93050] Fps is (10 sec: 3262.8, 60 sec: 3004.5, 300 sec: 2998.8). Total num frames: 3244032. Throughput: 0: 2998.8. Samples: 3252736. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:25:22,603][93050] Avg episode reward: [(0, '943.647')]
[2026-02-02 12:25:27,617][93050] Fps is (10 sec: 3233.0, 60 sec: 3001.2, 300 sec: 2999.1). Total num frames: 3260416. Throughput: 0: 3183.8. Samples: 3270656. Policy #0 lag: (min: 8.0, avg: 11.0, max: 72.0)
[2026-02-02 12:25:27,618][93050] Avg episode reward: [(0, '982.237')]
[2026-02-02 12:25:27,779][93050] Saving new best policy, reward=982.237!
[2026-02-02 12:25:32,564][93050] Fps is (10 sec: 3289.8, 60 sec: 3003.3, 300 sec: 2999.2). Total num frames: 3276800. Throughput: 0: 2979.8. Samples: 3279360. Policy #0 lag: (min: 8.0, avg: 11.0, max: 72.0)
[2026-02-02 12:25:32,564][93050] Avg episode reward: [(0, '969.713')]
[2026-02-02 12:25:34,923][93050] Signal inference workers to stop experience collection... (600 times)
[2026-02-02 12:25:35,314][93050] InferenceWorker_p0-w0: stopping experience collection (600 times)
[2026-02-02 12:25:35,316][93050] Signal inference workers to resume experience collection... (600 times)
[2026-02-02 12:25:35,477][93050] InferenceWorker_p0-w0: resuming experience collection (600 times)
[2026-02-02 12:25:37,536][93050] Fps is (10 sec: 3303.7, 60 sec: 3003.4, 300 sec: 2999.5). Total num frames: 3293184. Throughput: 0: 2980.0. Samples: 3297280. Policy #0 lag: (min: 6.0, avg: 9.0, max: 70.0)
[2026-02-02 12:25:37,536][93050] Avg episode reward: [(0, '1009.380')]
[2026-02-02 12:25:37,700][93050] Saving new best policy, reward=1009.380!
[2026-02-02 12:25:42,562][93050] Fps is (10 sec: 3277.4, 60 sec: 3005.1, 300 sec: 2998.2). Total num frames: 3309568. Throughput: 0: 3011.2. Samples: 3307520. Policy #0 lag: (min: 6.0, avg: 9.0, max: 70.0)
[2026-02-02 12:25:42,562][93050] Avg episode reward: [(0, '969.538')]
[2026-02-02 12:25:47,558][93050] Fps is (10 sec: 3269.5, 60 sec: 3003.1, 300 sec: 2999.7). Total num frames: 3325952. Throughput: 0: 3015.3. Samples: 3325440. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:25:47,558][93050] Avg episode reward: [(0, '955.076')]
[2026-02-02 12:25:52,521][93050] Fps is (10 sec: 3290.1, 60 sec: 3003.7, 300 sec: 2999.5). Total num frames: 3342336. Throughput: 0: 3009.3. Samples: 3343360. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:25:52,522][93050] Avg episode reward: [(0, '955.526')]
[2026-02-02 12:25:57,492][93050] Fps is (10 sec: 3298.7, 60 sec: 3004.3, 300 sec: 2999.8). Total num frames: 3358720. Throughput: 0: 3008.3. Samples: 3352064. Policy #0 lag: (min: 4.0, avg: 7.0, max: 68.0)
[2026-02-02 12:25:57,492][93050] Avg episode reward: [(0, '927.060')]
[2026-02-02 12:26:02,530][93050] Fps is (10 sec: 2455.5, 60 sec: 3005.3, 300 sec: 2999.4). Total num frames: 3366912. Throughput: 0: 3011.9. Samples: 3370496. Policy #0 lag: (min: 4.0, avg: 7.0, max: 68.0)
[2026-02-02 12:26:02,530][93050] Avg episode reward: [(0, '956.479')]
[2026-02-02 12:26:07,611][93050] Fps is (10 sec: 1619.1, 60 sec: 3003.4, 300 sec: 2998.7). Total num frames: 3375104. Throughput: 0: 3014.6. Samples: 3388416. Policy #0 lag: (min: 4.0, avg: 7.0, max: 68.0)
[2026-02-02 12:26:07,611][93050] Avg episode reward: [(0, '953.606')]
[2026-02-02 12:26:12,484][93050] Fps is (10 sec: 2469.0, 60 sec: 3007.6, 300 sec: 2999.6). Total num frames: 3391488. Throughput: 0: 2807.3. Samples: 3396608. Policy #0 lag: (min: 4.0, avg: 7.0, max: 68.0)
[2026-02-02 12:26:12,484][93050] Avg episode reward: [(0, '939.477')]
[2026-02-02 12:26:17,623][93050] Fps is (10 sec: 3272.9, 60 sec: 2996.7, 300 sec: 2998.8). Total num frames: 3407872. Throughput: 0: 3011.1. Samples: 3415040. Policy #0 lag: (min: 4.0, avg: 7.0, max: 68.0)
[2026-02-02 12:26:17,623][93050] Avg episode reward: [(0, '925.644')]
[2026-02-02 12:26:22,613][93050] Fps is (10 sec: 3235.0, 60 sec: 3003.2, 300 sec: 2998.2). Total num frames: 3424256. Throughput: 0: 3010.0. Samples: 3432960. Policy #0 lag: (min: 2.0, avg: 5.0, max: 66.0)
[2026-02-02 12:26:22,613][93050] Avg episode reward: [(0, '942.003')]
[2026-02-02 12:26:27,485][93050] Fps is (10 sec: 3322.7, 60 sec: 3010.4, 300 sec: 2999.0). Total num frames: 3440640. Throughput: 0: 2986.1. Samples: 3441664. Policy #0 lag: (min: 2.0, avg: 5.0, max: 66.0)
[2026-02-02 12:26:27,485][93050] Avg episode reward: [(0, '942.745')]
[2026-02-02 12:26:32,563][93050] Fps is (10 sec: 3293.1, 60 sec: 3003.7, 300 sec: 2999.7). Total num frames: 3457024. Throughput: 0: 2980.6. Samples: 3459584. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:26:32,564][93050] Avg episode reward: [(0, '974.191')]
[2026-02-02 12:26:37,540][93050] Fps is (10 sec: 3258.7, 60 sec: 3003.5, 300 sec: 2998.5). Total num frames: 3473408. Throughput: 0: 2991.1. Samples: 3478016. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:26:37,540][93050] Avg episode reward: [(0, '992.225')]
[2026-02-02 12:26:42,526][93050] Fps is (10 sec: 3289.0, 60 sec: 3005.5, 300 sec: 2999.4). Total num frames: 3489792. Throughput: 0: 3012.8. Samples: 3487744. Policy #0 lag: (min: 6.0, avg: 9.0, max: 70.0)
[2026-02-02 12:26:42,527][93050] Avg episode reward: [(0, '1019.892')]
[2026-02-02 12:26:42,685][93050] Saving new best policy, reward=1019.892!
[2026-02-02 12:26:47,598][93050] Fps is (10 sec: 3258.1, 60 sec: 3001.8, 300 sec: 2998.0). Total num frames: 3506176. Throughput: 0: 2999.2. Samples: 3505664. Policy #0 lag: (min: 6.0, avg: 9.0, max: 70.0)
[2026-02-02 12:26:47,598][93050] Avg episode reward: [(0, '1027.131')]
[2026-02-02 12:26:47,769][93050] Saving new best policy, reward=1027.131!
[2026-02-02 12:26:52,485][93050] Fps is (10 sec: 3290.5, 60 sec: 3005.6, 300 sec: 2999.0). Total num frames: 3522560. Throughput: 0: 3012.2. Samples: 3523584. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:26:52,485][93050] Avg episode reward: [(0, '994.887')]
[2026-02-02 12:26:52,653][93050] Saving /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_accel_policy2_aggressive_magpie_adp_nullified_02022026/checkpoint_p0/checkpoint_000013760_3522560.pth...
[2026-02-02 12:26:52,657][93050] Removing /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_accel_policy2_aggressive_magpie_adp_nullified_02022026/checkpoint_p0/checkpoint_000010944_2801664.pth
[2026-02-02 12:26:57,637][93050] Fps is (10 sec: 3263.9, 60 sec: 2996.5, 300 sec: 2997.9). Total num frames: 3538944. Throughput: 0: 2993.5. Samples: 3531776. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:26:57,637][93050] Avg episode reward: [(0, '990.523')]
[2026-02-02 12:27:02,708][93050] Signal inference workers to stop experience collection... (650 times)
[2026-02-02 12:27:02,708][93050] Fps is (10 sec: 2404.0, 60 sec: 2994.9, 300 sec: 2972.1). Total num frames: 3547136. Throughput: 0: 2986.7. Samples: 3549696. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:27:02,708][93050] Avg episode reward: [(0, '975.246')]
[2026-02-02 12:27:03,082][93050] InferenceWorker_p0-w0: stopping experience collection (650 times)
[2026-02-02 12:27:03,082][93050] Signal inference workers to resume experience collection... (650 times)
[2026-02-02 12:27:03,082][93050] InferenceWorker_p0-w0: resuming experience collection (650 times)
[2026-02-02 12:27:07,569][93050] Fps is (10 sec: 1649.6, 60 sec: 3005.8, 300 sec: 2973.7). Total num frames: 3555328. Throughput: 0: 3006.6. Samples: 3568128. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:27:07,570][93050] Avg episode reward: [(0, '1001.924')]
[2026-02-02 12:27:12,485][93050] Fps is (10 sec: 2513.6, 60 sec: 3003.7, 300 sec: 3000.0). Total num frames: 3571712. Throughput: 0: 2992.4. Samples: 3576320. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:27:12,485][93050] Avg episode reward: [(0, '1002.052')]
[2026-02-02 12:27:17,625][93050] Fps is (10 sec: 3258.7, 60 sec: 3003.6, 300 sec: 2998.6). Total num frames: 3588096. Throughput: 0: 2976.9. Samples: 3593728. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:27:17,625][93050] Avg episode reward: [(0, '980.339')]
[2026-02-02 12:27:22,615][93050] Fps is (10 sec: 3234.5, 60 sec: 3003.6, 300 sec: 2998.0). Total num frames: 3604480. Throughput: 0: 2976.0. Samples: 3612160. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:27:22,616][93050] Avg episode reward: [(0, '978.400')]
[2026-02-02 12:27:27,509][93050] Fps is (10 sec: 3315.2, 60 sec: 3002.5, 300 sec: 2999.9). Total num frames: 3620864. Throughput: 0: 2982.1. Samples: 3621888. Policy #0 lag: (min: 0.0, avg: 3.0, max: 64.0)
[2026-02-02 12:27:27,510][93050] Avg episode reward: [(0, '1009.802')]
[2026-02-02 12:27:32,567][93050] Fps is (10 sec: 3292.7, 60 sec: 3003.5, 300 sec: 2999.6). Total num frames: 3637248. Throughput: 0: 2948.9. Samples: 3638272. Policy #0 lag: (min: 0.0, avg: 3.0, max: 64.0)
[2026-02-02 12:27:32,567][93050] Avg episode reward: [(0, '1037.686')]
[2026-02-02 12:27:32,722][93050] Saving new best policy, reward=1037.686!
[2026-02-02 12:27:37,560][93050] Fps is (10 sec: 3260.1, 60 sec: 3002.7, 300 sec: 2999.1). Total num frames: 3653632. Throughput: 0: 2953.3. Samples: 3656704. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:27:37,561][93050] Avg episode reward: [(0, '1075.026')]
[2026-02-02 12:27:37,713][93050] Saving new best policy, reward=1075.026!
[2026-02-02 12:27:42,617][93050] Fps is (10 sec: 3260.5, 60 sec: 2999.2, 300 sec: 2997.9). Total num frames: 3670016. Throughput: 0: 2993.7. Samples: 3666432. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:27:42,617][93050] Avg episode reward: [(0, '1071.016')]
[2026-02-02 12:27:47,510][93050] Fps is (10 sec: 3293.3, 60 sec: 3008.1, 300 sec: 2999.3). Total num frames: 3686400. Throughput: 0: 3005.5. Samples: 3684352. Policy #0 lag: (min: 12.0, avg: 15.0, max: 76.0)
[2026-02-02 12:27:47,511][93050] Avg episode reward: [(0, '1071.738')]
[2026-02-02 12:27:52,476][93050] Fps is (10 sec: 3323.8, 60 sec: 3004.2, 300 sec: 2999.8). Total num frames: 3702784. Throughput: 0: 2998.6. Samples: 3702784. Policy #0 lag: (min: 12.0, avg: 15.0, max: 76.0)
[2026-02-02 12:27:52,476][93050] Avg episode reward: [(0, '1091.265')]
[2026-02-02 12:27:52,477][93050] Saving new best policy, reward=1091.265!
[2026-02-02 12:27:57,581][93050] Fps is (10 sec: 2440.5, 60 sec: 2869.9, 300 sec: 2971.8). Total num frames: 3710976. Throughput: 0: 2986.0. Samples: 3710976. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:27:57,581][93050] Avg episode reward: [(0, '1051.228')]
[2026-02-02 12:28:02,523][93050] Fps is (10 sec: 1630.6, 60 sec: 2876.0, 300 sec: 2972.0). Total num frames: 3719168. Throughput: 0: 3010.5. Samples: 3728896. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:28:02,524][93050] Avg episode reward: [(0, '1012.935')]
[2026-02-02 12:28:07,567][93050] Fps is (10 sec: 2460.9, 60 sec: 3003.8, 300 sec: 2999.1). Total num frames: 3735552. Throughput: 0: 2995.6. Samples: 3746816. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:28:07,567][93050] Avg episode reward: [(0, '972.310')]
[2026-02-02 12:28:12,587][93050] Fps is (10 sec: 3256.2, 60 sec: 2998.6, 300 sec: 2999.1). Total num frames: 3751936. Throughput: 0: 2964.5. Samples: 3755520. Policy #0 lag: (min: 13.0, avg: 16.0, max: 77.0)
[2026-02-02 12:28:12,587][93050] Avg episode reward: [(0, '994.298')]
[2026-02-02 12:28:17,605][93050] Fps is (10 sec: 3264.5, 60 sec: 3004.7, 300 sec: 2998.3). Total num frames: 3768320. Throughput: 0: 3001.2. Samples: 3773440. Policy #0 lag: (min: 13.0, avg: 16.0, max: 77.0)
[2026-02-02 12:28:17,605][93050] Avg episode reward: [(0, '1025.294')]
[2026-02-02 12:28:22,485][93050] Fps is (10 sec: 3310.3, 60 sec: 3010.3, 300 sec: 2999.0). Total num frames: 3784704. Throughput: 0: 2997.3. Samples: 3791360. Policy #0 lag: (min: 3.0, avg: 6.0, max: 67.0)
[2026-02-02 12:28:22,486][93050] Avg episode reward: [(0, '1015.621')]
[2026-02-02 12:28:27,593][93050] Fps is (10 sec: 3280.6, 60 sec: 2999.5, 300 sec: 2998.3). Total num frames: 3801088. Throughput: 0: 2993.9. Samples: 3801088. Policy #0 lag: (min: 3.0, avg: 6.0, max: 67.0)
[2026-02-02 12:28:27,594][93050] Avg episode reward: [(0, '1056.885')]
[2026-02-02 12:28:32,603][93050] Fps is (10 sec: 3238.7, 60 sec: 3001.9, 300 sec: 2998.2). Total num frames: 3817472. Throughput: 0: 2974.8. Samples: 3818496. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:28:32,603][93050] Avg episode reward: [(0, '1071.830')]
[2026-02-02 12:28:35,960][93050] Signal inference workers to stop experience collection... (700 times)
[2026-02-02 12:28:35,961][93050] Signal inference workers to resume experience collection... (700 times)
[2026-02-02 12:28:36,235][93050] InferenceWorker_p0-w0: stopping experience collection (700 times)
[2026-02-02 12:28:36,236][93050] InferenceWorker_p0-w0: resuming experience collection (700 times)
[2026-02-02 12:28:37,581][93050] Fps is (10 sec: 3280.9, 60 sec: 3002.7, 300 sec: 2998.2). Total num frames: 3833856. Throughput: 0: 2951.3. Samples: 3835904. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:28:37,581][93050] Avg episode reward: [(0, '1067.767')]
[2026-02-02 12:28:42,614][93050] Fps is (10 sec: 3273.2, 60 sec: 3003.9, 300 sec: 2998.7). Total num frames: 3850240. Throughput: 0: 3172.0. Samples: 3853824. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:28:42,614][93050] Avg episode reward: [(0, '1097.218')]
[2026-02-02 12:28:42,778][93050] Saving new best policy, reward=1097.218!
[2026-02-02 12:28:47,543][93050] Fps is (10 sec: 3289.1, 60 sec: 3002.1, 300 sec: 2999.4). Total num frames: 3866624. Throughput: 0: 2991.0. Samples: 3863552. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:28:47,544][93050] Avg episode reward: [(0, '1103.649')]
[2026-02-02 12:28:47,705][93050] Saving new best policy, reward=1103.649!
[2026-02-02 12:28:52,525][93050] Fps is (10 sec: 2479.6, 60 sec: 2864.8, 300 sec: 2971.3). Total num frames: 3874816. Throughput: 0: 2995.1. Samples: 3881472. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:28:52,525][93050] Avg episode reward: [(0, '1119.595')]
[2026-02-02 12:28:52,909][93050] Saving /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_accel_policy2_aggressive_magpie_adp_nullified_02022026/checkpoint_p0/checkpoint_000015168_3883008.pth...
[2026-02-02 12:28:52,913][93050] Removing /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_accel_policy2_aggressive_magpie_adp_nullified_02022026/checkpoint_p0/checkpoint_000012352_3162112.pth
[2026-02-02 12:28:52,914][93050] Saving new best policy, reward=1119.595!
[2026-02-02 12:28:57,518][93050] Fps is (10 sec: 1642.5, 60 sec: 2870.2, 300 sec: 2946.8). Total num frames: 3883008. Throughput: 0: 2985.5. Samples: 3889664. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:28:57,519][93050] Avg episode reward: [(0, '1083.123')]
[2026-02-02 12:29:02,575][93050] Fps is (10 sec: 2445.5, 60 sec: 3001.2, 300 sec: 2999.1). Total num frames: 3899392. Throughput: 0: 2983.0. Samples: 3907584. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:29:02,575][93050] Avg episode reward: [(0, '1076.134')]
[2026-02-02 12:29:07,608][93050] Fps is (10 sec: 3247.6, 60 sec: 3001.7, 300 sec: 2998.5). Total num frames: 3915776. Throughput: 0: 2972.9. Samples: 3925504. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:29:07,609][93050] Avg episode reward: [(0, '1073.550')]
[2026-02-02 12:29:12,473][93050] Fps is (10 sec: 3310.4, 60 sec: 3009.4, 300 sec: 3000.2). Total num frames: 3932160. Throughput: 0: 2943.3. Samples: 3933184. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:29:12,474][93050] Avg episode reward: [(0, '1080.426')]
[2026-02-02 12:29:17,613][93050] Fps is (10 sec: 3275.4, 60 sec: 3003.4, 300 sec: 2999.2). Total num frames: 3948544. Throughput: 0: 2969.0. Samples: 3952128. Policy #0 lag: (min: 27.0, avg: 30.0, max: 91.0)
[2026-02-02 12:29:17,613][93050] Avg episode reward: [(0, '1127.827')]
[2026-02-02 12:29:17,779][93050] Saving new best policy, reward=1127.827!
[2026-02-02 12:29:22,514][93050] Fps is (10 sec: 3263.7, 60 sec: 3002.3, 300 sec: 2999.6). Total num frames: 3964928. Throughput: 0: 2985.4. Samples: 3970048. Policy #0 lag: (min: 27.0, avg: 30.0, max: 91.0)
[2026-02-02 12:29:22,514][93050] Avg episode reward: [(0, '1087.065')]
[2026-02-02 12:29:27,506][93050] Fps is (10 sec: 3312.1, 60 sec: 3008.1, 300 sec: 2999.6). Total num frames: 3981312. Throughput: 0: 2805.7. Samples: 3979776. Policy #0 lag: (min: 47.0, avg: 50.0, max: 111.0)
[2026-02-02 12:29:27,506][93050] Avg episode reward: [(0, '1066.090')]
[2026-02-02 12:29:32,589][93050] Fps is (10 sec: 3252.2, 60 sec: 3004.4, 300 sec: 2998.5). Total num frames: 3997696. Throughput: 0: 2989.3. Samples: 3998208. Policy #0 lag: (min: 47.0, avg: 50.0, max: 111.0)
[2026-02-02 12:29:32,589][93050] Avg episode reward: [(0, '1068.817')]
[2026-02-02 12:29:37,563][93050] Fps is (10 sec: 3258.1, 60 sec: 3004.6, 300 sec: 2999.4). Total num frames: 4014080. Throughput: 0: 2967.1. Samples: 4015104. Policy #0 lag: (min: 47.0, avg: 50.0, max: 111.0)
[2026-02-02 12:29:37,563][93050] Avg episode reward: [(0, '1091.501')]
[2026-02-02 12:29:42,567][93050] Fps is (10 sec: 3284.1, 60 sec: 3006.1, 300 sec: 2998.9). Total num frames: 4030464. Throughput: 0: 3000.5. Samples: 4024832. Policy #0 lag: (min: 9.0, avg: 12.0, max: 73.0)
[2026-02-02 12:29:42,567][93050] Avg episode reward: [(0, '1160.874')]
[2026-02-02 12:29:42,730][93050] Saving new best policy, reward=1160.874!
[2026-02-02 12:29:47,710][93050] Fps is (10 sec: 3229.3, 60 sec: 2995.4, 300 sec: 2997.2). Total num frames: 4046848. Throughput: 0: 2994.7. Samples: 4042752. Policy #0 lag: (min: 9.0, avg: 12.0, max: 73.0)
[2026-02-02 12:29:47,710][93050] Avg episode reward: [(0, '1171.438')]
[2026-02-02 12:29:47,711][93050] Saving new best policy, reward=1171.438!
[2026-02-02 12:29:52,790][93050] Fps is (10 sec: 2403.9, 60 sec: 2990.5, 300 sec: 2968.4). Total num frames: 4055040. Throughput: 0: 2991.6. Samples: 4060672. Policy #0 lag: (min: 9.0, avg: 12.0, max: 73.0)
[2026-02-02 12:29:52,791][93050] Avg episode reward: [(0, '1195.454')]
[2026-02-02 12:29:53,172][93050] Saving new best policy, reward=1195.454!
[2026-02-02 12:29:57,582][93050] Fps is (10 sec: 1659.6, 60 sec: 3000.5, 300 sec: 2971.1). Total num frames: 4063232. Throughput: 0: 3019.2. Samples: 4069376. Policy #0 lag: (min: 42.0, avg: 45.0, max: 106.0)
[2026-02-02 12:29:57,582][93050] Avg episode reward: [(0, '1190.555')]
[2026-02-02 12:30:02,547][93050] Fps is (10 sec: 2519.0, 60 sec: 3005.1, 300 sec: 2999.7). Total num frames: 4079616. Throughput: 0: 3008.1. Samples: 4087296. Policy #0 lag: (min: 42.0, avg: 45.0, max: 106.0)
[2026-02-02 12:30:02,547][93050] Avg episode reward: [(0, '1179.838')]
[2026-02-02 12:30:07,564][93050] Fps is (10 sec: 3282.7, 60 sec: 3006.0, 300 sec: 2999.1). Total num frames: 4096000. Throughput: 0: 3000.4. Samples: 4105216. Policy #0 lag: (min: 42.0, avg: 45.0, max: 106.0)
[2026-02-02 12:30:07,564][93050] Avg episode reward: [(0, '1163.403')]
[2026-02-02 12:30:08,781][93050] Signal inference workers to stop experience collection... (750 times)
[2026-02-02 12:30:09,161][93050] InferenceWorker_p0-w0: stopping experience collection (750 times)
[2026-02-02 12:30:09,163][93050] Signal inference workers to resume experience collection... (750 times)
[2026-02-02 12:30:09,325][93050] InferenceWorker_p0-w0: resuming experience collection (750 times)
[2026-02-02 12:30:12,607][93050] Fps is (10 sec: 3257.3, 60 sec: 2997.1, 300 sec: 2997.8). Total num frames: 4112384. Throughput: 0: 2963.0. Samples: 4113408. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:30:12,607][93050] Avg episode reward: [(0, '1140.151')]
[2026-02-02 12:30:17,524][93050] Fps is (10 sec: 3290.1, 60 sec: 3008.2, 300 sec: 2999.9). Total num frames: 4128768. Throughput: 0: 2973.9. Samples: 4131840. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:30:17,524][93050] Avg episode reward: [(0, '1125.543')]
[2026-02-02 12:30:22,589][93050] Fps is (10 sec: 3282.5, 60 sec: 2999.9, 300 sec: 2999.4). Total num frames: 4145152. Throughput: 0: 2979.2. Samples: 4149248. Policy #0 lag: (min: 33.0, avg: 36.0, max: 97.0)
[2026-02-02 12:30:22,590][93050] Avg episode reward: [(0, '1172.677')]
[2026-02-02 12:30:27,623][93050] Fps is (10 sec: 3244.7, 60 sec: 2997.9, 300 sec: 2998.5). Total num frames: 4161536. Throughput: 0: 3159.1. Samples: 4167168. Policy #0 lag: (min: 33.0, avg: 36.0, max: 97.0)
[2026-02-02 12:30:27,623][93050] Avg episode reward: [(0, '1204.302')]
[2026-02-02 12:30:27,787][93050] Saving new best policy, reward=1204.302!
[2026-02-02 12:30:32,615][93050] Fps is (10 sec: 3268.4, 60 sec: 3002.4, 300 sec: 2998.3). Total num frames: 4177920. Throughput: 0: 2998.7. Samples: 4177408. Policy #0 lag: (min: 33.0, avg: 36.0, max: 97.0)
[2026-02-02 12:30:32,615][93050] Avg episode reward: [(0, '1198.555')]
[2026-02-02 12:30:37,491][93050] Fps is (10 sec: 3320.7, 60 sec: 3007.4, 300 sec: 2999.8). Total num frames: 4194304. Throughput: 0: 3012.4. Samples: 4195328. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:30:37,491][93050] Avg episode reward: [(0, '1195.635')]
[2026-02-02 12:30:42,703][93050] Fps is (10 sec: 3248.3, 60 sec: 2997.0, 300 sec: 2997.6). Total num frames: 4210688. Throughput: 0: 2973.0. Samples: 4203520. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:30:42,703][93050] Avg episode reward: [(0, '1149.038')]
[2026-02-02 12:30:47,852][93050] Fps is (10 sec: 2372.0, 60 sec: 2860.5, 300 sec: 2968.0). Total num frames: 4218880. Throughput: 0: 2960.9. Samples: 4221440. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:30:47,852][93050] Avg episode reward: [(0, '1125.946')]
[2026-02-02 12:30:52,623][93050] Fps is (10 sec: 1651.6, 60 sec: 2875.2, 300 sec: 2942.3). Total num frames: 4227072. Throughput: 0: 2977.1. Samples: 4239360. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:30:52,623][93050] Avg episode reward: [(0, '1130.321')]
[2026-02-02 12:30:52,787][93050] Saving /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_accel_policy2_aggressive_magpie_adp_nullified_02022026/checkpoint_p0/checkpoint_000016512_4227072.pth...
[2026-02-02 12:30:52,791][93050] Removing /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_accel_policy2_aggressive_magpie_adp_nullified_02022026/checkpoint_p0/checkpoint_000013760_3522560.pth
[2026-02-02 12:30:57,509][93050] Fps is (10 sec: 2544.7, 60 sec: 3007.4, 300 sec: 2971.5). Total num frames: 4243456. Throughput: 0: 2987.4. Samples: 4247552. Policy #0 lag: (min: 14.0, avg: 17.0, max: 78.0)
[2026-02-02 12:30:57,510][93050] Avg episode reward: [(0, '1182.586')]
[2026-02-02 12:31:02,546][93050] Fps is (10 sec: 3302.1, 60 sec: 3003.8, 300 sec: 2999.8). Total num frames: 4259840. Throughput: 0: 2968.1. Samples: 4265472. Policy #0 lag: (min: 14.0, avg: 17.0, max: 78.0)
[2026-02-02 12:31:02,546][93050] Avg episode reward: [(0, '1193.537')]
[2026-02-02 12:31:07,537][93050] Fps is (10 sec: 3267.7, 60 sec: 3005.1, 300 sec: 2998.6). Total num frames: 4276224. Throughput: 0: 2995.8. Samples: 4283904. Policy #0 lag: (min: 14.0, avg: 17.0, max: 78.0)
[2026-02-02 12:31:07,537][93050] Avg episode reward: [(0, '1199.062')]
[2026-02-02 12:31:12,577][93050] Fps is (10 sec: 3266.6, 60 sec: 3005.2, 300 sec: 2999.6). Total num frames: 4292608. Throughput: 0: 2813.1. Samples: 4293632. Policy #0 lag: (min: 10.0, avg: 13.0, max: 74.0)
[2026-02-02 12:31:12,578][93050] Avg episode reward: [(0, '1207.005')]
[2026-02-02 12:31:12,740][93050] Saving new best policy, reward=1207.005!
[2026-02-02 12:31:17,558][93050] Fps is (10 sec: 3270.1, 60 sec: 3002.0, 300 sec: 2999.7). Total num frames: 4308992. Throughput: 0: 2950.6. Samples: 4310016. Policy #0 lag: (min: 10.0, avg: 13.0, max: 74.0)
[2026-02-02 12:31:17,558][93050] Avg episode reward: [(0, '1220.745')]
[2026-02-02 12:31:17,727][93050] Saving new best policy, reward=1220.745!
[2026-02-02 12:31:22,578][93050] Fps is (10 sec: 3276.7, 60 sec: 3004.3, 300 sec: 2998.2). Total num frames: 4325376. Throughput: 0: 2929.8. Samples: 4327424. Policy #0 lag: (min: 10.0, avg: 13.0, max: 74.0)
[2026-02-02 12:31:22,578][93050] Avg episode reward: [(0, '1213.427')]
[2026-02-02 12:31:27,609][93050] Fps is (10 sec: 3260.1, 60 sec: 3004.4, 300 sec: 2998.6). Total num frames: 4341760. Throughput: 0: 2975.8. Samples: 4337152. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:31:27,609][93050] Avg episode reward: [(0, '1219.292')]
[2026-02-02 12:31:32,574][93050] Fps is (10 sec: 3278.0, 60 sec: 3005.8, 300 sec: 2998.8). Total num frames: 4358144. Throughput: 0: 2988.0. Samples: 4355072. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:31:32,574][93050] Avg episode reward: [(0, '1241.897')]
[2026-02-02 12:31:32,776][93050] Saving new best policy, reward=1241.897!
[2026-02-02 12:31:37,828][93050] Signal inference workers to stop experience collection... (800 times)
[2026-02-02 12:31:37,829][93050] Fps is (10 sec: 2404.8, 60 sec: 2851.1, 300 sec: 2968.3). Total num frames: 4366336. Throughput: 0: 2933.4. Samples: 4371968. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:31:37,829][93050] Avg episode reward: [(0, '1264.053')]
[2026-02-02 12:31:38,206][93050] InferenceWorker_p0-w0: stopping experience collection (800 times)
[2026-02-02 12:31:38,206][93050] Saving new best policy, reward=1264.053!
[2026-02-02 12:31:38,211][93050] Signal inference workers to resume experience collection... (800 times)
[2026-02-02 12:31:38,211][93050] InferenceWorker_p0-w0: resuming experience collection (800 times)
[2026-02-02 12:31:42,509][93050] Fps is (10 sec: 1649.0, 60 sec: 2739.5, 300 sec: 2944.4). Total num frames: 4374528. Throughput: 0: 2946.8. Samples: 4380160. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:31:42,510][93050] Avg episode reward: [(0, '1249.413')]
[2026-02-02 12:31:47,589][93050] Fps is (10 sec: 2518.0, 60 sec: 2879.8, 300 sec: 2942.5). Total num frames: 4390912. Throughput: 0: 2875.9. Samples: 4395008. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:31:47,589][93050] Avg episode reward: [(0, '1210.137')]
[2026-02-02 12:31:52,545][93050] Fps is (10 sec: 3265.1, 60 sec: 3007.6, 300 sec: 2944.5). Total num frames: 4407296. Throughput: 0: 2878.1. Samples: 4413440. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:31:52,545][93050] Avg episode reward: [(0, '1203.157')]
[2026-02-02 12:31:57,566][93050] Fps is (10 sec: 3284.4, 60 sec: 3000.9, 300 sec: 2972.8). Total num frames: 4423680. Throughput: 0: 2879.3. Samples: 4423168. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:31:57,566][93050] Avg episode reward: [(0, '1175.329')]
[2026-02-02 12:32:02,537][93050] Fps is (10 sec: 3279.4, 60 sec: 3004.2, 300 sec: 2999.4). Total num frames: 4440064. Throughput: 0: 2914.0. Samples: 4441088. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:32:02,538][93050] Avg episode reward: [(0, '1233.768')]
[2026-02-02 12:32:07,608][93050] Fps is (10 sec: 3263.2, 60 sec: 3000.2, 300 sec: 2997.9). Total num frames: 4456448. Throughput: 0: 2888.0. Samples: 4457472. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:32:07,608][93050] Avg episode reward: [(0, '1228.214')]
[2026-02-02 12:32:12,614][93050] Fps is (10 sec: 3252.0, 60 sec: 3001.9, 300 sec: 2999.2). Total num frames: 4472832. Throughput: 0: 2901.0. Samples: 4467712. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:32:12,614][93050] Avg episode reward: [(0, '1214.164')]
[2026-02-02 12:32:17,468][93050] Fps is (10 sec: 3323.0, 60 sec: 3008.2, 300 sec: 3000.6). Total num frames: 4489216. Throughput: 0: 2919.6. Samples: 4486144. Policy #0 lag: (min: 0.0, avg: 3.0, max: 64.0)
[2026-02-02 12:32:17,469][93050] Avg episode reward: [(0, '1239.603')]
[2026-02-02 12:32:22,632][93050] Fps is (10 sec: 2453.1, 60 sec: 2864.6, 300 sec: 2970.1). Total num frames: 4497408. Throughput: 0: 2948.4. Samples: 4504064. Policy #0 lag: (min: 0.0, avg: 3.0, max: 64.0)
[2026-02-02 12:32:22,632][93050] Avg episode reward: [(0, '1254.280')]
[2026-02-02 12:32:27,622][93050] Fps is (10 sec: 1613.7, 60 sec: 2730.1, 300 sec: 2943.0). Total num frames: 4505600. Throughput: 0: 2928.2. Samples: 4512256. Policy #0 lag: (min: 0.0, avg: 3.0, max: 64.0)
[2026-02-02 12:32:27,622][93050] Avg episode reward: [(0, '1251.971')]
[2026-02-02 12:32:32,623][93050] Fps is (10 sec: 2459.7, 60 sec: 2728.4, 300 sec: 2942.9). Total num frames: 4521984. Throughput: 0: 3001.4. Samples: 4530176. Policy #0 lag: (min: 0.0, avg: 3.0, max: 64.0)
[2026-02-02 12:32:32,624][93050] Avg episode reward: [(0, '1241.899')]
[2026-02-02 12:32:37,470][93050] Fps is (10 sec: 3327.3, 60 sec: 2884.4, 300 sec: 2945.0). Total num frames: 4538368. Throughput: 0: 2997.4. Samples: 4548096. Policy #0 lag: (min: 13.0, avg: 16.0, max: 77.0)
[2026-02-02 12:32:37,470][93050] Avg episode reward: [(0, '1216.615')]
[2026-02-02 12:32:42,572][93050] Fps is (10 sec: 3293.6, 60 sec: 3000.6, 300 sec: 2942.9). Total num frames: 4554752. Throughput: 0: 2946.4. Samples: 4555776. Policy #0 lag: (min: 13.0, avg: 16.0, max: 77.0)
[2026-02-02 12:32:42,573][93050] Avg episode reward: [(0, '1226.204')]
[2026-02-02 12:32:47,548][93050] Fps is (10 sec: 3251.4, 60 sec: 3005.8, 300 sec: 2942.8). Total num frames: 4571136. Throughput: 0: 2968.9. Samples: 4574720. Policy #0 lag: (min: 13.0, avg: 16.0, max: 77.0)
[2026-02-02 12:32:47,548][93050] Avg episode reward: [(0, '1233.132')]
[2026-02-02 12:32:52,527][93050] Fps is (10 sec: 3291.9, 60 sec: 3004.7, 300 sec: 2971.9). Total num frames: 4587520. Throughput: 0: 3020.5. Samples: 4593152. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:32:52,527][93050] Avg episode reward: [(0, '1234.787')]
[2026-02-02 12:32:52,680][93050] Saving /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_accel_policy2_aggressive_magpie_adp_nullified_02022026/checkpoint_p0/checkpoint_000017920_4587520.pth...
[2026-02-02 12:32:52,684][93050] Removing /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_accel_policy2_aggressive_magpie_adp_nullified_02022026/checkpoint_p0/checkpoint_000015168_3883008.pth
[2026-02-02 12:32:57,567][93050] Fps is (10 sec: 3270.4, 60 sec: 3003.6, 300 sec: 2998.7). Total num frames: 4603904. Throughput: 0: 3006.8. Samples: 4602880. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:32:57,568][93050] Avg episode reward: [(0, '1283.273')]
[2026-02-02 12:32:57,723][93050] Saving new best policy, reward=1283.273!
[2026-02-02 12:33:02,585][93050] Fps is (10 sec: 3257.7, 60 sec: 3001.3, 300 sec: 2998.9). Total num frames: 4620288. Throughput: 0: 2984.6. Samples: 4620800. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:33:02,585][93050] Avg episode reward: [(0, '1300.486')]
[2026-02-02 12:33:02,741][93050] Saving new best policy, reward=1300.486!
[2026-02-02 12:33:07,598][93050] Fps is (10 sec: 3266.9, 60 sec: 3004.2, 300 sec: 2999.0). Total num frames: 4636672. Throughput: 0: 2971.9. Samples: 4637696. Policy #0 lag: (min: 1.0, avg: 4.0, max: 65.0)
[2026-02-02 12:33:07,598][93050] Avg episode reward: [(0, '1274.355')]
[2026-02-02 12:33:11,881][93050] Signal inference workers to stop experience collection... (850 times)
[2026-02-02 12:33:11,881][93050] Signal inference workers to resume experience collection... (850 times)
[2026-02-02 12:33:12,149][93050] InferenceWorker_p0-w0: stopping experience collection (850 times)
[2026-02-02 12:33:12,149][93050] InferenceWorker_p0-w0: resuming experience collection (850 times)
[2026-02-02 12:33:12,590][93050] Fps is (10 sec: 3275.4, 60 sec: 3004.9, 300 sec: 2999.3). Total num frames: 4653056. Throughput: 0: 2994.5. Samples: 4646912. Policy #0 lag: (min: 1.0, avg: 4.0, max: 65.0)
[2026-02-02 12:33:12,590][93050] Avg episode reward: [(0, '1284.948')]
[2026-02-02 12:33:17,783][93050] Fps is (10 sec: 3217.2, 60 sec: 2988.1, 300 sec: 2996.1). Total num frames: 4669440. Throughput: 0: 2993.1. Samples: 4665344. Policy #0 lag: (min: 1.0, avg: 4.0, max: 65.0)
[2026-02-02 12:33:17,783][93050] Avg episode reward: [(0, '1276.476')]
[2026-02-02 12:33:22,475][93050] Fps is (10 sec: 1657.4, 60 sec: 2874.7, 300 sec: 2944.7). Total num frames: 4669440. Throughput: 0: 3003.4. Samples: 4683264. Policy #0 lag: (min: 1.0, avg: 4.0, max: 65.0)
[2026-02-02 12:33:22,475][93050] Avg episode reward: [(0, '1284.114')]
[2026-02-02 12:33:27,557][93050] Fps is (10 sec: 1676.3, 60 sec: 3007.0, 300 sec: 2944.0). Total num frames: 4685824. Throughput: 0: 3016.2. Samples: 4691456. Policy #0 lag: (min: 5.0, avg: 8.0, max: 69.0)
[2026-02-02 12:33:27,557][93050] Avg episode reward: [(0, '1282.657')]
[2026-02-02 12:33:32,553][93050] Fps is (10 sec: 3251.3, 60 sec: 3007.2, 300 sec: 2943.8). Total num frames: 4702208. Throughput: 0: 2992.0. Samples: 4709376. Policy #0 lag: (min: 5.0, avg: 8.0, max: 69.0)
[2026-02-02 12:33:32,554][93050] Avg episode reward: [(0, '1260.006')]
[2026-02-02 12:33:37,509][93050] Fps is (10 sec: 3292.6, 60 sec: 3001.8, 300 sec: 2944.6). Total num frames: 4718592. Throughput: 0: 2993.6. Samples: 4727808. Policy #0 lag: (min: 5.0, avg: 8.0, max: 69.0)
[2026-02-02 12:33:37,509][93050] Avg episode reward: [(0, '1272.905')]
[2026-02-02 12:33:42,527][93050] Fps is (10 sec: 3285.4, 60 sec: 3006.0, 300 sec: 2943.7). Total num frames: 4734976. Throughput: 0: 2960.9. Samples: 4736000. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:33:42,527][93050] Avg episode reward: [(0, '1273.648')]
[2026-02-02 12:33:47,591][93050] Fps is (10 sec: 3250.1, 60 sec: 3001.6, 300 sec: 2970.7). Total num frames: 4751360. Throughput: 0: 2957.9. Samples: 4753920. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:33:47,591][93050] Avg episode reward: [(0, '1290.386')]
[2026-02-02 12:33:52,545][93050] Fps is (10 sec: 3270.9, 60 sec: 3002.8, 300 sec: 2998.8). Total num frames: 4767744. Throughput: 0: 2995.8. Samples: 4772352. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:33:52,546][93050] Avg episode reward: [(0, '1362.624')]
[2026-02-02 12:33:52,710][93050] Saving new best policy, reward=1362.624!
[2026-02-02 12:33:57,484][93050] Fps is (10 sec: 3312.3, 60 sec: 3007.9, 300 sec: 3000.0). Total num frames: 4784128. Throughput: 0: 3022.2. Samples: 4782592. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:33:57,484][93050] Avg episode reward: [(0, '1333.268')]
[2026-02-02 12:34:02,512][93050] Fps is (10 sec: 3287.7, 60 sec: 3007.4, 300 sec: 3000.1). Total num frames: 4800512. Throughput: 0: 3021.9. Samples: 4800512. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:34:02,512][93050] Avg episode reward: [(0, '1338.434')]
[2026-02-02 12:34:07,628][93050] Fps is (10 sec: 3230.3, 60 sec: 3002.2, 300 sec: 2997.5). Total num frames: 4816896. Throughput: 0: 2982.2. Samples: 4817920. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:34:07,628][93050] Avg episode reward: [(0, '1286.049')]
[2026-02-02 12:34:12,477][93050] Fps is (10 sec: 3288.4, 60 sec: 3009.4, 300 sec: 3000.5). Total num frames: 4833280. Throughput: 0: 3020.5. Samples: 4827136. Policy #0 lag: (min: 9.0, avg: 12.0, max: 73.0)
[2026-02-02 12:34:12,477][93050] Avg episode reward: [(0, '1301.925')]
[2026-02-02 12:34:17,556][93050] Fps is (10 sec: 2475.4, 60 sec: 2878.1, 300 sec: 2970.9). Total num frames: 4841472. Throughput: 0: 3003.6. Samples: 4844544. Policy #0 lag: (min: 9.0, avg: 12.0, max: 73.0)
[2026-02-02 12:34:17,556][93050] Avg episode reward: [(0, '1316.377')]
[2026-02-02 12:34:22,585][93050] Fps is (10 sec: 1620.8, 60 sec: 2998.2, 300 sec: 2942.8). Total num frames: 4849664. Throughput: 0: 2998.6. Samples: 4862976. Policy #0 lag: (min: 9.0, avg: 12.0, max: 73.0)
[2026-02-02 12:34:22,586][93050] Avg episode reward: [(0, '1355.419')]
[2026-02-02 12:34:27,494][93050] Fps is (10 sec: 2472.8, 60 sec: 3006.9, 300 sec: 2944.5). Total num frames: 4866048. Throughput: 0: 3017.3. Samples: 4871680. Policy #0 lag: (min: 9.0, avg: 12.0, max: 73.0)
[2026-02-02 12:34:27,494][93050] Avg episode reward: [(0, '1334.249')]
[2026-02-02 12:34:32,509][93050] Fps is (10 sec: 3302.0, 60 sec: 3006.0, 300 sec: 2944.1). Total num frames: 4882432. Throughput: 0: 3020.6. Samples: 4889600. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:34:32,509][93050] Avg episode reward: [(0, '1292.704')]
[2026-02-02 12:34:37,490][93050] Fps is (10 sec: 3277.9, 60 sec: 3004.6, 300 sec: 2944.3). Total num frames: 4898816. Throughput: 0: 3018.8. Samples: 4908032. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:34:37,491][93050] Avg episode reward: [(0, '1282.567')]
[2026-02-02 12:34:42,503][93050] Fps is (10 sec: 3278.9, 60 sec: 3005.0, 300 sec: 2945.6). Total num frames: 4915200. Throughput: 0: 2968.3. Samples: 4916224. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:34:42,503][93050] Avg episode reward: [(0, '1268.259')]
[2026-02-02 12:34:44,533][93050] Signal inference workers to stop experience collection... (900 times)
[2026-02-02 12:34:44,907][93050] InferenceWorker_p0-w0: stopping experience collection (900 times)
[2026-02-02 12:34:44,909][93050] Signal inference workers to resume experience collection... (900 times)
[2026-02-02 12:34:45,056][93050] InferenceWorker_p0-w0: resuming experience collection (900 times)
[2026-02-02 12:34:47,486][93050] Fps is (10 sec: 3278.1, 60 sec: 3009.0, 300 sec: 2974.4). Total num frames: 4931584. Throughput: 0: 2971.3. Samples: 4934144. Policy #0 lag: (min: 0.0, avg: 3.0, max: 64.0)
[2026-02-02 12:34:47,487][93050] Avg episode reward: [(0, '1304.799')]
[2026-02-02 12:34:52,612][93050] Fps is (10 sec: 3241.4, 60 sec: 3000.4, 300 sec: 2998.8). Total num frames: 4947968. Throughput: 0: 2982.0. Samples: 4952064. Policy #0 lag: (min: 0.0, avg: 3.0, max: 64.0)
[2026-02-02 12:34:52,612][93050] Avg episode reward: [(0, '1343.180')]
[2026-02-02 12:34:52,771][93050] Saving /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_accel_policy2_aggressive_magpie_adp_nullified_02022026/checkpoint_p0/checkpoint_000019328_4947968.pth...
[2026-02-02 12:34:52,775][93050] Removing /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_accel_policy2_aggressive_magpie_adp_nullified_02022026/checkpoint_p0/checkpoint_000016512_4227072.pth
[2026-02-02 12:34:57,570][93050] Fps is (10 sec: 3249.5, 60 sec: 2999.4, 300 sec: 2998.9). Total num frames: 4964352. Throughput: 0: 2986.2. Samples: 4961792. Policy #0 lag: (min: 0.0, avg: 3.0, max: 64.0)
[2026-02-02 12:34:57,571][93050] Avg episode reward: [(0, '1337.881')]
[2026-02-02 12:35:02,475][93050] Fps is (10 sec: 3322.2, 60 sec: 3005.6, 300 sec: 3000.0). Total num frames: 4980736. Throughput: 0: 3020.5. Samples: 4980224. Policy #0 lag: (min: 11.0, avg: 14.0, max: 75.0)
[2026-02-02 12:35:02,475][93050] Avg episode reward: [(0, '1310.493')]
[2026-02-02 12:35:07,583][93050] Fps is (10 sec: 3272.8, 60 sec: 3006.0, 300 sec: 2999.4). Total num frames: 4997120. Throughput: 0: 3003.9. Samples: 4998144. Policy #0 lag: (min: 11.0, avg: 14.0, max: 75.0)
[2026-02-02 12:35:07,583][93050] Avg episode reward: [(0, '1244.618')]
[2026-02-02 12:35:12,499][93050] Fps is (10 sec: 3269.0, 60 sec: 3002.6, 300 sec: 2999.4). Total num frames: 5013504. Throughput: 0: 3003.4. Samples: 5006848. Policy #0 lag: (min: 11.0, avg: 14.0, max: 75.0)
[2026-02-02 12:35:12,499][93050] Avg episode reward: [(0, '1221.664')]
[2026-02-02 12:35:17,684][93050] Fps is (10 sec: 2432.8, 60 sec: 2997.3, 300 sec: 2970.4). Total num frames: 5021696. Throughput: 0: 2992.1. Samples: 5024768. Policy #0 lag: (min: 2.0, avg: 5.0, max: 66.0)
[2026-02-02 12:35:17,685][93050] Avg episode reward: [(0, '1269.078')]
[2026-02-02 12:35:22,593][93050] Fps is (10 sec: 1623.2, 60 sec: 3003.4, 300 sec: 2943.9). Total num frames: 5029888. Throughput: 0: 2985.6. Samples: 5042688. Policy #0 lag: (min: 2.0, avg: 5.0, max: 66.0)
[2026-02-02 12:35:22,593][93050] Avg episode reward: [(0, '1273.670')]
[2026-02-02 12:35:27,596][93050] Fps is (10 sec: 2479.4, 60 sec: 2998.6, 300 sec: 2943.8). Total num frames: 5046272. Throughput: 0: 2997.5. Samples: 5051392. Policy #0 lag: (min: 2.0, avg: 5.0, max: 66.0)
[2026-02-02 12:35:27,597][93050] Avg episode reward: [(0, '1299.229')]
[2026-02-02 12:35:32,517][93050] Fps is (10 sec: 3301.8, 60 sec: 3003.3, 300 sec: 2943.3). Total num frames: 5062656. Throughput: 0: 3001.7. Samples: 5069312. Policy #0 lag: (min: 2.0, avg: 5.0, max: 66.0)
[2026-02-02 12:35:32,517][93050] Avg episode reward: [(0, '1273.063')]
[2026-02-02 12:35:37,575][93050] Fps is (10 sec: 3283.9, 60 sec: 2999.5, 300 sec: 2944.8). Total num frames: 5079040. Throughput: 0: 3006.2. Samples: 5087232. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:35:37,575][93050] Avg episode reward: [(0, '1344.797')]
[2026-02-02 12:35:42,521][93050] Fps is (10 sec: 3275.7, 60 sec: 3002.8, 300 sec: 2974.7). Total num frames: 5095424. Throughput: 0: 2995.7. Samples: 5096448. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:35:42,521][93050] Avg episode reward: [(0, '1330.046')]
[2026-02-02 12:35:47,491][93050] Fps is (10 sec: 3304.5, 60 sec: 3003.5, 300 sec: 3000.4). Total num frames: 5111808. Throughput: 0: 2968.6. Samples: 5113856. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:35:47,491][93050] Avg episode reward: [(0, '1308.775')]
[2026-02-02 12:35:52,553][93050] Fps is (10 sec: 3266.3, 60 sec: 3006.7, 300 sec: 2998.7). Total num frames: 5128192. Throughput: 0: 2983.0. Samples: 5132288. Policy #0 lag: (min: 9.0, avg: 12.0, max: 73.0)
[2026-02-02 12:35:52,553][93050] Avg episode reward: [(0, '1347.327')]
[2026-02-02 12:35:57,495][93050] Fps is (10 sec: 3275.4, 60 sec: 3007.5, 300 sec: 2999.6). Total num frames: 5144576. Throughput: 0: 3004.0. Samples: 5142016. Policy #0 lag: (min: 9.0, avg: 12.0, max: 73.0)
[2026-02-02 12:35:57,495][93050] Avg episode reward: [(0, '1309.568')]
[2026-02-02 12:36:02,542][93050] Fps is (10 sec: 3280.2, 60 sec: 3000.4, 300 sec: 2999.1). Total num frames: 5160960. Throughput: 0: 3013.3. Samples: 5159936. Policy #0 lag: (min: 9.0, avg: 12.0, max: 73.0)
[2026-02-02 12:36:02,543][93050] Avg episode reward: [(0, '1337.682')]
[2026-02-02 12:36:07,607][93050] Fps is (10 sec: 3240.5, 60 sec: 3002.5, 300 sec: 2998.8). Total num frames: 5177344. Throughput: 0: 3002.8. Samples: 5177856. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:36:07,607][93050] Avg episode reward: [(0, '1262.705')]
[2026-02-02 12:36:12,505][93050] Signal inference workers to stop experience collection... (950 times)
[2026-02-02 12:36:12,505][93050] Fps is (10 sec: 2466.9, 60 sec: 2866.9, 300 sec: 2971.9). Total num frames: 5185536. Throughput: 0: 2998.5. Samples: 5186048. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:36:12,505][93050] Avg episode reward: [(0, '1238.462')]
[2026-02-02 12:36:12,881][93050] InferenceWorker_p0-w0: stopping experience collection (950 times)
[2026-02-02 12:36:12,881][93050] Signal inference workers to resume experience collection... (950 times)
[2026-02-02 12:36:12,881][93050] InferenceWorker_p0-w0: resuming experience collection (950 times)
[2026-02-02 12:36:17,600][93050] Fps is (10 sec: 1639.6, 60 sec: 2871.2, 300 sec: 2943.3). Total num frames: 5193728. Throughput: 0: 2986.9. Samples: 5203968. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:36:17,600][93050] Avg episode reward: [(0, '1306.227')]
[2026-02-02 12:36:22,587][93050] Fps is (10 sec: 2437.6, 60 sec: 3004.0, 300 sec: 2943.8). Total num frames: 5210112. Throughput: 0: 2991.5. Samples: 5221888. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:36:22,587][93050] Avg episode reward: [(0, '1325.946')]
[2026-02-02 12:36:27,505][93050] Fps is (10 sec: 3308.3, 60 sec: 3008.3, 300 sec: 2944.3). Total num frames: 5226496. Throughput: 0: 2982.0. Samples: 5230592. Policy #0 lag: (min: 10.0, avg: 13.0, max: 74.0)
[2026-02-02 12:36:27,505][93050] Avg episode reward: [(0, '1360.359')]
[2026-02-02 12:36:32,604][93050] Fps is (10 sec: 3271.2, 60 sec: 2999.4, 300 sec: 2973.6). Total num frames: 5242880. Throughput: 0: 2984.8. Samples: 5248512. Policy #0 lag: (min: 10.0, avg: 13.0, max: 74.0)
[2026-02-02 12:36:32,604][93050] Avg episode reward: [(0, '1368.240')]
[2026-02-02 12:36:32,756][93050] Saving new best policy, reward=1368.240!
[2026-02-02 12:36:37,603][93050] Fps is (10 sec: 3245.1, 60 sec: 3002.3, 300 sec: 2998.2). Total num frames: 5259264. Throughput: 0: 2977.7. Samples: 5266432. Policy #0 lag: (min: 10.0, avg: 13.0, max: 74.0)
[2026-02-02 12:36:37,603][93050] Avg episode reward: [(0, '1319.707')]
[2026-02-02 12:36:42,480][93050] Fps is (10 sec: 3318.0, 60 sec: 3005.8, 300 sec: 3000.2). Total num frames: 5275648. Throughput: 0: 2982.0. Samples: 5276160. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:36:42,480][93050] Avg episode reward: [(0, '1329.530')]
[2026-02-02 12:36:47,496][93050] Fps is (10 sec: 3312.1, 60 sec: 3003.5, 300 sec: 2999.6). Total num frames: 5292032. Throughput: 0: 2961.3. Samples: 5293056. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:36:47,496][93050] Avg episode reward: [(0, '1326.394')]
[2026-02-02 12:36:52,623][93050] Fps is (10 sec: 3230.5, 60 sec: 3000.2, 300 sec: 2998.5). Total num frames: 5308416. Throughput: 0: 2957.2. Samples: 5310976. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:36:52,623][93050] Avg episode reward: [(0, '1311.529')]
[2026-02-02 12:36:52,783][93050] Saving /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_accel_policy2_aggressive_magpie_adp_nullified_02022026/checkpoint_p0/checkpoint_000020736_5308416.pth...
[2026-02-02 12:36:52,786][93050] Removing /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_accel_policy2_aggressive_magpie_adp_nullified_02022026/checkpoint_p0/checkpoint_000017920_4587520.pth
[2026-02-02 12:36:57,475][93050] Fps is (10 sec: 3283.9, 60 sec: 3004.8, 300 sec: 2999.7). Total num frames: 5324800. Throughput: 0: 2994.4. Samples: 5320704. Policy #0 lag: (min: 14.0, avg: 17.0, max: 78.0)
[2026-02-02 12:36:57,475][93050] Avg episode reward: [(0, '1296.227')]
[2026-02-02 12:37:02,525][93050] Fps is (10 sec: 3309.4, 60 sec: 3004.6, 300 sec: 2999.9). Total num frames: 5341184. Throughput: 0: 3008.8. Samples: 5339136. Policy #0 lag: (min: 14.0, avg: 17.0, max: 78.0)
[2026-02-02 12:37:02,525][93050] Avg episode reward: [(0, '1270.012')]
[2026-02-02 12:37:07,471][93050] Fps is (10 sec: 3277.9, 60 sec: 3010.5, 300 sec: 3000.6). Total num frames: 5357568. Throughput: 0: 3022.9. Samples: 5357568. Policy #0 lag: (min: 14.0, avg: 17.0, max: 78.0)
[2026-02-02 12:37:07,472][93050] Avg episode reward: [(0, '1309.325')]
[2026-02-02 12:37:12,659][93050] Fps is (10 sec: 2425.1, 60 sec: 2996.0, 300 sec: 2969.4). Total num frames: 5365760. Throughput: 0: 2993.5. Samples: 5365760. Policy #0 lag: (min: 3.0, avg: 6.0, max: 67.0)
[2026-02-02 12:37:12,659][93050] Avg episode reward: [(0, '1275.282')]
[2026-02-02 12:37:17,571][93050] Fps is (10 sec: 1622.3, 60 sec: 3005.2, 300 sec: 2972.0). Total num frames: 5373952. Throughput: 0: 3006.0. Samples: 5383680. Policy #0 lag: (min: 3.0, avg: 6.0, max: 67.0)
[2026-02-02 12:37:17,571][93050] Avg episode reward: [(0, '1314.041')]
[2026-02-02 12:37:22,501][93050] Fps is (10 sec: 2497.0, 60 sec: 3008.0, 300 sec: 3000.3). Total num frames: 5390336. Throughput: 0: 3021.9. Samples: 5402112. Policy #0 lag: (min: 3.0, avg: 6.0, max: 67.0)
[2026-02-02 12:37:22,501][93050] Avg episode reward: [(0, '1304.946')]
[2026-02-02 12:37:27,521][93050] Fps is (10 sec: 3293.1, 60 sec: 3002.9, 300 sec: 3000.1). Total num frames: 5406720. Throughput: 0: 2978.2. Samples: 5410304. Policy #0 lag: (min: 3.0, avg: 6.0, max: 67.0)
[2026-02-02 12:37:27,521][93050] Avg episode reward: [(0, '1282.915')]
[2026-02-02 12:37:32,599][93050] Fps is (10 sec: 3245.1, 60 sec: 3004.0, 300 sec: 2997.8). Total num frames: 5423104. Throughput: 0: 3008.3. Samples: 5428736. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:37:32,599][93050] Avg episode reward: [(0, '1272.983')]
[2026-02-02 12:37:37,531][93050] Fps is (10 sec: 3273.4, 60 sec: 3007.3, 300 sec: 2999.5). Total num frames: 5439488. Throughput: 0: 3021.3. Samples: 5446656. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:37:37,532][93050] Avg episode reward: [(0, '1270.172')]
[2026-02-02 12:37:42,538][93050] Fps is (10 sec: 3296.7, 60 sec: 3000.8, 300 sec: 2999.2). Total num frames: 5455872. Throughput: 0: 3022.2. Samples: 5456896. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:37:42,539][93050] Avg episode reward: [(0, '1325.288')]
[2026-02-02 12:37:45,290][93050] Signal inference workers to stop experience collection... (1000 times)
[2026-02-02 12:37:45,293][93050] Signal inference workers to resume experience collection... (1000 times)
[2026-02-02 12:37:45,552][93050] InferenceWorker_p0-w0: stopping experience collection (1000 times)
[2026-02-02 12:37:45,552][93050] InferenceWorker_p0-w0: resuming experience collection (1000 times)
[2026-02-02 12:37:47,538][93050] Fps is (10 sec: 3274.6, 60 sec: 3001.6, 300 sec: 2999.0). Total num frames: 5472256. Throughput: 0: 2980.1. Samples: 5473280. Policy #0 lag: (min: 6.0, avg: 9.0, max: 70.0)
[2026-02-02 12:37:47,538][93050] Avg episode reward: [(0, '1378.751')]
[2026-02-02 12:37:47,699][93050] Saving new best policy, reward=1378.751!
[2026-02-02 12:37:52,558][93050] Fps is (10 sec: 3270.3, 60 sec: 3007.0, 300 sec: 2999.2). Total num frames: 5488640. Throughput: 0: 2975.2. Samples: 5491712. Policy #0 lag: (min: 6.0, avg: 9.0, max: 70.0)
[2026-02-02 12:37:52,559][93050] Avg episode reward: [(0, '1388.114')]
[2026-02-02 12:37:52,722][93050] Saving new best policy, reward=1388.114!
[2026-02-02 12:37:57,612][93050] Fps is (10 sec: 3252.8, 60 sec: 2996.9, 300 sec: 2998.8). Total num frames: 5505024. Throughput: 0: 3006.9. Samples: 5500928. Policy #0 lag: (min: 6.0, avg: 9.0, max: 70.0)
[2026-02-02 12:37:57,612][93050] Avg episode reward: [(0, '1409.604')]
[2026-02-02 12:37:57,773][93050] Saving new best policy, reward=1409.604!
[2026-02-02 12:38:02,595][93050] Fps is (10 sec: 3264.9, 60 sec: 3000.2, 300 sec: 2999.1). Total num frames: 5521408. Throughput: 0: 3013.5. Samples: 5519360. Policy #0 lag: (min: 7.0, avg: 10.0, max: 71.0)
[2026-02-02 12:38:02,595][93050] Avg episode reward: [(0, '1386.505')]
[2026-02-02 12:38:07,499][93050] Fps is (10 sec: 3314.2, 60 sec: 3002.3, 300 sec: 3000.0). Total num frames: 5537792. Throughput: 0: 3015.2. Samples: 5537792. Policy #0 lag: (min: 7.0, avg: 10.0, max: 71.0)
[2026-02-02 12:38:07,499][93050] Avg episode reward: [(0, '1399.970')]
[2026-02-02 12:38:12,609][93050] Fps is (10 sec: 2454.0, 60 sec: 3006.2, 300 sec: 2973.1). Total num frames: 5545984. Throughput: 0: 3009.2. Samples: 5545984. Policy #0 lag: (min: 7.0, avg: 10.0, max: 71.0)
[2026-02-02 12:38:12,610][93050] Avg episode reward: [(0, '1369.003')]
[2026-02-02 12:38:17,612][93050] Fps is (10 sec: 1620.1, 60 sec: 3001.7, 300 sec: 2997.7). Total num frames: 5554176. Throughput: 0: 3002.8. Samples: 5563904. Policy #0 lag: (min: 7.0, avg: 10.0, max: 71.0)
[2026-02-02 12:38:17,612][93050] Avg episode reward: [(0, '1370.612')]
[2026-02-02 12:38:22,548][93050] Fps is (10 sec: 2472.7, 60 sec: 3001.4, 300 sec: 2999.2). Total num frames: 5570560. Throughput: 0: 3002.6. Samples: 5581824. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:38:22,549][93050] Avg episode reward: [(0, '1374.857')]
[2026-02-02 12:38:27,497][93050] Fps is (10 sec: 3314.8, 60 sec: 3004.9, 300 sec: 2999.7). Total num frames: 5586944. Throughput: 0: 2972.3. Samples: 5590528. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:38:27,498][93050] Avg episode reward: [(0, '1360.501')]
[2026-02-02 12:38:32,493][93050] Fps is (10 sec: 3295.1, 60 sec: 3009.0, 300 sec: 2999.3). Total num frames: 5603328. Throughput: 0: 3006.8. Samples: 5608448. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:38:32,493][93050] Avg episode reward: [(0, '1340.094')]
[2026-02-02 12:38:37,478][93050] Fps is (10 sec: 3283.2, 60 sec: 3006.4, 300 sec: 2999.6). Total num frames: 5619712. Throughput: 0: 3009.1. Samples: 5626880. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:38:37,478][93050] Avg episode reward: [(0, '1304.014')]
[2026-02-02 12:38:42,476][93050] Fps is (10 sec: 3282.4, 60 sec: 3006.9, 300 sec: 3000.3). Total num frames: 5636096. Throughput: 0: 3024.3. Samples: 5636608. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:38:42,476][93050] Avg episode reward: [(0, '1341.432')]
[2026-02-02 12:38:47,565][93050] Fps is (10 sec: 3248.5, 60 sec: 3002.4, 300 sec: 2998.9). Total num frames: 5652480. Throughput: 0: 2983.0. Samples: 5653504. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:38:47,565][93050] Avg episode reward: [(0, '1360.375')]
[2026-02-02 12:38:52,475][93050] Fps is (10 sec: 3277.2, 60 sec: 3007.9, 300 sec: 2999.2). Total num frames: 5668864. Throughput: 0: 2959.8. Samples: 5670912. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:38:52,475][93050] Avg episode reward: [(0, '1384.111')]
[2026-02-02 12:38:52,638][93050] Saving /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_accel_policy2_aggressive_magpie_adp_nullified_02022026/checkpoint_p0/checkpoint_000022144_5668864.pth...
[2026-02-02 12:38:52,642][93050] Removing /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_accel_policy2_aggressive_magpie_adp_nullified_02022026/checkpoint_p0/checkpoint_000019328_4947968.pth
[2026-02-02 12:38:57,549][93050] Fps is (10 sec: 3282.0, 60 sec: 3006.9, 300 sec: 2998.7). Total num frames: 5685248. Throughput: 0: 2996.4. Samples: 5680640. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:38:57,549][93050] Avg episode reward: [(0, '1359.098')]
[2026-02-02 12:39:02,543][93050] Fps is (10 sec: 3254.6, 60 sec: 3006.4, 300 sec: 3000.0). Total num frames: 5701632. Throughput: 0: 2997.0. Samples: 5698560. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:39:02,543][93050] Avg episode reward: [(0, '1351.384')]
[2026-02-02 12:39:07,500][93050] Fps is (10 sec: 2469.7, 60 sec: 2867.2, 300 sec: 2971.1). Total num frames: 5709824. Throughput: 0: 2995.6. Samples: 5716480. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:39:07,500][93050] Avg episode reward: [(0, '1405.834')]
[2026-02-02 12:39:12,604][93050] Fps is (10 sec: 1628.4, 60 sec: 2867.5, 300 sec: 2970.8). Total num frames: 5718016. Throughput: 0: 2985.3. Samples: 5725184. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:39:12,604][93050] Avg episode reward: [(0, '1414.446')]
[2026-02-02 12:39:12,995][93050] Saving new best policy, reward=1414.446!
[2026-02-02 12:39:17,509][93050] Fps is (10 sec: 2455.3, 60 sec: 3008.9, 300 sec: 2999.9). Total num frames: 5734400. Throughput: 0: 2991.3. Samples: 5743104. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:39:17,510][93050] Avg episode reward: [(0, '1452.913')]
[2026-02-02 12:39:17,664][93050] Saving new best policy, reward=1452.913!
[2026-02-02 12:39:18,159][93050] Signal inference workers to stop experience collection... (1050 times)
[2026-02-02 12:39:18,558][93050] InferenceWorker_p0-w0: stopping experience collection (1050 times)
[2026-02-02 12:39:18,560][93050] Signal inference workers to resume experience collection... (1050 times)
[2026-02-02 12:39:18,721][93050] InferenceWorker_p0-w0: resuming experience collection (1050 times)
[2026-02-02 12:39:22,607][93050] Fps is (10 sec: 3275.7, 60 sec: 3000.8, 300 sec: 2998.0). Total num frames: 5750784. Throughput: 0: 2961.1. Samples: 5760512. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:39:22,608][93050] Avg episode reward: [(0, '1418.860')]
[2026-02-02 12:39:27,502][93050] Fps is (10 sec: 3279.1, 60 sec: 3003.5, 300 sec: 2999.2). Total num frames: 5767168. Throughput: 0: 2922.4. Samples: 5768192. Policy #0 lag: (min: 11.0, avg: 14.0, max: 75.0)
[2026-02-02 12:39:27,502][93050] Avg episode reward: [(0, '1415.980')]
[2026-02-02 12:39:32,538][93050] Fps is (10 sec: 3299.8, 60 sec: 3001.5, 300 sec: 2998.6). Total num frames: 5783552. Throughput: 0: 2960.0. Samples: 5786624. Policy #0 lag: (min: 11.0, avg: 14.0, max: 75.0)
[2026-02-02 12:39:32,538][93050] Avg episode reward: [(0, '1341.113')]
[2026-02-02 12:39:37,610][93050] Fps is (10 sec: 3241.9, 60 sec: 2997.1, 300 sec: 2998.0). Total num frames: 5799936. Throughput: 0: 2960.7. Samples: 5804544. Policy #0 lag: (min: 11.0, avg: 14.0, max: 75.0)
[2026-02-02 12:39:37,610][93050] Avg episode reward: [(0, '1360.688')]
[2026-02-02 12:39:42,482][93050] Fps is (10 sec: 3295.0, 60 sec: 3003.4, 300 sec: 2999.1). Total num frames: 5816320. Throughput: 0: 2974.0. Samples: 5814272. Policy #0 lag: (min: 0.0, avg: 3.0, max: 64.0)
[2026-02-02 12:39:42,483][93050] Avg episode reward: [(0, '1336.203')]
[2026-02-02 12:39:47,530][93050] Fps is (10 sec: 3303.1, 60 sec: 3005.5, 300 sec: 2999.9). Total num frames: 5832704. Throughput: 0: 2970.4. Samples: 5832192. Policy #0 lag: (min: 0.0, avg: 3.0, max: 64.0)
[2026-02-02 12:39:47,531][93050] Avg episode reward: [(0, '1343.770')]
[2026-02-02 12:39:52,566][93050] Fps is (10 sec: 3249.7, 60 sec: 2999.2, 300 sec: 2999.2). Total num frames: 5849088. Throughput: 0: 2965.3. Samples: 5850112. Policy #0 lag: (min: 0.0, avg: 3.0, max: 64.0)
[2026-02-02 12:39:52,566][93050] Avg episode reward: [(0, '1337.505')]
[2026-02-02 12:39:57,519][93050] Fps is (10 sec: 3280.5, 60 sec: 3005.2, 300 sec: 2998.7). Total num frames: 5865472. Throughput: 0: 2975.2. Samples: 5858816. Policy #0 lag: (min: 8.0, avg: 11.0, max: 72.0)
[2026-02-02 12:39:57,519][93050] Avg episode reward: [(0, '1410.935')]
[2026-02-02 12:40:02,637][93050] Fps is (10 sec: 2440.2, 60 sec: 2862.7, 300 sec: 2970.8). Total num frames: 5873664. Throughput: 0: 2961.2. Samples: 5876736. Policy #0 lag: (min: 8.0, avg: 11.0, max: 72.0)
[2026-02-02 12:40:02,637][93050] Avg episode reward: [(0, '1407.046')]
[2026-02-02 12:40:07,529][93050] Fps is (10 sec: 1636.7, 60 sec: 2865.8, 300 sec: 2943.3). Total num frames: 5881856. Throughput: 0: 2997.6. Samples: 5895168. Policy #0 lag: (min: 8.0, avg: 11.0, max: 72.0)
[2026-02-02 12:40:07,530][93050] Avg episode reward: [(0, '1422.125')]
[2026-02-02 12:40:12,573][93050] Fps is (10 sec: 2473.3, 60 sec: 3005.3, 300 sec: 2972.5). Total num frames: 5898240. Throughput: 0: 2999.0. Samples: 5903360. Policy #0 lag: (min: 8.0, avg: 11.0, max: 72.0)
[2026-02-02 12:40:12,573][93050] Avg episode reward: [(0, '1387.897')]
[2026-02-02 12:40:17,482][93050] Fps is (10 sec: 3292.3, 60 sec: 3005.1, 300 sec: 3000.2). Total num frames: 5914624. Throughput: 0: 2996.0. Samples: 5921280. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:40:17,483][93050] Avg episode reward: [(0, '1348.104')]
[2026-02-02 12:40:22,554][93050] Fps is (10 sec: 3283.0, 60 sec: 3006.4, 300 sec: 2999.5). Total num frames: 5931008. Throughput: 0: 2996.0. Samples: 5939200. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:40:22,555][93050] Avg episode reward: [(0, '1337.074')]
[2026-02-02 12:40:27,540][93050] Fps is (10 sec: 3258.1, 60 sec: 3001.9, 300 sec: 2998.9). Total num frames: 5947392. Throughput: 0: 2977.2. Samples: 5948416. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:40:27,540][93050] Avg episode reward: [(0, '1342.068')]
[2026-02-02 12:40:32,582][93050] Fps is (10 sec: 3267.8, 60 sec: 3001.5, 300 sec: 2999.0). Total num frames: 5963776. Throughput: 0: 2966.2. Samples: 5965824. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:40:32,582][93050] Avg episode reward: [(0, '1402.904')]
[2026-02-02 12:40:37,581][93050] Fps is (10 sec: 3263.3, 60 sec: 3005.2, 300 sec: 2998.5). Total num frames: 5980160. Throughput: 0: 2968.6. Samples: 5983744. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:40:37,581][93050] Avg episode reward: [(0, '1416.245')]
[2026-02-02 12:40:42,594][93050] Fps is (10 sec: 3273.0, 60 sec: 2998.2, 300 sec: 2998.1). Total num frames: 5996544. Throughput: 0: 2987.4. Samples: 5993472. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:40:42,594][93050] Avg episode reward: [(0, '1394.825')]
[2026-02-02 12:40:46,451][93050] Signal inference workers to stop experience collection... (1100 times)
[2026-02-02 12:40:46,835][93050] InferenceWorker_p0-w0: stopping experience collection (1100 times)
[2026-02-02 12:40:46,835][93050] Signal inference workers to resume experience collection... (1100 times)
[2026-02-02 12:40:46,835][93050] InferenceWorker_p0-w0: resuming experience collection (1100 times)
[2026-02-02 12:40:47,471][93050] Fps is (10 sec: 3313.2, 60 sec: 3006.7, 300 sec: 2999.9). Total num frames: 6012928. Throughput: 0: 3014.8. Samples: 6011904. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:40:47,471][93050] Avg episode reward: [(0, '1359.238')]
[2026-02-02 12:40:52,530][93050] Fps is (10 sec: 3297.6, 60 sec: 3005.5, 300 sec: 2998.7). Total num frames: 6029312. Throughput: 0: 2980.9. Samples: 6029312. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:40:52,531][93050] Avg episode reward: [(0, '1403.954')]
[2026-02-02 12:40:52,692][93050] Saving /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_accel_policy2_aggressive_magpie_adp_nullified_02022026/checkpoint_p0/checkpoint_000023552_6029312.pth...
[2026-02-02 12:40:52,696][93050] Removing /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_accel_policy2_aggressive_magpie_adp_nullified_02022026/checkpoint_p0/checkpoint_000020736_5308416.pth
[2026-02-02 12:40:57,846][93050] Fps is (10 sec: 2368.7, 60 sec: 2851.6, 300 sec: 2968.3). Total num frames: 6037504. Throughput: 0: 2974.3. Samples: 6038016. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:40:57,847][93050] Avg episode reward: [(0, '1419.237')]
[2026-02-02 12:41:02,594][93050] Fps is (10 sec: 1628.1, 60 sec: 2869.3, 300 sec: 2943.7). Total num frames: 6045696. Throughput: 0: 2985.0. Samples: 6055936. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:41:02,594][93050] Avg episode reward: [(0, '1411.014')]
[2026-02-02 12:41:07,522][93050] Fps is (10 sec: 2539.9, 60 sec: 3004.1, 300 sec: 2971.2). Total num frames: 6062080. Throughput: 0: 2994.5. Samples: 6073856. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:41:07,523][93050] Avg episode reward: [(0, '1334.010')]
[2026-02-02 12:41:12,546][93050] Fps is (10 sec: 3292.5, 60 sec: 3005.1, 300 sec: 2999.7). Total num frames: 6078464. Throughput: 0: 2969.2. Samples: 6082048. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:41:12,546][93050] Avg episode reward: [(0, '1307.599')]
[2026-02-02 12:41:17,512][93050] Fps is (10 sec: 3280.2, 60 sec: 3002.2, 300 sec: 2999.9). Total num frames: 6094848. Throughput: 0: 2985.6. Samples: 6099968. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:41:17,512][93050] Avg episode reward: [(0, '1338.289')]
[2026-02-02 12:41:22,566][93050] Fps is (10 sec: 3270.5, 60 sec: 3003.2, 300 sec: 2998.5). Total num frames: 6111232. Throughput: 0: 2982.0. Samples: 6117888. Policy #0 lag: (min: 1.0, avg: 4.0, max: 65.0)
[2026-02-02 12:41:22,566][93050] Avg episode reward: [(0, '1364.253')]
[2026-02-02 12:41:27,570][93050] Fps is (10 sec: 3258.0, 60 sec: 3002.2, 300 sec: 2999.5). Total num frames: 6127616. Throughput: 0: 2993.9. Samples: 6128128. Policy #0 lag: (min: 1.0, avg: 4.0, max: 65.0)
[2026-02-02 12:41:27,570][93050] Avg episode reward: [(0, '1386.936')]
[2026-02-02 12:41:32,495][93050] Fps is (10 sec: 3300.2, 60 sec: 3008.1, 300 sec: 3000.2). Total num frames: 6144000. Throughput: 0: 2956.7. Samples: 6145024. Policy #0 lag: (min: 1.0, avg: 4.0, max: 65.0)
[2026-02-02 12:41:32,495][93050] Avg episode reward: [(0, '1427.372')]
[2026-02-02 12:41:37,614][93050] Fps is (10 sec: 3262.5, 60 sec: 3002.1, 300 sec: 2997.7). Total num frames: 6160384. Throughput: 0: 2964.1. Samples: 6162944. Policy #0 lag: (min: 7.0, avg: 10.0, max: 71.0)
[2026-02-02 12:41:37,614][93050] Avg episode reward: [(0, '1489.938')]
[2026-02-02 12:41:37,773][93050] Saving new best policy, reward=1489.938!
[2026-02-02 12:41:42,542][93050] Fps is (10 sec: 3261.2, 60 sec: 3006.3, 300 sec: 2998.6). Total num frames: 6176768. Throughput: 0: 3012.7. Samples: 6172672. Policy #0 lag: (min: 7.0, avg: 10.0, max: 71.0)
[2026-02-02 12:41:42,542][93050] Avg episode reward: [(0, '1513.174')]
[2026-02-02 12:41:42,697][93050] Saving new best policy, reward=1513.174!
[2026-02-02 12:41:47,590][93050] Fps is (10 sec: 3284.4, 60 sec: 2997.8, 300 sec: 2999.4). Total num frames: 6193152. Throughput: 0: 3004.0. Samples: 6191104. Policy #0 lag: (min: 7.0, avg: 10.0, max: 71.0)
[2026-02-02 12:41:47,591][93050] Avg episode reward: [(0, '1491.547')]
[2026-02-02 12:41:52,808][93050] Fps is (10 sec: 3192.0, 60 sec: 2989.9, 300 sec: 2995.7). Total num frames: 6209536. Throughput: 0: 2973.5. Samples: 6208512. Policy #0 lag: (min: 4.0, avg: 7.0, max: 68.0)
[2026-02-02 12:41:52,808][93050] Avg episode reward: [(0, '1451.128')]
[2026-02-02 12:41:57,828][93050] Fps is (10 sec: 2400.5, 60 sec: 3004.6, 300 sec: 2968.3). Total num frames: 6217728. Throughput: 0: 2973.7. Samples: 6216704. Policy #0 lag: (min: 4.0, avg: 7.0, max: 68.0)
[2026-02-02 12:41:57,828][93050] Avg episode reward: [(0, '1377.757')]
[2026-02-02 12:42:02,604][93050] Fps is (10 sec: 1672.5, 60 sec: 3003.2, 300 sec: 2942.2). Total num frames: 6225920. Throughput: 0: 2997.6. Samples: 6235136. Policy #0 lag: (min: 4.0, avg: 7.0, max: 68.0)
[2026-02-02 12:42:02,604][93050] Avg episode reward: [(0, '1425.994')]
[2026-02-02 12:42:07,627][93050] Fps is (10 sec: 2508.0, 60 sec: 2998.5, 300 sec: 2971.7). Total num frames: 6242304. Throughput: 0: 2999.6. Samples: 6253056. Policy #0 lag: (min: 4.0, avg: 7.0, max: 68.0)
[2026-02-02 12:42:07,627][93050] Avg episode reward: [(0, '1465.074')]
[2026-02-02 12:42:12,600][93050] Fps is (10 sec: 3278.2, 60 sec: 3001.1, 300 sec: 2998.8). Total num frames: 6258688. Throughput: 0: 2956.3. Samples: 6261248. Policy #0 lag: (min: 2.0, avg: 5.0, max: 66.0)
[2026-02-02 12:42:12,600][93050] Avg episode reward: [(0, '1499.352')]
[2026-02-02 12:42:17,480][93050] Fps is (10 sec: 3325.6, 60 sec: 3005.3, 300 sec: 2999.3). Total num frames: 6275072. Throughput: 0: 2993.3. Samples: 6279680. Policy #0 lag: (min: 2.0, avg: 5.0, max: 66.0)
[2026-02-02 12:42:17,481][93050] Avg episode reward: [(0, '1514.561')]
[2026-02-02 12:42:17,642][93050] Saving new best policy, reward=1514.561!
[2026-02-02 12:42:19,758][93050] Signal inference workers to stop experience collection... (1150 times)
[2026-02-02 12:42:19,759][93050] Signal inference workers to resume experience collection... (1150 times)
[2026-02-02 12:42:20,020][93050] InferenceWorker_p0-w0: stopping experience collection (1150 times)
[2026-02-02 12:42:20,020][93050] InferenceWorker_p0-w0: resuming experience collection (1150 times)
[2026-02-02 12:42:22,519][93050] Fps is (10 sec: 3303.4, 60 sec: 3006.1, 300 sec: 2999.1). Total num frames: 6291456. Throughput: 0: 2998.6. Samples: 6297600. Policy #0 lag: (min: 2.0, avg: 5.0, max: 66.0)
[2026-02-02 12:42:22,519][93050] Avg episode reward: [(0, '1504.054')]
[2026-02-02 12:42:27,579][93050] Fps is (10 sec: 3244.9, 60 sec: 3003.3, 300 sec: 2999.3). Total num frames: 6307840. Throughput: 0: 2989.9. Samples: 6307328. Policy #0 lag: (min: 8.0, avg: 11.0, max: 72.0)
[2026-02-02 12:42:27,579][93050] Avg episode reward: [(0, '1467.736')]
[2026-02-02 12:42:32,595][93050] Fps is (10 sec: 3252.0, 60 sec: 2998.7, 300 sec: 2998.5). Total num frames: 6324224. Throughput: 0: 2980.7. Samples: 6325248. Policy #0 lag: (min: 8.0, avg: 11.0, max: 72.0)
[2026-02-02 12:42:32,596][93050] Avg episode reward: [(0, '1433.467')]
[2026-02-02 12:42:37,603][93050] Fps is (10 sec: 3268.7, 60 sec: 3004.2, 300 sec: 2998.4). Total num frames: 6340608. Throughput: 0: 2971.7. Samples: 6341632. Policy #0 lag: (min: 8.0, avg: 11.0, max: 72.0)
[2026-02-02 12:42:37,604][93050] Avg episode reward: [(0, '1401.022')]
[2026-02-02 12:42:42,572][93050] Fps is (10 sec: 3284.3, 60 sec: 3002.2, 300 sec: 2998.8). Total num frames: 6356992. Throughput: 0: 3009.5. Samples: 6351360. Policy #0 lag: (min: 22.0, avg: 25.0, max: 86.0)
[2026-02-02 12:42:42,573][93050] Avg episode reward: [(0, '1395.481')]
[2026-02-02 12:42:47,622][93050] Fps is (10 sec: 3270.8, 60 sec: 3002.2, 300 sec: 2998.5). Total num frames: 6373376. Throughput: 0: 2991.2. Samples: 6369792. Policy #0 lag: (min: 22.0, avg: 25.0, max: 86.0)
[2026-02-02 12:42:47,622][93050] Avg episode reward: [(0, '1435.990')]
[2026-02-02 12:42:52,703][93050] Fps is (10 sec: 2425.8, 60 sec: 2872.2, 300 sec: 2970.4). Total num frames: 6381568. Throughput: 0: 2987.3. Samples: 6387712. Policy #0 lag: (min: 22.0, avg: 25.0, max: 86.0)
[2026-02-02 12:42:52,704][93050] Avg episode reward: [(0, '1425.939')]
[2026-02-02 12:42:53,107][93050] Saving /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_accel_policy2_aggressive_magpie_adp_nullified_02022026/checkpoint_p0/checkpoint_000024960_6389760.pth...
[2026-02-02 12:42:53,111][93050] Removing /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_accel_policy2_aggressive_magpie_adp_nullified_02022026/checkpoint_p0/checkpoint_000022144_5668864.pth
[2026-02-02 12:42:57,509][93050] Fps is (10 sec: 1657.1, 60 sec: 2882.5, 300 sec: 2944.4). Total num frames: 6389760. Throughput: 0: 2998.4. Samples: 6395904. Policy #0 lag: (min: 22.0, avg: 25.0, max: 86.0)
[2026-02-02 12:42:57,510][93050] Avg episode reward: [(0, '1389.293')]
[2026-02-02 12:43:02,585][93050] Fps is (10 sec: 2487.1, 60 sec: 3004.7, 300 sec: 2942.7). Total num frames: 6406144. Throughput: 0: 2974.1. Samples: 6413824. Policy #0 lag: (min: 44.0, avg: 47.0, max: 108.0)
[2026-02-02 12:43:02,585][93050] Avg episode reward: [(0, '1400.140')]
[2026-02-02 12:43:07,564][93050] Fps is (10 sec: 3258.9, 60 sec: 3006.9, 300 sec: 2971.8). Total num frames: 6422528. Throughput: 0: 2978.0. Samples: 6431744. Policy #0 lag: (min: 44.0, avg: 47.0, max: 108.0)
[2026-02-02 12:43:07,564][93050] Avg episode reward: [(0, '1459.395')]
[2026-02-02 12:43:12,567][93050] Fps is (10 sec: 3282.6, 60 sec: 3005.4, 300 sec: 2999.6). Total num frames: 6438912. Throughput: 0: 2947.6. Samples: 6439936. Policy #0 lag: (min: 44.0, avg: 47.0, max: 108.0)
[2026-02-02 12:43:12,567][93050] Avg episode reward: [(0, '1521.082')]
[2026-02-02 12:43:12,730][93050] Saving new best policy, reward=1521.082!
[2026-02-02 12:43:17,580][93050] Fps is (10 sec: 3271.6, 60 sec: 2998.7, 300 sec: 2998.8). Total num frames: 6455296. Throughput: 0: 2959.2. Samples: 6458368. Policy #0 lag: (min: 44.0, avg: 47.0, max: 108.0)
[2026-02-02 12:43:17,580][93050] Avg episode reward: [(0, '1508.826')]
[2026-02-02 12:43:22,541][93050] Fps is (10 sec: 3285.2, 60 sec: 3002.6, 300 sec: 2998.7). Total num frames: 6471680. Throughput: 0: 2996.5. Samples: 6476288. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:43:22,542][93050] Avg episode reward: [(0, '1460.564')]
[2026-02-02 12:43:27,501][93050] Fps is (10 sec: 3303.0, 60 sec: 3007.6, 300 sec: 2999.0). Total num frames: 6488064. Throughput: 0: 2997.1. Samples: 6486016. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:43:27,501][93050] Avg episode reward: [(0, '1430.575')]
[2026-02-02 12:43:32,625][93050] Fps is (10 sec: 3249.8, 60 sec: 3002.3, 300 sec: 2997.6). Total num frames: 6504448. Throughput: 0: 2980.8. Samples: 6503936. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:43:32,625][93050] Avg episode reward: [(0, '1377.028')]
[2026-02-02 12:43:37,500][93050] Fps is (10 sec: 3277.1, 60 sec: 3008.9, 300 sec: 2998.9). Total num frames: 6520832. Throughput: 0: 2994.5. Samples: 6521856. Policy #0 lag: (min: 47.0, avg: 50.0, max: 111.0)
[2026-02-02 12:43:37,500][93050] Avg episode reward: [(0, '1402.562')]
[2026-02-02 12:43:42,472][93050] Fps is (10 sec: 3327.5, 60 sec: 3008.8, 300 sec: 3000.1). Total num frames: 6537216. Throughput: 0: 2994.8. Samples: 6530560. Policy #0 lag: (min: 47.0, avg: 50.0, max: 111.0)
[2026-02-02 12:43:42,472][93050] Avg episode reward: [(0, '1440.046')]
[2026-02-02 12:43:47,573][93050] Fps is (10 sec: 2439.8, 60 sec: 2869.6, 300 sec: 2970.3). Total num frames: 6545408. Throughput: 0: 2993.1. Samples: 6548480. Policy #0 lag: (min: 47.0, avg: 50.0, max: 111.0)
[2026-02-02 12:43:47,573][93050] Avg episode reward: [(0, '1459.310')]
[2026-02-02 12:43:52,521][93050] Fps is (10 sec: 1630.4, 60 sec: 2875.9, 300 sec: 2943.8). Total num frames: 6553600. Throughput: 0: 3006.6. Samples: 6566912. Policy #0 lag: (min: 47.0, avg: 50.0, max: 111.0)
[2026-02-02 12:43:52,521][93050] Avg episode reward: [(0, '1508.073')]
[2026-02-02 12:43:52,679][93050] Signal inference workers to stop experience collection... (1200 times)
[2026-02-02 12:43:53,054][93050] InferenceWorker_p0-w0: stopping experience collection (1200 times)
[2026-02-02 12:43:53,056][93050] Signal inference workers to resume experience collection... (1200 times)
[2026-02-02 12:43:53,205][93050] InferenceWorker_p0-w0: resuming experience collection (1200 times)
[2026-02-02 12:43:57,581][93050] Fps is (10 sec: 2455.5, 60 sec: 3000.1, 300 sec: 2943.2). Total num frames: 6569984. Throughput: 0: 3002.8. Samples: 6575104. Policy #0 lag: (min: 47.0, avg: 50.0, max: 111.0)
[2026-02-02 12:43:57,582][93050] Avg episode reward: [(0, '1429.851')]
[2026-02-02 12:44:02,533][93050] Fps is (10 sec: 3272.8, 60 sec: 3006.3, 300 sec: 2971.0). Total num frames: 6586368. Throughput: 0: 2995.5. Samples: 6593024. Policy #0 lag: (min: 8.0, avg: 11.0, max: 72.0)
[2026-02-02 12:44:02,534][93050] Avg episode reward: [(0, '1427.041')]
[2026-02-02 12:44:07,487][93050] Fps is (10 sec: 3308.1, 60 sec: 3007.6, 300 sec: 3000.3). Total num frames: 6602752. Throughput: 0: 3007.4. Samples: 6611456. Policy #0 lag: (min: 8.0, avg: 11.0, max: 72.0)
[2026-02-02 12:44:07,487][93050] Avg episode reward: [(0, '1378.151')]
[2026-02-02 12:44:12,594][93050] Fps is (10 sec: 3257.0, 60 sec: 3002.4, 300 sec: 2998.2). Total num frames: 6619136. Throughput: 0: 2974.8. Samples: 6620160. Policy #0 lag: (min: 8.0, avg: 11.0, max: 72.0)
[2026-02-02 12:44:12,595][93050] Avg episode reward: [(0, '1437.981')]
[2026-02-02 12:44:17,539][93050] Fps is (10 sec: 3259.7, 60 sec: 3005.8, 300 sec: 2999.8). Total num frames: 6635520. Throughput: 0: 2986.6. Samples: 6638080. Policy #0 lag: (min: 8.0, avg: 11.0, max: 72.0)
[2026-02-02 12:44:17,540][93050] Avg episode reward: [(0, '1476.697')]
[2026-02-02 12:44:22,499][93050] Fps is (10 sec: 3308.4, 60 sec: 3005.9, 300 sec: 2999.1). Total num frames: 6651904. Throughput: 0: 2992.4. Samples: 6656512. Policy #0 lag: (min: 7.0, avg: 10.0, max: 71.0)
[2026-02-02 12:44:22,499][93050] Avg episode reward: [(0, '1473.598')]
[2026-02-02 12:44:27,504][93050] Fps is (10 sec: 3288.3, 60 sec: 3003.6, 300 sec: 2999.4). Total num frames: 6668288. Throughput: 0: 3012.9. Samples: 6666240. Policy #0 lag: (min: 7.0, avg: 10.0, max: 71.0)
[2026-02-02 12:44:27,505][93050] Avg episode reward: [(0, '1481.526')]
[2026-02-02 12:44:32,488][93050] Fps is (10 sec: 3280.4, 60 sec: 3010.6, 300 sec: 3000.3). Total num frames: 6684672. Throughput: 0: 3032.2. Samples: 6684672. Policy #0 lag: (min: 7.0, avg: 10.0, max: 71.0)
[2026-02-02 12:44:32,488][93050] Avg episode reward: [(0, '1418.333')]
[2026-02-02 12:44:37,470][93050] Fps is (10 sec: 3288.1, 60 sec: 3005.2, 300 sec: 2999.2). Total num frames: 6701056. Throughput: 0: 3007.2. Samples: 6702080. Policy #0 lag: (min: 7.0, avg: 10.0, max: 71.0)
[2026-02-02 12:44:37,470][93050] Avg episode reward: [(0, '1510.617')]
[2026-02-02 12:44:42,509][93050] Fps is (10 sec: 3269.9, 60 sec: 3001.9, 300 sec: 2999.3). Total num frames: 6717440. Throughput: 0: 3031.4. Samples: 6711296. Policy #0 lag: (min: 6.0, avg: 9.0, max: 70.0)
[2026-02-02 12:44:42,509][93050] Avg episode reward: [(0, '1559.510')]
[2026-02-02 12:44:42,663][93050] Saving new best policy, reward=1559.510!
[2026-02-02 12:44:47,760][93050] Fps is (10 sec: 3184.4, 60 sec: 3130.5, 300 sec: 2997.1). Total num frames: 6733824. Throughput: 0: 3022.6. Samples: 6729728. Policy #0 lag: (min: 6.0, avg: 9.0, max: 70.0)
[2026-02-02 12:44:47,760][93050] Avg episode reward: [(0, '1616.378')]
[2026-02-02 12:44:47,760][93050] Saving new best policy, reward=1616.378!
[2026-02-02 12:44:52,775][93050] Fps is (10 sec: 2393.9, 60 sec: 3127.1, 300 sec: 2968.8). Total num frames: 6742016. Throughput: 0: 3018.5. Samples: 6748160. Policy #0 lag: (min: 6.0, avg: 9.0, max: 70.0)
[2026-02-02 12:44:52,775][93050] Avg episode reward: [(0, '1587.951')]
[2026-02-02 12:44:53,147][93050] Saving /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_accel_policy2_aggressive_magpie_adp_nullified_02022026/checkpoint_p0/checkpoint_000026368_6750208.pth...
[2026-02-02 12:44:53,151][93050] Removing /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_accel_policy2_aggressive_magpie_adp_nullified_02022026/checkpoint_p0/checkpoint_000023552_6029312.pth
[2026-02-02 12:44:57,570][93050] Fps is (10 sec: 1670.2, 60 sec: 3004.3, 300 sec: 2972.0). Total num frames: 6750208. Throughput: 0: 3028.2. Samples: 6756352. Policy #0 lag: (min: 6.0, avg: 9.0, max: 70.0)
[2026-02-02 12:44:57,570][93050] Avg episode reward: [(0, '1589.988')]
[2026-02-02 12:45:02,582][93050] Fps is (10 sec: 2505.9, 60 sec: 3001.3, 300 sec: 2998.6). Total num frames: 6766592. Throughput: 0: 3023.6. Samples: 6774272. Policy #0 lag: (min: 6.0, avg: 9.0, max: 70.0)
[2026-02-02 12:45:02,582][93050] Avg episode reward: [(0, '1541.052')]
[2026-02-02 12:45:07,591][93050] Fps is (10 sec: 3269.7, 60 sec: 2998.5, 300 sec: 2998.9). Total num frames: 6782976. Throughput: 0: 3008.9. Samples: 6792192. Policy #0 lag: (min: 0.0, avg: 3.0, max: 64.0)
[2026-02-02 12:45:07,592][93050] Avg episode reward: [(0, '1499.598')]
[2026-02-02 12:45:12,595][93050] Fps is (10 sec: 3272.6, 60 sec: 3003.7, 300 sec: 2998.0). Total num frames: 6799360. Throughput: 0: 2975.0. Samples: 6800384. Policy #0 lag: (min: 0.0, avg: 3.0, max: 64.0)
[2026-02-02 12:45:12,595][93050] Avg episode reward: [(0, '1498.970')]
[2026-02-02 12:45:17,512][93050] Fps is (10 sec: 3302.9, 60 sec: 3005.1, 300 sec: 2999.5). Total num frames: 6815744. Throughput: 0: 2979.3. Samples: 6818816. Policy #0 lag: (min: 0.0, avg: 3.0, max: 64.0)
[2026-02-02 12:45:17,513][93050] Avg episode reward: [(0, '1519.387')]
[2026-02-02 12:45:20,258][93050] Signal inference workers to stop experience collection... (1250 times)
[2026-02-02 12:45:20,624][93050] InferenceWorker_p0-w0: stopping experience collection (1250 times)
[2026-02-02 12:45:20,625][93050] Signal inference workers to resume experience collection... (1250 times)
[2026-02-02 12:45:20,625][93050] InferenceWorker_p0-w0: resuming experience collection (1250 times)
[2026-02-02 12:45:22,610][93050] Fps is (10 sec: 3271.9, 60 sec: 2998.2, 300 sec: 2998.4). Total num frames: 6832128. Throughput: 0: 2983.1. Samples: 6836736. Policy #0 lag: (min: 0.0, avg: 3.0, max: 64.0)
[2026-02-02 12:45:22,610][93050] Avg episode reward: [(0, '1500.649')]
[2026-02-02 12:45:27,597][93050] Fps is (10 sec: 3249.3, 60 sec: 2999.1, 300 sec: 2999.0). Total num frames: 6848512. Throughput: 0: 2997.9. Samples: 6846464. Policy #0 lag: (min: 0.0, avg: 3.0, max: 64.0)
[2026-02-02 12:45:27,597][93050] Avg episode reward: [(0, '1487.218')]
[2026-02-02 12:45:32,504][93050] Fps is (10 sec: 3312.0, 60 sec: 3002.9, 300 sec: 2999.9). Total num frames: 6864896. Throughput: 0: 3021.0. Samples: 6864896. Policy #0 lag: (min: 0.0, avg: 3.0, max: 64.0)
[2026-02-02 12:45:32,504][93050] Avg episode reward: [(0, '1469.004')]
[2026-02-02 12:45:37,612][93050] Fps is (10 sec: 3271.9, 60 sec: 2996.6, 300 sec: 2998.9). Total num frames: 6881280. Throughput: 0: 2991.8. Samples: 6882304. Policy #0 lag: (min: 0.0, avg: 3.0, max: 64.0)
[2026-02-02 12:45:37,612][93050] Avg episode reward: [(0, '1463.726')]
[2026-02-02 12:45:42,575][93050] Fps is (10 sec: 3253.7, 60 sec: 3000.4, 300 sec: 2998.1). Total num frames: 6897664. Throughput: 0: 3003.4. Samples: 6891520. Policy #0 lag: (min: 0.0, avg: 3.0, max: 64.0)
[2026-02-02 12:45:42,575][93050] Avg episode reward: [(0, '1491.839')]
[2026-02-02 12:45:47,700][93050] Fps is (10 sec: 3248.1, 60 sec: 3006.7, 300 sec: 2997.4). Total num frames: 6914048. Throughput: 0: 3007.2. Samples: 6909952. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:45:47,701][93050] Avg episode reward: [(0, '1524.235')]
[2026-02-02 12:45:52,768][93050] Fps is (10 sec: 2410.9, 60 sec: 3004.0, 300 sec: 2999.9). Total num frames: 6922240. Throughput: 0: 3014.6. Samples: 6928384. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:45:52,769][93050] Avg episode reward: [(0, '1559.021')]
[2026-02-02 12:45:57,572][93050] Fps is (10 sec: 1659.7, 60 sec: 3003.6, 300 sec: 2999.3). Total num frames: 6930432. Throughput: 0: 3028.0. Samples: 6936576. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:45:57,572][93050] Avg episode reward: [(0, '1532.887')]
[2026-02-02 12:46:02,563][93050] Fps is (10 sec: 2509.1, 60 sec: 3004.7, 300 sec: 2998.7). Total num frames: 6946816. Throughput: 0: 3011.7. Samples: 6954496. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:46:02,563][93050] Avg episode reward: [(0, '1545.745')]
[2026-02-02 12:46:07,487][93050] Fps is (10 sec: 3304.8, 60 sec: 3009.0, 300 sec: 2999.7). Total num frames: 6963200. Throughput: 0: 3034.8. Samples: 6972928. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:46:07,487][93050] Avg episode reward: [(0, '1504.228')]
[2026-02-02 12:46:12,540][93050] Fps is (10 sec: 3284.6, 60 sec: 3006.5, 300 sec: 2998.8). Total num frames: 6979584. Throughput: 0: 2984.8. Samples: 6980608. Policy #0 lag: (min: 8.0, avg: 11.0, max: 72.0)
[2026-02-02 12:46:12,540][93050] Avg episode reward: [(0, '1530.980')]
[2026-02-02 12:46:17,570][93050] Fps is (10 sec: 3249.7, 60 sec: 3000.8, 300 sec: 2999.1). Total num frames: 6995968. Throughput: 0: 2976.6. Samples: 6999040. Policy #0 lag: (min: 8.0, avg: 11.0, max: 72.0)
[2026-02-02 12:46:17,571][93050] Avg episode reward: [(0, '1522.604')]
[2026-02-02 12:46:22,581][93050] Fps is (10 sec: 3263.4, 60 sec: 3005.2, 300 sec: 2999.0). Total num frames: 7012352. Throughput: 0: 2994.4. Samples: 7016960. Policy #0 lag: (min: 8.0, avg: 11.0, max: 72.0)
[2026-02-02 12:46:22,581][93050] Avg episode reward: [(0, '1544.926')]
[2026-02-02 12:46:27,529][93050] Fps is (10 sec: 3290.4, 60 sec: 3007.1, 300 sec: 2998.8). Total num frames: 7028736. Throughput: 0: 3006.8. Samples: 7026688. Policy #0 lag: (min: 8.0, avg: 11.0, max: 72.0)
[2026-02-02 12:46:27,529][93050] Avg episode reward: [(0, '1583.885')]
[2026-02-02 12:46:32,485][93050] Fps is (10 sec: 3308.4, 60 sec: 3004.7, 300 sec: 3000.4). Total num frames: 7045120. Throughput: 0: 3018.2. Samples: 7045120. Policy #0 lag: (min: 6.0, avg: 9.0, max: 70.0)
[2026-02-02 12:46:32,485][93050] Avg episode reward: [(0, '1568.885')]
[2026-02-02 12:46:37,573][93050] Fps is (10 sec: 3262.5, 60 sec: 3005.7, 300 sec: 2998.8). Total num frames: 7061504. Throughput: 0: 2994.0. Samples: 7062528. Policy #0 lag: (min: 6.0, avg: 9.0, max: 70.0)
[2026-02-02 12:46:37,573][93050] Avg episode reward: [(0, '1542.902')]
[2026-02-02 12:46:42,601][93050] Fps is (10 sec: 3239.1, 60 sec: 3002.4, 300 sec: 2999.0). Total num frames: 7077888. Throughput: 0: 3001.8. Samples: 7071744. Policy #0 lag: (min: 6.0, avg: 9.0, max: 70.0)
[2026-02-02 12:46:42,602][93050] Avg episode reward: [(0, '1535.060')]
[2026-02-02 12:46:47,789][93050] Fps is (10 sec: 3207.5, 60 sec: 2999.3, 300 sec: 2999.3). Total num frames: 7094272. Throughput: 0: 2988.7. Samples: 7089664. Policy #0 lag: (min: 6.0, avg: 9.0, max: 70.0)
[2026-02-02 12:46:47,789][93050] Avg episode reward: [(0, '1552.707')]
[2026-02-02 12:46:52,511][93050] Fps is (10 sec: 1653.4, 60 sec: 2879.6, 300 sec: 2974.5). Total num frames: 7094272. Throughput: 0: 3002.1. Samples: 7108096. Policy #0 lag: (min: 6.0, avg: 9.0, max: 70.0)
[2026-02-02 12:46:52,511][93050] Avg episode reward: [(0, '1561.661')]
[2026-02-02 12:46:52,909][93050] Saving /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_accel_policy2_aggressive_magpie_adp_nullified_02022026/checkpoint_p0/checkpoint_000027744_7102464.pth...
[2026-02-02 12:46:52,912][93050] Removing /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_accel_policy2_aggressive_magpie_adp_nullified_02022026/checkpoint_p0/checkpoint_000024960_6389760.pth
[2026-02-02 12:46:52,913][93050] Signal inference workers to stop experience collection... (1300 times)
[2026-02-02 12:46:52,915][93050] Signal inference workers to resume experience collection... (1300 times)
[2026-02-02 12:46:53,184][93050] InferenceWorker_p0-w0: stopping experience collection (1300 times)
[2026-02-02 12:46:53,184][93050] InferenceWorker_p0-w0: resuming experience collection (1300 times)
[2026-02-02 12:46:57,491][93050] Fps is (10 sec: 1688.8, 60 sec: 3007.8, 300 sec: 3000.3). Total num frames: 7110656. Throughput: 0: 3018.4. Samples: 7116288. Policy #0 lag: (min: 6.0, avg: 9.0, max: 70.0)
[2026-02-02 12:46:57,491][93050] Avg episode reward: [(0, '1569.232')]
[2026-02-02 12:47:02,530][93050] Fps is (10 sec: 3270.5, 60 sec: 3005.4, 300 sec: 3000.1). Total num frames: 7127040. Throughput: 0: 3006.4. Samples: 7134208. Policy #0 lag: (min: 6.0, avg: 9.0, max: 70.0)
[2026-02-02 12:47:02,530][93050] Avg episode reward: [(0, '1575.527')]
[2026-02-02 12:47:07,633][93050] Fps is (10 sec: 3230.9, 60 sec: 2996.5, 300 sec: 2998.8). Total num frames: 7143424. Throughput: 0: 3011.6. Samples: 7152640. Policy #0 lag: (min: 6.0, avg: 9.0, max: 70.0)
[2026-02-02 12:47:07,633][93050] Avg episode reward: [(0, '1656.661')]
[2026-02-02 12:47:07,796][93050] Saving new best policy, reward=1656.661!
[2026-02-02 12:47:12,588][93050] Fps is (10 sec: 3257.9, 60 sec: 3001.3, 300 sec: 2998.0). Total num frames: 7159808. Throughput: 0: 2977.1. Samples: 7160832. Policy #0 lag: (min: 6.0, avg: 9.0, max: 70.0)
[2026-02-02 12:47:12,588][93050] Avg episode reward: [(0, '1724.319')]
[2026-02-02 12:47:12,745][93050] Saving new best policy, reward=1724.319!
[2026-02-02 12:47:17,574][93050] Fps is (10 sec: 3296.0, 60 sec: 3003.5, 300 sec: 2998.5). Total num frames: 7176192. Throughput: 0: 2963.7. Samples: 7178752. Policy #0 lag: (min: 0.0, avg: 3.0, max: 64.0)
[2026-02-02 12:47:17,575][93050] Avg episode reward: [(0, '1716.737')]
[2026-02-02 12:47:22,544][93050] Fps is (10 sec: 3291.3, 60 sec: 3005.6, 300 sec: 2999.5). Total num frames: 7192576. Throughput: 0: 2994.3. Samples: 7197184. Policy #0 lag: (min: 0.0, avg: 3.0, max: 64.0)
[2026-02-02 12:47:22,544][93050] Avg episode reward: [(0, '1627.143')]
[2026-02-02 12:47:27,634][93050] Fps is (10 sec: 3257.3, 60 sec: 2998.5, 300 sec: 2998.7). Total num frames: 7208960. Throughput: 0: 3001.6. Samples: 7206912. Policy #0 lag: (min: 0.0, avg: 3.0, max: 64.0)
[2026-02-02 12:47:27,634][93050] Avg episode reward: [(0, '1608.140')]
[2026-02-02 12:47:32,616][93050] Fps is (10 sec: 3253.4, 60 sec: 2997.2, 300 sec: 2999.0). Total num frames: 7225344. Throughput: 0: 3026.8. Samples: 7225344. Policy #0 lag: (min: 0.0, avg: 3.0, max: 64.0)
[2026-02-02 12:47:32,616][93050] Avg episode reward: [(0, '1629.495')]
[2026-02-02 12:47:37,525][93050] Fps is (10 sec: 3313.0, 60 sec: 3006.1, 300 sec: 2999.6). Total num frames: 7241728. Throughput: 0: 2991.4. Samples: 7242752. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:47:37,525][93050] Avg episode reward: [(0, '1699.687')]
[2026-02-02 12:47:42,499][93050] Fps is (10 sec: 3315.6, 60 sec: 3008.9, 300 sec: 3000.4). Total num frames: 7258112. Throughput: 0: 3014.6. Samples: 7251968. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:47:42,499][93050] Avg episode reward: [(0, '1733.454')]
[2026-02-02 12:47:42,655][93050] Saving new best policy, reward=1733.454!
[2026-02-02 12:47:47,793][93050] Fps is (10 sec: 3191.4, 60 sec: 3003.6, 300 sec: 3026.0). Total num frames: 7274496. Throughput: 0: 2997.6. Samples: 7269888. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:47:47,793][93050] Avg episode reward: [(0, '1666.610')]
[2026-02-02 12:47:52,487][93050] Fps is (10 sec: 1640.2, 60 sec: 3004.9, 300 sec: 2999.3). Total num frames: 7274496. Throughput: 0: 3024.9. Samples: 7288320. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:47:52,488][93050] Avg episode reward: [(0, '1665.990')]
[2026-02-02 12:47:57,514][93050] Fps is (10 sec: 1685.3, 60 sec: 3002.5, 300 sec: 2999.8). Total num frames: 7290880. Throughput: 0: 3020.1. Samples: 7296512. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:47:57,515][93050] Avg episode reward: [(0, '1626.470')]
[2026-02-02 12:48:02,603][93050] Fps is (10 sec: 3239.4, 60 sec: 3000.1, 300 sec: 2998.7). Total num frames: 7307264. Throughput: 0: 3013.2. Samples: 7314432. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:48:02,603][93050] Avg episode reward: [(0, '1633.354')]
[2026-02-02 12:48:07,588][93050] Fps is (10 sec: 3252.7, 60 sec: 3005.9, 300 sec: 2998.9). Total num frames: 7323648. Throughput: 0: 3012.1. Samples: 7332864. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:48:07,589][93050] Avg episode reward: [(0, '1589.948')]
[2026-02-02 12:48:12,620][93050] Fps is (10 sec: 3271.2, 60 sec: 3002.1, 300 sec: 2998.7). Total num frames: 7340032. Throughput: 0: 3198.2. Samples: 7350784. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:48:12,620][93050] Avg episode reward: [(0, '1570.235')]
[2026-02-02 12:48:17,504][93050] Fps is (10 sec: 3304.8, 60 sec: 3007.3, 300 sec: 2999.5). Total num frames: 7356416. Throughput: 0: 2977.0. Samples: 7358976. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:48:17,504][93050] Avg episode reward: [(0, '1587.982')]
[2026-02-02 12:48:22,582][93050] Fps is (10 sec: 3289.2, 60 sec: 3001.8, 300 sec: 2998.3). Total num frames: 7372800. Throughput: 0: 2988.6. Samples: 7377408. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:48:22,582][93050] Avg episode reward: [(0, '1596.312')]
[2026-02-02 12:48:25,248][93050] Signal inference workers to stop experience collection... (1350 times)
[2026-02-02 12:48:25,621][93050] InferenceWorker_p0-w0: stopping experience collection (1350 times)
[2026-02-02 12:48:25,623][93050] Signal inference workers to resume experience collection... (1350 times)
[2026-02-02 12:48:25,763][93050] InferenceWorker_p0-w0: resuming experience collection (1350 times)
[2026-02-02 12:48:27,522][93050] Fps is (10 sec: 3270.8, 60 sec: 3009.4, 300 sec: 3000.1). Total num frames: 7389184. Throughput: 0: 3002.2. Samples: 7387136. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:48:27,522][93050] Avg episode reward: [(0, '1591.783')]
[2026-02-02 12:48:32,540][93050] Fps is (10 sec: 3290.7, 60 sec: 3007.5, 300 sec: 2998.7). Total num frames: 7405568. Throughput: 0: 3032.1. Samples: 7405568. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:48:32,540][93050] Avg episode reward: [(0, '1611.704')]
[2026-02-02 12:48:37,472][93050] Fps is (10 sec: 3293.3, 60 sec: 3006.4, 300 sec: 2999.1). Total num frames: 7421952. Throughput: 0: 2993.4. Samples: 7422976. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:48:37,472][93050] Avg episode reward: [(0, '1633.572')]
[2026-02-02 12:48:42,477][93050] Fps is (10 sec: 3297.5, 60 sec: 3004.8, 300 sec: 3027.9). Total num frames: 7438336. Throughput: 0: 3017.6. Samples: 7432192. Policy #0 lag: (min: 1.0, avg: 4.0, max: 65.0)
[2026-02-02 12:48:42,477][93050] Avg episode reward: [(0, '1646.681')]
[2026-02-02 12:48:47,791][93050] Fps is (10 sec: 3175.7, 60 sec: 3003.8, 300 sec: 3051.9). Total num frames: 7454720. Throughput: 0: 3002.6. Samples: 7450112. Policy #0 lag: (min: 1.0, avg: 4.0, max: 65.0)
[2026-02-02 12:48:47,791][93050] Avg episode reward: [(0, '1696.904')]
[2026-02-02 12:48:52,571][93050] Fps is (10 sec: 1623.2, 60 sec: 2999.6, 300 sec: 2999.2). Total num frames: 7454720. Throughput: 0: 3016.3. Samples: 7468544. Policy #0 lag: (min: 1.0, avg: 4.0, max: 65.0)
[2026-02-02 12:48:52,571][93050] Avg episode reward: [(0, '1649.875')]
[2026-02-02 12:48:52,948][93050] Saving /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_accel_policy2_aggressive_magpie_adp_nullified_02022026/checkpoint_p0/checkpoint_000029152_7462912.pth...
[2026-02-02 12:48:52,952][93050] Removing /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_accel_policy2_aggressive_magpie_adp_nullified_02022026/checkpoint_p0/checkpoint_000026368_6750208.pth
[2026-02-02 12:48:57,502][93050] Fps is (10 sec: 1687.1, 60 sec: 3004.3, 300 sec: 2999.4). Total num frames: 7471104. Throughput: 0: 2806.3. Samples: 7476736. Policy #0 lag: (min: 1.0, avg: 4.0, max: 65.0)
[2026-02-02 12:48:57,502][93050] Avg episode reward: [(0, '1626.046')]
[2026-02-02 12:49:02,631][93050] Fps is (10 sec: 3257.2, 60 sec: 3002.3, 300 sec: 2997.6). Total num frames: 7487488. Throughput: 0: 3018.0. Samples: 7495168. Policy #0 lag: (min: 1.0, avg: 4.0, max: 65.0)
[2026-02-02 12:49:02,631][93050] Avg episode reward: [(0, '1604.953')]
[2026-02-02 12:49:07,614][93050] Fps is (10 sec: 3240.6, 60 sec: 3002.5, 300 sec: 2998.9). Total num frames: 7503872. Throughput: 0: 3013.0. Samples: 7513088. Policy #0 lag: (min: 2.0, avg: 5.0, max: 66.0)
[2026-02-02 12:49:07,614][93050] Avg episode reward: [(0, '1532.956')]
[2026-02-02 12:49:12,680][93050] Fps is (10 sec: 3260.8, 60 sec: 3000.7, 300 sec: 2997.7). Total num frames: 7520256. Throughput: 0: 2970.6. Samples: 7521280. Policy #0 lag: (min: 2.0, avg: 5.0, max: 66.0)
[2026-02-02 12:49:12,680][93050] Avg episode reward: [(0, '1561.752')]
[2026-02-02 12:49:17,524][93050] Fps is (10 sec: 3306.6, 60 sec: 3002.7, 300 sec: 2998.8). Total num frames: 7536640. Throughput: 0: 2925.1. Samples: 7537152. Policy #0 lag: (min: 2.0, avg: 5.0, max: 66.0)
[2026-02-02 12:49:17,524][93050] Avg episode reward: [(0, '1552.889')]
[2026-02-02 12:49:22,536][93050] Fps is (10 sec: 3324.5, 60 sec: 3006.0, 300 sec: 2998.8). Total num frames: 7553024. Throughput: 0: 2908.6. Samples: 7554048. Policy #0 lag: (min: 2.0, avg: 5.0, max: 66.0)
[2026-02-02 12:49:22,537][93050] Avg episode reward: [(0, '1560.968')]
[2026-02-02 12:49:27,572][93050] Fps is (10 sec: 3261.0, 60 sec: 3001.2, 300 sec: 2998.2). Total num frames: 7569408. Throughput: 0: 2929.3. Samples: 7564288. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:49:27,573][93050] Avg episode reward: [(0, '1579.822')]
[2026-02-02 12:49:32,514][93050] Fps is (10 sec: 3284.3, 60 sec: 3005.0, 300 sec: 2998.7). Total num frames: 7585792. Throughput: 0: 2965.1. Samples: 7582720. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:49:32,514][93050] Avg episode reward: [(0, '1631.129')]
[2026-02-02 12:49:37,486][93050] Fps is (10 sec: 2479.0, 60 sec: 2866.5, 300 sec: 2971.6). Total num frames: 7593984. Throughput: 0: 2941.0. Samples: 7600640. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:49:37,486][93050] Avg episode reward: [(0, '1587.920')]
[2026-02-02 12:49:42,606][93050] Fps is (10 sec: 1623.4, 60 sec: 2724.8, 300 sec: 2945.1). Total num frames: 7602176. Throughput: 0: 2928.7. Samples: 7608832. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:49:42,606][93050] Avg episode reward: [(0, '1626.227')]
[2026-02-02 12:49:47,556][93050] Fps is (10 sec: 2440.6, 60 sec: 2741.4, 300 sec: 2973.5). Total num frames: 7618560. Throughput: 0: 2929.0. Samples: 7626752. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:49:47,556][93050] Avg episode reward: [(0, '1610.323')]
[2026-02-02 12:49:52,483][93050] Fps is (10 sec: 3317.6, 60 sec: 3008.1, 300 sec: 3000.0). Total num frames: 7634944. Throughput: 0: 2921.2. Samples: 7644160. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:49:52,483][93050] Avg episode reward: [(0, '1605.012')]
[2026-02-02 12:49:54,361][93050] Signal inference workers to stop experience collection... (1400 times)
[2026-02-02 12:49:54,759][93050] InferenceWorker_p0-w0: stopping experience collection (1400 times)
[2026-02-02 12:49:54,759][93050] Signal inference workers to resume experience collection... (1400 times)
[2026-02-02 12:49:54,760][93050] InferenceWorker_p0-w0: resuming experience collection (1400 times)
[2026-02-02 12:49:57,493][93050] Fps is (10 sec: 3297.4, 60 sec: 3004.2, 300 sec: 3000.0). Total num frames: 7651328. Throughput: 0: 2924.8. Samples: 7652352. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:49:57,494][93050] Avg episode reward: [(0, '1573.807')]
[2026-02-02 12:50:02,474][93050] Fps is (10 sec: 3279.7, 60 sec: 3011.6, 300 sec: 3000.3). Total num frames: 7667712. Throughput: 0: 2950.1. Samples: 7669760. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:50:02,474][93050] Avg episode reward: [(0, '1567.398')]
[2026-02-02 12:50:07,598][93050] Fps is (10 sec: 3242.7, 60 sec: 3004.5, 300 sec: 2999.1). Total num frames: 7684096. Throughput: 0: 2954.2. Samples: 7687168. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:50:07,599][93050] Avg episode reward: [(0, '1587.260')]
[2026-02-02 12:50:12,522][93050] Fps is (10 sec: 3261.2, 60 sec: 3011.7, 300 sec: 2999.0). Total num frames: 7700480. Throughput: 0: 2938.8. Samples: 7696384. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:50:12,522][93050] Avg episode reward: [(0, '1591.467')]
[2026-02-02 12:50:17,570][93050] Fps is (10 sec: 3286.0, 60 sec: 3001.4, 300 sec: 2999.5). Total num frames: 7716864. Throughput: 0: 2909.0. Samples: 7713792. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:50:17,571][93050] Avg episode reward: [(0, '1606.261')]
[2026-02-02 12:50:22,645][93050] Fps is (10 sec: 1618.4, 60 sec: 2725.7, 300 sec: 2943.1). Total num frames: 7716864. Throughput: 0: 2857.1. Samples: 7729664. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:50:22,646][93050] Avg episode reward: [(0, '1623.913')]
[2026-02-02 12:50:27,504][93050] Fps is (10 sec: 1649.4, 60 sec: 2733.8, 300 sec: 2943.6). Total num frames: 7733248. Throughput: 0: 2850.9. Samples: 7736832. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:50:27,504][93050] Avg episode reward: [(0, '1619.133')]
[2026-02-02 12:50:32,573][93050] Fps is (10 sec: 3300.7, 60 sec: 2728.0, 300 sec: 2944.0). Total num frames: 7749632. Throughput: 0: 2820.6. Samples: 7753728. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:50:32,573][93050] Avg episode reward: [(0, '1643.351')]
[2026-02-02 12:50:37,500][93050] Fps is (10 sec: 3278.0, 60 sec: 2866.5, 300 sec: 2944.3). Total num frames: 7766016. Throughput: 0: 2809.2. Samples: 7770624. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:50:37,500][93050] Avg episode reward: [(0, '1650.030')]
[2026-02-02 12:50:42,617][93050] Fps is (10 sec: 3262.5, 60 sec: 3003.2, 300 sec: 2944.4). Total num frames: 7782400. Throughput: 0: 2836.7. Samples: 7780352. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:50:42,617][93050] Avg episode reward: [(0, '1671.763')]
[2026-02-02 12:50:47,501][93050] Fps is (10 sec: 3276.4, 60 sec: 3006.5, 300 sec: 2974.0). Total num frames: 7798784. Throughput: 0: 2842.7. Samples: 7797760. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:50:47,502][93050] Avg episode reward: [(0, '1672.962')]
[2026-02-02 12:50:52,630][93050] Fps is (10 sec: 3272.6, 60 sec: 2996.4, 300 sec: 2998.5). Total num frames: 7815168. Throughput: 0: 2831.1. Samples: 7814656. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:50:52,630][93050] Avg episode reward: [(0, '1669.167')]
[2026-02-02 12:50:52,632][93050] Saving /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_accel_policy2_aggressive_magpie_adp_nullified_02022026/checkpoint_p0/checkpoint_000030528_7815168.pth...
[2026-02-02 12:50:52,636][93050] Removing /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_accel_policy2_aggressive_magpie_adp_nullified_02022026/checkpoint_p0/checkpoint_000027744_7102464.pth
[2026-02-02 12:50:57,857][93050] Fps is (10 sec: 2373.1, 60 sec: 2849.9, 300 sec: 2968.4). Total num frames: 7823360. Throughput: 0: 2789.5. Samples: 7822848. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:50:57,857][93050] Avg episode reward: [(0, '1694.966')]
[2026-02-02 12:51:02,500][93050] Fps is (10 sec: 1659.9, 60 sec: 2729.5, 300 sec: 2943.4). Total num frames: 7831552. Throughput: 0: 2814.7. Samples: 7840256. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:51:02,500][93050] Avg episode reward: [(0, '1651.153')]
[2026-02-02 12:51:07,510][93050] Fps is (10 sec: 2545.9, 60 sec: 2734.7, 300 sec: 2943.9). Total num frames: 7847936. Throughput: 0: 2853.0. Samples: 7857664. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:51:07,511][93050] Avg episode reward: [(0, '1635.266')]
[2026-02-02 12:51:12,507][93050] Fps is (10 sec: 3274.6, 60 sec: 2731.4, 300 sec: 2944.2). Total num frames: 7864320. Throughput: 0: 2855.6. Samples: 7865344. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:51:12,507][93050] Avg episode reward: [(0, '1554.531')]
[2026-02-02 12:51:17,470][93050] Fps is (10 sec: 3290.0, 60 sec: 2735.2, 300 sec: 2944.7). Total num frames: 7880704. Throughput: 0: 2850.9. Samples: 7881728. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:51:17,471][93050] Avg episode reward: [(0, '1576.185')]
[2026-02-02 12:51:22,512][93050] Fps is (10 sec: 3275.0, 60 sec: 3010.4, 300 sec: 2943.7). Total num frames: 7897088. Throughput: 0: 2866.4. Samples: 7899648. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:51:22,512][93050] Avg episode reward: [(0, '1607.334')]
[2026-02-02 12:51:27,479][93050] Fps is (10 sec: 3274.0, 60 sec: 3005.0, 300 sec: 2943.6). Total num frames: 7913472. Throughput: 0: 2864.6. Samples: 7908864. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:51:27,479][93050] Avg episode reward: [(0, '1600.410')]
[2026-02-02 12:51:32,314][93050] Signal inference workers to stop experience collection... (1450 times)
[2026-02-02 12:51:32,315][93050] Signal inference workers to resume experience collection... (1450 times)
[2026-02-02 12:51:32,604][93050] InferenceWorker_p0-w0: stopping experience collection (1450 times)
[2026-02-02 12:51:32,605][93050] InferenceWorker_p0-w0: resuming experience collection (1450 times)
[2026-02-02 12:51:32,733][93050] Fps is (10 sec: 3206.0, 60 sec: 2995.7, 300 sec: 2942.0). Total num frames: 7929856. Throughput: 0: 2841.2. Samples: 7926272. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:51:32,733][93050] Avg episode reward: [(0, '1625.766')]
[2026-02-02 12:51:37,573][93050] Fps is (10 sec: 1623.1, 60 sec: 2727.4, 300 sec: 2888.3). Total num frames: 7929856. Throughput: 0: 2848.0. Samples: 7942656. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:51:37,573][93050] Avg episode reward: [(0, '1588.289')]
[2026-02-02 12:51:42,616][93050] Fps is (10 sec: 1657.8, 60 sec: 2730.7, 300 sec: 2889.7). Total num frames: 7946240. Throughput: 0: 2848.3. Samples: 7950336. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:51:42,616][93050] Avg episode reward: [(0, '1613.205')]
[2026-02-02 12:51:47,476][93050] Fps is (10 sec: 3308.8, 60 sec: 2731.8, 300 sec: 2943.9). Total num frames: 7962624. Throughput: 0: 2834.6. Samples: 7967744. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:51:47,476][93050] Avg episode reward: [(0, '1624.604')]
[2026-02-02 12:51:52,479][93050] Fps is (10 sec: 3322.4, 60 sec: 2737.5, 300 sec: 2943.7). Total num frames: 7979008. Throughput: 0: 2835.0. Samples: 7985152. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:51:52,479][93050] Avg episode reward: [(0, '1646.034')]
[2026-02-02 12:51:57,558][93050] Fps is (10 sec: 3250.0, 60 sec: 2881.5, 300 sec: 2943.3). Total num frames: 7995392. Throughput: 0: 2875.3. Samples: 7994880. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:51:57,559][93050] Avg episode reward: [(0, '1647.385')]
[2026-02-02 12:52:02,506][93050] Fps is (10 sec: 3268.1, 60 sec: 3003.4, 300 sec: 2944.8). Total num frames: 8011776. Throughput: 0: 2899.1. Samples: 8012288. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:52:02,506][93050] Avg episode reward: [(0, '1652.204')]
[2026-02-02 12:52:07,543][93050] Fps is (10 sec: 3281.8, 60 sec: 3002.1, 300 sec: 2944.0). Total num frames: 8028160. Throughput: 0: 2876.6. Samples: 8029184. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:52:07,544][93050] Avg episode reward: [(0, '1693.842')]
[2026-02-02 12:52:12,549][93050] Fps is (10 sec: 3262.6, 60 sec: 3001.6, 300 sec: 2943.8). Total num frames: 8044544. Throughput: 0: 2862.7. Samples: 8037888. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:52:12,549][93050] Avg episode reward: [(0, '1765.720')]
[2026-02-02 12:52:12,552][93050] Saving new best policy, reward=1765.720!
[2026-02-02 12:52:17,760][93050] Fps is (10 sec: 2405.4, 60 sec: 2853.4, 300 sec: 2913.7). Total num frames: 8052736. Throughput: 0: 2876.8. Samples: 8055808. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:52:17,761][93050] Avg episode reward: [(0, '1736.581')]
[2026-02-02 12:52:22,625][93050] Fps is (10 sec: 1626.1, 60 sec: 2725.5, 300 sec: 2888.1). Total num frames: 8060928. Throughput: 0: 2898.0. Samples: 8073216. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:52:22,625][93050] Avg episode reward: [(0, '1697.214')]
[2026-02-02 12:52:27,572][93050] Fps is (10 sec: 2504.9, 60 sec: 2726.5, 300 sec: 2888.5). Total num frames: 8077312. Throughput: 0: 2915.6. Samples: 8081408. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:52:27,572][93050] Avg episode reward: [(0, '1636.454')]
[2026-02-02 12:52:32,633][93050] Fps is (10 sec: 3274.3, 60 sec: 2735.2, 300 sec: 2887.0). Total num frames: 8093696. Throughput: 0: 2913.9. Samples: 8099328. Policy #0 lag: (min: 1.0, avg: 4.0, max: 65.0)
[2026-02-02 12:52:32,633][93050] Avg episode reward: [(0, '1612.761')]
[2026-02-02 12:52:37,569][93050] Fps is (10 sec: 3277.6, 60 sec: 3003.9, 300 sec: 2887.3). Total num frames: 8110080. Throughput: 0: 2929.6. Samples: 8117248. Policy #0 lag: (min: 1.0, avg: 4.0, max: 65.0)
[2026-02-02 12:52:37,569][93050] Avg episode reward: [(0, '1604.827')]
[2026-02-02 12:52:42,599][93050] Fps is (10 sec: 3287.8, 60 sec: 3004.6, 300 sec: 2889.9). Total num frames: 8126464. Throughput: 0: 2921.4. Samples: 8126464. Policy #0 lag: (min: 1.0, avg: 4.0, max: 65.0)
[2026-02-02 12:52:42,600][93050] Avg episode reward: [(0, '1552.340')]
[2026-02-02 12:52:47,605][93050] Fps is (10 sec: 3265.0, 60 sec: 2997.3, 300 sec: 2942.4). Total num frames: 8142848. Throughput: 0: 2917.6. Samples: 8143872. Policy #0 lag: (min: 1.0, avg: 4.0, max: 65.0)
[2026-02-02 12:52:47,605][93050] Avg episode reward: [(0, '1635.379')]
[2026-02-02 12:52:52,496][93050] Fps is (10 sec: 3311.1, 60 sec: 3002.9, 300 sec: 2943.8). Total num frames: 8159232. Throughput: 0: 2915.8. Samples: 8160256. Policy #0 lag: (min: 1.0, avg: 4.0, max: 65.0)
[2026-02-02 12:52:52,496][93050] Avg episode reward: [(0, '1634.853')]
[2026-02-02 12:52:52,669][93050] Saving /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_accel_policy2_aggressive_magpie_adp_nullified_02022026/checkpoint_p0/checkpoint_000031872_8159232.pth...
[2026-02-02 12:52:52,673][93050] Removing /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_accel_policy2_aggressive_magpie_adp_nullified_02022026/checkpoint_p0/checkpoint_000029152_7462912.pth
[2026-02-02 12:52:57,545][93050] Fps is (10 sec: 3296.8, 60 sec: 3004.4, 300 sec: 2944.1). Total num frames: 8175616. Throughput: 0: 2913.0. Samples: 8168960. Policy #0 lag: (min: 1.0, avg: 4.0, max: 65.0)
[2026-02-02 12:52:57,545][93050] Avg episode reward: [(0, '1666.424')]
[2026-02-02 12:53:02,640][93050] Fps is (10 sec: 2422.7, 60 sec: 2860.8, 300 sec: 2915.3). Total num frames: 8183808. Throughput: 0: 2920.5. Samples: 8186880. Policy #0 lag: (min: 1.0, avg: 4.0, max: 65.0)
[2026-02-02 12:53:02,640][93050] Avg episode reward: [(0, '1631.309')]
[2026-02-02 12:53:07,510][93050] Fps is (10 sec: 1644.0, 60 sec: 2732.2, 300 sec: 2889.1). Total num frames: 8192000. Throughput: 0: 2931.6. Samples: 8204800. Policy #0 lag: (min: 1.0, avg: 4.0, max: 65.0)
[2026-02-02 12:53:07,511][93050] Avg episode reward: [(0, '1594.462')]
[2026-02-02 12:53:07,827][93050] Signal inference workers to stop experience collection... (1500 times)
[2026-02-02 12:53:08,214][93050] InferenceWorker_p0-w0: stopping experience collection (1500 times)
[2026-02-02 12:53:08,216][93050] Signal inference workers to resume experience collection... (1500 times)
[2026-02-02 12:53:08,373][93050] InferenceWorker_p0-w0: resuming experience collection (1500 times)
[2026-02-02 12:53:12,602][93050] Fps is (10 sec: 2467.0, 60 sec: 2728.3, 300 sec: 2887.1). Total num frames: 8208384. Throughput: 0: 2922.1. Samples: 8212992. Policy #0 lag: (min: 1.0, avg: 4.0, max: 65.0)
[2026-02-02 12:53:12,602][93050] Avg episode reward: [(0, '1597.616')]
[2026-02-02 12:53:17,579][93050] Fps is (10 sec: 3254.4, 60 sec: 2875.9, 300 sec: 2888.1). Total num frames: 8224768. Throughput: 0: 2916.2. Samples: 8230400. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:53:17,580][93050] Avg episode reward: [(0, '1606.564')]
[2026-02-02 12:53:22,472][93050] Fps is (10 sec: 3320.0, 60 sec: 3011.4, 300 sec: 2888.5). Total num frames: 8241152. Throughput: 0: 2919.0. Samples: 8248320. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:53:22,472][93050] Avg episode reward: [(0, '1653.841')]
[2026-02-02 12:53:27,622][93050] Fps is (10 sec: 3262.9, 60 sec: 3001.2, 300 sec: 2887.2). Total num frames: 8257536. Throughput: 0: 3104.6. Samples: 8266240. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:53:27,622][93050] Avg episode reward: [(0, '1635.818')]
[2026-02-02 12:53:32,500][93050] Fps is (10 sec: 3267.7, 60 sec: 3010.4, 300 sec: 2887.8). Total num frames: 8273920. Throughput: 0: 2919.6. Samples: 8274944. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:53:32,500][93050] Avg episode reward: [(0, '1620.161')]
[2026-02-02 12:53:37,484][93050] Fps is (10 sec: 3322.5, 60 sec: 3008.0, 300 sec: 2888.0). Total num frames: 8290304. Throughput: 0: 2947.6. Samples: 8292864. Policy #0 lag: (min: 12.0, avg: 15.0, max: 76.0)
[2026-02-02 12:53:37,485][93050] Avg episode reward: [(0, '1634.844')]
[2026-02-02 12:53:42,511][93050] Fps is (10 sec: 3273.0, 60 sec: 3008.2, 300 sec: 2890.8). Total num frames: 8306688. Throughput: 0: 2971.8. Samples: 8302592. Policy #0 lag: (min: 12.0, avg: 15.0, max: 76.0)
[2026-02-02 12:53:42,512][93050] Avg episode reward: [(0, '1643.624')]
[2026-02-02 12:53:47,510][93050] Fps is (10 sec: 3268.3, 60 sec: 3008.5, 300 sec: 2944.2). Total num frames: 8323072. Throughput: 0: 2989.6. Samples: 8321024. Policy #0 lag: (min: 12.0, avg: 15.0, max: 76.0)
[2026-02-02 12:53:47,511][93050] Avg episode reward: [(0, '1689.674')]
[2026-02-02 12:53:52,609][93050] Fps is (10 sec: 3245.1, 60 sec: 2998.1, 300 sec: 2942.5). Total num frames: 8339456. Throughput: 0: 3008.5. Samples: 8340480. Policy #0 lag: (min: 12.0, avg: 15.0, max: 76.0)
[2026-02-02 12:53:52,609][93050] Avg episode reward: [(0, '1569.966')]
[2026-02-02 12:53:57,588][93050] Fps is (10 sec: 3251.6, 60 sec: 3001.6, 300 sec: 2944.0). Total num frames: 8355840. Throughput: 0: 3073.0. Samples: 8351232. Policy #0 lag: (min: 12.0, avg: 15.0, max: 76.0)
[2026-02-02 12:53:57,588][93050] Avg episode reward: [(0, '1572.939')]
[2026-02-02 12:54:02,604][93050] Fps is (10 sec: 3278.4, 60 sec: 3142.1, 300 sec: 2943.7). Total num frames: 8372224. Throughput: 0: 3161.3. Samples: 8372736. Policy #0 lag: (min: 4.0, avg: 7.0, max: 68.0)
[2026-02-02 12:54:02,605][93050] Avg episode reward: [(0, '1561.138')]
[2026-02-02 12:54:07,585][93050] Fps is (10 sec: 3277.6, 60 sec: 3272.7, 300 sec: 2944.5). Total num frames: 8388608. Throughput: 0: 3189.1. Samples: 8392192. Policy #0 lag: (min: 4.0, avg: 7.0, max: 68.0)
[2026-02-02 12:54:07,586][93050] Avg episode reward: [(0, '1636.231')]
[2026-02-02 12:54:12,497][93050] Fps is (10 sec: 3312.2, 60 sec: 3282.5, 300 sec: 2943.8). Total num frames: 8404992. Throughput: 0: 3046.3. Samples: 8402944. Policy #0 lag: (min: 4.0, avg: 7.0, max: 68.0)
[2026-02-02 12:54:12,498][93050] Avg episode reward: [(0, '1616.812')]
[2026-02-02 12:54:17,547][93050] Fps is (10 sec: 3289.4, 60 sec: 3278.6, 300 sec: 2943.5). Total num frames: 8421376. Throughput: 0: 3273.4. Samples: 8422400. Policy #0 lag: (min: 4.0, avg: 7.0, max: 68.0)
[2026-02-02 12:54:17,547][93050] Avg episode reward: [(0, '1582.051')]
[2026-02-02 12:54:22,523][93050] Fps is (10 sec: 3268.3, 60 sec: 3274.0, 300 sec: 2944.1). Total num frames: 8437760. Throughput: 0: 3342.2. Samples: 8443392. Policy #0 lag: (min: 4.0, avg: 7.0, max: 68.0)
[2026-02-02 12:54:22,524][93050] Avg episode reward: [(0, '1601.959')]
[2026-02-02 12:54:27,479][93050] Fps is (10 sec: 3299.1, 60 sec: 3284.6, 300 sec: 2943.9). Total num frames: 8454144. Throughput: 0: 3381.6. Samples: 8454656. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:54:27,480][93050] Avg episode reward: [(0, '1572.343')]
[2026-02-02 12:54:29,592][93050] Signal inference workers to stop experience collection... (1550 times)
[2026-02-02 12:54:29,941][93050] InferenceWorker_p0-w0: stopping experience collection (1550 times)
[2026-02-02 12:54:29,941][93050] Signal inference workers to resume experience collection... (1550 times)
[2026-02-02 12:54:29,941][93050] InferenceWorker_p0-w0: resuming experience collection (1550 times)
[2026-02-02 12:54:32,578][93050] Fps is (10 sec: 3258.9, 60 sec: 3272.5, 300 sec: 2970.4). Total num frames: 8470528. Throughput: 0: 3396.8. Samples: 8474112. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:54:32,578][93050] Avg episode reward: [(0, '1609.670')]
[2026-02-02 12:54:37,525][93050] Fps is (10 sec: 3262.0, 60 sec: 3274.6, 300 sec: 2999.9). Total num frames: 8486912. Throughput: 0: 3454.0. Samples: 8495616. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:54:37,525][93050] Avg episode reward: [(0, '1587.004')]
[2026-02-02 12:54:42,580][93050] Fps is (10 sec: 3276.3, 60 sec: 3273.1, 300 sec: 2998.9). Total num frames: 8503296. Throughput: 0: 3425.3. Samples: 8505344. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:54:42,580][93050] Avg episode reward: [(0, '1662.353')]
[2026-02-02 12:54:47,474][93050] Fps is (10 sec: 3293.5, 60 sec: 3278.8, 300 sec: 2999.2). Total num frames: 8519680. Throughput: 0: 3423.2. Samples: 8526336. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:54:47,474][93050] Avg episode reward: [(0, '1696.691')]
[2026-02-02 12:54:52,556][93050] Fps is (10 sec: 3284.5, 60 sec: 3279.7, 300 sec: 2998.5). Total num frames: 8536064. Throughput: 0: 3438.3. Samples: 8546816. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:54:52,557][93050] Avg episode reward: [(0, '1648.791')]
[2026-02-02 12:54:52,692][93050] Saving /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_accel_policy2_aggressive_magpie_adp_nullified_02022026/checkpoint_p0/checkpoint_000033344_8536064.pth...
[2026-02-02 12:54:52,696][93050] Removing /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_accel_policy2_aggressive_magpie_adp_nullified_02022026/checkpoint_p0/checkpoint_000030528_7815168.pth
[2026-02-02 12:54:57,577][93050] Fps is (10 sec: 3243.5, 60 sec: 3277.4, 300 sec: 2998.1). Total num frames: 8552448. Throughput: 0: 3407.3. Samples: 8556544. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:54:57,577][93050] Avg episode reward: [(0, '1649.047')]
[2026-02-02 12:55:02,554][93050] Fps is (10 sec: 3277.5, 60 sec: 3279.5, 300 sec: 2999.6). Total num frames: 8568832. Throughput: 0: 3446.9. Samples: 8577536. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:55:02,555][93050] Avg episode reward: [(0, '1594.425')]
[2026-02-02 12:55:07,596][93050] Fps is (10 sec: 3270.4, 60 sec: 3276.2, 300 sec: 2998.3). Total num frames: 8585216. Throughput: 0: 3430.5. Samples: 8598016. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:55:07,597][93050] Avg episode reward: [(0, '1612.456')]
[2026-02-02 12:55:12,534][93050] Fps is (10 sec: 3283.5, 60 sec: 3274.8, 300 sec: 2999.5). Total num frames: 8601600. Throughput: 0: 3386.5. Samples: 8607232. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:55:12,534][93050] Avg episode reward: [(0, '1631.677')]
[2026-02-02 12:55:17,620][93050] Fps is (10 sec: 3269.0, 60 sec: 3272.8, 300 sec: 3054.9). Total num frames: 8617984. Throughput: 0: 3376.0. Samples: 8626176. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:55:17,620][93050] Avg episode reward: [(0, '1648.793')]
[2026-02-02 12:55:22,626][93050] Fps is (10 sec: 3246.8, 60 sec: 3271.2, 300 sec: 3053.4). Total num frames: 8634368. Throughput: 0: 3280.8. Samples: 8643584. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:55:22,627][93050] Avg episode reward: [(0, '1681.335')]
[2026-02-02 12:55:27,611][93050] Fps is (10 sec: 3279.7, 60 sec: 3269.6, 300 sec: 3054.2). Total num frames: 8650752. Throughput: 0: 3251.8. Samples: 8651776. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:55:27,612][93050] Avg episode reward: [(0, '1693.172')]
[2026-02-02 12:55:32,502][93050] Fps is (10 sec: 3318.1, 60 sec: 3281.0, 300 sec: 3054.6). Total num frames: 8667136. Throughput: 0: 3172.4. Samples: 8669184. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:55:32,502][93050] Avg episode reward: [(0, '1650.623')]
[2026-02-02 12:55:37,487][93050] Fps is (10 sec: 3318.2, 60 sec: 3278.9, 300 sec: 3056.0). Total num frames: 8683520. Throughput: 0: 3156.5. Samples: 8688640. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:55:37,487][93050] Avg episode reward: [(0, '1622.809')]
[2026-02-02 12:55:42,521][93050] Fps is (10 sec: 3270.7, 60 sec: 3280.0, 300 sec: 3054.4). Total num frames: 8699904. Throughput: 0: 3189.8. Samples: 8699904. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:55:42,521][93050] Avg episode reward: [(0, '1599.005')]
[2026-02-02 12:55:47,599][93050] Fps is (10 sec: 3240.3, 60 sec: 3270.0, 300 sec: 3055.0). Total num frames: 8716288. Throughput: 0: 3137.1. Samples: 8718848. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:55:47,600][93050] Avg episode reward: [(0, '1642.901')]
[2026-02-02 12:55:52,527][93050] Fps is (10 sec: 3274.7, 60 sec: 3278.4, 300 sec: 3085.9). Total num frames: 8732672. Throughput: 0: 3156.5. Samples: 8739840. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:55:52,527][93050] Avg episode reward: [(0, '1643.567')]
[2026-02-02 12:55:54,536][93050] Signal inference workers to stop experience collection... (1600 times)
[2026-02-02 12:55:54,536][93050] Signal inference workers to resume experience collection... (1600 times)
[2026-02-02 12:55:54,787][93050] InferenceWorker_p0-w0: stopping experience collection (1600 times)
[2026-02-02 12:55:54,787][93050] InferenceWorker_p0-w0: resuming experience collection (1600 times)
[2026-02-02 12:55:57,568][93050] Fps is (10 sec: 3287.1, 60 sec: 3277.3, 300 sec: 3109.5). Total num frames: 8749056. Throughput: 0: 3172.0. Samples: 8750080. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:55:57,568][93050] Avg episode reward: [(0, '1711.655')]
[2026-02-02 12:56:02,559][93050] Fps is (10 sec: 3266.4, 60 sec: 3276.6, 300 sec: 3109.7). Total num frames: 8765440. Throughput: 0: 3212.9. Samples: 8770560. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:56:02,559][93050] Avg episode reward: [(0, '1710.951')]
[2026-02-02 12:56:07,559][93050] Fps is (10 sec: 3279.6, 60 sec: 3278.8, 300 sec: 3109.6). Total num frames: 8781824. Throughput: 0: 3293.1. Samples: 8791552. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:56:07,560][93050] Avg episode reward: [(0, '1776.119')]
[2026-02-02 12:56:07,704][93050] Saving new best policy, reward=1776.119!
[2026-02-02 12:56:12,578][93050] Fps is (10 sec: 3270.6, 60 sec: 3274.4, 300 sec: 3109.0). Total num frames: 8798208. Throughput: 0: 3324.8. Samples: 8801280. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:56:12,578][93050] Avg episode reward: [(0, '1751.964')]
[2026-02-02 12:56:17,514][93050] Fps is (10 sec: 3291.7, 60 sec: 3282.6, 300 sec: 3110.2). Total num frames: 8814592. Throughput: 0: 3401.1. Samples: 8822272. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:56:17,514][93050] Avg episode reward: [(0, '1758.543')]
[2026-02-02 12:56:22,565][93050] Fps is (10 sec: 3281.2, 60 sec: 3280.2, 300 sec: 3109.3). Total num frames: 8830976. Throughput: 0: 3430.2. Samples: 8843264. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:56:22,565][93050] Avg episode reward: [(0, '1757.445')]
[2026-02-02 12:56:27,491][93050] Fps is (10 sec: 3284.2, 60 sec: 3283.4, 300 sec: 3112.7). Total num frames: 8847360. Throughput: 0: 3404.2. Samples: 8852992. Policy #0 lag: (min: 0.0, avg: 3.0, max: 64.0)
[2026-02-02 12:56:27,492][93050] Avg episode reward: [(0, '1748.414')]
[2026-02-02 12:56:32,619][93050] Fps is (10 sec: 4074.0, 60 sec: 3406.7, 300 sec: 3193.0). Total num frames: 8871936. Throughput: 0: 3446.0. Samples: 8873984. Policy #0 lag: (min: 0.0, avg: 3.0, max: 64.0)
[2026-02-02 12:56:32,619][93050] Avg episode reward: [(0, '1743.820')]
[2026-02-02 12:56:37,761][93050] Fps is (10 sec: 4786.3, 60 sec: 3533.7, 300 sec: 3219.7). Total num frames: 8896512. Throughput: 0: 3429.7. Samples: 8894976. Policy #0 lag: (min: 0.0, avg: 3.0, max: 64.0)
[2026-02-02 12:56:37,761][93050] Avg episode reward: [(0, '1742.148')]
[2026-02-02 12:56:42,490][93050] Fps is (10 sec: 4149.5, 60 sec: 3551.7, 300 sec: 3221.1). Total num frames: 8912896. Throughput: 0: 3442.1. Samples: 8904704. Policy #0 lag: (min: 0.0, avg: 3.0, max: 64.0)
[2026-02-02 12:56:42,490][93050] Avg episode reward: [(0, '1751.137')]
[2026-02-02 12:56:47,563][93050] Fps is (10 sec: 3343.0, 60 sec: 3552.0, 300 sec: 3220.3). Total num frames: 8929280. Throughput: 0: 3458.6. Samples: 8926208. Policy #0 lag: (min: 4.0, avg: 7.0, max: 68.0)
[2026-02-02 12:56:47,563][93050] Avg episode reward: [(0, '1783.007')]
[2026-02-02 12:56:47,697][93050] Saving new best policy, reward=1783.007!
[2026-02-02 12:56:52,581][93050] Fps is (10 sec: 3247.0, 60 sec: 3546.7, 300 sec: 3221.0). Total num frames: 8945664. Throughput: 0: 3445.8. Samples: 8946688. Policy #0 lag: (min: 4.0, avg: 7.0, max: 68.0)
[2026-02-02 12:56:52,581][93050] Avg episode reward: [(0, '1748.348')]
[2026-02-02 12:56:52,734][93050] Saving /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_accel_policy2_aggressive_magpie_adp_nullified_02022026/checkpoint_p0/checkpoint_000034944_8945664.pth...
[2026-02-02 12:56:52,738][93050] Removing /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_accel_policy2_aggressive_magpie_adp_nullified_02022026/checkpoint_p0/checkpoint_000031872_8159232.pth
[2026-02-02 12:56:57,483][93050] Fps is (10 sec: 3303.2, 60 sec: 3554.9, 300 sec: 3221.5). Total num frames: 8962048. Throughput: 0: 3454.8. Samples: 8956416. Policy #0 lag: (min: 4.0, avg: 7.0, max: 68.0)
[2026-02-02 12:56:57,483][93050] Avg episode reward: [(0, '1727.762')]
[2026-02-02 12:57:02,522][93050] Fps is (10 sec: 3296.4, 60 sec: 3552.1, 300 sec: 3221.5). Total num frames: 8978432. Throughput: 0: 3458.2. Samples: 8977920. Policy #0 lag: (min: 4.0, avg: 7.0, max: 68.0)
[2026-02-02 12:57:02,522][93050] Avg episode reward: [(0, '1717.179')]
[2026-02-02 12:57:07,591][93050] Fps is (10 sec: 3241.5, 60 sec: 3548.0, 300 sec: 3220.8). Total num frames: 8994816. Throughput: 0: 3422.7. Samples: 8997376. Policy #0 lag: (min: 4.0, avg: 7.0, max: 68.0)
[2026-02-02 12:57:07,592][93050] Avg episode reward: [(0, '1778.882')]
[2026-02-02 12:57:12,542][93050] Fps is (10 sec: 3270.3, 60 sec: 3552.0, 300 sec: 3251.4). Total num frames: 9011200. Throughput: 0: 3455.0. Samples: 9008640. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:57:12,542][93050] Avg episode reward: [(0, '1795.494')]
[2026-02-02 12:57:12,670][93050] Saving new best policy, reward=1795.494!
[2026-02-02 12:57:15,066][93050] Signal inference workers to stop experience collection... (1650 times)
[2026-02-02 12:57:15,416][93050] InferenceWorker_p0-w0: stopping experience collection (1650 times)
[2026-02-02 12:57:15,418][93050] Signal inference workers to resume experience collection... (1650 times)
[2026-02-02 12:57:15,547][93050] InferenceWorker_p0-w0: resuming experience collection (1650 times)
[2026-02-02 12:57:17,529][93050] Fps is (10 sec: 3297.3, 60 sec: 3549.0, 300 sec: 3277.9). Total num frames: 9027584. Throughput: 0: 3442.9. Samples: 9028608. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:57:17,529][93050] Avg episode reward: [(0, '1791.405')]
[2026-02-02 12:57:22,470][93050] Fps is (10 sec: 3300.5, 60 sec: 3555.5, 300 sec: 3277.9). Total num frames: 9043968. Throughput: 0: 3447.0. Samples: 9049088. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:57:22,470][93050] Avg episode reward: [(0, '1759.718')]
[2026-02-02 12:57:27,523][93050] Fps is (10 sec: 3278.7, 60 sec: 3548.0, 300 sec: 3278.0). Total num frames: 9060352. Throughput: 0: 3456.3. Samples: 9060352. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:57:27,523][93050] Avg episode reward: [(0, '1691.684')]
[2026-02-02 12:57:32,474][93050] Fps is (10 sec: 3275.4, 60 sec: 3421.6, 300 sec: 3277.9). Total num frames: 9076736. Throughput: 0: 3420.1. Samples: 9079808. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:57:32,474][93050] Avg episode reward: [(0, '1709.251')]
[2026-02-02 12:57:37,518][93050] Fps is (10 sec: 3278.5, 60 sec: 3290.1, 300 sec: 3277.7). Total num frames: 9093120. Throughput: 0: 3429.5. Samples: 9100800. Policy #0 lag: (min: 6.0, avg: 9.0, max: 70.0)
[2026-02-02 12:57:37,518][93050] Avg episode reward: [(0, '1730.853')]
[2026-02-02 12:57:42,564][93050] Fps is (10 sec: 3247.5, 60 sec: 3272.7, 300 sec: 3277.3). Total num frames: 9109504. Throughput: 0: 3418.5. Samples: 9110528. Policy #0 lag: (min: 6.0, avg: 9.0, max: 70.0)
[2026-02-02 12:57:42,565][93050] Avg episode reward: [(0, '1771.952')]
[2026-02-02 12:57:47,480][93050] Fps is (10 sec: 3289.3, 60 sec: 3281.3, 300 sec: 3277.0). Total num frames: 9125888. Throughput: 0: 3427.9. Samples: 9132032. Policy #0 lag: (min: 6.0, avg: 9.0, max: 70.0)
[2026-02-02 12:57:47,480][93050] Avg episode reward: [(0, '1759.711')]
[2026-02-02 12:57:52,499][93050] Fps is (10 sec: 3298.3, 60 sec: 3281.3, 300 sec: 3277.3). Total num frames: 9142272. Throughput: 0: 3454.5. Samples: 9152512. Policy #0 lag: (min: 6.0, avg: 9.0, max: 70.0)
[2026-02-02 12:57:52,499][93050] Avg episode reward: [(0, '1658.395')]
[2026-02-02 12:57:57,550][93050] Fps is (10 sec: 3254.0, 60 sec: 3273.1, 300 sec: 3305.6). Total num frames: 9158656. Throughput: 0: 3412.7. Samples: 9162240. Policy #0 lag: (min: 6.0, avg: 9.0, max: 70.0)
[2026-02-02 12:57:57,551][93050] Avg episode reward: [(0, '1647.741')]
[2026-02-02 12:58:02,523][93050] Fps is (10 sec: 3269.0, 60 sec: 3276.7, 300 sec: 3332.2). Total num frames: 9175040. Throughput: 0: 3425.2. Samples: 9182720. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:58:02,523][93050] Avg episode reward: [(0, '1622.141')]
[2026-02-02 12:58:07,546][93050] Fps is (10 sec: 3278.3, 60 sec: 3279.3, 300 sec: 3333.0). Total num frames: 9191424. Throughput: 0: 3430.3. Samples: 9203712. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:58:07,546][93050] Avg episode reward: [(0, '1678.211')]
[2026-02-02 12:58:12,542][93050] Fps is (10 sec: 3270.5, 60 sec: 3276.8, 300 sec: 3332.8). Total num frames: 9207808. Throughput: 0: 3389.2. Samples: 9212928. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:58:12,542][93050] Avg episode reward: [(0, '1637.910')]
[2026-02-02 12:58:17,472][93050] Fps is (10 sec: 3301.0, 60 sec: 3279.9, 300 sec: 3332.3). Total num frames: 9224192. Throughput: 0: 3424.9. Samples: 9233920. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:58:17,473][93050] Avg episode reward: [(0, '1662.615')]
[2026-02-02 12:58:22,640][93050] Fps is (10 sec: 4056.2, 60 sec: 3403.7, 300 sec: 3359.9). Total num frames: 9248768. Throughput: 0: 3404.1. Samples: 9254400. Policy #0 lag: (min: 13.0, avg: 16.0, max: 77.0)
[2026-02-02 12:58:22,641][93050] Avg episode reward: [(0, '1655.284')]
[2026-02-02 12:58:27,510][93050] Fps is (10 sec: 4080.5, 60 sec: 3414.1, 300 sec: 3360.0). Total num frames: 9265152. Throughput: 0: 3417.4. Samples: 9264128. Policy #0 lag: (min: 13.0, avg: 16.0, max: 77.0)
[2026-02-02 12:58:27,510][93050] Avg episode reward: [(0, '1667.787')]
[2026-02-02 12:58:32,292][93050] Signal inference workers to stop experience collection... (1700 times)
[2026-02-02 12:58:32,658][93050] InferenceWorker_p0-w0: stopping experience collection (1700 times)
[2026-02-02 12:58:32,658][93050] Signal inference workers to resume experience collection... (1700 times)
[2026-02-02 12:58:32,658][93050] Fps is (10 sec: 4088.7, 60 sec: 3539.0, 300 sec: 3385.9). Total num frames: 9289728. Throughput: 0: 3388.6. Samples: 9285120. Policy #0 lag: (min: 13.0, avg: 16.0, max: 77.0)
[2026-02-02 12:58:32,658][93050] Avg episode reward: [(0, '1638.116')]
[2026-02-02 12:58:32,660][93050] InferenceWorker_p0-w0: resuming experience collection (1700 times)
[2026-02-02 12:58:37,546][93050] Fps is (10 sec: 4081.2, 60 sec: 3548.2, 300 sec: 3387.5). Total num frames: 9306112. Throughput: 0: 3409.8. Samples: 9306112. Policy #0 lag: (min: 13.0, avg: 16.0, max: 77.0)
[2026-02-02 12:58:37,547][93050] Avg episode reward: [(0, '1639.920')]
[2026-02-02 12:58:42,573][93050] Fps is (10 sec: 3304.9, 60 sec: 3549.3, 300 sec: 3387.2). Total num frames: 9322496. Throughput: 0: 3411.6. Samples: 9315840. Policy #0 lag: (min: 13.0, avg: 16.0, max: 77.0)
[2026-02-02 12:58:42,573][93050] Avg episode reward: [(0, '1622.427')]
[2026-02-02 12:58:47,559][93050] Fps is (10 sec: 3272.7, 60 sec: 3545.2, 300 sec: 3388.5). Total num frames: 9338880. Throughput: 0: 3410.6. Samples: 9336320. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:58:47,559][93050] Avg episode reward: [(0, '1586.641')]
[2026-02-02 12:58:52,569][93050] Fps is (10 sec: 3278.2, 60 sec: 3545.8, 300 sec: 3388.1). Total num frames: 9355264. Throughput: 0: 3388.8. Samples: 9356288. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:58:52,569][93050] Avg episode reward: [(0, '1597.322')]
[2026-02-02 12:58:52,710][93050] Saving /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_accel_policy2_aggressive_magpie_adp_nullified_02022026/checkpoint_p0/checkpoint_000036544_9355264.pth...
[2026-02-02 12:58:52,714][93050] Removing /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_accel_policy2_aggressive_magpie_adp_nullified_02022026/checkpoint_p0/checkpoint_000033344_8536064.pth
[2026-02-02 12:58:57,589][93050] Fps is (10 sec: 3266.9, 60 sec: 3547.6, 300 sec: 3388.1). Total num frames: 9371648. Throughput: 0: 3421.1. Samples: 9367040. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:58:57,589][93050] Avg episode reward: [(0, '1631.282')]
[2026-02-02 12:59:02,509][93050] Fps is (10 sec: 3296.7, 60 sec: 3550.7, 300 sec: 3388.8). Total num frames: 9388032. Throughput: 0: 3433.3. Samples: 9388544. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:59:02,509][93050] Avg episode reward: [(0, '1732.634')]
[2026-02-02 12:59:07,567][93050] Fps is (10 sec: 3284.1, 60 sec: 3548.6, 300 sec: 3387.1). Total num frames: 9404416. Throughput: 0: 3430.3. Samples: 9408512. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 12:59:07,567][93050] Avg episode reward: [(0, '1726.354')]
[2026-02-02 12:59:12,507][93050] Fps is (10 sec: 3277.3, 60 sec: 3551.9, 300 sec: 3388.3). Total num frames: 9420800. Throughput: 0: 3447.7. Samples: 9419264. Policy #0 lag: (min: 4.0, avg: 7.0, max: 68.0)
[2026-02-02 12:59:12,507][93050] Avg episode reward: [(0, '1676.463')]
[2026-02-02 12:59:17,551][93050] Fps is (10 sec: 3281.9, 60 sec: 3545.2, 300 sec: 3387.6). Total num frames: 9437184. Throughput: 0: 3410.0. Samples: 9438208. Policy #0 lag: (min: 4.0, avg: 7.0, max: 68.0)
[2026-02-02 12:59:17,552][93050] Avg episode reward: [(0, '1607.139')]
[2026-02-02 12:59:22,597][93050] Fps is (10 sec: 3247.7, 60 sec: 3415.8, 300 sec: 3386.5). Total num frames: 9453568. Throughput: 0: 3409.5. Samples: 9459712. Policy #0 lag: (min: 4.0, avg: 7.0, max: 68.0)
[2026-02-02 12:59:22,597][93050] Avg episode reward: [(0, '1607.389')]
[2026-02-02 12:59:27,518][93050] Fps is (10 sec: 3288.0, 60 sec: 3412.9, 300 sec: 3388.6). Total num frames: 9469952. Throughput: 0: 3451.7. Samples: 9470976. Policy #0 lag: (min: 4.0, avg: 7.0, max: 68.0)
[2026-02-02 12:59:27,518][93050] Avg episode reward: [(0, '1680.217')]
[2026-02-02 12:59:32,524][93050] Fps is (10 sec: 3300.9, 60 sec: 3284.2, 300 sec: 3387.9). Total num frames: 9486336. Throughput: 0: 3427.4. Samples: 9490432. Policy #0 lag: (min: 4.0, avg: 7.0, max: 68.0)
[2026-02-02 12:59:32,524][93050] Avg episode reward: [(0, '1708.847')]
[2026-02-02 12:59:37,529][93050] Fps is (10 sec: 3272.9, 60 sec: 3277.7, 300 sec: 3388.5). Total num frames: 9502720. Throughput: 0: 3450.5. Samples: 9511424. Policy #0 lag: (min: 0.0, avg: 3.0, max: 64.0)
[2026-02-02 12:59:37,530][93050] Avg episode reward: [(0, '1731.410')]
[2026-02-02 12:59:42,517][93050] Fps is (10 sec: 3278.9, 60 sec: 3279.9, 300 sec: 3387.4). Total num frames: 9519104. Throughput: 0: 3430.2. Samples: 9521152. Policy #0 lag: (min: 0.0, avg: 3.0, max: 64.0)
[2026-02-02 12:59:42,518][93050] Avg episode reward: [(0, '1688.839')]
[2026-02-02 12:59:47,481][93050] Fps is (10 sec: 3292.7, 60 sec: 3281.1, 300 sec: 3388.7). Total num frames: 9535488. Throughput: 0: 3404.0. Samples: 9541632. Policy #0 lag: (min: 0.0, avg: 3.0, max: 64.0)
[2026-02-02 12:59:47,481][93050] Avg episode reward: [(0, '1709.983')]
[2026-02-02 12:59:52,598][93050] Fps is (10 sec: 3250.7, 60 sec: 3275.2, 300 sec: 3387.6). Total num frames: 9551872. Throughput: 0: 3422.4. Samples: 9562624. Policy #0 lag: (min: 0.0, avg: 3.0, max: 64.0)
[2026-02-02 12:59:52,598][93050] Avg episode reward: [(0, '1705.080')]
[2026-02-02 12:59:53,507][93050] Signal inference workers to stop experience collection... (1750 times)
[2026-02-02 12:59:53,507][93050] Signal inference workers to resume experience collection... (1750 times)
[2026-02-02 12:59:53,752][93050] InferenceWorker_p0-w0: stopping experience collection (1750 times)
[2026-02-02 12:59:53,753][93050] InferenceWorker_p0-w0: resuming experience collection (1750 times)
[2026-02-02 12:59:57,558][93050] Fps is (10 sec: 3251.9, 60 sec: 3278.5, 300 sec: 3387.8). Total num frames: 9568256. Throughput: 0: 3398.1. Samples: 9572352. Policy #0 lag: (min: 0.0, avg: 3.0, max: 64.0)
[2026-02-02 12:59:57,558][93050] Avg episode reward: [(0, '1679.574')]
[2026-02-02 13:00:02,541][93050] Fps is (10 sec: 3295.6, 60 sec: 3275.0, 300 sec: 3388.5). Total num frames: 9584640. Throughput: 0: 3436.9. Samples: 9592832. Policy #0 lag: (min: 2.0, avg: 5.0, max: 66.0)
[2026-02-02 13:00:02,541][93050] Avg episode reward: [(0, '1692.362')]
[2026-02-02 13:00:07,472][93050] Fps is (10 sec: 3305.3, 60 sec: 3282.0, 300 sec: 3388.6). Total num frames: 9601024. Throughput: 0: 3434.3. Samples: 9613824. Policy #0 lag: (min: 2.0, avg: 5.0, max: 66.0)
[2026-02-02 13:00:07,472][93050] Avg episode reward: [(0, '1696.511')]
[2026-02-02 13:00:12,678][93050] Fps is (10 sec: 4040.4, 60 sec: 3403.6, 300 sec: 3415.0). Total num frames: 9625600. Throughput: 0: 3378.5. Samples: 9623552. Policy #0 lag: (min: 2.0, avg: 5.0, max: 66.0)
[2026-02-02 13:00:12,679][93050] Avg episode reward: [(0, '1696.866')]
[2026-02-02 13:00:17,500][93050] Fps is (10 sec: 4084.5, 60 sec: 3416.3, 300 sec: 3417.1). Total num frames: 9641984. Throughput: 0: 3426.5. Samples: 9644544. Policy #0 lag: (min: 2.0, avg: 5.0, max: 66.0)
[2026-02-02 13:00:17,500][93050] Avg episode reward: [(0, '1738.398')]
[2026-02-02 13:00:22,598][93050] Fps is (10 sec: 4129.3, 60 sec: 3549.8, 300 sec: 3443.6). Total num frames: 9666560. Throughput: 0: 3430.9. Samples: 9666048. Policy #0 lag: (min: 31.0, avg: 34.0, max: 95.0)
[2026-02-02 13:00:22,598][93050] Avg episode reward: [(0, '1723.524')]
[2026-02-02 13:00:27,484][93050] Fps is (10 sec: 4102.4, 60 sec: 3551.9, 300 sec: 3443.6). Total num frames: 9682944. Throughput: 0: 3427.2. Samples: 9675264. Policy #0 lag: (min: 31.0, avg: 34.0, max: 95.0)
[2026-02-02 13:00:27,484][93050] Avg episode reward: [(0, '1729.936')]
[2026-02-02 13:00:32,507][93050] Fps is (10 sec: 3306.9, 60 sec: 3550.9, 300 sec: 3443.2). Total num frames: 9699328. Throughput: 0: 3445.5. Samples: 9696768. Policy #0 lag: (min: 31.0, avg: 34.0, max: 95.0)
[2026-02-02 13:00:32,507][93050] Avg episode reward: [(0, '1723.495')]
[2026-02-02 13:00:37,565][93050] Fps is (10 sec: 3250.4, 60 sec: 3547.8, 300 sec: 3442.9). Total num frames: 9715712. Throughput: 0: 3427.2. Samples: 9716736. Policy #0 lag: (min: 31.0, avg: 34.0, max: 95.0)
[2026-02-02 13:00:37,565][93050] Avg episode reward: [(0, '1737.357')]
[2026-02-02 13:00:42,511][93050] Fps is (10 sec: 3275.6, 60 sec: 3550.3, 300 sec: 3444.5). Total num frames: 9732096. Throughput: 0: 3439.7. Samples: 9726976. Policy #0 lag: (min: 31.0, avg: 34.0, max: 95.0)
[2026-02-02 13:00:42,511][93050] Avg episode reward: [(0, '1707.297')]
[2026-02-02 13:00:47,562][93050] Fps is (10 sec: 3277.7, 60 sec: 3545.1, 300 sec: 3443.0). Total num frames: 9748480. Throughput: 0: 3445.8. Samples: 9747968. Policy #0 lag: (min: 60.0, avg: 63.0, max: 124.0)
[2026-02-02 13:00:47,563][93050] Avg episode reward: [(0, '1695.507')]
[2026-02-02 13:00:52,520][93050] Fps is (10 sec: 3273.8, 60 sec: 3554.5, 300 sec: 3444.0). Total num frames: 9764864. Throughput: 0: 3409.7. Samples: 9767424. Policy #0 lag: (min: 60.0, avg: 63.0, max: 124.0)
[2026-02-02 13:00:52,520][93050] Avg episode reward: [(0, '1650.613')]
[2026-02-02 13:00:52,660][93050] Saving /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_accel_policy2_aggressive_magpie_adp_nullified_02022026/checkpoint_p0/checkpoint_000038144_9764864.pth...
[2026-02-02 13:00:52,664][93050] Removing /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_accel_policy2_aggressive_magpie_adp_nullified_02022026/checkpoint_p0/checkpoint_000034944_8945664.pth
[2026-02-02 13:00:57,509][93050] Fps is (10 sec: 3294.5, 60 sec: 3552.8, 300 sec: 3444.0). Total num frames: 9781248. Throughput: 0: 3460.5. Samples: 9778688. Policy #0 lag: (min: 60.0, avg: 63.0, max: 124.0)
[2026-02-02 13:00:57,509][93050] Avg episode reward: [(0, '1680.553')]
[2026-02-02 13:01:02,538][93050] Fps is (10 sec: 3271.0, 60 sec: 3550.0, 300 sec: 3443.7). Total num frames: 9797632. Throughput: 0: 3421.8. Samples: 9798656. Policy #0 lag: (min: 60.0, avg: 63.0, max: 124.0)
[2026-02-02 13:01:02,538][93050] Avg episode reward: [(0, '1684.098')]
[2026-02-02 13:01:07,544][93050] Fps is (10 sec: 3265.2, 60 sec: 3545.6, 300 sec: 3443.8). Total num frames: 9814016. Throughput: 0: 3406.0. Samples: 9819136. Policy #0 lag: (min: 60.0, avg: 63.0, max: 124.0)
[2026-02-02 13:01:07,545][93050] Avg episode reward: [(0, '1732.442')]
[2026-02-02 13:01:12,557][93050] Fps is (10 sec: 3270.5, 60 sec: 3420.3, 300 sec: 3442.9). Total num frames: 9830400. Throughput: 0: 3453.3. Samples: 9830912. Policy #0 lag: (min: 60.0, avg: 63.0, max: 124.0)
[2026-02-02 13:01:12,557][93050] Avg episode reward: [(0, '1760.296')]
[2026-02-02 13:01:14,347][93050] Signal inference workers to stop experience collection... (1800 times)
[2026-02-02 13:01:14,730][93050] InferenceWorker_p0-w0: stopping experience collection (1800 times)
[2026-02-02 13:01:14,732][93050] Signal inference workers to resume experience collection... (1800 times)
[2026-02-02 13:01:14,868][93050] InferenceWorker_p0-w0: resuming experience collection (1800 times)
[2026-02-02 13:01:17,513][93050] Fps is (10 sec: 3287.1, 60 sec: 3412.6, 300 sec: 3444.0). Total num frames: 9846784. Throughput: 0: 3401.5. Samples: 9849856. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 13:01:17,513][93050] Avg episode reward: [(0, '1724.639')]
[2026-02-02 13:01:22,575][93050] Fps is (10 sec: 3271.0, 60 sec: 3278.1, 300 sec: 3442.4). Total num frames: 9863168. Throughput: 0: 3424.0. Samples: 9870848. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 13:01:22,575][93050] Avg episode reward: [(0, '1683.836')]
[2026-02-02 13:01:27,600][93050] Fps is (10 sec: 3248.4, 60 sec: 3270.5, 300 sec: 3415.9). Total num frames: 9879552. Throughput: 0: 3656.3. Samples: 9891840. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 13:01:27,601][93050] Avg episode reward: [(0, '1643.521')]
[2026-02-02 13:01:32,592][93050] Fps is (10 sec: 3271.2, 60 sec: 3272.2, 300 sec: 3389.8). Total num frames: 9895936. Throughput: 0: 3411.1. Samples: 9901568. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 13:01:32,592][93050] Avg episode reward: [(0, '1619.966')]
[2026-02-02 13:01:37,508][93050] Fps is (10 sec: 3307.2, 60 sec: 3279.9, 300 sec: 3387.7). Total num frames: 9912320. Throughput: 0: 3448.3. Samples: 9922560. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 13:01:37,509][93050] Avg episode reward: [(0, '1654.266')]
[2026-02-02 13:01:42,556][93050] Fps is (10 sec: 3288.6, 60 sec: 3274.3, 300 sec: 3388.0). Total num frames: 9928704. Throughput: 0: 3409.8. Samples: 9932288. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 13:01:42,556][93050] Avg episode reward: [(0, '1680.525')]
[2026-02-02 13:01:47,559][93050] Fps is (10 sec: 3260.5, 60 sec: 3277.0, 300 sec: 3388.1). Total num frames: 9945088. Throughput: 0: 3434.5. Samples: 9953280. Policy #0 lag: (min: 9.0, avg: 12.0, max: 73.0)
[2026-02-02 13:01:47,559][93050] Avg episode reward: [(0, '1723.098')]
[2026-02-02 13:01:52,565][93050] Fps is (10 sec: 3274.0, 60 sec: 3274.4, 300 sec: 3386.9). Total num frames: 9961472. Throughput: 0: 3445.9. Samples: 9974272. Policy #0 lag: (min: 9.0, avg: 12.0, max: 73.0)
[2026-02-02 13:01:52,565][93050] Avg episode reward: [(0, '1750.184')]
[2026-02-02 13:01:57,711][93050] Fps is (10 sec: 4034.6, 60 sec: 3401.9, 300 sec: 3413.5). Total num frames: 9986048. Throughput: 0: 3390.4. Samples: 9984000. Policy #0 lag: (min: 9.0, avg: 12.0, max: 73.0)
[2026-02-02 13:01:57,711][93050] Avg episode reward: [(0, '1774.942')]
[2026-02-02 13:02:02,517][93050] Fps is (10 sec: 4115.4, 60 sec: 3414.5, 300 sec: 3416.5). Total num frames: 10002432. Throughput: 0: 3447.1. Samples: 10004992. Policy #0 lag: (min: 9.0, avg: 12.0, max: 73.0)
[2026-02-02 13:02:02,518][93050] Avg episode reward: [(0, '1825.504')]
[2026-02-02 13:02:02,909][93050] Saving new best policy, reward=1825.504!
[2026-02-02 13:02:07,764][93050] Fps is (10 sec: 3259.4, 60 sec: 3400.9, 300 sec: 3413.1). Total num frames: 10018816. Throughput: 0: 3399.0. Samples: 10024448. Policy #0 lag: (min: 9.0, avg: 12.0, max: 73.0)
[2026-02-02 13:02:07,764][93050] Avg episode reward: [(0, '1802.435')]
[2026-02-02 13:02:12,781][93050] Fps is (10 sec: 3192.6, 60 sec: 3400.6, 300 sec: 3412.7). Total num frames: 10035200. Throughput: 0: 3139.0. Samples: 10033664. Policy #0 lag: (min: 63.0, avg: 66.0, max: 127.0)
[2026-02-02 13:02:12,781][93050] Avg episode reward: [(0, '1763.773')]
[2026-02-02 13:02:17,488][93050] Fps is (10 sec: 2527.3, 60 sec: 3278.1, 300 sec: 3387.7). Total num frames: 10043392. Throughput: 0: 3387.0. Samples: 10053632. Policy #0 lag: (min: 63.0, avg: 66.0, max: 127.0)
[2026-02-02 13:02:17,489][93050] Avg episode reward: [(0, '1775.674')]
[2026-02-02 13:02:22,573][93050] Fps is (10 sec: 2509.9, 60 sec: 3276.9, 300 sec: 3387.3). Total num frames: 10059776. Throughput: 0: 3317.6. Samples: 10072064. Policy #0 lag: (min: 63.0, avg: 66.0, max: 127.0)
[2026-02-02 13:02:22,573][93050] Avg episode reward: [(0, '1774.190')]
[2026-02-02 13:02:27,475][93050] Fps is (10 sec: 3281.1, 60 sec: 3283.6, 300 sec: 3387.9). Total num frames: 10076160. Throughput: 0: 3305.5. Samples: 10080768. Policy #0 lag: (min: 63.0, avg: 66.0, max: 127.0)
[2026-02-02 13:02:27,476][93050] Avg episode reward: [(0, '1792.866')]
[2026-02-02 13:02:32,512][93050] Fps is (10 sec: 3296.9, 60 sec: 3281.2, 300 sec: 3388.0). Total num frames: 10092544. Throughput: 0: 3280.2. Samples: 10100736. Policy #0 lag: (min: 63.0, avg: 66.0, max: 127.0)
[2026-02-02 13:02:32,512][93050] Avg episode reward: [(0, '1768.512')]
[2026-02-02 13:02:33,152][93050] Signal inference workers to stop experience collection... (1850 times)
[2026-02-02 13:02:33,510][93050] InferenceWorker_p0-w0: stopping experience collection (1850 times)
[2026-02-02 13:02:33,510][93050] Signal inference workers to resume experience collection... (1850 times)
[2026-02-02 13:02:33,511][93050] InferenceWorker_p0-w0: resuming experience collection (1850 times)
[2026-02-02 13:02:37,553][93050] Fps is (10 sec: 3251.6, 60 sec: 3274.4, 300 sec: 3388.0). Total num frames: 10108928. Throughput: 0: 3277.6. Samples: 10121728. Policy #0 lag: (min: 31.0, avg: 34.0, max: 95.0)
[2026-02-02 13:02:37,553][93050] Avg episode reward: [(0, '1708.218')]
[2026-02-02 13:02:42,756][93050] Fps is (10 sec: 3998.5, 60 sec: 3402.0, 300 sec: 3412.5). Total num frames: 10133504. Throughput: 0: 3273.5. Samples: 10131456. Policy #0 lag: (min: 31.0, avg: 34.0, max: 95.0)
[2026-02-02 13:02:42,756][93050] Avg episode reward: [(0, '1748.984')]
[2026-02-02 13:02:47,655][93050] Fps is (10 sec: 4054.5, 60 sec: 3407.8, 300 sec: 3413.8). Total num frames: 10149888. Throughput: 0: 3266.8. Samples: 10152448. Policy #0 lag: (min: 31.0, avg: 34.0, max: 95.0)
[2026-02-02 13:02:47,656][93050] Avg episode reward: [(0, '1737.302')]
[2026-02-02 13:02:52,553][93050] Fps is (10 sec: 3344.5, 60 sec: 3414.0, 300 sec: 3415.6). Total num frames: 10166272. Throughput: 0: 3303.7. Samples: 10172416. Policy #0 lag: (min: 31.0, avg: 34.0, max: 95.0)
[2026-02-02 13:02:52,554][93050] Avg episode reward: [(0, '1748.825')]
[2026-02-02 13:02:52,908][93050] Saving /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_accel_policy2_aggressive_magpie_adp_nullified_02022026/checkpoint_p0/checkpoint_000039744_10174464.pth...
[2026-02-02 13:02:52,912][93050] Removing /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_accel_policy2_aggressive_magpie_adp_nullified_02022026/checkpoint_p0/checkpoint_000036544_9355264.pth
[2026-02-02 13:02:57,679][93050] Fps is (10 sec: 4086.4, 60 sec: 3415.2, 300 sec: 3441.6). Total num frames: 10190848. Throughput: 0: 3307.1. Samples: 10182144. Policy #0 lag: (min: 31.0, avg: 34.0, max: 95.0)
[2026-02-02 13:02:57,679][93050] Avg episode reward: [(0, '1741.969')]
[2026-02-02 13:03:02,522][93050] Fps is (10 sec: 4108.9, 60 sec: 3413.1, 300 sec: 3443.7). Total num frames: 10207232. Throughput: 0: 3319.8. Samples: 10203136. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 13:03:02,522][93050] Avg episode reward: [(0, '1745.332')]
[2026-02-02 13:03:07,553][93050] Fps is (10 sec: 3318.6, 60 sec: 3425.4, 300 sec: 3443.3). Total num frames: 10223616. Throughput: 0: 3357.9. Samples: 10223104. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 13:03:07,553][93050] Avg episode reward: [(0, '1797.188')]
[2026-02-02 13:03:12,588][93050] Fps is (10 sec: 3255.2, 60 sec: 3424.3, 300 sec: 3442.1). Total num frames: 10240000. Throughput: 0: 3359.4. Samples: 10232320. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 13:03:12,589][93050] Avg episode reward: [(0, '1769.579')]
[2026-02-02 13:03:17,533][93050] Fps is (10 sec: 3283.2, 60 sec: 3547.2, 300 sec: 3416.9). Total num frames: 10256384. Throughput: 0: 3389.0. Samples: 10253312. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 13:03:17,533][93050] Avg episode reward: [(0, '1769.929')]
[2026-02-02 13:03:22,595][93050] Fps is (10 sec: 3274.7, 60 sec: 3548.6, 300 sec: 3414.7). Total num frames: 10272768. Throughput: 0: 3376.1. Samples: 10273792. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 13:03:22,595][93050] Avg episode reward: [(0, '1757.209')]
[2026-02-02 13:03:27,537][93050] Fps is (10 sec: 3275.7, 60 sec: 3546.3, 300 sec: 3389.3). Total num frames: 10289152. Throughput: 0: 3395.7. Samples: 10283520. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 13:03:27,537][93050] Avg episode reward: [(0, '1729.508')]
[2026-02-02 13:03:32,489][93050] Fps is (10 sec: 3311.9, 60 sec: 3551.2, 300 sec: 3388.5). Total num frames: 10305536. Throughput: 0: 3391.7. Samples: 10304512. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 13:03:32,489][93050] Avg episode reward: [(0, '1695.228')]
[2026-02-02 13:03:37,496][93050] Fps is (10 sec: 3290.0, 60 sec: 3553.2, 300 sec: 3388.8). Total num frames: 10321920. Throughput: 0: 3349.3. Samples: 10322944. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 13:03:37,497][93050] Avg episode reward: [(0, '1718.934')]
[2026-02-02 13:03:42,577][93050] Fps is (10 sec: 3248.1, 60 sec: 3423.5, 300 sec: 3387.7). Total num frames: 10338304. Throughput: 0: 3386.8. Samples: 10334208. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 13:03:42,577][93050] Avg episode reward: [(0, '1741.916')]
[2026-02-02 13:03:47,527][93050] Fps is (10 sec: 3266.8, 60 sec: 3420.7, 300 sec: 3388.4). Total num frames: 10354688. Throughput: 0: 3367.5. Samples: 10354688. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 13:03:47,527][93050] Avg episode reward: [(0, '1795.847')]
[2026-02-02 13:03:52,608][93050] Fps is (10 sec: 3266.8, 60 sec: 3410.2, 300 sec: 3387.7). Total num frames: 10371072. Throughput: 0: 3352.3. Samples: 10374144. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 13:03:52,608][93050] Avg episode reward: [(0, '1768.440')]
[2026-02-02 13:03:55,641][93050] Signal inference workers to stop experience collection... (1900 times)
[2026-02-02 13:03:55,641][93050] Signal inference workers to resume experience collection... (1900 times)
[2026-02-02 13:03:55,902][93050] InferenceWorker_p0-w0: stopping experience collection (1900 times)
[2026-02-02 13:03:55,902][93050] InferenceWorker_p0-w0: resuming experience collection (1900 times)
[2026-02-02 13:03:57,524][93050] Fps is (10 sec: 3277.8, 60 sec: 3285.3, 300 sec: 3387.7). Total num frames: 10387456. Throughput: 0: 3406.8. Samples: 10385408. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 13:03:57,524][93050] Avg episode reward: [(0, '1740.749')]
[2026-02-02 13:04:02,519][93050] Fps is (10 sec: 3306.0, 60 sec: 3276.9, 300 sec: 3388.4). Total num frames: 10403840. Throughput: 0: 3368.9. Samples: 10404864. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 13:04:02,520][93050] Avg episode reward: [(0, '1670.254')]
[2026-02-02 13:04:07,553][93050] Fps is (10 sec: 3267.2, 60 sec: 3276.8, 300 sec: 3387.4). Total num frames: 10420224. Throughput: 0: 3370.9. Samples: 10425344. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 13:04:07,553][93050] Avg episode reward: [(0, '1668.909')]
[2026-02-02 13:04:12,534][93050] Fps is (10 sec: 3272.0, 60 sec: 3279.8, 300 sec: 3388.1). Total num frames: 10436608. Throughput: 0: 3402.1. Samples: 10436608. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 13:04:12,534][93050] Avg episode reward: [(0, '1716.762')]
[2026-02-02 13:04:17,556][93050] Fps is (10 sec: 3275.8, 60 sec: 3275.6, 300 sec: 3388.3). Total num frames: 10452992. Throughput: 0: 3351.4. Samples: 10455552. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 13:04:17,556][93050] Avg episode reward: [(0, '1756.119')]
[2026-02-02 13:04:22,501][93050] Fps is (10 sec: 3287.6, 60 sec: 3281.9, 300 sec: 3388.1). Total num frames: 10469376. Throughput: 0: 3413.0. Samples: 10476544. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 13:04:22,501][93050] Avg episode reward: [(0, '1769.294')]
[2026-02-02 13:04:27,530][93050] Fps is (10 sec: 3285.4, 60 sec: 3277.2, 300 sec: 3387.8). Total num frames: 10485760. Throughput: 0: 3394.2. Samples: 10486784. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 13:04:27,530][93050] Avg episode reward: [(0, '1802.684')]
[2026-02-02 13:04:32,526][93050] Fps is (10 sec: 3268.7, 60 sec: 3274.8, 300 sec: 3387.9). Total num frames: 10502144. Throughput: 0: 3367.9. Samples: 10506240. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 13:04:32,526][93050] Avg episode reward: [(0, '1757.055')]
[2026-02-02 13:04:37,489][93050] Fps is (10 sec: 3290.3, 60 sec: 3277.2, 300 sec: 3388.2). Total num frames: 10518528. Throughput: 0: 3376.8. Samples: 10525696. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 13:04:37,489][93050] Avg episode reward: [(0, '1738.459')]
[2026-02-02 13:04:42,489][93050] Fps is (10 sec: 3288.8, 60 sec: 3281.6, 300 sec: 3387.8). Total num frames: 10534912. Throughput: 0: 3347.6. Samples: 10535936. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 13:04:42,490][93050] Avg episode reward: [(0, '1719.193')]
[2026-02-02 13:04:47,483][93050] Fps is (10 sec: 3278.5, 60 sec: 3279.2, 300 sec: 3389.2). Total num frames: 10551296. Throughput: 0: 3359.1. Samples: 10555904. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 13:04:47,484][93050] Avg episode reward: [(0, '1732.684')]
[2026-02-02 13:04:52,555][93050] Fps is (10 sec: 3255.4, 60 sec: 3279.7, 300 sec: 3387.9). Total num frames: 10567680. Throughput: 0: 3356.3. Samples: 10576384. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 13:04:52,556][93050] Avg episode reward: [(0, '1718.768')]
[2026-02-02 13:04:52,693][93050] Saving /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_accel_policy2_aggressive_magpie_adp_nullified_02022026/checkpoint_p0/checkpoint_000041280_10567680.pth...
[2026-02-02 13:04:52,697][93050] Removing /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_accel_policy2_aggressive_magpie_adp_nullified_02022026/checkpoint_p0/checkpoint_000038144_9764864.pth
[2026-02-02 13:04:57,517][93050] Fps is (10 sec: 3265.8, 60 sec: 3277.2, 300 sec: 3388.1). Total num frames: 10584064. Throughput: 0: 3323.6. Samples: 10586112. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 13:04:57,517][93050] Avg episode reward: [(0, '1681.583')]
[2026-02-02 13:05:02,557][93050] Fps is (10 sec: 3276.3, 60 sec: 3274.7, 300 sec: 3386.9). Total num frames: 10600448. Throughput: 0: 3356.4. Samples: 10606592. Policy #0 lag: (min: 7.0, avg: 10.0, max: 71.0)
[2026-02-02 13:05:02,557][93050] Avg episode reward: [(0, '1675.749')]
[2026-02-02 13:05:07,583][93050] Fps is (10 sec: 3255.2, 60 sec: 3275.1, 300 sec: 3361.2). Total num frames: 10616832. Throughput: 0: 3327.6. Samples: 10626560. Policy #0 lag: (min: 7.0, avg: 10.0, max: 71.0)
[2026-02-02 13:05:07,584][93050] Avg episode reward: [(0, '1722.906')]
[2026-02-02 13:05:12,585][93050] Fps is (10 sec: 3267.8, 60 sec: 3274.0, 300 sec: 3359.1). Total num frames: 10633216. Throughput: 0: 3295.5. Samples: 10635264. Policy #0 lag: (min: 7.0, avg: 10.0, max: 71.0)
[2026-02-02 13:05:12,585][93050] Avg episode reward: [(0, '1722.258')]
[2026-02-02 13:05:17,536][93050] Fps is (10 sec: 3292.3, 60 sec: 3277.9, 300 sec: 3333.0). Total num frames: 10649600. Throughput: 0: 3298.8. Samples: 10654720. Policy #0 lag: (min: 7.0, avg: 10.0, max: 71.0)
[2026-02-02 13:05:17,537][93050] Avg episode reward: [(0, '1722.667')]
[2026-02-02 13:05:19,387][93050] Signal inference workers to stop experience collection... (1950 times)
[2026-02-02 13:05:19,872][93050] InferenceWorker_p0-w0: stopping experience collection (1950 times)
[2026-02-02 13:05:19,876][93050] Signal inference workers to resume experience collection... (1950 times)
[2026-02-02 13:05:20,073][93050] InferenceWorker_p0-w0: resuming experience collection (1950 times)
[2026-02-02 13:05:22,534][93050] Fps is (10 sec: 3293.3, 60 sec: 3275.0, 300 sec: 3331.8). Total num frames: 10665984. Throughput: 0: 3228.0. Samples: 10671104. Policy #0 lag: (min: 7.0, avg: 10.0, max: 71.0)
[2026-02-02 13:05:22,535][93050] Avg episode reward: [(0, '1743.474')]
[2026-02-02 13:05:27,590][93050] Fps is (10 sec: 3259.3, 60 sec: 3273.5, 300 sec: 3331.4). Total num frames: 10682368. Throughput: 0: 3235.4. Samples: 10681856. Policy #0 lag: (min: 31.0, avg: 34.0, max: 95.0)
[2026-02-02 13:05:27,590][93050] Avg episode reward: [(0, '1731.236')]
[2026-02-02 13:05:32,573][93050] Fps is (10 sec: 3264.2, 60 sec: 3274.2, 300 sec: 3332.2). Total num frames: 10698752. Throughput: 0: 3224.9. Samples: 10701312. Policy #0 lag: (min: 31.0, avg: 34.0, max: 95.0)
[2026-02-02 13:05:32,573][93050] Avg episode reward: [(0, '1668.004')]
[2026-02-02 13:05:37,479][93050] Fps is (10 sec: 3313.5, 60 sec: 3277.3, 300 sec: 3332.7). Total num frames: 10715136. Throughput: 0: 3236.8. Samples: 10721792. Policy #0 lag: (min: 31.0, avg: 34.0, max: 95.0)
[2026-02-02 13:05:37,480][93050] Avg episode reward: [(0, '1676.431')]
[2026-02-02 13:05:42,512][93050] Fps is (10 sec: 3296.9, 60 sec: 3275.6, 300 sec: 3332.9). Total num frames: 10731520. Throughput: 0: 3254.4. Samples: 10732544. Policy #0 lag: (min: 31.0, avg: 34.0, max: 95.0)
[2026-02-02 13:05:42,512][93050] Avg episode reward: [(0, '1623.510')]
[2026-02-02 13:05:47,544][93050] Fps is (10 sec: 3255.7, 60 sec: 3273.5, 300 sec: 3332.1). Total num frames: 10747904. Throughput: 0: 3232.2. Samples: 10752000. Policy #0 lag: (min: 31.0, avg: 34.0, max: 95.0)
[2026-02-02 13:05:47,545][93050] Avg episode reward: [(0, '1690.217')]
[2026-02-02 13:05:52,473][93050] Fps is (10 sec: 3289.8, 60 sec: 3281.3, 300 sec: 3332.7). Total num frames: 10764288. Throughput: 0: 3250.7. Samples: 10772480. Policy #0 lag: (min: 31.0, avg: 34.0, max: 95.0)
[2026-02-02 13:05:52,473][93050] Avg episode reward: [(0, '1752.905')]
[2026-02-02 13:05:57,527][93050] Fps is (10 sec: 3282.3, 60 sec: 3276.2, 300 sec: 3332.5). Total num frames: 10780672. Throughput: 0: 3258.2. Samples: 10781696. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 13:05:57,528][93050] Avg episode reward: [(0, '1838.165')]
[2026-02-02 13:05:57,661][93050] Saving new best policy, reward=1838.165!
[2026-02-02 13:06:02,527][93050] Fps is (10 sec: 3259.1, 60 sec: 3278.4, 300 sec: 3332.5). Total num frames: 10797056. Throughput: 0: 3300.3. Samples: 10803200. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 13:06:02,527][93050] Avg episode reward: [(0, '1862.104')]
[2026-02-02 13:06:02,664][93050] Saving new best policy, reward=1862.104!
[2026-02-02 13:06:07,471][93050] Fps is (10 sec: 3295.4, 60 sec: 3282.9, 300 sec: 3333.3). Total num frames: 10813440. Throughput: 0: 3406.8. Samples: 10824192. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 13:06:07,471][93050] Avg episode reward: [(0, '1754.840')]
[2026-02-02 13:06:12,565][93050] Fps is (10 sec: 3264.2, 60 sec: 3277.8, 300 sec: 3331.7). Total num frames: 10829824. Throughput: 0: 3381.1. Samples: 10833920. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 13:06:12,566][93050] Avg episode reward: [(0, '1706.365')]
[2026-02-02 13:06:17,477][93050] Fps is (10 sec: 3275.0, 60 sec: 3280.1, 300 sec: 3333.4). Total num frames: 10846208. Throughput: 0: 3409.3. Samples: 10854400. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 13:06:17,477][93050] Avg episode reward: [(0, '1699.713')]
[2026-02-02 13:06:22,822][93050] Fps is (10 sec: 3993.4, 60 sec: 3397.0, 300 sec: 3357.6). Total num frames: 10870784. Throughput: 0: 3398.8. Samples: 10875904. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-02-02 13:06:22,822][93050] Avg episode reward: [(0, '1731.973')]
[2026-02-02 13:06:25,872][93050] Keyboard interrupt detected in the event loop EvtLoop [Runner_EvtLoop, process=main process 93050], exiting...
[2026-02-02 13:06:25,873][93050] Runner profile tree view:
main_loop: 3556.7902
[2026-02-02 13:06:25,873][93050] Collected {0: 10878976}, FPS: 3058.6
