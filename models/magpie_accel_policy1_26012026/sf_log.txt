[2026-01-26 13:42:20,642][144664] Saving configuration to /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_accel_policy1_26012026/config.json...
[2026-01-26 13:42:20,668][144664] Using GPUs [0] for process 0 (actually maps to GPUs [0])
[2026-01-26 13:42:20,668][144664] Rollout worker 0 uses device cuda:0
[2026-01-26 13:42:21,059][144664] Using GPUs [0] for process 0 (actually maps to GPUs [0])
[2026-01-26 13:42:21,059][144664] InferenceWorker_p0-w0: min num requests: 1
[2026-01-26 13:42:21,059][144664] Using GPUs [0] for process 0 (actually maps to GPUs [0])
[2026-01-26 13:42:21,060][144664] Starting seed is not provided
[2026-01-26 13:42:21,060][144664] Using GPUs [0] for process 0 (actually maps to GPUs [0])
[2026-01-26 13:42:21,060][144664] Initializing actor-critic model on device cuda:0
[2026-01-26 13:42:21,060][144664] RunningMeanStd input shape: (337,)
[2026-01-26 13:42:21,060][144664] RunningMeanStd input shape: (1,)
[2026-01-26 13:42:21,074][144664] Created Actor Critic model with architecture:
[2026-01-26 13:42:21,074][144664] ActorCriticSharedWeights(
  (obs_normalizer): ObservationNormalizer(
    (running_mean_std): RunningMeanStdDictInPlace(
      (running_mean_std): ModuleDict(
        (observations): RunningMeanStdInPlace()
      )
    )
  )
  (returns_normalizer): RecursiveScriptModule(original_name=RunningMeanStdInPlace)
  (encoder): CustomEncoder(
    (encoders): ModuleDict(
      (obs_image): Sequential(
        (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): ELU(alpha=1.0)
        (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
        (3): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (4): ELU(alpha=1.0)
        (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
        (6): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (7): ELU(alpha=1.0)
        (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        (9): Flatten(start_dim=1, end_dim=-1)
      )
    )
    (mlp_head_custom): Sequential(
      (0): Linear(in_features=145, out_features=256, bias=True)
      (1): ELU(alpha=1.0)
      (2): Linear(in_features=256, out_features=128, bias=True)
      (3): ELU(alpha=1.0)
      (4): Linear(in_features=128, out_features=64, bias=True)
      (5): ELU(alpha=1.0)
    )
  )
  (core): ModelCoreRNN(
    (core): GRU(64, 128)
  )
  (decoder): MlpDecoder(
    (mlp): Identity()
  )
  (critic_linear): Linear(in_features=128, out_features=1, bias=True)
  (action_parameterization): ActionParameterizationDefault(
    (distribution_linear): Linear(in_features=128, out_features=8, bias=True)
  )
)
[2026-01-26 13:42:21,467][144664] Using optimizer <class 'torch.optim.adam.Adam'>
[2026-01-26 13:42:21,468][144664] No checkpoints found
[2026-01-26 13:42:21,468][144664] Did not load from checkpoint, starting from scratch!
[2026-01-26 13:42:21,468][144664] Initialized policy 0 weights for model version 0
[2026-01-26 13:42:21,468][144664] LearnerWorker_p0 finished initialization!
[2026-01-26 13:42:21,469][144664] Using GPUs [0] for process 0 (actually maps to GPUs [0])
[2026-01-26 13:42:21,475][144664] Fps is (10 sec: nan, 60 sec: nan, 300 sec: nan). Total num frames: 0. Throughput: 0: nan. Samples: 0. Policy #0 lag: (min: -1.0, avg: -1.0, max: -1.0)
[2026-01-26 13:42:21,475][144664] Inference worker 0-0 is ready!
[2026-01-26 13:42:21,475][144664] All inference workers are ready! Signal rollout workers to start!
[2026-01-26 13:42:21,475][144664] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 0.0). Total num frames: 0. Throughput: 0: 0.0. Samples: 0. Policy #0 lag: (min: -1.0, avg: -1.0, max: -1.0)
[2026-01-26 13:42:21,475][144664] EnvRunner 0-0 uses policy 0
[2026-01-26 13:42:36,016][144664] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 0.0). Total num frames: 0. Throughput: 0: 0.0. Samples: 0. Policy #0 lag: (min: -1.0, avg: -1.0, max: -1.0)
[2026-01-26 13:42:40,436][144664] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 0.0). Total num frames: 0. Throughput: 0: 0.0. Samples: 0. Policy #0 lag: (min: -1.0, avg: -1.0, max: -1.0)
[2026-01-26 13:42:40,537][144664] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 0.0). Total num frames: 0. Throughput: 0: 26.9. Samples: 512. Policy #0 lag: (min: -1.0, avg: -1.0, max: -1.0)
[2026-01-26 13:42:40,537][144664] Avg episode reward: [(0, '-10.000')]
[2026-01-26 13:42:41,882][144664] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 0.0). Total num frames: 0. Throughput: 0: 50.2. Samples: 1024. Policy #0 lag: (min: -1.0, avg: -1.0, max: -1.0)
[2026-01-26 13:42:41,882][144664] Avg episode reward: [(0, '-10.000')]
[2026-01-26 13:42:42,036][144664] Heartbeat connected on Batcher_0
[2026-01-26 13:42:42,036][144664] Heartbeat connected on LearnerWorker_p0
[2026-01-26 13:42:42,036][144664] Heartbeat connected on InferenceWorker_p0-w0
[2026-01-26 13:42:42,036][144664] Heartbeat connected on RolloutWorker_w0
[2026-01-26 13:42:43,125][144664] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 0.0). Total num frames: 0. Throughput: 0: 189.2. Samples: 4096. Policy #0 lag: (min: -1.0, avg: -1.0, max: -1.0)
[2026-01-26 13:42:43,125][144664] Avg episode reward: [(0, '-10.000')]
[2026-01-26 13:42:48,095][144664] Signal inference workers to stop experience collection...
[2026-01-26 13:42:48,095][144664] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 0.0). Total num frames: 0. Throughput: 0: 384.7. Samples: 10240. Policy #0 lag: (min: -1.0, avg: -1.0, max: -1.0)
[2026-01-26 13:42:48,095][144664] Avg episode reward: [(0, '-16.065')]
[2026-01-26 13:42:49,507][144664] InferenceWorker_p0-w0: stopping experience collection
[2026-01-26 13:42:49,509][144664] Signal inference workers to resume experience collection...
[2026-01-26 13:42:49,671][144664] InferenceWorker_p0-w0: resuming experience collection
[2026-01-26 13:42:53,003][144664] Fps is (10 sec: 1658.7, 60 sec: 519.7, 300 sec: 519.7). Total num frames: 16384. Throughput: 0: 747.0. Samples: 23552. Policy #0 lag: (min: 0.0, avg: 0.0, max: 0.0)
[2026-01-26 13:42:53,003][144664] Avg episode reward: [(0, '-20.770')]
[2026-01-26 13:42:58,011][144664] Fps is (10 sec: 3304.7, 60 sec: 896.9, 300 sec: 896.9). Total num frames: 32768. Throughput: 0: 1191.2. Samples: 43520. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 13:42:58,011][144664] Avg episode reward: [(0, '-25.513')]
[2026-01-26 13:43:03,086][144664] Fps is (10 sec: 3249.7, 60 sec: 1181.2, 300 sec: 1181.2). Total num frames: 49152. Throughput: 0: 1267.4. Samples: 52736. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 13:43:03,086][144664] Avg episode reward: [(0, '-311.768')]
[2026-01-26 13:43:08,069][144664] Fps is (10 sec: 3257.9, 60 sec: 1406.5, 300 sec: 1406.5). Total num frames: 65536. Throughput: 0: 2156.4. Samples: 69120. Policy #0 lag: (min: 12.0, avg: 15.0, max: 76.0)
[2026-01-26 13:43:08,069][144664] Avg episode reward: [(0, '-319.552')]
[2026-01-26 13:43:13,099][144664] Fps is (10 sec: 3272.7, 60 sec: 1586.9, 300 sec: 1586.9). Total num frames: 81920. Throughput: 0: 2711.8. Samples: 88576. Policy #0 lag: (min: 1.0, avg: 4.0, max: 65.0)
[2026-01-26 13:43:13,099][144664] Avg episode reward: [(0, '-183.449')]
[2026-01-26 13:43:18,063][144664] Fps is (10 sec: 3278.6, 60 sec: 1737.2, 300 sec: 1737.2). Total num frames: 98304. Throughput: 0: 2633.2. Samples: 99328. Policy #0 lag: (min: 4.0, avg: 7.0, max: 68.0)
[2026-01-26 13:43:18,063][144664] Avg episode reward: [(0, '-65.126')]
[2026-01-26 13:43:23,059][144664] Fps is (10 sec: 3289.9, 60 sec: 2437.9, 300 sec: 1862.3). Total num frames: 114688. Throughput: 0: 2785.2. Samples: 115712. Policy #0 lag: (min: 12.0, avg: 15.0, max: 76.0)
[2026-01-26 13:43:23,059][144664] Avg episode reward: [(0, '-153.913')]
[2026-01-26 13:43:23,209][144664] Saving new best policy, reward=-153.913!
[2026-01-26 13:43:28,012][144664] Fps is (10 sec: 3293.5, 60 sec: 2755.0, 300 sec: 1969.9). Total num frames: 131072. Throughput: 0: 2931.4. Samples: 135680. Policy #0 lag: (min: 1.0, avg: 4.0, max: 65.0)
[2026-01-26 13:43:28,013][144664] Avg episode reward: [(0, '-157.410')]
[2026-01-26 13:43:33,088][144664] Fps is (10 sec: 3267.3, 60 sec: 2806.0, 300 sec: 2059.1). Total num frames: 147456. Throughput: 0: 3027.0. Samples: 146432. Policy #0 lag: (min: 6.0, avg: 9.0, max: 70.0)
[2026-01-26 13:43:33,088][144664] Avg episode reward: [(0, '-82.837')]
[2026-01-26 13:43:33,226][144664] Saving new best policy, reward=-82.837!
[2026-01-26 13:43:38,282][144664] Fps is (10 sec: 3190.7, 60 sec: 2904.9, 300 sec: 2133.1). Total num frames: 163840. Throughput: 0: 3143.5. Samples: 165888. Policy #0 lag: (min: 4.0, avg: 7.0, max: 68.0)
[2026-01-26 13:43:38,282][144664] Avg episode reward: [(0, '-65.893')]
[2026-01-26 13:43:38,455][144664] Saving new best policy, reward=-65.893!
[2026-01-26 13:43:43,094][144664] Fps is (10 sec: 3274.8, 60 sec: 3005.3, 300 sec: 2208.1). Total num frames: 180224. Throughput: 0: 3134.5. Samples: 184832. Policy #0 lag: (min: 0.0, avg: 3.0, max: 64.0)
[2026-01-26 13:43:43,094][144664] Avg episode reward: [(0, '-63.550')]
[2026-01-26 13:43:43,254][144664] Saving new best policy, reward=-63.550!
[2026-01-26 13:43:48,068][144664] Fps is (10 sec: 3348.5, 60 sec: 3278.3, 300 sec: 2270.5). Total num frames: 196608. Throughput: 0: 3175.7. Samples: 195584. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 13:43:48,068][144664] Avg episode reward: [(0, '-55.722')]
[2026-01-26 13:43:48,228][144664] Saving new best policy, reward=-55.722!
[2026-01-26 13:43:53,131][144664] Fps is (10 sec: 3264.7, 60 sec: 3269.8, 300 sec: 2323.8). Total num frames: 212992. Throughput: 0: 3215.5. Samples: 214016. Policy #0 lag: (min: 8.0, avg: 11.0, max: 72.0)
[2026-01-26 13:43:53,131][144664] Avg episode reward: [(0, '-30.572')]
[2026-01-26 13:43:53,286][144664] Saving new best policy, reward=-30.572!
[2026-01-26 13:43:58,025][144664] Fps is (10 sec: 3291.1, 60 sec: 3276.0, 300 sec: 2375.7). Total num frames: 229376. Throughput: 0: 3213.8. Samples: 232960. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 13:43:58,025][144664] Avg episode reward: [(0, '-33.351')]
[2026-01-26 13:44:03,097][144664] Fps is (10 sec: 3288.1, 60 sec: 3276.2, 300 sec: 2418.4). Total num frames: 245760. Throughput: 0: 3206.2. Samples: 243712. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 13:44:03,097][144664] Avg episode reward: [(0, '-27.268')]
[2026-01-26 13:44:03,242][144664] Saving /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_accel_policy1_26012026/checkpoint_p0/checkpoint_000000960_245760.pth...
[2026-01-26 13:44:03,246][144664] Saving new best policy, reward=-27.268!
[2026-01-26 13:44:08,122][144664] Fps is (10 sec: 3245.2, 60 sec: 3273.9, 300 sec: 2458.0). Total num frames: 262144. Throughput: 0: 3272.2. Samples: 263168. Policy #0 lag: (min: 6.0, avg: 9.0, max: 70.0)
[2026-01-26 13:44:08,122][144664] Avg episode reward: [(0, '-15.482')]
[2026-01-26 13:44:08,265][144664] Saving new best policy, reward=-15.482!
[2026-01-26 13:44:11,744][144664] Signal inference workers to stop experience collection... (50 times)
[2026-01-26 13:44:12,088][144664] InferenceWorker_p0-w0: stopping experience collection (50 times)
[2026-01-26 13:44:12,088][144664] Signal inference workers to resume experience collection... (50 times)
[2026-01-26 13:44:12,088][144664] InferenceWorker_p0-w0: resuming experience collection (50 times)
[2026-01-26 13:44:13,093][144664] Fps is (10 sec: 3277.9, 60 sec: 3277.1, 300 sec: 2495.4). Total num frames: 278528. Throughput: 0: 3248.2. Samples: 282112. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 13:44:13,093][144664] Avg episode reward: [(0, '-5.532')]
[2026-01-26 13:44:13,379][144664] Saving new best policy, reward=-5.532!
[2026-01-26 13:44:18,054][144664] Fps is (10 sec: 3299.1, 60 sec: 3277.3, 300 sec: 2529.7). Total num frames: 294912. Throughput: 0: 3290.6. Samples: 294400. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 13:44:18,054][144664] Avg episode reward: [(0, '1.149')]
[2026-01-26 13:44:18,186][144664] Saving new best policy, reward=1.149!
[2026-01-26 13:44:23,052][144664] Fps is (10 sec: 3290.2, 60 sec: 3277.1, 300 sec: 2560.5). Total num frames: 311296. Throughput: 0: 3327.9. Samples: 314880. Policy #0 lag: (min: 4.0, avg: 7.0, max: 68.0)
[2026-01-26 13:44:23,053][144664] Avg episode reward: [(0, '10.385')]
[2026-01-26 13:44:23,191][144664] Saving new best policy, reward=10.385!
[2026-01-26 13:44:28,023][144664] Fps is (10 sec: 3286.9, 60 sec: 3276.2, 300 sec: 2589.4). Total num frames: 327680. Throughput: 0: 3407.3. Samples: 337920. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 13:44:28,024][144664] Avg episode reward: [(0, '20.565')]
[2026-01-26 13:44:28,155][144664] Saving new best policy, reward=20.565!
[2026-01-26 13:44:33,008][144664] Fps is (10 sec: 3291.4, 60 sec: 3281.2, 300 sec: 2615.8). Total num frames: 344064. Throughput: 0: 3406.5. Samples: 348672. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 13:44:33,008][144664] Avg episode reward: [(0, '29.671')]
[2026-01-26 13:44:33,142][144664] Saving new best policy, reward=29.671!
[2026-01-26 13:44:38,269][144664] Fps is (10 sec: 3997.7, 60 sec: 3414.1, 300 sec: 2694.8). Total num frames: 368640. Throughput: 0: 3493.6. Samples: 371712. Policy #0 lag: (min: 8.0, avg: 11.0, max: 72.0)
[2026-01-26 13:44:38,269][144664] Avg episode reward: [(0, '37.657')]
[2026-01-26 13:44:38,609][144664] Saving new best policy, reward=37.657!
[2026-01-26 13:44:43,095][144664] Fps is (10 sec: 4872.8, 60 sec: 3549.8, 300 sec: 2776.6). Total num frames: 393216. Throughput: 0: 3578.4. Samples: 394240. Policy #0 lag: (min: 6.0, avg: 9.0, max: 70.0)
[2026-01-26 13:44:43,095][144664] Avg episode reward: [(0, '43.198')]
[2026-01-26 13:44:43,231][144664] Saving new best policy, reward=43.198!
[2026-01-26 13:44:48,012][144664] Fps is (10 sec: 4204.4, 60 sec: 3553.2, 300 sec: 2795.2). Total num frames: 409600. Throughput: 0: 3602.2. Samples: 405504. Policy #0 lag: (min: 9.0, avg: 12.0, max: 73.0)
[2026-01-26 13:44:48,012][144664] Avg episode reward: [(0, '51.400')]
[2026-01-26 13:44:48,136][144664] Saving new best policy, reward=51.400!
[2026-01-26 13:44:53,004][144664] Fps is (10 sec: 3306.8, 60 sec: 3557.4, 300 sec: 2811.2). Total num frames: 425984. Throughput: 0: 3650.4. Samples: 427008. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 13:44:53,004][144664] Avg episode reward: [(0, '60.187')]
[2026-01-26 13:44:53,141][144664] Saving new best policy, reward=60.187!
[2026-01-26 13:44:58,078][144664] Fps is (10 sec: 3255.1, 60 sec: 3546.7, 300 sec: 2824.8). Total num frames: 442368. Throughput: 0: 3721.8. Samples: 449536. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 13:44:58,079][144664] Avg episode reward: [(0, '64.859')]
[2026-01-26 13:44:58,205][144664] Saving new best policy, reward=64.859!
[2026-01-26 13:45:03,083][144664] Fps is (10 sec: 3251.2, 60 sec: 3550.7, 300 sec: 2838.7). Total num frames: 458752. Throughput: 0: 3672.7. Samples: 459776. Policy #0 lag: (min: 13.0, avg: 16.0, max: 77.0)
[2026-01-26 13:45:03,083][144664] Avg episode reward: [(0, '74.689')]
[2026-01-26 13:45:03,213][144664] Saving new best policy, reward=74.689!
[2026-01-26 13:45:08,114][144664] Fps is (10 sec: 3265.0, 60 sec: 3550.3, 300 sec: 2851.3). Total num frames: 475136. Throughput: 0: 3704.1. Samples: 481792. Policy #0 lag: (min: 0.0, avg: 3.0, max: 64.0)
[2026-01-26 13:45:08,115][144664] Avg episode reward: [(0, '86.477')]
[2026-01-26 13:45:08,239][144664] Saving new best policy, reward=86.477!
[2026-01-26 13:45:13,001][144664] Fps is (10 sec: 3304.0, 60 sec: 3555.3, 300 sec: 2865.6). Total num frames: 491520. Throughput: 0: 3665.5. Samples: 502784. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 13:45:13,001][144664] Avg episode reward: [(0, '94.706')]
[2026-01-26 13:45:13,148][144664] Saving new best policy, reward=94.706!
[2026-01-26 13:45:18,061][144664] Fps is (10 sec: 3294.5, 60 sec: 3549.5, 300 sec: 2876.2). Total num frames: 507904. Throughput: 0: 3636.6. Samples: 512512. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 13:45:18,061][144664] Avg episode reward: [(0, '99.884')]
[2026-01-26 13:45:18,189][144664] Saving new best policy, reward=99.884!
[2026-01-26 13:45:23,036][144664] Fps is (10 sec: 3265.2, 60 sec: 3550.8, 300 sec: 2887.7). Total num frames: 524288. Throughput: 0: 3648.4. Samples: 535040. Policy #0 lag: (min: 6.0, avg: 9.0, max: 70.0)
[2026-01-26 13:45:23,036][144664] Avg episode reward: [(0, '106.810')]
[2026-01-26 13:45:23,167][144664] Saving new best policy, reward=106.810!
[2026-01-26 13:45:28,066][144664] Signal inference workers to stop experience collection... (100 times)
[2026-01-26 13:45:28,072][144664] Signal inference workers to resume experience collection... (100 times)
[2026-01-26 13:45:28,074][144664] Fps is (10 sec: 4090.8, 60 sec: 3683.3, 300 sec: 2941.4). Total num frames: 548864. Throughput: 0: 3619.8. Samples: 557056. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 13:45:28,074][144664] Avg episode reward: [(0, '107.382')]
[2026-01-26 13:45:28,320][144664] InferenceWorker_p0-w0: stopping experience collection (100 times)
[2026-01-26 13:45:28,321][144664] InferenceWorker_p0-w0: resuming experience collection (100 times)
[2026-01-26 13:45:28,430][144664] Saving new best policy, reward=107.382!
[2026-01-26 13:45:33,077][144664] Fps is (10 sec: 4895.2, 60 sec: 3818.5, 300 sec: 2992.9). Total num frames: 573440. Throughput: 0: 3578.8. Samples: 566784. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 13:45:33,077][144664] Avg episode reward: [(0, '112.888')]
[2026-01-26 13:45:33,225][144664] Saving new best policy, reward=112.888!
[2026-01-26 13:45:38,000][144664] Fps is (10 sec: 4126.2, 60 sec: 3703.0, 300 sec: 3001.3). Total num frames: 589824. Throughput: 0: 3607.1. Samples: 589312. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 13:45:38,001][144664] Avg episode reward: [(0, '118.945')]
[2026-01-26 13:45:38,143][144664] Saving new best policy, reward=118.945!
[2026-01-26 13:45:43,085][144664] Fps is (10 sec: 3274.2, 60 sec: 3550.5, 300 sec: 3006.8). Total num frames: 606208. Throughput: 0: 3549.3. Samples: 609280. Policy #0 lag: (min: 6.0, avg: 9.0, max: 70.0)
[2026-01-26 13:45:43,085][144664] Avg episode reward: [(0, '128.058')]
[2026-01-26 13:45:43,220][144664] Saving new best policy, reward=128.058!
[2026-01-26 13:45:47,997][144664] Fps is (10 sec: 3277.9, 60 sec: 3550.7, 300 sec: 3014.6). Total num frames: 622592. Throughput: 0: 3590.9. Samples: 621056. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 13:45:47,997][144664] Avg episode reward: [(0, '133.932')]
[2026-01-26 13:45:48,145][144664] Saving new best policy, reward=133.932!
[2026-01-26 13:45:53,114][144664] Fps is (10 sec: 3267.3, 60 sec: 3543.4, 300 sec: 3019.2). Total num frames: 638976. Throughput: 0: 3538.5. Samples: 641024. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 13:45:53,114][144664] Avg episode reward: [(0, '137.536')]
[2026-01-26 13:45:53,243][144664] Saving new best policy, reward=137.536!
[2026-01-26 13:45:58,031][144664] Fps is (10 sec: 3265.6, 60 sec: 3552.6, 300 sec: 3026.3). Total num frames: 655360. Throughput: 0: 3570.2. Samples: 663552. Policy #0 lag: (min: 14.0, avg: 17.0, max: 78.0)
[2026-01-26 13:45:58,032][144664] Avg episode reward: [(0, '141.620')]
[2026-01-26 13:45:58,161][144664] Saving new best policy, reward=141.620!
[2026-01-26 13:46:03,080][144664] Fps is (10 sec: 3288.1, 60 sec: 3550.1, 300 sec: 3031.3). Total num frames: 671744. Throughput: 0: 3582.5. Samples: 673792. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 13:46:03,080][144664] Avg episode reward: [(0, '147.715')]
[2026-01-26 13:46:03,215][144664] Saving /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_accel_policy1_26012026/checkpoint_p0/checkpoint_000002624_671744.pth...
[2026-01-26 13:46:03,219][144664] Saving new best policy, reward=147.715!
[2026-01-26 13:46:08,050][144664] Fps is (10 sec: 3270.6, 60 sec: 3553.7, 300 sec: 3037.1). Total num frames: 688128. Throughput: 0: 3560.1. Samples: 695296. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 13:46:08,051][144664] Avg episode reward: [(0, '151.080')]
[2026-01-26 13:46:08,194][144664] Saving new best policy, reward=151.080!
[2026-01-26 13:46:13,079][144664] Fps is (10 sec: 3277.0, 60 sec: 3545.2, 300 sec: 3041.9). Total num frames: 704512. Throughput: 0: 3538.1. Samples: 716288. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 13:46:13,079][144664] Avg episode reward: [(0, '155.075')]
[2026-01-26 13:46:13,212][144664] Saving new best policy, reward=155.075!
[2026-01-26 13:46:18,110][144664] Fps is (10 sec: 3257.3, 60 sec: 3546.9, 300 sec: 3046.4). Total num frames: 720896. Throughput: 0: 3535.9. Samples: 726016. Policy #0 lag: (min: 1.0, avg: 4.0, max: 65.0)
[2026-01-26 13:46:18,111][144664] Avg episode reward: [(0, '159.111')]
[2026-01-26 13:46:18,264][144664] Saving new best policy, reward=159.111!
[2026-01-26 13:46:23,128][144664] Fps is (10 sec: 3260.9, 60 sec: 3544.5, 300 sec: 3051.0). Total num frames: 737280. Throughput: 0: 3494.5. Samples: 747008. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 13:46:23,128][144664] Avg episode reward: [(0, '163.362')]
[2026-01-26 13:46:23,268][144664] Saving new best policy, reward=163.362!
[2026-01-26 13:46:28,296][144664] Fps is (10 sec: 4021.1, 60 sec: 3536.7, 300 sec: 3086.7). Total num frames: 761856. Throughput: 0: 3533.3. Samples: 769024. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 13:46:28,297][144664] Avg episode reward: [(0, '167.803')]
[2026-01-26 13:46:28,667][144664] Saving new best policy, reward=167.803!
[2026-01-26 13:46:33,320][144664] Fps is (10 sec: 4822.4, 60 sec: 3535.5, 300 sec: 3122.7). Total num frames: 786432. Throughput: 0: 3479.4. Samples: 778752. Policy #0 lag: (min: 14.0, avg: 17.0, max: 78.0)
[2026-01-26 13:46:33,321][144664] Avg episode reward: [(0, '174.110')]
[2026-01-26 13:46:33,324][144664] Saving new best policy, reward=174.110!
[2026-01-26 13:46:38,106][144664] Fps is (10 sec: 4175.7, 60 sec: 3543.7, 300 sec: 3128.3). Total num frames: 802816. Throughput: 0: 3539.2. Samples: 800256. Policy #0 lag: (min: 12.0, avg: 15.0, max: 76.0)
[2026-01-26 13:46:38,106][144664] Avg episode reward: [(0, '180.508')]
[2026-01-26 13:46:38,106][144664] Saving new best policy, reward=180.508!
[2026-01-26 13:46:42,998][144664] Fps is (10 sec: 3386.1, 60 sec: 3555.0, 300 sec: 3132.4). Total num frames: 819200. Throughput: 0: 3484.2. Samples: 820224. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 13:46:42,998][144664] Avg episode reward: [(0, '180.990')]
[2026-01-26 13:46:43,139][144664] Saving new best policy, reward=180.990!
[2026-01-26 13:46:46,537][144664] Signal inference workers to stop experience collection... (150 times)
[2026-01-26 13:46:46,889][144664] InferenceWorker_p0-w0: stopping experience collection (150 times)
[2026-01-26 13:46:46,891][144664] Signal inference workers to resume experience collection... (150 times)
[2026-01-26 13:46:47,021][144664] InferenceWorker_p0-w0: resuming experience collection (150 times)
[2026-01-26 13:46:48,103][144664] Fps is (10 sec: 3277.5, 60 sec: 3543.6, 300 sec: 3133.9). Total num frames: 835584. Throughput: 0: 3513.9. Samples: 832000. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 13:46:48,104][144664] Avg episode reward: [(0, '184.408')]
[2026-01-26 13:46:48,237][144664] Saving new best policy, reward=184.408!
[2026-01-26 13:46:53,104][144664] Fps is (10 sec: 3242.2, 60 sec: 3550.5, 300 sec: 3136.5). Total num frames: 851968. Throughput: 0: 3500.2. Samples: 852992. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 13:46:53,104][144664] Avg episode reward: [(0, '182.363')]
[2026-01-26 13:46:58,118][144664] Fps is (10 sec: 3272.2, 60 sec: 3544.8, 300 sec: 3138.9). Total num frames: 868352. Throughput: 0: 3524.1. Samples: 875008. Policy #0 lag: (min: 4.0, avg: 7.0, max: 68.0)
[2026-01-26 13:46:58,118][144664] Avg episode reward: [(0, '188.191')]
[2026-01-26 13:46:58,252][144664] Saving new best policy, reward=188.191!
[2026-01-26 13:47:03,037][144664] Fps is (10 sec: 3299.1, 60 sec: 3552.4, 300 sec: 3142.2). Total num frames: 884736. Throughput: 0: 3555.7. Samples: 885760. Policy #0 lag: (min: 14.0, avg: 17.0, max: 78.0)
[2026-01-26 13:47:03,037][144664] Avg episode reward: [(0, '188.837')]
[2026-01-26 13:47:03,180][144664] Saving new best policy, reward=188.837!
[2026-01-26 13:47:08,116][144664] Fps is (10 sec: 3277.2, 60 sec: 3546.0, 300 sec: 3143.7). Total num frames: 901120. Throughput: 0: 3562.2. Samples: 907264. Policy #0 lag: (min: 13.0, avg: 16.0, max: 77.0)
[2026-01-26 13:47:08,117][144664] Avg episode reward: [(0, '197.602')]
[2026-01-26 13:47:08,256][144664] Saving new best policy, reward=197.602!
[2026-01-26 13:47:13,101][144664] Fps is (10 sec: 3256.0, 60 sec: 3548.6, 300 sec: 3146.2). Total num frames: 917504. Throughput: 0: 3565.4. Samples: 928768. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 13:47:13,101][144664] Avg episode reward: [(0, '200.820')]
[2026-01-26 13:47:13,240][144664] Saving new best policy, reward=200.820!
[2026-01-26 13:47:18,051][144664] Fps is (10 sec: 3298.2, 60 sec: 3553.4, 300 sec: 3311.2). Total num frames: 933888. Throughput: 0: 3594.1. Samples: 939520. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 13:47:18,052][144664] Avg episode reward: [(0, '205.337')]
[2026-01-26 13:47:18,184][144664] Saving new best policy, reward=205.337!
[2026-01-26 13:47:23,086][144664] Fps is (10 sec: 3281.7, 60 sec: 3552.4, 300 sec: 3362.0). Total num frames: 950272. Throughput: 0: 3574.2. Samples: 961024. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 13:47:23,086][144664] Avg episode reward: [(0, '214.378')]
[2026-01-26 13:47:23,449][144664] Saving new best policy, reward=214.378!
[2026-01-26 13:47:28,025][144664] Fps is (10 sec: 4106.6, 60 sec: 3566.0, 300 sec: 3390.9). Total num frames: 974848. Throughput: 0: 3615.9. Samples: 983040. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 13:47:28,026][144664] Avg episode reward: [(0, '222.194')]
[2026-01-26 13:47:28,375][144664] Saving new best policy, reward=222.194!
[2026-01-26 13:47:33,003][144664] Fps is (10 sec: 4956.0, 60 sec: 3568.7, 300 sec: 3433.0). Total num frames: 999424. Throughput: 0: 3580.6. Samples: 992768. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 13:47:33,004][144664] Avg episode reward: [(0, '233.215')]
[2026-01-26 13:47:33,007][144664] Saving new best policy, reward=233.215!
[2026-01-26 13:47:38,118][144664] Fps is (10 sec: 4058.4, 60 sec: 3549.1, 300 sec: 3443.5). Total num frames: 1015808. Throughput: 0: 3594.2. Samples: 1014784. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 13:47:38,118][144664] Avg episode reward: [(0, '237.036')]
[2026-01-26 13:47:38,254][144664] Saving new best policy, reward=237.036!
[2026-01-26 13:47:43,064][144664] Fps is (10 sec: 3257.0, 60 sec: 3545.9, 300 sec: 3499.3). Total num frames: 1032192. Throughput: 0: 3542.7. Samples: 1034240. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 13:47:43,064][144664] Avg episode reward: [(0, '247.012')]
[2026-01-26 13:47:43,211][144664] Saving new best policy, reward=247.012!
[2026-01-26 13:47:48,111][144664] Fps is (10 sec: 3279.0, 60 sec: 3549.4, 300 sec: 3497.7). Total num frames: 1048576. Throughput: 0: 3544.0. Samples: 1045504. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 13:47:48,112][144664] Avg episode reward: [(0, '254.344')]
[2026-01-26 13:47:48,248][144664] Saving new best policy, reward=254.344!
[2026-01-26 13:47:53,034][144664] Fps is (10 sec: 3286.6, 60 sec: 3554.0, 300 sec: 3498.7). Total num frames: 1064960. Throughput: 0: 3533.6. Samples: 1065984. Policy #0 lag: (min: 13.0, avg: 16.0, max: 77.0)
[2026-01-26 13:47:53,034][144664] Avg episode reward: [(0, '260.569')]
[2026-01-26 13:47:53,173][144664] Saving new best policy, reward=260.569!
[2026-01-26 13:47:58,050][144664] Fps is (10 sec: 3297.1, 60 sec: 3553.9, 300 sec: 3499.4). Total num frames: 1081344. Throughput: 0: 3508.3. Samples: 1086464. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 13:47:58,050][144664] Avg episode reward: [(0, '262.532')]
[2026-01-26 13:47:58,180][144664] Saving new best policy, reward=262.532!
[2026-01-26 13:48:00,858][144664] Signal inference workers to stop experience collection... (200 times)
[2026-01-26 13:48:01,216][144664] InferenceWorker_p0-w0: stopping experience collection (200 times)
[2026-01-26 13:48:01,217][144664] Signal inference workers to resume experience collection... (200 times)
[2026-01-26 13:48:01,217][144664] InferenceWorker_p0-w0: resuming experience collection (200 times)
[2026-01-26 13:48:03,042][144664] Fps is (10 sec: 3274.2, 60 sec: 3549.5, 300 sec: 3499.3). Total num frames: 1097728. Throughput: 0: 3527.8. Samples: 1098240. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 13:48:03,042][144664] Avg episode reward: [(0, '267.071')]
[2026-01-26 13:48:03,178][144664] Saving /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_accel_policy1_26012026/checkpoint_p0/checkpoint_000004288_1097728.pth...
[2026-01-26 13:48:03,182][144664] Removing /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_accel_policy1_26012026/checkpoint_p0/checkpoint_000000960_245760.pth
[2026-01-26 13:48:03,183][144664] Saving new best policy, reward=267.071!
[2026-01-26 13:48:08,075][144664] Fps is (10 sec: 3268.5, 60 sec: 3552.3, 300 sec: 3499.2). Total num frames: 1114112. Throughput: 0: 3505.2. Samples: 1118720. Policy #0 lag: (min: 31.0, avg: 34.0, max: 95.0)
[2026-01-26 13:48:08,075][144664] Avg episode reward: [(0, '271.834')]
[2026-01-26 13:48:08,216][144664] Saving new best policy, reward=271.834!
[2026-01-26 13:48:13,101][144664] Fps is (10 sec: 3257.5, 60 sec: 3549.8, 300 sec: 3498.5). Total num frames: 1130496. Throughput: 0: 3498.5. Samples: 1140736. Policy #0 lag: (min: 33.0, avg: 36.0, max: 97.0)
[2026-01-26 13:48:13,101][144664] Avg episode reward: [(0, '277.410')]
[2026-01-26 13:48:13,237][144664] Saving new best policy, reward=277.410!
[2026-01-26 13:48:18,040][144664] Fps is (10 sec: 3288.3, 60 sec: 3550.5, 300 sec: 3499.2). Total num frames: 1146880. Throughput: 0: 3501.5. Samples: 1150464. Policy #0 lag: (min: 47.0, avg: 50.0, max: 111.0)
[2026-01-26 13:48:18,040][144664] Avg episode reward: [(0, '280.714')]
[2026-01-26 13:48:18,179][144664] Saving new best policy, reward=280.714!
[2026-01-26 13:48:23,078][144664] Fps is (10 sec: 3284.4, 60 sec: 3550.3, 300 sec: 3498.2). Total num frames: 1163264. Throughput: 0: 3496.1. Samples: 1171968. Policy #0 lag: (min: 63.0, avg: 66.0, max: 127.0)
[2026-01-26 13:48:23,078][144664] Avg episode reward: [(0, '282.189')]
[2026-01-26 13:48:23,215][144664] Saving new best policy, reward=282.189!
[2026-01-26 13:48:28,044][144664] Fps is (10 sec: 3275.7, 60 sec: 3412.3, 300 sec: 3499.5). Total num frames: 1179648. Throughput: 0: 3540.1. Samples: 1193472. Policy #0 lag: (min: 63.0, avg: 66.0, max: 127.0)
[2026-01-26 13:48:28,044][144664] Avg episode reward: [(0, '288.555')]
[2026-01-26 13:48:28,189][144664] Saving new best policy, reward=288.555!
[2026-01-26 13:48:33,162][144664] Fps is (10 sec: 4061.9, 60 sec: 3404.3, 300 sec: 3528.2). Total num frames: 1204224. Throughput: 0: 3511.8. Samples: 1203712. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 13:48:33,162][144664] Avg episode reward: [(0, '290.951')]
[2026-01-26 13:48:33,511][144664] Saving new best policy, reward=290.951!
[2026-01-26 13:48:38,154][144664] Fps is (10 sec: 4861.6, 60 sec: 3547.8, 300 sec: 3553.8). Total num frames: 1228800. Throughput: 0: 3540.4. Samples: 1225728. Policy #0 lag: (min: 63.0, avg: 66.0, max: 127.0)
[2026-01-26 13:48:38,154][144664] Avg episode reward: [(0, '297.434')]
[2026-01-26 13:48:38,154][144664] Saving new best policy, reward=297.434!
[2026-01-26 13:48:43,088][144664] Fps is (10 sec: 4126.6, 60 sec: 3548.5, 300 sec: 3554.3). Total num frames: 1245184. Throughput: 0: 3546.9. Samples: 1246208. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 13:48:43,088][144664] Avg episode reward: [(0, '307.760')]
[2026-01-26 13:48:43,227][144664] Saving new best policy, reward=307.760!
[2026-01-26 13:48:48,021][144664] Fps is (10 sec: 3320.9, 60 sec: 3555.2, 300 sec: 3555.8). Total num frames: 1261568. Throughput: 0: 3540.1. Samples: 1257472. Policy #0 lag: (min: 45.0, avg: 48.0, max: 109.0)
[2026-01-26 13:48:48,022][144664] Avg episode reward: [(0, '310.408')]
[2026-01-26 13:48:48,154][144664] Saving new best policy, reward=310.408!
[2026-01-26 13:48:53,086][144664] Fps is (10 sec: 3277.4, 60 sec: 3546.8, 300 sec: 3553.8). Total num frames: 1277952. Throughput: 0: 3549.0. Samples: 1278464. Policy #0 lag: (min: 45.0, avg: 48.0, max: 109.0)
[2026-01-26 13:48:53,086][144664] Avg episode reward: [(0, '315.131')]
[2026-01-26 13:48:53,232][144664] Saving new best policy, reward=315.131!
[2026-01-26 13:48:58,040][144664] Fps is (10 sec: 3270.8, 60 sec: 3550.5, 300 sec: 3555.2). Total num frames: 1294336. Throughput: 0: 3509.1. Samples: 1298432. Policy #0 lag: (min: 12.0, avg: 15.0, max: 76.0)
[2026-01-26 13:48:58,040][144664] Avg episode reward: [(0, '312.575')]
[2026-01-26 13:49:03,119][144664] Fps is (10 sec: 3266.2, 60 sec: 3545.3, 300 sec: 3554.5). Total num frames: 1310720. Throughput: 0: 3543.7. Samples: 1310208. Policy #0 lag: (min: 47.0, avg: 50.0, max: 111.0)
[2026-01-26 13:49:03,119][144664] Avg episode reward: [(0, '307.920')]
[2026-01-26 13:49:08,085][144664] Fps is (10 sec: 3261.9, 60 sec: 3549.3, 300 sec: 3554.6). Total num frames: 1327104. Throughput: 0: 3515.2. Samples: 1330176. Policy #0 lag: (min: 47.0, avg: 50.0, max: 111.0)
[2026-01-26 13:49:08,086][144664] Avg episode reward: [(0, '314.722')]
[2026-01-26 13:49:13,090][144664] Fps is (10 sec: 3286.3, 60 sec: 3550.5, 300 sec: 3554.1). Total num frames: 1343488. Throughput: 0: 3500.8. Samples: 1351168. Policy #0 lag: (min: 3.0, avg: 6.0, max: 67.0)
[2026-01-26 13:49:13,090][144664] Avg episode reward: [(0, '320.447')]
[2026-01-26 13:49:13,227][144664] Saving new best policy, reward=320.447!
[2026-01-26 13:49:18,102][144664] Fps is (10 sec: 3271.5, 60 sec: 3546.2, 300 sec: 3553.9). Total num frames: 1359872. Throughput: 0: 3497.7. Samples: 1360896. Policy #0 lag: (min: 63.0, avg: 66.0, max: 127.0)
[2026-01-26 13:49:18,102][144664] Avg episode reward: [(0, '336.789')]
[2026-01-26 13:49:18,238][144664] Saving new best policy, reward=336.789!
[2026-01-26 13:49:19,941][144664] Signal inference workers to stop experience collection... (250 times)
[2026-01-26 13:49:19,942][144664] Signal inference workers to resume experience collection... (250 times)
[2026-01-26 13:49:20,184][144664] InferenceWorker_p0-w0: stopping experience collection (250 times)
[2026-01-26 13:49:20,184][144664] InferenceWorker_p0-w0: resuming experience collection (250 times)
[2026-01-26 13:49:23,027][144664] Fps is (10 sec: 3297.3, 60 sec: 3552.9, 300 sec: 3554.4). Total num frames: 1376256. Throughput: 0: 3502.8. Samples: 1382912. Policy #0 lag: (min: 63.0, avg: 66.0, max: 127.0)
[2026-01-26 13:49:23,028][144664] Avg episode reward: [(0, '330.035')]
[2026-01-26 13:49:28,035][144664] Fps is (10 sec: 3298.9, 60 sec: 3550.4, 300 sec: 3554.2). Total num frames: 1392640. Throughput: 0: 3519.9. Samples: 1404416. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 13:49:28,035][144664] Avg episode reward: [(0, '340.534')]
[2026-01-26 13:49:28,162][144664] Saving new best policy, reward=340.534!
[2026-01-26 13:49:33,096][144664] Fps is (10 sec: 3254.5, 60 sec: 3417.1, 300 sec: 3528.8). Total num frames: 1409024. Throughput: 0: 3487.2. Samples: 1414656. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 13:49:33,096][144664] Avg episode reward: [(0, '346.118')]
[2026-01-26 13:49:33,236][144664] Saving new best policy, reward=346.118!
[2026-01-26 13:49:38,020][144664] Fps is (10 sec: 3281.7, 60 sec: 3284.2, 300 sec: 3499.9). Total num frames: 1425408. Throughput: 0: 3520.9. Samples: 1436672. Policy #0 lag: (min: 9.0, avg: 12.0, max: 73.0)
[2026-01-26 13:49:38,020][144664] Avg episode reward: [(0, '349.891')]
[2026-01-26 13:49:38,383][144664] Saving new best policy, reward=349.891!
[2026-01-26 13:49:43,123][144664] Fps is (10 sec: 4085.2, 60 sec: 3411.4, 300 sec: 3525.4). Total num frames: 1449984. Throughput: 0: 3532.0. Samples: 1457664. Policy #0 lag: (min: 11.0, avg: 14.0, max: 75.0)
[2026-01-26 13:49:43,123][144664] Avg episode reward: [(0, '349.641')]
[2026-01-26 13:49:48,255][144664] Fps is (10 sec: 4801.9, 60 sec: 3536.1, 300 sec: 3551.5). Total num frames: 1474560. Throughput: 0: 3493.7. Samples: 1467904. Policy #0 lag: (min: 11.0, avg: 14.0, max: 75.0)
[2026-01-26 13:49:48,256][144664] Avg episode reward: [(0, '353.374')]
[2026-01-26 13:49:48,256][144664] Saving new best policy, reward=353.374!
[2026-01-26 13:49:53,334][144664] Fps is (10 sec: 4011.4, 60 sec: 3535.3, 300 sec: 3551.4). Total num frames: 1490944. Throughput: 0: 3485.1. Samples: 1487872. Policy #0 lag: (min: 5.0, avg: 8.0, max: 69.0)
[2026-01-26 13:49:53,334][144664] Avg episode reward: [(0, '359.140')]
[2026-01-26 13:49:53,337][144664] Saving new best policy, reward=359.140!
[2026-01-26 13:49:58,195][144664] Fps is (10 sec: 3296.7, 60 sec: 3540.7, 300 sec: 3553.1). Total num frames: 1507328. Throughput: 0: 3473.5. Samples: 1507840. Policy #0 lag: (min: 5.0, avg: 8.0, max: 69.0)
[2026-01-26 13:49:58,196][144664] Avg episode reward: [(0, '365.296')]
[2026-01-26 13:49:58,196][144664] Saving new best policy, reward=365.296!
[2026-01-26 13:50:03,013][144664] Fps is (10 sec: 3385.4, 60 sec: 3556.1, 300 sec: 3555.7). Total num frames: 1523712. Throughput: 0: 3499.9. Samples: 1518080. Policy #0 lag: (min: 10.0, avg: 13.0, max: 74.0)
[2026-01-26 13:50:03,013][144664] Avg episode reward: [(0, '363.793')]
[2026-01-26 13:50:03,153][144664] Saving /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_accel_policy1_26012026/checkpoint_p0/checkpoint_000005952_1523712.pth...
[2026-01-26 13:50:03,157][144664] Removing /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_accel_policy1_26012026/checkpoint_p0/checkpoint_000002624_671744.pth
[2026-01-26 13:50:08,045][144664] Fps is (10 sec: 3326.6, 60 sec: 3552.2, 300 sec: 3554.0). Total num frames: 1540096. Throughput: 0: 3491.6. Samples: 1540096. Policy #0 lag: (min: 10.0, avg: 13.0, max: 74.0)
[2026-01-26 13:50:08,046][144664] Avg episode reward: [(0, '362.843')]
[2026-01-26 13:50:13,091][144664] Fps is (10 sec: 3251.4, 60 sec: 3549.8, 300 sec: 3554.1). Total num frames: 1556480. Throughput: 0: 3431.8. Samples: 1559040. Policy #0 lag: (min: 5.0, avg: 8.0, max: 69.0)
[2026-01-26 13:50:13,091][144664] Avg episode reward: [(0, '370.677')]
[2026-01-26 13:50:13,237][144664] Saving new best policy, reward=370.677!
[2026-01-26 13:50:18,027][144664] Fps is (10 sec: 3282.9, 60 sec: 3554.3, 300 sec: 3554.6). Total num frames: 1572864. Throughput: 0: 3464.2. Samples: 1570304. Policy #0 lag: (min: 5.0, avg: 8.0, max: 69.0)
[2026-01-26 13:50:18,027][144664] Avg episode reward: [(0, '373.459')]
[2026-01-26 13:50:18,169][144664] Saving new best policy, reward=373.459!
[2026-01-26 13:50:23,058][144664] Fps is (10 sec: 3287.7, 60 sec: 3548.1, 300 sec: 3526.9). Total num frames: 1589248. Throughput: 0: 3410.4. Samples: 1590272. Policy #0 lag: (min: 10.0, avg: 13.0, max: 74.0)
[2026-01-26 13:50:23,058][144664] Avg episode reward: [(0, '378.620')]
[2026-01-26 13:50:23,200][144664] Saving new best policy, reward=378.620!
[2026-01-26 13:50:28,123][144664] Fps is (10 sec: 3245.5, 60 sec: 3544.6, 300 sec: 3498.4). Total num frames: 1605632. Throughput: 0: 3367.8. Samples: 1609216. Policy #0 lag: (min: 10.0, avg: 13.0, max: 74.0)
[2026-01-26 13:50:28,124][144664] Avg episode reward: [(0, '380.413')]
[2026-01-26 13:50:28,261][144664] Saving new best policy, reward=380.413!
[2026-01-26 13:50:33,036][144664] Fps is (10 sec: 3283.8, 60 sec: 3553.4, 300 sec: 3498.5). Total num frames: 1622016. Throughput: 0: 3395.7. Samples: 1619968. Policy #0 lag: (min: 11.0, avg: 14.0, max: 75.0)
[2026-01-26 13:50:33,037][144664] Avg episode reward: [(0, '393.228')]
[2026-01-26 13:50:33,185][144664] Saving new best policy, reward=393.228!
[2026-01-26 13:50:38,118][144664] Fps is (10 sec: 3278.4, 60 sec: 3544.0, 300 sec: 3498.6). Total num frames: 1638400. Throughput: 0: 3384.0. Samples: 1639424. Policy #0 lag: (min: 11.0, avg: 14.0, max: 75.0)
[2026-01-26 13:50:38,119][144664] Avg episode reward: [(0, '395.567')]
[2026-01-26 13:50:38,263][144664] Saving new best policy, reward=395.567!
[2026-01-26 13:50:41,021][144664] Signal inference workers to stop experience collection... (300 times)
[2026-01-26 13:50:41,399][144664] InferenceWorker_p0-w0: stopping experience collection (300 times)
[2026-01-26 13:50:41,401][144664] Signal inference workers to resume experience collection... (300 times)
[2026-01-26 13:50:41,545][144664] InferenceWorker_p0-w0: resuming experience collection (300 times)
[2026-01-26 13:50:43,110][144664] Fps is (10 sec: 3252.9, 60 sec: 3414.0, 300 sec: 3497.6). Total num frames: 1654784. Throughput: 0: 3362.8. Samples: 1658880. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 13:50:43,110][144664] Avg episode reward: [(0, '407.339')]
[2026-01-26 13:50:43,275][144664] Saving new best policy, reward=407.339!
[2026-01-26 13:50:48,022][144664] Fps is (10 sec: 3308.6, 60 sec: 3289.6, 300 sec: 3500.0). Total num frames: 1671168. Throughput: 0: 3355.8. Samples: 1669120. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 13:50:48,022][144664] Avg episode reward: [(0, '418.053')]
[2026-01-26 13:50:48,181][144664] Saving new best policy, reward=418.053!
[2026-01-26 13:50:53,077][144664] Fps is (10 sec: 3287.8, 60 sec: 3290.9, 300 sec: 3498.4). Total num frames: 1687552. Throughput: 0: 3285.9. Samples: 1688064. Policy #0 lag: (min: 0.0, avg: 3.0, max: 64.0)
[2026-01-26 13:50:53,077][144664] Avg episode reward: [(0, '419.409')]
[2026-01-26 13:50:53,226][144664] Saving new best policy, reward=419.409!
[2026-01-26 13:50:58,071][144664] Fps is (10 sec: 3260.8, 60 sec: 3283.6, 300 sec: 3499.1). Total num frames: 1703936. Throughput: 0: 3244.1. Samples: 1704960. Policy #0 lag: (min: 0.0, avg: 3.0, max: 64.0)
[2026-01-26 13:50:58,072][144664] Avg episode reward: [(0, '417.560')]
[2026-01-26 13:51:03,068][144664] Fps is (10 sec: 3279.5, 60 sec: 3273.8, 300 sec: 3498.7). Total num frames: 1720320. Throughput: 0: 3239.7. Samples: 1716224. Policy #0 lag: (min: 7.0, avg: 10.0, max: 71.0)
[2026-01-26 13:51:03,068][144664] Avg episode reward: [(0, '417.535')]
[2026-01-26 13:51:07,996][144664] Fps is (10 sec: 3301.6, 60 sec: 3279.5, 300 sec: 3499.9). Total num frames: 1736704. Throughput: 0: 3281.3. Samples: 1737728. Policy #0 lag: (min: 7.0, avg: 10.0, max: 71.0)
[2026-01-26 13:51:07,997][144664] Avg episode reward: [(0, '407.727')]
[2026-01-26 13:51:13,057][144664] Fps is (10 sec: 3280.4, 60 sec: 3278.6, 300 sec: 3499.6). Total num frames: 1753088. Throughput: 0: 3304.4. Samples: 1757696. Policy #0 lag: (min: 3.0, avg: 6.0, max: 67.0)
[2026-01-26 13:51:13,058][144664] Avg episode reward: [(0, '410.289')]
[2026-01-26 13:51:18,085][144664] Fps is (10 sec: 3248.0, 60 sec: 3273.6, 300 sec: 3499.5). Total num frames: 1769472. Throughput: 0: 3318.7. Samples: 1769472. Policy #0 lag: (min: 3.0, avg: 6.0, max: 67.0)
[2026-01-26 13:51:18,085][144664] Avg episode reward: [(0, '418.630')]
[2026-01-26 13:51:23,055][144664] Fps is (10 sec: 3277.4, 60 sec: 3276.9, 300 sec: 3474.0). Total num frames: 1785856. Throughput: 0: 3338.4. Samples: 1789440. Policy #0 lag: (min: 4.0, avg: 7.0, max: 68.0)
[2026-01-26 13:51:23,055][144664] Avg episode reward: [(0, '432.968')]
[2026-01-26 13:51:23,199][144664] Saving new best policy, reward=432.968!
[2026-01-26 13:51:28,078][144664] Fps is (10 sec: 3278.9, 60 sec: 3279.3, 300 sec: 3446.2). Total num frames: 1802240. Throughput: 0: 3370.2. Samples: 1810432. Policy #0 lag: (min: 4.0, avg: 7.0, max: 68.0)
[2026-01-26 13:51:28,079][144664] Avg episode reward: [(0, '437.324')]
[2026-01-26 13:51:28,213][144664] Saving new best policy, reward=437.324!
[2026-01-26 13:51:33,070][144664] Fps is (10 sec: 3271.8, 60 sec: 3274.9, 300 sec: 3443.8). Total num frames: 1818624. Throughput: 0: 3341.5. Samples: 1819648. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 13:51:33,071][144664] Avg episode reward: [(0, '442.539')]
[2026-01-26 13:51:33,220][144664] Saving new best policy, reward=442.539!
[2026-01-26 13:51:38,024][144664] Fps is (10 sec: 3294.8, 60 sec: 3282.0, 300 sec: 3443.1). Total num frames: 1835008. Throughput: 0: 3405.9. Samples: 1841152. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 13:51:38,024][144664] Avg episode reward: [(0, '456.589')]
[2026-01-26 13:51:38,166][144664] Saving new best policy, reward=456.589!
[2026-01-26 13:51:43,070][144664] Fps is (10 sec: 3276.9, 60 sec: 3279.0, 300 sec: 3443.8). Total num frames: 1851392. Throughput: 0: 3493.1. Samples: 1862144. Policy #0 lag: (min: 1.0, avg: 4.0, max: 65.0)
[2026-01-26 13:51:43,070][144664] Avg episode reward: [(0, '465.370')]
[2026-01-26 13:51:43,220][144664] Saving new best policy, reward=465.370!
[2026-01-26 13:51:48,074][144664] Fps is (10 sec: 3260.3, 60 sec: 3274.0, 300 sec: 3443.8). Total num frames: 1867776. Throughput: 0: 3458.4. Samples: 1871872. Policy #0 lag: (min: 1.0, avg: 4.0, max: 65.0)
[2026-01-26 13:51:48,074][144664] Avg episode reward: [(0, '471.987')]
[2026-01-26 13:51:48,214][144664] Saving new best policy, reward=471.987!
[2026-01-26 13:51:53,099][144664] Fps is (10 sec: 3267.6, 60 sec: 3275.6, 300 sec: 3443.6). Total num frames: 1884160. Throughput: 0: 3428.3. Samples: 1892352. Policy #0 lag: (min: 5.0, avg: 8.0, max: 69.0)
[2026-01-26 13:51:53,099][144664] Avg episode reward: [(0, '459.973')]
[2026-01-26 13:51:58,042][144664] Fps is (10 sec: 3287.4, 60 sec: 3278.4, 300 sec: 3443.4). Total num frames: 1900544. Throughput: 0: 3460.0. Samples: 1913344. Policy #0 lag: (min: 5.0, avg: 8.0, max: 69.0)
[2026-01-26 13:51:58,042][144664] Avg episode reward: [(0, '461.742')]
[2026-01-26 13:51:58,943][144664] Signal inference workers to stop experience collection... (350 times)
[2026-01-26 13:51:59,303][144664] InferenceWorker_p0-w0: stopping experience collection (350 times)
[2026-01-26 13:51:59,303][144664] Signal inference workers to resume experience collection... (350 times)
[2026-01-26 13:51:59,303][144664] InferenceWorker_p0-w0: resuming experience collection (350 times)
[2026-01-26 13:52:03,003][144664] Fps is (10 sec: 3308.5, 60 sec: 3280.4, 300 sec: 3444.7). Total num frames: 1916928. Throughput: 0: 3419.6. Samples: 1923072. Policy #0 lag: (min: 7.0, avg: 10.0, max: 71.0)
[2026-01-26 13:52:03,003][144664] Avg episode reward: [(0, '463.822')]
[2026-01-26 13:52:03,148][144664] Saving /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_accel_policy1_26012026/checkpoint_p0/checkpoint_000007488_1916928.pth...
[2026-01-26 13:52:03,152][144664] Removing /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_accel_policy1_26012026/checkpoint_p0/checkpoint_000004288_1097728.pth
[2026-01-26 13:52:08,042][144664] Fps is (10 sec: 3277.0, 60 sec: 3274.3, 300 sec: 3444.1). Total num frames: 1933312. Throughput: 0: 3437.1. Samples: 1944064. Policy #0 lag: (min: 7.0, avg: 10.0, max: 71.0)
[2026-01-26 13:52:08,042][144664] Avg episode reward: [(0, '457.713')]
[2026-01-26 13:52:13,058][144664] Fps is (10 sec: 3258.6, 60 sec: 3276.7, 300 sec: 3443.3). Total num frames: 1949696. Throughput: 0: 3426.2. Samples: 1964544. Policy #0 lag: (min: 8.0, avg: 11.0, max: 72.0)
[2026-01-26 13:52:13,059][144664] Avg episode reward: [(0, '450.695')]
[2026-01-26 13:52:18,158][144664] Fps is (10 sec: 4048.9, 60 sec: 3409.2, 300 sec: 3470.3). Total num frames: 1974272. Throughput: 0: 3429.4. Samples: 1974272. Policy #0 lag: (min: 5.0, avg: 8.0, max: 69.0)
[2026-01-26 13:52:18,158][144664] Avg episode reward: [(0, '459.779')]
[2026-01-26 13:52:23,000][144664] Fps is (10 sec: 4120.2, 60 sec: 3416.5, 300 sec: 3443.7). Total num frames: 1990656. Throughput: 0: 3426.5. Samples: 1995264. Policy #0 lag: (min: 5.0, avg: 8.0, max: 69.0)
[2026-01-26 13:52:23,000][144664] Avg episode reward: [(0, '475.834')]
[2026-01-26 13:52:23,454][144664] Saving new best policy, reward=475.834!
[2026-01-26 13:52:28,289][144664] Fps is (10 sec: 4043.0, 60 sec: 3537.4, 300 sec: 3440.1). Total num frames: 2015232. Throughput: 0: 3396.8. Samples: 2015744. Policy #0 lag: (min: 0.0, avg: 3.0, max: 64.0)
[2026-01-26 13:52:28,289][144664] Avg episode reward: [(0, '493.125')]
[2026-01-26 13:52:28,290][144664] Saving new best policy, reward=493.125!
[2026-01-26 13:52:33,165][144664] Fps is (10 sec: 4029.6, 60 sec: 3544.3, 300 sec: 3442.9). Total num frames: 2031616. Throughput: 0: 3395.1. Samples: 2024960. Policy #0 lag: (min: 0.0, avg: 3.0, max: 64.0)
[2026-01-26 13:52:33,165][144664] Avg episode reward: [(0, '498.842')]
[2026-01-26 13:52:33,168][144664] Saving new best policy, reward=498.842!
[2026-01-26 13:52:38,030][144664] Fps is (10 sec: 3364.1, 60 sec: 3549.5, 300 sec: 3443.8). Total num frames: 2048000. Throughput: 0: 3407.2. Samples: 2045440. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 13:52:38,030][144664] Avg episode reward: [(0, '501.126')]
[2026-01-26 13:52:38,030][144664] Saving new best policy, reward=501.126!
[2026-01-26 13:52:43,076][144664] Fps is (10 sec: 3305.9, 60 sec: 3549.5, 300 sec: 3443.8). Total num frames: 2064384. Throughput: 0: 3376.6. Samples: 2065408. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 13:52:43,077][144664] Avg episode reward: [(0, '505.205')]
[2026-01-26 13:52:43,218][144664] Saving new best policy, reward=505.205!
[2026-01-26 13:52:48,072][144664] Fps is (10 sec: 3262.9, 60 sec: 3550.0, 300 sec: 3443.0). Total num frames: 2080768. Throughput: 0: 3408.1. Samples: 2076672. Policy #0 lag: (min: 1.0, avg: 4.0, max: 65.0)
[2026-01-26 13:52:48,072][144664] Avg episode reward: [(0, '513.529')]
[2026-01-26 13:52:48,209][144664] Saving new best policy, reward=513.529!
[2026-01-26 13:52:53,003][144664] Fps is (10 sec: 3301.0, 60 sec: 3555.5, 300 sec: 3444.0). Total num frames: 2097152. Throughput: 0: 3427.6. Samples: 2098176. Policy #0 lag: (min: 1.0, avg: 4.0, max: 65.0)
[2026-01-26 13:52:53,003][144664] Avg episode reward: [(0, '516.301')]
[2026-01-26 13:52:53,149][144664] Saving new best policy, reward=516.301!
[2026-01-26 13:52:58,038][144664] Fps is (10 sec: 3287.9, 60 sec: 3550.1, 300 sec: 3443.5). Total num frames: 2113536. Throughput: 0: 3403.5. Samples: 2117632. Policy #0 lag: (min: 13.0, avg: 16.0, max: 77.0)
[2026-01-26 13:52:58,039][144664] Avg episode reward: [(0, '538.817')]
[2026-01-26 13:52:58,180][144664] Saving new best policy, reward=538.817!
[2026-01-26 13:53:03,021][144664] Fps is (10 sec: 3271.0, 60 sec: 3548.8, 300 sec: 3444.1). Total num frames: 2129920. Throughput: 0: 3458.0. Samples: 2129408. Policy #0 lag: (min: 13.0, avg: 16.0, max: 77.0)
[2026-01-26 13:53:03,021][144664] Avg episode reward: [(0, '536.927')]
[2026-01-26 13:53:08,096][144664] Fps is (10 sec: 3257.9, 60 sec: 3546.6, 300 sec: 3443.5). Total num frames: 2146304. Throughput: 0: 3406.0. Samples: 2148864. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 13:53:08,096][144664] Avg episode reward: [(0, '549.867')]
[2026-01-26 13:53:08,235][144664] Saving new best policy, reward=549.867!
[2026-01-26 13:53:13,080][144664] Fps is (10 sec: 3257.4, 60 sec: 3548.6, 300 sec: 3442.9). Total num frames: 2162688. Throughput: 0: 3463.5. Samples: 2170880. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 13:53:13,081][144664] Avg episode reward: [(0, '549.919')]
[2026-01-26 13:53:13,215][144664] Saving new best policy, reward=549.919!
[2026-01-26 13:53:18,050][144664] Fps is (10 sec: 3292.2, 60 sec: 3419.5, 300 sec: 3443.7). Total num frames: 2179072. Throughput: 0: 3456.3. Samples: 2180096. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 13:53:18,050][144664] Avg episode reward: [(0, '558.229')]
[2026-01-26 13:53:18,193][144664] Saving new best policy, reward=558.229!
[2026-01-26 13:53:19,990][144664] Signal inference workers to stop experience collection... (400 times)
[2026-01-26 13:53:19,990][144664] Signal inference workers to resume experience collection... (400 times)
[2026-01-26 13:53:20,244][144664] InferenceWorker_p0-w0: stopping experience collection (400 times)
[2026-01-26 13:53:20,244][144664] InferenceWorker_p0-w0: resuming experience collection (400 times)
[2026-01-26 13:53:23,130][144664] Fps is (10 sec: 3260.7, 60 sec: 3405.9, 300 sec: 3442.4). Total num frames: 2195456. Throughput: 0: 3462.5. Samples: 2201600. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 13:53:23,130][144664] Avg episode reward: [(0, '558.399')]
[2026-01-26 13:53:23,136][144664] Saving new best policy, reward=558.399!
[2026-01-26 13:53:28,025][144664] Fps is (10 sec: 3284.8, 60 sec: 3291.3, 300 sec: 3417.2). Total num frames: 2211840. Throughput: 0: 3485.6. Samples: 2222080. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 13:53:28,025][144664] Avg episode reward: [(0, '557.069')]
[2026-01-26 13:53:33,006][144664] Fps is (10 sec: 3318.1, 60 sec: 3285.5, 300 sec: 3389.6). Total num frames: 2228224. Throughput: 0: 3464.0. Samples: 2232320. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 13:53:33,006][144664] Avg episode reward: [(0, '570.803')]
[2026-01-26 13:53:33,145][144664] Saving new best policy, reward=570.803!
[2026-01-26 13:53:38,037][144664] Fps is (10 sec: 3273.0, 60 sec: 3276.4, 300 sec: 3388.5). Total num frames: 2244608. Throughput: 0: 3467.6. Samples: 2254336. Policy #0 lag: (min: 2.0, avg: 5.0, max: 66.0)
[2026-01-26 13:53:38,037][144664] Avg episode reward: [(0, '591.040')]
[2026-01-26 13:53:38,168][144664] Saving new best policy, reward=591.040!
[2026-01-26 13:53:43,089][144664] Fps is (10 sec: 3249.7, 60 sec: 3276.1, 300 sec: 3387.1). Total num frames: 2260992. Throughput: 0: 3511.8. Samples: 2275840. Policy #0 lag: (min: 2.0, avg: 5.0, max: 66.0)
[2026-01-26 13:53:43,089][144664] Avg episode reward: [(0, '594.851')]
[2026-01-26 13:53:43,467][144664] Saving new best policy, reward=594.851!
[2026-01-26 13:53:48,212][144664] Fps is (10 sec: 4025.6, 60 sec: 3405.4, 300 sec: 3414.2). Total num frames: 2285568. Throughput: 0: 3455.6. Samples: 2285568. Policy #0 lag: (min: 14.0, avg: 17.0, max: 78.0)
[2026-01-26 13:53:48,212][144664] Avg episode reward: [(0, '593.426')]
[2026-01-26 13:53:53,140][144664] Fps is (10 sec: 4890.2, 60 sec: 3541.8, 300 sec: 3442.2). Total num frames: 2310144. Throughput: 0: 3512.3. Samples: 2307072. Policy #0 lag: (min: 10.0, avg: 13.0, max: 74.0)
[2026-01-26 13:53:53,140][144664] Avg episode reward: [(0, '591.650')]
[2026-01-26 13:53:58,073][144664] Fps is (10 sec: 4153.8, 60 sec: 3547.8, 300 sec: 3444.0). Total num frames: 2326528. Throughput: 0: 3482.2. Samples: 2327552. Policy #0 lag: (min: 10.0, avg: 13.0, max: 74.0)
[2026-01-26 13:53:58,073][144664] Avg episode reward: [(0, '598.482')]
[2026-01-26 13:53:58,203][144664] Saving new best policy, reward=598.482!
[2026-01-26 13:54:03,009][144664] Fps is (10 sec: 3320.2, 60 sec: 3550.6, 300 sec: 3444.3). Total num frames: 2342912. Throughput: 0: 3541.7. Samples: 2339328. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 13:54:03,009][144664] Avg episode reward: [(0, '597.346')]
[2026-01-26 13:54:03,148][144664] Saving /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_accel_policy1_26012026/checkpoint_p0/checkpoint_000009152_2342912.pth...
[2026-01-26 13:54:03,151][144664] Removing /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_accel_policy1_26012026/checkpoint_p0/checkpoint_000005952_1523712.pth
[2026-01-26 13:54:08,114][144664] Fps is (10 sec: 3263.3, 60 sec: 3548.8, 300 sec: 3443.1). Total num frames: 2359296. Throughput: 0: 3528.4. Samples: 2360320. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 13:54:08,114][144664] Avg episode reward: [(0, '617.471')]
[2026-01-26 13:54:08,245][144664] Saving new best policy, reward=617.471!
[2026-01-26 13:54:13,022][144664] Fps is (10 sec: 3272.7, 60 sec: 3553.3, 300 sec: 3444.3). Total num frames: 2375680. Throughput: 0: 3527.4. Samples: 2380800. Policy #0 lag: (min: 5.0, avg: 8.0, max: 69.0)
[2026-01-26 13:54:13,022][144664] Avg episode reward: [(0, '618.191')]
[2026-01-26 13:54:13,159][144664] Saving new best policy, reward=618.191!
[2026-01-26 13:54:18,092][144664] Fps is (10 sec: 3283.8, 60 sec: 3547.3, 300 sec: 3442.7). Total num frames: 2392064. Throughput: 0: 3554.4. Samples: 2392576. Policy #0 lag: (min: 5.0, avg: 8.0, max: 69.0)
[2026-01-26 13:54:18,093][144664] Avg episode reward: [(0, '622.821')]
[2026-01-26 13:54:18,229][144664] Saving new best policy, reward=622.821!
[2026-01-26 13:54:23,096][144664] Fps is (10 sec: 3252.8, 60 sec: 3551.9, 300 sec: 3442.7). Total num frames: 2408448. Throughput: 0: 3499.8. Samples: 2412032. Policy #0 lag: (min: 10.0, avg: 13.0, max: 74.0)
[2026-01-26 13:54:23,096][144664] Avg episode reward: [(0, '609.231')]
[2026-01-26 13:54:28,006][144664] Fps is (10 sec: 3305.3, 60 sec: 3551.0, 300 sec: 3444.5). Total num frames: 2424832. Throughput: 0: 3522.2. Samples: 2434048. Policy #0 lag: (min: 10.0, avg: 13.0, max: 74.0)
[2026-01-26 13:54:28,007][144664] Avg episode reward: [(0, '621.253')]
[2026-01-26 13:54:33,050][144664] Fps is (10 sec: 3291.7, 60 sec: 3547.2, 300 sec: 3443.1). Total num frames: 2441216. Throughput: 0: 3528.4. Samples: 2443776. Policy #0 lag: (min: 6.0, avg: 9.0, max: 70.0)
[2026-01-26 13:54:33,051][144664] Avg episode reward: [(0, '626.426')]
[2026-01-26 13:54:33,187][144664] Saving new best policy, reward=626.426!
[2026-01-26 13:54:38,120][144664] Fps is (10 sec: 3239.9, 60 sec: 3544.9, 300 sec: 3415.7). Total num frames: 2457600. Throughput: 0: 3528.7. Samples: 2465792. Policy #0 lag: (min: 6.0, avg: 9.0, max: 70.0)
[2026-01-26 13:54:38,120][144664] Avg episode reward: [(0, '638.243')]
[2026-01-26 13:54:38,271][144664] Saving new best policy, reward=638.243!
[2026-01-26 13:54:38,830][144664] Signal inference workers to stop experience collection... (450 times)
[2026-01-26 13:54:39,216][144664] InferenceWorker_p0-w0: stopping experience collection (450 times)
[2026-01-26 13:54:39,218][144664] Signal inference workers to resume experience collection... (450 times)
[2026-01-26 13:54:39,384][144664] InferenceWorker_p0-w0: resuming experience collection (450 times)
[2026-01-26 13:54:43,003][144664] Fps is (10 sec: 3292.3, 60 sec: 3554.9, 300 sec: 3390.8). Total num frames: 2473984. Throughput: 0: 3532.6. Samples: 2486272. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 13:54:43,004][144664] Avg episode reward: [(0, '639.619')]
[2026-01-26 13:54:43,164][144664] Saving new best policy, reward=639.619!
[2026-01-26 13:54:48,093][144664] Fps is (10 sec: 3285.8, 60 sec: 3420.1, 300 sec: 3390.6). Total num frames: 2490368. Throughput: 0: 3463.8. Samples: 2495488. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 13:54:48,093][144664] Avg episode reward: [(0, '646.633')]
[2026-01-26 13:54:48,238][144664] Saving new best policy, reward=646.633!
[2026-01-26 13:54:53,062][144664] Fps is (10 sec: 3257.6, 60 sec: 3281.1, 300 sec: 3389.4). Total num frames: 2506752. Throughput: 0: 3474.2. Samples: 2516480. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 13:54:53,062][144664] Avg episode reward: [(0, '673.946')]
[2026-01-26 13:54:53,202][144664] Saving new best policy, reward=673.946!
[2026-01-26 13:54:58,059][144664] Fps is (10 sec: 3288.0, 60 sec: 3277.5, 300 sec: 3387.3). Total num frames: 2523136. Throughput: 0: 3478.7. Samples: 2537472. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 13:54:58,059][144664] Avg episode reward: [(0, '684.738')]
[2026-01-26 13:54:58,204][144664] Saving new best policy, reward=684.738!
[2026-01-26 13:55:03,267][144664] Fps is (10 sec: 4013.9, 60 sec: 3398.7, 300 sec: 3413.1). Total num frames: 2547712. Throughput: 0: 3422.8. Samples: 2547200. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 13:55:03,267][144664] Avg episode reward: [(0, '685.068')]
[2026-01-26 13:55:03,641][144664] Saving new best policy, reward=685.068!
[2026-01-26 13:55:08,146][144664] Fps is (10 sec: 4060.7, 60 sec: 3411.5, 300 sec: 3415.0). Total num frames: 2564096. Throughput: 0: 3466.4. Samples: 2568192. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 13:55:08,146][144664] Avg episode reward: [(0, '671.867')]
[2026-01-26 13:55:13,194][144664] Fps is (10 sec: 4126.0, 60 sec: 3539.7, 300 sec: 3441.5). Total num frames: 2588672. Throughput: 0: 3433.1. Samples: 2589184. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 13:55:13,194][144664] Avg episode reward: [(0, '672.066')]
[2026-01-26 13:55:18,017][144664] Fps is (10 sec: 4149.6, 60 sec: 3554.4, 300 sec: 3443.9). Total num frames: 2605056. Throughput: 0: 3461.4. Samples: 2599424. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 13:55:18,017][144664] Avg episode reward: [(0, '660.019')]
[2026-01-26 13:55:23,052][144664] Fps is (10 sec: 3324.0, 60 sec: 3552.4, 300 sec: 3444.2). Total num frames: 2621440. Throughput: 0: 3429.9. Samples: 2619904. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 13:55:23,052][144664] Avg episode reward: [(0, '663.275')]
[2026-01-26 13:55:28,123][144664] Fps is (10 sec: 3242.2, 60 sec: 3543.0, 300 sec: 3442.4). Total num frames: 2637824. Throughput: 0: 3404.2. Samples: 2639872. Policy #0 lag: (min: 0.0, avg: 3.0, max: 64.0)
[2026-01-26 13:55:28,124][144664] Avg episode reward: [(0, '685.218')]
[2026-01-26 13:55:28,269][144664] Saving new best policy, reward=685.218!
[2026-01-26 13:55:33,023][144664] Fps is (10 sec: 3286.3, 60 sec: 3551.5, 300 sec: 3444.5). Total num frames: 2654208. Throughput: 0: 3464.2. Samples: 2651136. Policy #0 lag: (min: 0.0, avg: 3.0, max: 64.0)
[2026-01-26 13:55:33,024][144664] Avg episode reward: [(0, '689.629')]
[2026-01-26 13:55:33,163][144664] Saving new best policy, reward=689.629!
[2026-01-26 13:55:38,044][144664] Fps is (10 sec: 3303.0, 60 sec: 3554.4, 300 sec: 3444.2). Total num frames: 2670592. Throughput: 0: 3448.9. Samples: 2671616. Policy #0 lag: (min: 8.0, avg: 11.0, max: 72.0)
[2026-01-26 13:55:38,044][144664] Avg episode reward: [(0, '699.483')]
[2026-01-26 13:55:38,186][144664] Saving new best policy, reward=699.483!
[2026-01-26 13:55:43,036][144664] Fps is (10 sec: 3272.7, 60 sec: 3547.9, 300 sec: 3443.3). Total num frames: 2686976. Throughput: 0: 3449.2. Samples: 2692608. Policy #0 lag: (min: 8.0, avg: 11.0, max: 72.0)
[2026-01-26 13:55:43,036][144664] Avg episode reward: [(0, '720.022')]
[2026-01-26 13:55:43,168][144664] Saving new best policy, reward=720.022!
[2026-01-26 13:55:48,113][144664] Fps is (10 sec: 3254.6, 60 sec: 3548.7, 300 sec: 3443.0). Total num frames: 2703360. Throughput: 0: 3493.6. Samples: 2703872. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 13:55:48,113][144664] Avg episode reward: [(0, '730.266')]
[2026-01-26 13:55:48,254][144664] Saving new best policy, reward=730.266!
[2026-01-26 13:55:53,082][144664] Fps is (10 sec: 3261.8, 60 sec: 3548.7, 300 sec: 3443.3). Total num frames: 2719744. Throughput: 0: 3452.4. Samples: 2723328. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 13:55:53,082][144664] Avg episode reward: [(0, '731.469')]
[2026-01-26 13:55:53,220][144664] Saving new best policy, reward=731.469!
[2026-01-26 13:55:55,359][144664] Signal inference workers to stop experience collection... (500 times)
[2026-01-26 13:55:55,706][144664] InferenceWorker_p0-w0: stopping experience collection (500 times)
[2026-01-26 13:55:55,706][144664] Signal inference workers to resume experience collection... (500 times)
[2026-01-26 13:55:55,706][144664] InferenceWorker_p0-w0: resuming experience collection (500 times)
[2026-01-26 13:55:58,041][144664] Fps is (10 sec: 3300.4, 60 sec: 3550.9, 300 sec: 3443.7). Total num frames: 2736128. Throughput: 0: 3470.7. Samples: 2744832. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 13:55:58,041][144664] Avg episode reward: [(0, '711.519')]
[2026-01-26 13:56:03,040][144664] Fps is (10 sec: 3290.6, 60 sec: 3426.3, 300 sec: 3442.9). Total num frames: 2752512. Throughput: 0: 3445.7. Samples: 2754560. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 13:56:03,040][144664] Avg episode reward: [(0, '690.885')]
[2026-01-26 13:56:03,183][144664] Saving /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_accel_policy1_26012026/checkpoint_p0/checkpoint_000010752_2752512.pth...
[2026-01-26 13:56:03,186][144664] Removing /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_accel_policy1_26012026/checkpoint_p0/checkpoint_000007488_1916928.pth
[2026-01-26 13:56:08,080][144664] Fps is (10 sec: 3264.0, 60 sec: 3417.1, 300 sec: 3443.2). Total num frames: 2768896. Throughput: 0: 3468.1. Samples: 2776064. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 13:56:08,080][144664] Avg episode reward: [(0, '671.945')]
[2026-01-26 13:56:13,061][144664] Fps is (10 sec: 3269.8, 60 sec: 3284.1, 300 sec: 3443.7). Total num frames: 2785280. Throughput: 0: 3497.8. Samples: 2797056. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 13:56:13,062][144664] Avg episode reward: [(0, '681.579')]
[2026-01-26 13:56:18,064][144664] Fps is (10 sec: 3282.1, 60 sec: 3274.2, 300 sec: 3443.3). Total num frames: 2801664. Throughput: 0: 3455.7. Samples: 2806784. Policy #0 lag: (min: 12.0, avg: 15.0, max: 76.0)
[2026-01-26 13:56:18,064][144664] Avg episode reward: [(0, '711.534')]
[2026-01-26 13:56:23,074][144664] Fps is (10 sec: 3272.8, 60 sec: 3275.6, 300 sec: 3443.5). Total num frames: 2818048. Throughput: 0: 3490.7. Samples: 2828800. Policy #0 lag: (min: 12.0, avg: 15.0, max: 76.0)
[2026-01-26 13:56:23,074][144664] Avg episode reward: [(0, '729.279')]
[2026-01-26 13:56:28,257][144664] Fps is (10 sec: 4018.6, 60 sec: 3405.8, 300 sec: 3469.0). Total num frames: 2842624. Throughput: 0: 3475.9. Samples: 2849792. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 13:56:28,257][144664] Avg episode reward: [(0, '742.135')]
[2026-01-26 13:56:28,620][144664] Saving new best policy, reward=742.135!
[2026-01-26 13:56:33,091][144664] Fps is (10 sec: 4088.8, 60 sec: 3409.5, 300 sec: 3470.4). Total num frames: 2859008. Throughput: 0: 3460.5. Samples: 2859520. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 13:56:33,091][144664] Avg episode reward: [(0, '744.963')]
[2026-01-26 13:56:33,458][144664] Saving new best policy, reward=744.963!
[2026-01-26 13:56:38,282][144664] Fps is (10 sec: 4085.5, 60 sec: 3535.8, 300 sec: 3496.4). Total num frames: 2883584. Throughput: 0: 3466.2. Samples: 2880000. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 13:56:38,283][144664] Avg episode reward: [(0, '769.497')]
[2026-01-26 13:56:38,283][144664] Saving new best policy, reward=769.497!
[2026-01-26 13:56:43,047][144664] Fps is (10 sec: 4114.3, 60 sec: 3549.2, 300 sec: 3499.3). Total num frames: 2899968. Throughput: 0: 3469.8. Samples: 2900992. Policy #0 lag: (min: 3.0, avg: 6.0, max: 67.0)
[2026-01-26 13:56:43,047][144664] Avg episode reward: [(0, '763.903')]
[2026-01-26 13:56:48,034][144664] Fps is (10 sec: 3360.1, 60 sec: 3554.5, 300 sec: 3499.7). Total num frames: 2916352. Throughput: 0: 3470.7. Samples: 2910720. Policy #0 lag: (min: 3.0, avg: 6.0, max: 67.0)
[2026-01-26 13:56:48,035][144664] Avg episode reward: [(0, '754.659')]
[2026-01-26 13:56:53,043][144664] Fps is (10 sec: 3278.1, 60 sec: 3552.2, 300 sec: 3499.0). Total num frames: 2932736. Throughput: 0: 3439.0. Samples: 2930688. Policy #0 lag: (min: 9.0, avg: 12.0, max: 73.0)
[2026-01-26 13:56:53,043][144664] Avg episode reward: [(0, '744.746')]
[2026-01-26 13:56:58,063][144664] Fps is (10 sec: 3267.5, 60 sec: 3548.6, 300 sec: 3498.2). Total num frames: 2949120. Throughput: 0: 3401.8. Samples: 2950144. Policy #0 lag: (min: 9.0, avg: 12.0, max: 73.0)
[2026-01-26 13:56:58,063][144664] Avg episode reward: [(0, '760.398')]
[2026-01-26 13:57:03,077][144664] Fps is (10 sec: 3265.5, 60 sec: 3547.7, 300 sec: 3498.5). Total num frames: 2965504. Throughput: 0: 3401.0. Samples: 2959872. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 13:57:03,078][144664] Avg episode reward: [(0, '762.367')]
[2026-01-26 13:57:08,022][144664] Fps is (10 sec: 3290.4, 60 sec: 3553.3, 300 sec: 3499.4). Total num frames: 2981888. Throughput: 0: 3394.5. Samples: 2981376. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 13:57:08,022][144664] Avg episode reward: [(0, '766.258')]
[2026-01-26 13:57:13,036][144664] Fps is (10 sec: 3290.2, 60 sec: 3551.3, 300 sec: 3472.6). Total num frames: 2998272. Throughput: 0: 3372.9. Samples: 3000832. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 13:57:13,037][144664] Avg episode reward: [(0, '779.494')]
[2026-01-26 13:57:13,183][144664] Saving new best policy, reward=779.494!
[2026-01-26 13:57:16,703][144664] Signal inference workers to stop experience collection... (550 times)
[2026-01-26 13:57:16,703][144664] Signal inference workers to resume experience collection... (550 times)
[2026-01-26 13:57:16,959][144664] InferenceWorker_p0-w0: stopping experience collection (550 times)
[2026-01-26 13:57:16,959][144664] InferenceWorker_p0-w0: resuming experience collection (550 times)
[2026-01-26 13:57:18,034][144664] Fps is (10 sec: 3272.7, 60 sec: 3551.6, 300 sec: 3470.8). Total num frames: 3014656. Throughput: 0: 3394.9. Samples: 3012096. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 13:57:18,034][144664] Avg episode reward: [(0, '775.317')]
[2026-01-26 13:57:23,066][144664] Fps is (10 sec: 3267.1, 60 sec: 3550.3, 300 sec: 3446.0). Total num frames: 3031040. Throughput: 0: 3395.5. Samples: 3032064. Policy #0 lag: (min: 7.0, avg: 10.0, max: 71.0)
[2026-01-26 13:57:23,066][144664] Avg episode reward: [(0, '790.120')]
[2026-01-26 13:57:23,208][144664] Saving new best policy, reward=790.120!
[2026-01-26 13:57:28,109][144664] Fps is (10 sec: 3252.5, 60 sec: 3421.7, 300 sec: 3444.1). Total num frames: 3047424. Throughput: 0: 3363.2. Samples: 3052544. Policy #0 lag: (min: 7.0, avg: 10.0, max: 71.0)
[2026-01-26 13:57:28,109][144664] Avg episode reward: [(0, '812.380')]
[2026-01-26 13:57:28,243][144664] Saving new best policy, reward=812.380!
[2026-01-26 13:57:33,020][144664] Fps is (10 sec: 3291.8, 60 sec: 3417.4, 300 sec: 3443.5). Total num frames: 3063808. Throughput: 0: 3403.0. Samples: 3063808. Policy #0 lag: (min: 8.0, avg: 11.0, max: 72.0)
[2026-01-26 13:57:33,021][144664] Avg episode reward: [(0, '849.913')]
[2026-01-26 13:57:33,161][144664] Saving new best policy, reward=849.913!
[2026-01-26 13:57:38,041][144664] Fps is (10 sec: 3299.1, 60 sec: 3290.0, 300 sec: 3443.8). Total num frames: 3080192. Throughput: 0: 3413.4. Samples: 3084288. Policy #0 lag: (min: 8.0, avg: 11.0, max: 72.0)
[2026-01-26 13:57:38,042][144664] Avg episode reward: [(0, '848.719')]
[2026-01-26 13:57:43,084][144664] Fps is (10 sec: 3256.1, 60 sec: 3274.8, 300 sec: 3443.3). Total num frames: 3096576. Throughput: 0: 3457.2. Samples: 3105792. Policy #0 lag: (min: 10.0, avg: 13.0, max: 74.0)
[2026-01-26 13:57:43,084][144664] Avg episode reward: [(0, '819.488')]
[2026-01-26 13:57:48,097][144664] Fps is (10 sec: 3258.7, 60 sec: 3273.4, 300 sec: 3442.3). Total num frames: 3112960. Throughput: 0: 3457.3. Samples: 3115520. Policy #0 lag: (min: 10.0, avg: 13.0, max: 74.0)
[2026-01-26 13:57:48,097][144664] Avg episode reward: [(0, '828.973')]
[2026-01-26 13:57:53,107][144664] Fps is (10 sec: 3269.4, 60 sec: 3273.3, 300 sec: 3442.6). Total num frames: 3129344. Throughput: 0: 3463.7. Samples: 3137536. Policy #0 lag: (min: 11.0, avg: 14.0, max: 75.0)
[2026-01-26 13:57:53,107][144664] Avg episode reward: [(0, '833.494')]
[2026-01-26 13:57:58,031][144664] Fps is (10 sec: 3298.7, 60 sec: 3278.6, 300 sec: 3443.3). Total num frames: 3145728. Throughput: 0: 3516.2. Samples: 3159040. Policy #0 lag: (min: 11.0, avg: 14.0, max: 75.0)
[2026-01-26 13:57:58,031][144664] Avg episode reward: [(0, '829.868')]
[2026-01-26 13:58:03,060][144664] Fps is (10 sec: 3292.0, 60 sec: 3277.7, 300 sec: 3443.8). Total num frames: 3162112. Throughput: 0: 3491.0. Samples: 3169280. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 13:58:03,060][144664] Avg episode reward: [(0, '812.785')]
[2026-01-26 13:58:03,432][144664] Saving /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_accel_policy1_26012026/checkpoint_p0/checkpoint_000012384_3170304.pth...
[2026-01-26 13:58:03,437][144664] Removing /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_accel_policy1_26012026/checkpoint_p0/checkpoint_000009152_2342912.pth
[2026-01-26 13:58:08,116][144664] Fps is (10 sec: 4061.2, 60 sec: 3408.0, 300 sec: 3470.8). Total num frames: 3186688. Throughput: 0: 3523.2. Samples: 3190784. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 13:58:08,116][144664] Avg episode reward: [(0, '813.331')]
[2026-01-26 13:58:13,154][144664] Fps is (10 sec: 4869.4, 60 sec: 3542.9, 300 sec: 3497.7). Total num frames: 3211264. Throughput: 0: 3546.3. Samples: 3212288. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 13:58:13,155][144664] Avg episode reward: [(0, '840.737')]
[2026-01-26 13:58:18,117][144664] Fps is (10 sec: 4095.6, 60 sec: 3545.0, 300 sec: 3499.1). Total num frames: 3227648. Throughput: 0: 3508.2. Samples: 3222016. Policy #0 lag: (min: 31.0, avg: 34.0, max: 95.0)
[2026-01-26 13:58:18,117][144664] Avg episode reward: [(0, '836.946')]
[2026-01-26 13:58:23,011][144664] Fps is (10 sec: 3324.4, 60 sec: 3553.1, 300 sec: 3499.1). Total num frames: 3244032. Throughput: 0: 3529.5. Samples: 3243008. Policy #0 lag: (min: 31.0, avg: 34.0, max: 95.0)
[2026-01-26 13:58:23,011][144664] Avg episode reward: [(0, '847.595')]
[2026-01-26 13:58:27,997][144664] Fps is (10 sec: 3316.5, 60 sec: 3556.5, 300 sec: 3499.1). Total num frames: 3260416. Throughput: 0: 3488.3. Samples: 3262464. Policy #0 lag: (min: 31.0, avg: 34.0, max: 95.0)
[2026-01-26 13:58:27,998][144664] Avg episode reward: [(0, '865.004')]
[2026-01-26 13:58:28,133][144664] Saving new best policy, reward=865.004!
[2026-01-26 13:58:33,101][144664] Fps is (10 sec: 3247.6, 60 sec: 3545.1, 300 sec: 3498.2). Total num frames: 3276800. Throughput: 0: 3526.8. Samples: 3274240. Policy #0 lag: (min: 31.0, avg: 34.0, max: 95.0)
[2026-01-26 13:58:33,101][144664] Avg episode reward: [(0, '879.396')]
[2026-01-26 13:58:33,247][144664] Saving new best policy, reward=879.396!
[2026-01-26 13:58:35,991][144664] Signal inference workers to stop experience collection... (600 times)
[2026-01-26 13:58:36,339][144664] InferenceWorker_p0-w0: stopping experience collection (600 times)
[2026-01-26 13:58:36,341][144664] Signal inference workers to resume experience collection... (600 times)
[2026-01-26 13:58:36,469][144664] InferenceWorker_p0-w0: resuming experience collection (600 times)
[2026-01-26 13:58:38,025][144664] Fps is (10 sec: 3268.0, 60 sec: 3550.9, 300 sec: 3499.7). Total num frames: 3293184. Throughput: 0: 3488.0. Samples: 3294208. Policy #0 lag: (min: 47.0, avg: 50.0, max: 111.0)
[2026-01-26 13:58:38,025][144664] Avg episode reward: [(0, '895.599')]
[2026-01-26 13:58:38,158][144664] Saving new best policy, reward=895.599!
[2026-01-26 13:58:43,064][144664] Fps is (10 sec: 3288.8, 60 sec: 3551.0, 300 sec: 3472.9). Total num frames: 3309568. Throughput: 0: 3479.0. Samples: 3315712. Policy #0 lag: (min: 47.0, avg: 50.0, max: 111.0)
[2026-01-26 13:58:43,065][144664] Avg episode reward: [(0, '892.069')]
[2026-01-26 13:58:48,118][144664] Fps is (10 sec: 3246.4, 60 sec: 3548.6, 300 sec: 3443.7). Total num frames: 3325952. Throughput: 0: 3499.8. Samples: 3326976. Policy #0 lag: (min: 47.0, avg: 50.0, max: 111.0)
[2026-01-26 13:58:48,118][144664] Avg episode reward: [(0, '920.977')]
[2026-01-26 13:58:48,259][144664] Saving new best policy, reward=920.977!
[2026-01-26 13:58:53,067][144664] Fps is (10 sec: 3275.9, 60 sec: 3552.2, 300 sec: 3443.5). Total num frames: 3342336. Throughput: 0: 3462.6. Samples: 3346432. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 13:58:53,067][144664] Avg episode reward: [(0, '921.103')]
[2026-01-26 13:58:53,210][144664] Saving new best policy, reward=921.103!
[2026-01-26 13:58:58,005][144664] Fps is (10 sec: 3314.3, 60 sec: 3551.4, 300 sec: 3443.5). Total num frames: 3358720. Throughput: 0: 3481.8. Samples: 3368448. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 13:58:58,005][144664] Avg episode reward: [(0, '940.007')]
[2026-01-26 13:58:58,134][144664] Saving new best policy, reward=940.007!
[2026-01-26 13:59:03,027][144664] Fps is (10 sec: 3290.0, 60 sec: 3551.8, 300 sec: 3444.4). Total num frames: 3375104. Throughput: 0: 3488.6. Samples: 3378688. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 13:59:03,027][144664] Avg episode reward: [(0, '940.627')]
[2026-01-26 13:59:03,162][144664] Saving new best policy, reward=940.627!
[2026-01-26 13:59:08,115][144664] Fps is (10 sec: 3241.3, 60 sec: 3413.4, 300 sec: 3442.3). Total num frames: 3391488. Throughput: 0: 3485.0. Samples: 3400192. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 13:59:08,115][144664] Avg episode reward: [(0, '911.720')]
[2026-01-26 13:59:13,028][144664] Fps is (10 sec: 3276.6, 60 sec: 3283.7, 300 sec: 3444.2). Total num frames: 3407872. Throughput: 0: 3536.1. Samples: 3421696. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 13:59:13,028][144664] Avg episode reward: [(0, '892.782')]
[2026-01-26 13:59:18,058][144664] Fps is (10 sec: 3295.3, 60 sec: 3280.0, 300 sec: 3443.9). Total num frames: 3424256. Throughput: 0: 3484.9. Samples: 3430912. Policy #0 lag: (min: 63.0, avg: 66.0, max: 127.0)
[2026-01-26 13:59:18,059][144664] Avg episode reward: [(0, '879.371')]
[2026-01-26 13:59:23,025][144664] Fps is (10 sec: 4096.9, 60 sec: 3412.5, 300 sec: 3471.0). Total num frames: 3448832. Throughput: 0: 3527.0. Samples: 3452928. Policy #0 lag: (min: 63.0, avg: 66.0, max: 127.0)
[2026-01-26 13:59:23,026][144664] Avg episode reward: [(0, '885.527')]
[2026-01-26 13:59:28,052][144664] Fps is (10 sec: 4918.2, 60 sec: 3546.6, 300 sec: 3498.9). Total num frames: 3473408. Throughput: 0: 3528.1. Samples: 3474432. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 13:59:28,053][144664] Avg episode reward: [(0, '915.601')]
[2026-01-26 13:59:33,056][144664] Fps is (10 sec: 4083.6, 60 sec: 3552.5, 300 sec: 3499.7). Total num frames: 3489792. Throughput: 0: 3497.8. Samples: 3484160. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 13:59:33,056][144664] Avg episode reward: [(0, '928.470')]
[2026-01-26 13:59:38,041][144664] Fps is (10 sec: 3280.4, 60 sec: 3548.9, 300 sec: 3498.5). Total num frames: 3506176. Throughput: 0: 3540.5. Samples: 3505664. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 13:59:38,041][144664] Avg episode reward: [(0, '958.722')]
[2026-01-26 13:59:38,187][144664] Saving new best policy, reward=958.722!
[2026-01-26 13:59:43,111][144664] Fps is (10 sec: 3258.6, 60 sec: 3547.1, 300 sec: 3498.7). Total num frames: 3522560. Throughput: 0: 3484.7. Samples: 3525632. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 13:59:43,112][144664] Avg episode reward: [(0, '959.333')]
[2026-01-26 13:59:43,259][144664] Saving new best policy, reward=959.333!
[2026-01-26 13:59:48,006][144664] Fps is (10 sec: 3288.5, 60 sec: 3556.5, 300 sec: 3499.6). Total num frames: 3538944. Throughput: 0: 3517.4. Samples: 3536896. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 13:59:48,006][144664] Avg episode reward: [(0, '964.125')]
[2026-01-26 13:59:48,142][144664] Saving new best policy, reward=964.125!
[2026-01-26 13:59:51,323][144664] Signal inference workers to stop experience collection... (650 times)
[2026-01-26 13:59:51,696][144664] InferenceWorker_p0-w0: stopping experience collection (650 times)
[2026-01-26 13:59:51,696][144664] Signal inference workers to resume experience collection... (650 times)
[2026-01-26 13:59:51,696][144664] InferenceWorker_p0-w0: resuming experience collection (650 times)
[2026-01-26 13:59:53,051][144664] Fps is (10 sec: 3296.9, 60 sec: 3550.8, 300 sec: 3499.1). Total num frames: 3555328. Throughput: 0: 3475.2. Samples: 3556352. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 13:59:53,051][144664] Avg episode reward: [(0, '970.066')]
[2026-01-26 13:59:53,194][144664] Saving new best policy, reward=970.066!
[2026-01-26 13:59:58,087][144664] Fps is (10 sec: 3250.5, 60 sec: 3545.0, 300 sec: 3473.3). Total num frames: 3571712. Throughput: 0: 3454.3. Samples: 3577344. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 13:59:58,087][144664] Avg episode reward: [(0, '981.262')]
[2026-01-26 13:59:58,233][144664] Saving new best policy, reward=981.262!
[2026-01-26 14:00:03,077][144664] Fps is (10 sec: 3268.3, 60 sec: 3546.9, 300 sec: 3472.0). Total num frames: 3588096. Throughput: 0: 3502.9. Samples: 3588608. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 14:00:03,077][144664] Avg episode reward: [(0, '967.824')]
[2026-01-26 14:00:03,218][144664] Saving /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_accel_policy1_26012026/checkpoint_p0/checkpoint_000014016_3588096.pth...
[2026-01-26 14:00:03,221][144664] Removing /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_accel_policy1_26012026/checkpoint_p0/checkpoint_000010752_2752512.pth
[2026-01-26 14:00:08,018][144664] Fps is (10 sec: 3299.3, 60 sec: 3555.6, 300 sec: 3445.5). Total num frames: 3604480. Throughput: 0: 3459.4. Samples: 3608576. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 14:00:08,019][144664] Avg episode reward: [(0, '963.894')]
[2026-01-26 14:00:13,072][144664] Fps is (10 sec: 3278.3, 60 sec: 3547.2, 300 sec: 3442.8). Total num frames: 3620864. Throughput: 0: 3457.3. Samples: 3630080. Policy #0 lag: (min: 1.0, avg: 4.0, max: 65.0)
[2026-01-26 14:00:13,072][144664] Avg episode reward: [(0, '949.420')]
[2026-01-26 14:00:18,091][144664] Fps is (10 sec: 3253.3, 60 sec: 3548.0, 300 sec: 3443.0). Total num frames: 3637248. Throughput: 0: 3456.2. Samples: 3639808. Policy #0 lag: (min: 1.0, avg: 4.0, max: 65.0)
[2026-01-26 14:00:18,091][144664] Avg episode reward: [(0, '958.080')]
[2026-01-26 14:00:23,077][144664] Fps is (10 sec: 3275.0, 60 sec: 3410.4, 300 sec: 3444.0). Total num frames: 3653632. Throughput: 0: 3467.4. Samples: 3661824. Policy #0 lag: (min: 1.0, avg: 4.0, max: 65.0)
[2026-01-26 14:00:23,078][144664] Avg episode reward: [(0, '986.674')]
[2026-01-26 14:00:23,230][144664] Saving new best policy, reward=986.674!
[2026-01-26 14:00:27,995][144664] Fps is (10 sec: 3308.4, 60 sec: 3279.9, 300 sec: 3443.7). Total num frames: 3670016. Throughput: 0: 3502.0. Samples: 3682816. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 14:00:27,995][144664] Avg episode reward: [(0, '1003.240')]
[2026-01-26 14:00:28,131][144664] Saving new best policy, reward=1003.240!
[2026-01-26 14:00:33,044][144664] Fps is (10 sec: 3287.7, 60 sec: 3277.4, 300 sec: 3443.4). Total num frames: 3686400. Throughput: 0: 3467.2. Samples: 3693056. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 14:00:33,045][144664] Avg episode reward: [(0, '1032.760')]
[2026-01-26 14:00:33,193][144664] Saving new best policy, reward=1032.760!
[2026-01-26 14:00:38,318][144664] Fps is (10 sec: 3967.8, 60 sec: 3397.7, 300 sec: 3467.9). Total num frames: 3710976. Throughput: 0: 3483.7. Samples: 3714048. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 14:00:38,318][144664] Avg episode reward: [(0, '1046.316')]
[2026-01-26 14:00:38,667][144664] Saving new best policy, reward=1046.316!
[2026-01-26 14:00:43,083][144664] Fps is (10 sec: 4080.2, 60 sec: 3415.0, 300 sec: 3471.5). Total num frames: 3727360. Throughput: 0: 3516.0. Samples: 3735552. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 14:00:43,083][144664] Avg episode reward: [(0, '1019.422')]
[2026-01-26 14:00:48,294][144664] Fps is (10 sec: 4106.0, 60 sec: 3532.9, 300 sec: 3496.4). Total num frames: 3751936. Throughput: 0: 3464.9. Samples: 3745280. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 14:00:48,294][144664] Avg episode reward: [(0, '985.737')]
[2026-01-26 14:00:53,122][144664] Fps is (10 sec: 4079.9, 60 sec: 3545.6, 300 sec: 3498.0). Total num frames: 3768320. Throughput: 0: 3484.9. Samples: 3765760. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 14:00:53,123][144664] Avg episode reward: [(0, '964.649')]
[2026-01-26 14:00:58,076][144664] Fps is (10 sec: 3349.6, 60 sec: 3550.5, 300 sec: 3498.5). Total num frames: 3784704. Throughput: 0: 3458.5. Samples: 3785728. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 14:00:58,077][144664] Avg episode reward: [(0, '979.379')]
[2026-01-26 14:01:03,118][144664] Fps is (10 sec: 3278.1, 60 sec: 3547.4, 300 sec: 3498.5). Total num frames: 3801088. Throughput: 0: 3468.1. Samples: 3795968. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 14:01:03,119][144664] Avg episode reward: [(0, '999.416')]
[2026-01-26 14:01:08,118][144664] Fps is (10 sec: 3263.1, 60 sec: 3544.0, 300 sec: 3498.3). Total num frames: 3817472. Throughput: 0: 3444.3. Samples: 3816960. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 14:01:08,118][144664] Avg episode reward: [(0, '985.961')]
[2026-01-26 14:01:11,870][144664] Signal inference workers to stop experience collection... (700 times)
[2026-01-26 14:01:11,870][144664] Signal inference workers to resume experience collection... (700 times)
[2026-01-26 14:01:12,123][144664] InferenceWorker_p0-w0: stopping experience collection (700 times)
[2026-01-26 14:01:12,123][144664] InferenceWorker_p0-w0: resuming experience collection (700 times)
[2026-01-26 14:01:13,025][144664] Fps is (10 sec: 3307.6, 60 sec: 3552.6, 300 sec: 3499.4). Total num frames: 3833856. Throughput: 0: 3411.0. Samples: 3836416. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 14:01:13,026][144664] Avg episode reward: [(0, '1019.688')]
[2026-01-26 14:01:18,005][144664] Fps is (10 sec: 3314.2, 60 sec: 3554.9, 300 sec: 3499.8). Total num frames: 3850240. Throughput: 0: 3439.1. Samples: 3847680. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 14:01:18,005][144664] Avg episode reward: [(0, '1033.294')]
[2026-01-26 14:01:22,998][144664] Fps is (10 sec: 3285.8, 60 sec: 3554.6, 300 sec: 3474.2). Total num frames: 3866624. Throughput: 0: 3437.8. Samples: 3867648. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 14:01:22,998][144664] Avg episode reward: [(0, '1056.328')]
[2026-01-26 14:01:23,138][144664] Saving new best policy, reward=1056.328!
[2026-01-26 14:01:28,030][144664] Fps is (10 sec: 3268.7, 60 sec: 3547.8, 300 sec: 3471.9). Total num frames: 3883008. Throughput: 0: 3360.4. Samples: 3886592. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 14:01:28,030][144664] Avg episode reward: [(0, '1069.549')]
[2026-01-26 14:01:28,159][144664] Saving new best policy, reward=1069.549!
[2026-01-26 14:01:33,071][144664] Fps is (10 sec: 3253.1, 60 sec: 3548.3, 300 sec: 3445.9). Total num frames: 3899392. Throughput: 0: 3407.5. Samples: 3897856. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 14:01:33,071][144664] Avg episode reward: [(0, '1040.177')]
[2026-01-26 14:01:38,126][144664] Fps is (10 sec: 3245.7, 60 sec: 3424.3, 300 sec: 3442.5). Total num frames: 3915776. Throughput: 0: 3356.2. Samples: 3916800. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 14:01:38,126][144664] Avg episode reward: [(0, '1055.863')]
[2026-01-26 14:01:43,119][144664] Fps is (10 sec: 3261.2, 60 sec: 3411.3, 300 sec: 3442.4). Total num frames: 3932160. Throughput: 0: 3376.0. Samples: 3937792. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 14:01:43,119][144664] Avg episode reward: [(0, '1018.471')]
[2026-01-26 14:01:48,126][144664] Fps is (10 sec: 3276.9, 60 sec: 3286.0, 300 sec: 3442.4). Total num frames: 3948544. Throughput: 0: 3390.0. Samples: 3948544. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 14:01:48,126][144664] Avg episode reward: [(0, '1050.988')]
[2026-01-26 14:01:53,107][144664] Fps is (10 sec: 3280.6, 60 sec: 3277.6, 300 sec: 3442.9). Total num frames: 3964928. Throughput: 0: 3357.3. Samples: 3968000. Policy #0 lag: (min: 8.0, avg: 11.0, max: 72.0)
[2026-01-26 14:01:53,107][144664] Avg episode reward: [(0, '1028.201')]
[2026-01-26 14:01:58,067][144664] Fps is (10 sec: 3296.1, 60 sec: 3277.3, 300 sec: 3443.5). Total num frames: 3981312. Throughput: 0: 3376.1. Samples: 3988480. Policy #0 lag: (min: 8.0, avg: 11.0, max: 72.0)
[2026-01-26 14:01:58,067][144664] Avg episode reward: [(0, '1035.943')]
[2026-01-26 14:02:03,077][144664] Fps is (10 sec: 3286.6, 60 sec: 3279.1, 300 sec: 3442.8). Total num frames: 3997696. Throughput: 0: 3351.1. Samples: 3998720. Policy #0 lag: (min: 8.0, avg: 11.0, max: 72.0)
[2026-01-26 14:02:03,077][144664] Avg episode reward: [(0, '1052.176')]
[2026-01-26 14:02:03,222][144664] Saving /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_accel_policy1_26012026/checkpoint_p0/checkpoint_000015616_3997696.pth...
[2026-01-26 14:02:03,226][144664] Removing /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_accel_policy1_26012026/checkpoint_p0/checkpoint_000012384_3170304.pth
[2026-01-26 14:02:08,003][144664] Fps is (10 sec: 3297.9, 60 sec: 3283.1, 300 sec: 3443.8). Total num frames: 4014080. Throughput: 0: 3333.3. Samples: 4017664. Policy #0 lag: (min: 7.0, avg: 10.0, max: 71.0)
[2026-01-26 14:02:08,003][144664] Avg episode reward: [(0, '1077.386')]
[2026-01-26 14:02:08,133][144664] Saving new best policy, reward=1077.386!
[2026-01-26 14:02:13,018][144664] Fps is (10 sec: 3296.2, 60 sec: 3277.2, 300 sec: 3443.6). Total num frames: 4030464. Throughput: 0: 3380.1. Samples: 4038656. Policy #0 lag: (min: 7.0, avg: 10.0, max: 71.0)
[2026-01-26 14:02:13,019][144664] Avg episode reward: [(0, '1123.401')]
[2026-01-26 14:02:13,166][144664] Saving new best policy, reward=1123.401!
[2026-01-26 14:02:18,021][144664] Fps is (10 sec: 3271.0, 60 sec: 3276.0, 300 sec: 3443.9). Total num frames: 4046848. Throughput: 0: 3337.4. Samples: 4047872. Policy #0 lag: (min: 7.0, avg: 10.0, max: 71.0)
[2026-01-26 14:02:18,021][144664] Avg episode reward: [(0, '1083.363')]
[2026-01-26 14:02:23,100][144664] Fps is (10 sec: 3250.4, 60 sec: 3271.3, 300 sec: 3443.5). Total num frames: 4063232. Throughput: 0: 3369.8. Samples: 4068352. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 14:02:23,100][144664] Avg episode reward: [(0, '1082.005')]
[2026-01-26 14:02:28,104][144664] Fps is (10 sec: 3249.7, 60 sec: 3272.8, 300 sec: 3442.4). Total num frames: 4079616. Throughput: 0: 3380.3. Samples: 4089856. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 14:02:28,104][144664] Avg episode reward: [(0, '1075.890')]
[2026-01-26 14:02:33,064][144664] Fps is (10 sec: 3288.5, 60 sec: 3277.2, 300 sec: 3443.2). Total num frames: 4096000. Throughput: 0: 3349.7. Samples: 4099072. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 14:02:33,064][144664] Avg episode reward: [(0, '1068.464')]
[2026-01-26 14:02:34,378][144664] Signal inference workers to stop experience collection... (750 times)
[2026-01-26 14:02:34,795][144664] InferenceWorker_p0-w0: stopping experience collection (750 times)
[2026-01-26 14:02:34,797][144664] Signal inference workers to resume experience collection... (750 times)
[2026-01-26 14:02:34,976][144664] InferenceWorker_p0-w0: resuming experience collection (750 times)
[2026-01-26 14:02:37,998][144664] Fps is (10 sec: 3312.0, 60 sec: 3283.8, 300 sec: 3444.4). Total num frames: 4112384. Throughput: 0: 3353.2. Samples: 4118528. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 14:02:37,998][144664] Avg episode reward: [(0, '1053.682')]
[2026-01-26 14:02:43,048][144664] Fps is (10 sec: 3282.2, 60 sec: 3280.7, 300 sec: 3444.0). Total num frames: 4128768. Throughput: 0: 3357.9. Samples: 4139520. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 14:02:43,048][144664] Avg episode reward: [(0, '1047.379')]
[2026-01-26 14:02:48,068][144664] Fps is (10 sec: 3254.1, 60 sec: 3280.0, 300 sec: 3443.9). Total num frames: 4145152. Throughput: 0: 3345.8. Samples: 4149248. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 14:02:48,068][144664] Avg episode reward: [(0, '1061.882')]
[2026-01-26 14:02:53,126][144664] Fps is (10 sec: 3251.4, 60 sec: 3275.8, 300 sec: 3442.3). Total num frames: 4161536. Throughput: 0: 3370.0. Samples: 4169728. Policy #0 lag: (min: 6.0, avg: 9.0, max: 70.0)
[2026-01-26 14:02:53,126][144664] Avg episode reward: [(0, '1096.679')]
[2026-01-26 14:02:58,028][144664] Fps is (10 sec: 3290.0, 60 sec: 3279.0, 300 sec: 3443.8). Total num frames: 4177920. Throughput: 0: 3367.1. Samples: 4190208. Policy #0 lag: (min: 6.0, avg: 9.0, max: 70.0)
[2026-01-26 14:02:58,028][144664] Avg episode reward: [(0, '1105.195')]
[2026-01-26 14:03:03,013][144664] Fps is (10 sec: 3314.2, 60 sec: 3280.3, 300 sec: 3416.8). Total num frames: 4194304. Throughput: 0: 3379.8. Samples: 4199936. Policy #0 lag: (min: 6.0, avg: 9.0, max: 70.0)
[2026-01-26 14:03:03,013][144664] Avg episode reward: [(0, '1095.640')]
[2026-01-26 14:03:08,082][144664] Fps is (10 sec: 3259.0, 60 sec: 3272.5, 300 sec: 3388.7). Total num frames: 4210688. Throughput: 0: 3403.3. Samples: 4221440. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 14:03:08,082][144664] Avg episode reward: [(0, '1067.625')]
[2026-01-26 14:03:13,102][144664] Fps is (10 sec: 3248.0, 60 sec: 3272.3, 300 sec: 3388.1). Total num frames: 4227072. Throughput: 0: 3379.4. Samples: 4241920. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 14:03:13,102][144664] Avg episode reward: [(0, '1075.362')]
[2026-01-26 14:03:18,105][144664] Fps is (10 sec: 4086.5, 60 sec: 3408.5, 300 sec: 3414.6). Total num frames: 4251648. Throughput: 0: 3387.5. Samples: 4251648. Policy #0 lag: (min: 10.0, avg: 13.0, max: 74.0)
[2026-01-26 14:03:18,106][144664] Avg episode reward: [(0, '1095.111')]
[2026-01-26 14:03:23,079][144664] Fps is (10 sec: 4105.3, 60 sec: 3414.5, 300 sec: 3414.7). Total num frames: 4268032. Throughput: 0: 3407.2. Samples: 4272128. Policy #0 lag: (min: 10.0, avg: 13.0, max: 74.0)
[2026-01-26 14:03:23,079][144664] Avg episode reward: [(0, '1117.610')]
[2026-01-26 14:03:28,174][144664] Fps is (10 sec: 4068.3, 60 sec: 3545.8, 300 sec: 3442.6). Total num frames: 4292608. Throughput: 0: 3415.1. Samples: 4293632. Policy #0 lag: (min: 10.0, avg: 13.0, max: 74.0)
[2026-01-26 14:03:28,174][144664] Avg episode reward: [(0, '1140.819')]
[2026-01-26 14:03:28,174][144664] Saving new best policy, reward=1140.819!
[2026-01-26 14:03:32,998][144664] Fps is (10 sec: 4129.3, 60 sec: 3553.7, 300 sec: 3443.7). Total num frames: 4308992. Throughput: 0: 3418.6. Samples: 4302848. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 14:03:32,999][144664] Avg episode reward: [(0, '1154.152')]
[2026-01-26 14:03:33,002][144664] Saving new best policy, reward=1154.152!
[2026-01-26 14:03:38,012][144664] Fps is (10 sec: 3330.6, 60 sec: 3549.0, 300 sec: 3444.0). Total num frames: 4325376. Throughput: 0: 3433.4. Samples: 4323840. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 14:03:38,012][144664] Avg episode reward: [(0, '1164.315')]
[2026-01-26 14:03:38,157][144664] Saving new best policy, reward=1164.315!
[2026-01-26 14:03:43,090][144664] Fps is (10 sec: 3247.1, 60 sec: 3547.4, 300 sec: 3443.7). Total num frames: 4341760. Throughput: 0: 3385.9. Samples: 4342784. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 14:03:43,090][144664] Avg episode reward: [(0, '1162.313')]
[2026-01-26 14:03:48,016][144664] Fps is (10 sec: 3275.5, 60 sec: 3552.9, 300 sec: 3444.0). Total num frames: 4358144. Throughput: 0: 3424.5. Samples: 4354048. Policy #0 lag: (min: 1.0, avg: 4.0, max: 65.0)
[2026-01-26 14:03:48,016][144664] Avg episode reward: [(0, '1168.251')]
[2026-01-26 14:03:48,162][144664] Saving new best policy, reward=1168.251!
[2026-01-26 14:03:52,013][144664] Signal inference workers to stop experience collection... (800 times)
[2026-01-26 14:03:52,391][144664] InferenceWorker_p0-w0: stopping experience collection (800 times)
[2026-01-26 14:03:52,391][144664] Signal inference workers to resume experience collection... (800 times)
[2026-01-26 14:03:52,391][144664] InferenceWorker_p0-w0: resuming experience collection (800 times)
[2026-01-26 14:03:53,080][144664] Fps is (10 sec: 3279.9, 60 sec: 3552.6, 300 sec: 3442.5). Total num frames: 4374528. Throughput: 0: 3402.1. Samples: 4374528. Policy #0 lag: (min: 1.0, avg: 4.0, max: 65.0)
[2026-01-26 14:03:53,081][144664] Avg episode reward: [(0, '1183.862')]
[2026-01-26 14:03:53,224][144664] Saving new best policy, reward=1183.862!
[2026-01-26 14:03:58,041][144664] Fps is (10 sec: 3268.8, 60 sec: 3549.1, 300 sec: 3443.3). Total num frames: 4390912. Throughput: 0: 3372.4. Samples: 4393472. Policy #0 lag: (min: 1.0, avg: 4.0, max: 65.0)
[2026-01-26 14:03:58,041][144664] Avg episode reward: [(0, '1162.172')]
[2026-01-26 14:04:03,095][144664] Fps is (10 sec: 3272.2, 60 sec: 3545.1, 300 sec: 3443.7). Total num frames: 4407296. Throughput: 0: 3391.4. Samples: 4404224. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 14:04:03,095][144664] Avg episode reward: [(0, '1188.569')]
[2026-01-26 14:04:03,243][144664] Saving /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_accel_policy1_26012026/checkpoint_p0/checkpoint_000017216_4407296.pth...
[2026-01-26 14:04:03,247][144664] Removing /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_accel_policy1_26012026/checkpoint_p0/checkpoint_000014016_3588096.pth
[2026-01-26 14:04:03,248][144664] Saving new best policy, reward=1188.569!
[2026-01-26 14:04:08,004][144664] Fps is (10 sec: 3288.7, 60 sec: 3554.5, 300 sec: 3443.7). Total num frames: 4423680. Throughput: 0: 3396.2. Samples: 4424704. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 14:04:08,005][144664] Avg episode reward: [(0, '1170.871')]
[2026-01-26 14:04:13,034][144664] Fps is (10 sec: 3296.7, 60 sec: 3553.9, 300 sec: 3443.7). Total num frames: 4440064. Throughput: 0: 3332.6. Samples: 4443136. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 14:04:13,034][144664] Avg episode reward: [(0, '1198.748')]
[2026-01-26 14:04:13,183][144664] Saving new best policy, reward=1198.748!
[2026-01-26 14:04:18,060][144664] Fps is (10 sec: 3258.6, 60 sec: 3415.9, 300 sec: 3415.2). Total num frames: 4456448. Throughput: 0: 3363.2. Samples: 4454400. Policy #0 lag: (min: 8.0, avg: 11.0, max: 72.0)
[2026-01-26 14:04:18,060][144664] Avg episode reward: [(0, '1170.539')]
[2026-01-26 14:04:23,013][144664] Fps is (10 sec: 3283.7, 60 sec: 3417.1, 300 sec: 3388.3). Total num frames: 4472832. Throughput: 0: 3333.6. Samples: 4473856. Policy #0 lag: (min: 8.0, avg: 11.0, max: 72.0)
[2026-01-26 14:04:23,013][144664] Avg episode reward: [(0, '1201.562')]
[2026-01-26 14:04:23,165][144664] Saving new best policy, reward=1201.562!
[2026-01-26 14:04:28,084][144664] Fps is (10 sec: 3268.9, 60 sec: 3281.7, 300 sec: 3387.6). Total num frames: 4489216. Throughput: 0: 3379.6. Samples: 4494848. Policy #0 lag: (min: 8.0, avg: 11.0, max: 72.0)
[2026-01-26 14:04:28,084][144664] Avg episode reward: [(0, '1180.582')]
[2026-01-26 14:04:33,052][144664] Fps is (10 sec: 3264.2, 60 sec: 3273.9, 300 sec: 3387.8). Total num frames: 4505600. Throughput: 0: 3387.9. Samples: 4506624. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 14:04:33,052][144664] Avg episode reward: [(0, '1206.107')]
[2026-01-26 14:04:33,188][144664] Saving new best policy, reward=1206.107!
[2026-01-26 14:04:38,042][144664] Fps is (10 sec: 3290.7, 60 sec: 3275.2, 300 sec: 3388.7). Total num frames: 4521984. Throughput: 0: 3370.7. Samples: 4526080. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 14:04:38,042][144664] Avg episode reward: [(0, '1211.736')]
[2026-01-26 14:04:38,186][144664] Saving new best policy, reward=1211.736!
[2026-01-26 14:04:43,069][144664] Fps is (10 sec: 3271.3, 60 sec: 3278.0, 300 sec: 3387.2). Total num frames: 4538368. Throughput: 0: 3411.2. Samples: 4547072. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 14:04:43,069][144664] Avg episode reward: [(0, '1225.149')]
[2026-01-26 14:04:43,213][144664] Saving new best policy, reward=1225.149!
[2026-01-26 14:04:48,054][144664] Fps is (10 sec: 3272.9, 60 sec: 3274.8, 300 sec: 3387.8). Total num frames: 4554752. Throughput: 0: 3370.9. Samples: 4555776. Policy #0 lag: (min: 7.0, avg: 10.0, max: 71.0)
[2026-01-26 14:04:48,054][144664] Avg episode reward: [(0, '1252.697')]
[2026-01-26 14:04:48,203][144664] Saving new best policy, reward=1252.697!
[2026-01-26 14:04:53,033][144664] Fps is (10 sec: 3288.4, 60 sec: 3279.4, 300 sec: 3388.5). Total num frames: 4571136. Throughput: 0: 3399.8. Samples: 4577792. Policy #0 lag: (min: 7.0, avg: 10.0, max: 71.0)
[2026-01-26 14:04:53,034][144664] Avg episode reward: [(0, '1245.239')]
[2026-01-26 14:04:58,007][144664] Fps is (10 sec: 3292.1, 60 sec: 3278.6, 300 sec: 3388.7). Total num frames: 4587520. Throughput: 0: 3472.3. Samples: 4599296. Policy #0 lag: (min: 7.0, avg: 10.0, max: 71.0)
[2026-01-26 14:04:58,007][144664] Avg episode reward: [(0, '1245.885')]
[2026-01-26 14:05:03,061][144664] Fps is (10 sec: 3267.8, 60 sec: 3278.6, 300 sec: 3387.4). Total num frames: 4603904. Throughput: 0: 3424.6. Samples: 4608512. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 14:05:03,061][144664] Avg episode reward: [(0, '1250.085')]
[2026-01-26 14:05:08,005][144664] Fps is (10 sec: 3277.5, 60 sec: 3276.8, 300 sec: 3388.6). Total num frames: 4620288. Throughput: 0: 3436.7. Samples: 4628480. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 14:05:08,005][144664] Avg episode reward: [(0, '1250.645')]
[2026-01-26 14:05:13,120][144664] Fps is (10 sec: 3257.4, 60 sec: 3272.1, 300 sec: 3387.5). Total num frames: 4636672. Throughput: 0: 3433.3. Samples: 4649472. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 14:05:13,121][144664] Avg episode reward: [(0, '1219.003')]
[2026-01-26 14:05:14,030][144664] Signal inference workers to stop experience collection... (850 times)
[2026-01-26 14:05:14,037][144664] Signal inference workers to resume experience collection... (850 times)
[2026-01-26 14:05:14,292][144664] InferenceWorker_p0-w0: stopping experience collection (850 times)
[2026-01-26 14:05:14,292][144664] InferenceWorker_p0-w0: resuming experience collection (850 times)
[2026-01-26 14:05:18,013][144664] Fps is (10 sec: 3274.2, 60 sec: 3279.4, 300 sec: 3388.6). Total num frames: 4653056. Throughput: 0: 3382.1. Samples: 4658688. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 14:05:18,013][144664] Avg episode reward: [(0, '1212.716')]
[2026-01-26 14:05:23,097][144664] Fps is (10 sec: 3284.6, 60 sec: 3272.2, 300 sec: 3386.7). Total num frames: 4669440. Throughput: 0: 3397.8. Samples: 4679168. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 14:05:23,097][144664] Avg episode reward: [(0, '1195.755')]
[2026-01-26 14:05:28,051][144664] Fps is (10 sec: 3264.2, 60 sec: 3278.6, 300 sec: 3387.8). Total num frames: 4685824. Throughput: 0: 3403.3. Samples: 4700160. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 14:05:28,052][144664] Avg episode reward: [(0, '1217.876')]
[2026-01-26 14:05:33,299][144664] Fps is (10 sec: 4014.9, 60 sec: 3399.3, 300 sec: 3388.1). Total num frames: 4710400. Throughput: 0: 3406.2. Samples: 4709888. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 14:05:33,299][144664] Avg episode reward: [(0, '1235.589')]
[2026-01-26 14:05:38,021][144664] Fps is (10 sec: 4108.6, 60 sec: 3414.5, 300 sec: 3388.6). Total num frames: 4726784. Throughput: 0: 3402.9. Samples: 4730880. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 14:05:38,021][144664] Avg episode reward: [(0, '1216.724')]
[2026-01-26 14:05:43,043][144664] Fps is (10 sec: 4203.6, 60 sec: 3551.4, 300 sec: 3390.8). Total num frames: 4751360. Throughput: 0: 3399.3. Samples: 4752384. Policy #0 lag: (min: 2.0, avg: 5.0, max: 66.0)
[2026-01-26 14:05:43,043][144664] Avg episode reward: [(0, '1252.635')]
[2026-01-26 14:05:48,071][144664] Fps is (10 sec: 4075.7, 60 sec: 3548.9, 300 sec: 3388.5). Total num frames: 4767744. Throughput: 0: 3412.6. Samples: 4762112. Policy #0 lag: (min: 2.0, avg: 5.0, max: 66.0)
[2026-01-26 14:05:48,071][144664] Avg episode reward: [(0, '1220.757')]
[2026-01-26 14:05:53,018][144664] Fps is (10 sec: 3284.9, 60 sec: 3550.8, 300 sec: 3388.5). Total num frames: 4784128. Throughput: 0: 3435.1. Samples: 4783104. Policy #0 lag: (min: 2.0, avg: 5.0, max: 66.0)
[2026-01-26 14:05:53,018][144664] Avg episode reward: [(0, '1266.124')]
[2026-01-26 14:05:53,161][144664] Saving new best policy, reward=1266.124!
[2026-01-26 14:05:58,025][144664] Fps is (10 sec: 3291.8, 60 sec: 3548.8, 300 sec: 3388.9). Total num frames: 4800512. Throughput: 0: 3409.2. Samples: 4802560. Policy #0 lag: (min: 9.0, avg: 12.0, max: 73.0)
[2026-01-26 14:05:58,025][144664] Avg episode reward: [(0, '1253.861')]
[2026-01-26 14:06:03,127][144664] Fps is (10 sec: 3241.6, 60 sec: 3546.0, 300 sec: 3387.8). Total num frames: 4816896. Throughput: 0: 3450.1. Samples: 4814336. Policy #0 lag: (min: 9.0, avg: 12.0, max: 73.0)
[2026-01-26 14:06:03,127][144664] Avg episode reward: [(0, '1257.825')]
[2026-01-26 14:06:03,267][144664] Saving /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_accel_policy1_26012026/checkpoint_p0/checkpoint_000018816_4816896.pth...
[2026-01-26 14:06:03,271][144664] Removing /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_accel_policy1_26012026/checkpoint_p0/checkpoint_000015616_3997696.pth
[2026-01-26 14:06:08,099][144664] Fps is (10 sec: 3252.8, 60 sec: 3544.3, 300 sec: 3387.0). Total num frames: 4833280. Throughput: 0: 3447.3. Samples: 4834304. Policy #0 lag: (min: 9.0, avg: 12.0, max: 73.0)
[2026-01-26 14:06:08,099][144664] Avg episode reward: [(0, '1275.400')]
[2026-01-26 14:06:08,227][144664] Saving new best policy, reward=1275.400!
[2026-01-26 14:06:13,043][144664] Fps is (10 sec: 3304.5, 60 sec: 3554.5, 300 sec: 3387.4). Total num frames: 4849664. Throughput: 0: 3436.7. Samples: 4854784. Policy #0 lag: (min: 13.0, avg: 16.0, max: 77.0)
[2026-01-26 14:06:13,043][144664] Avg episode reward: [(0, '1290.433')]
[2026-01-26 14:06:13,190][144664] Saving new best policy, reward=1290.433!
[2026-01-26 14:06:18,018][144664] Fps is (10 sec: 3303.4, 60 sec: 3549.5, 300 sec: 3387.6). Total num frames: 4866048. Throughput: 0: 3503.4. Samples: 4866560. Policy #0 lag: (min: 13.0, avg: 16.0, max: 77.0)
[2026-01-26 14:06:18,019][144664] Avg episode reward: [(0, '1292.966')]
[2026-01-26 14:06:18,161][144664] Saving new best policy, reward=1292.966!
[2026-01-26 14:06:23,109][144664] Fps is (10 sec: 3255.2, 60 sec: 3549.1, 300 sec: 3387.0). Total num frames: 4882432. Throughput: 0: 3452.1. Samples: 4886528. Policy #0 lag: (min: 13.0, avg: 16.0, max: 77.0)
[2026-01-26 14:06:23,110][144664] Avg episode reward: [(0, '1271.387')]
[2026-01-26 14:06:28,056][144664] Fps is (10 sec: 3264.5, 60 sec: 3549.6, 300 sec: 3388.0). Total num frames: 4898816. Throughput: 0: 3446.4. Samples: 4907520. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 14:06:28,056][144664] Avg episode reward: [(0, '1257.230')]
[2026-01-26 14:06:33,005][144664] Fps is (10 sec: 3311.3, 60 sec: 3430.1, 300 sec: 3389.3). Total num frames: 4915200. Throughput: 0: 3452.5. Samples: 4917248. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 14:06:33,005][144664] Avg episode reward: [(0, '1249.757')]
[2026-01-26 14:06:34,385][144664] Signal inference workers to stop experience collection... (900 times)
[2026-01-26 14:06:34,735][144664] InferenceWorker_p0-w0: stopping experience collection (900 times)
[2026-01-26 14:06:34,737][144664] Signal inference workers to resume experience collection... (900 times)
[2026-01-26 14:06:34,865][144664] InferenceWorker_p0-w0: resuming experience collection (900 times)
[2026-01-26 14:06:38,076][144664] Fps is (10 sec: 3270.3, 60 sec: 3410.2, 300 sec: 3388.4). Total num frames: 4931584. Throughput: 0: 3454.4. Samples: 4938752. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 14:06:38,076][144664] Avg episode reward: [(0, '1204.116')]
[2026-01-26 14:06:43,010][144664] Fps is (10 sec: 3275.3, 60 sec: 3278.6, 300 sec: 3389.2). Total num frames: 4947968. Throughput: 0: 3505.6. Samples: 4960256. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 14:06:43,010][144664] Avg episode reward: [(0, '1250.738')]
[2026-01-26 14:06:48,122][144664] Fps is (10 sec: 3261.8, 60 sec: 3274.0, 300 sec: 3387.7). Total num frames: 4964352. Throughput: 0: 3470.6. Samples: 4970496. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 14:06:48,122][144664] Avg episode reward: [(0, '1325.315')]
[2026-01-26 14:06:48,262][144664] Saving new best policy, reward=1325.315!
[2026-01-26 14:06:53,082][144664] Fps is (10 sec: 3253.2, 60 sec: 3273.3, 300 sec: 3387.7). Total num frames: 4980736. Throughput: 0: 3494.3. Samples: 4991488. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 14:06:53,082][144664] Avg episode reward: [(0, '1356.819')]
[2026-01-26 14:06:53,456][144664] Saving new best policy, reward=1356.819!
[2026-01-26 14:06:58,161][144664] Fps is (10 sec: 4079.9, 60 sec: 3405.6, 300 sec: 3414.7). Total num frames: 5005312. Throughput: 0: 3506.5. Samples: 5012992. Policy #0 lag: (min: 1.0, avg: 4.0, max: 65.0)
[2026-01-26 14:06:58,162][144664] Avg episode reward: [(0, '1337.750')]
[2026-01-26 14:07:03,173][144664] Fps is (10 sec: 4871.1, 60 sec: 3547.2, 300 sec: 3441.4). Total num frames: 5029888. Throughput: 0: 3458.4. Samples: 5022720. Policy #0 lag: (min: 1.0, avg: 4.0, max: 65.0)
[2026-01-26 14:07:03,173][144664] Avg episode reward: [(0, '1293.201')]
[2026-01-26 14:07:08,123][144664] Fps is (10 sec: 4111.8, 60 sec: 3548.4, 300 sec: 3442.2). Total num frames: 5046272. Throughput: 0: 3503.3. Samples: 5044224. Policy #0 lag: (min: 13.0, avg: 16.0, max: 77.0)
[2026-01-26 14:07:08,123][144664] Avg episode reward: [(0, '1259.088')]
[2026-01-26 14:07:13,074][144664] Fps is (10 sec: 3309.4, 60 sec: 3548.0, 300 sec: 3442.8). Total num frames: 5062656. Throughput: 0: 3468.8. Samples: 5063680. Policy #0 lag: (min: 13.0, avg: 16.0, max: 77.0)
[2026-01-26 14:07:13,075][144664] Avg episode reward: [(0, '1284.558')]
[2026-01-26 14:07:17,999][144664] Fps is (10 sec: 3317.9, 60 sec: 3551.0, 300 sec: 3444.6). Total num frames: 5079040. Throughput: 0: 3504.8. Samples: 5074944. Policy #0 lag: (min: 13.0, avg: 16.0, max: 77.0)
[2026-01-26 14:07:17,999][144664] Avg episode reward: [(0, '1303.763')]
[2026-01-26 14:07:23,097][144664] Fps is (10 sec: 3269.2, 60 sec: 3550.6, 300 sec: 3443.5). Total num frames: 5095424. Throughput: 0: 3491.3. Samples: 5095936. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 14:07:23,098][144664] Avg episode reward: [(0, '1338.347')]
[2026-01-26 14:07:28,121][144664] Fps is (10 sec: 3237.3, 60 sec: 3546.0, 300 sec: 3442.7). Total num frames: 5111808. Throughput: 0: 3427.6. Samples: 5114880. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 14:07:28,121][144664] Avg episode reward: [(0, '1314.089')]
[2026-01-26 14:07:33,108][144664] Fps is (10 sec: 3273.3, 60 sec: 3543.8, 300 sec: 3442.1). Total num frames: 5128192. Throughput: 0: 3459.9. Samples: 5126144. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 14:07:33,108][144664] Avg episode reward: [(0, '1262.536')]
[2026-01-26 14:07:38,093][144664] Fps is (10 sec: 3286.0, 60 sec: 3548.9, 300 sec: 3442.9). Total num frames: 5144576. Throughput: 0: 3423.9. Samples: 5145600. Policy #0 lag: (min: 13.0, avg: 16.0, max: 77.0)
[2026-01-26 14:07:38,093][144664] Avg episode reward: [(0, '1244.202')]
[2026-01-26 14:07:43,015][144664] Fps is (10 sec: 3307.7, 60 sec: 3549.6, 300 sec: 3444.0). Total num frames: 5160960. Throughput: 0: 3435.9. Samples: 5167104. Policy #0 lag: (min: 13.0, avg: 16.0, max: 77.0)
[2026-01-26 14:07:43,015][144664] Avg episode reward: [(0, '1254.540')]
[2026-01-26 14:07:48,010][144664] Fps is (10 sec: 3304.2, 60 sec: 3556.5, 300 sec: 3444.8). Total num frames: 5177344. Throughput: 0: 3471.4. Samples: 5178368. Policy #0 lag: (min: 13.0, avg: 16.0, max: 77.0)
[2026-01-26 14:07:48,010][144664] Avg episode reward: [(0, '1270.415')]
[2026-01-26 14:07:50,574][144664] Signal inference workers to stop experience collection... (950 times)
[2026-01-26 14:07:50,938][144664] InferenceWorker_p0-w0: stopping experience collection (950 times)
[2026-01-26 14:07:50,939][144664] Signal inference workers to resume experience collection... (950 times)
[2026-01-26 14:07:50,939][144664] InferenceWorker_p0-w0: resuming experience collection (950 times)
[2026-01-26 14:07:53,106][144664] Fps is (10 sec: 3247.0, 60 sec: 3548.4, 300 sec: 3442.5). Total num frames: 5193728. Throughput: 0: 3403.2. Samples: 5197312. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 14:07:53,106][144664] Avg episode reward: [(0, '1264.565')]
[2026-01-26 14:07:58,025][144664] Fps is (10 sec: 3272.0, 60 sec: 3421.1, 300 sec: 3443.3). Total num frames: 5210112. Throughput: 0: 3439.9. Samples: 5218304. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 14:07:58,025][144664] Avg episode reward: [(0, '1264.841')]
[2026-01-26 14:08:03,056][144664] Fps is (10 sec: 3293.3, 60 sec: 3283.2, 300 sec: 3443.7). Total num frames: 5226496. Throughput: 0: 3386.3. Samples: 5227520. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 14:08:03,056][144664] Avg episode reward: [(0, '1280.840')]
[2026-01-26 14:08:03,200][144664] Saving /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_accel_policy1_26012026/checkpoint_p0/checkpoint_000020416_5226496.pth...
[2026-01-26 14:08:03,204][144664] Removing /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_accel_policy1_26012026/checkpoint_p0/checkpoint_000017216_4407296.pth
[2026-01-26 14:08:08,013][144664] Fps is (10 sec: 3280.5, 60 sec: 3282.8, 300 sec: 3444.4). Total num frames: 5242880. Throughput: 0: 3408.3. Samples: 5249024. Policy #0 lag: (min: 14.0, avg: 17.0, max: 78.0)
[2026-01-26 14:08:08,014][144664] Avg episode reward: [(0, '1283.794')]
[2026-01-26 14:08:13,119][144664] Fps is (10 sec: 3256.3, 60 sec: 3274.4, 300 sec: 3415.5). Total num frames: 5259264. Throughput: 0: 3459.0. Samples: 5270528. Policy #0 lag: (min: 14.0, avg: 17.0, max: 78.0)
[2026-01-26 14:08:13,119][144664] Avg episode reward: [(0, '1281.579')]
[2026-01-26 14:08:18,064][144664] Fps is (10 sec: 3260.2, 60 sec: 3273.2, 300 sec: 3415.8). Total num frames: 5275648. Throughput: 0: 3428.0. Samples: 5280256. Policy #0 lag: (min: 14.0, avg: 17.0, max: 78.0)
[2026-01-26 14:08:18,065][144664] Avg episode reward: [(0, '1302.118')]
[2026-01-26 14:08:23,070][144664] Fps is (10 sec: 3293.0, 60 sec: 3278.3, 300 sec: 3389.1). Total num frames: 5292032. Throughput: 0: 3472.0. Samples: 5301760. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 14:08:23,070][144664] Avg episode reward: [(0, '1357.239')]
[2026-01-26 14:08:23,214][144664] Saving new best policy, reward=1357.239!
[2026-01-26 14:08:28,113][144664] Fps is (10 sec: 3260.8, 60 sec: 3277.2, 300 sec: 3386.6). Total num frames: 5308416. Throughput: 0: 3462.6. Samples: 5323264. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 14:08:28,113][144664] Avg episode reward: [(0, '1342.437')]
[2026-01-26 14:08:33,215][144664] Fps is (10 sec: 4037.5, 60 sec: 3407.3, 300 sec: 3413.3). Total num frames: 5332992. Throughput: 0: 3420.5. Samples: 5332992. Policy #0 lag: (min: 30.0, avg: 33.0, max: 94.0)
[2026-01-26 14:08:33,216][144664] Avg episode reward: [(0, '1336.614')]
[2026-01-26 14:08:38,257][144664] Fps is (10 sec: 4845.4, 60 sec: 3540.2, 300 sec: 3441.5). Total num frames: 5357568. Throughput: 0: 3470.0. Samples: 5353984. Policy #0 lag: (min: 30.0, avg: 33.0, max: 94.0)
[2026-01-26 14:08:38,257][144664] Avg episode reward: [(0, '1280.940')]
[2026-01-26 14:08:43,040][144664] Fps is (10 sec: 4168.9, 60 sec: 3548.4, 300 sec: 3443.1). Total num frames: 5373952. Throughput: 0: 3480.4. Samples: 5374976. Policy #0 lag: (min: 30.0, avg: 33.0, max: 94.0)
[2026-01-26 14:08:43,040][144664] Avg episode reward: [(0, '1305.766')]
[2026-01-26 14:08:48,065][144664] Fps is (10 sec: 3340.9, 60 sec: 3546.6, 300 sec: 3443.6). Total num frames: 5390336. Throughput: 0: 3503.6. Samples: 5385216. Policy #0 lag: (min: 47.0, avg: 50.0, max: 111.0)
[2026-01-26 14:08:48,065][144664] Avg episode reward: [(0, '1329.774')]
[2026-01-26 14:08:53,045][144664] Fps is (10 sec: 3275.3, 60 sec: 3553.5, 300 sec: 3443.4). Total num frames: 5406720. Throughput: 0: 3501.9. Samples: 5406720. Policy #0 lag: (min: 47.0, avg: 50.0, max: 111.0)
[2026-01-26 14:08:53,045][144664] Avg episode reward: [(0, '1386.844')]
[2026-01-26 14:08:53,177][144664] Saving new best policy, reward=1386.844!
[2026-01-26 14:08:58,044][144664] Fps is (10 sec: 3283.8, 60 sec: 3548.7, 300 sec: 3444.0). Total num frames: 5423104. Throughput: 0: 3464.6. Samples: 5426176. Policy #0 lag: (min: 47.0, avg: 50.0, max: 111.0)
[2026-01-26 14:08:58,044][144664] Avg episode reward: [(0, '1416.109')]
[2026-01-26 14:08:58,186][144664] Saving new best policy, reward=1416.109!
[2026-01-26 14:09:02,998][144664] Fps is (10 sec: 3292.2, 60 sec: 3553.3, 300 sec: 3443.5). Total num frames: 5439488. Throughput: 0: 3498.1. Samples: 5437440. Policy #0 lag: (min: 47.0, avg: 50.0, max: 111.0)
[2026-01-26 14:09:02,998][144664] Avg episode reward: [(0, '1444.948')]
[2026-01-26 14:09:03,143][144664] Saving new best policy, reward=1444.948!
[2026-01-26 14:09:08,074][144664] Fps is (10 sec: 3267.0, 60 sec: 3546.3, 300 sec: 3443.0). Total num frames: 5455872. Throughput: 0: 3447.2. Samples: 5456896. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 14:09:08,074][144664] Avg episode reward: [(0, '1411.250')]
[2026-01-26 14:09:11,082][144664] Signal inference workers to stop experience collection... (1000 times)
[2026-01-26 14:09:11,082][144664] Signal inference workers to resume experience collection... (1000 times)
[2026-01-26 14:09:11,333][144664] InferenceWorker_p0-w0: stopping experience collection (1000 times)
[2026-01-26 14:09:11,333][144664] InferenceWorker_p0-w0: resuming experience collection (1000 times)
[2026-01-26 14:09:13,135][144664] Fps is (10 sec: 3232.4, 60 sec: 3548.9, 300 sec: 3442.5). Total num frames: 5472256. Throughput: 0: 3434.4. Samples: 5477888. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 14:09:13,135][144664] Avg episode reward: [(0, '1391.004')]
[2026-01-26 14:09:18,085][144664] Fps is (10 sec: 3273.2, 60 sec: 3548.6, 300 sec: 3442.6). Total num frames: 5488640. Throughput: 0: 3468.9. Samples: 5488640. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 14:09:18,085][144664] Avg episode reward: [(0, '1407.633')]
[2026-01-26 14:09:23,047][144664] Fps is (10 sec: 3305.9, 60 sec: 3551.2, 300 sec: 3443.9). Total num frames: 5505024. Throughput: 0: 3452.2. Samples: 5508608. Policy #0 lag: (min: 47.0, avg: 50.0, max: 111.0)
[2026-01-26 14:09:23,047][144664] Avg episode reward: [(0, '1436.869')]
[2026-01-26 14:09:27,999][144664] Fps is (10 sec: 3305.3, 60 sec: 3556.6, 300 sec: 3444.0). Total num frames: 5521408. Throughput: 0: 3450.6. Samples: 5530112. Policy #0 lag: (min: 47.0, avg: 50.0, max: 111.0)
[2026-01-26 14:09:27,999][144664] Avg episode reward: [(0, '1468.612')]
[2026-01-26 14:09:28,127][144664] Saving new best policy, reward=1468.612!
[2026-01-26 14:09:33,032][144664] Fps is (10 sec: 3281.8, 60 sec: 3423.8, 300 sec: 3443.5). Total num frames: 5537792. Throughput: 0: 3415.9. Samples: 5538816. Policy #0 lag: (min: 47.0, avg: 50.0, max: 111.0)
[2026-01-26 14:09:33,032][144664] Avg episode reward: [(0, '1449.071')]
[2026-01-26 14:09:38,120][144664] Fps is (10 sec: 3237.7, 60 sec: 3284.3, 300 sec: 3442.8). Total num frames: 5554176. Throughput: 0: 3419.0. Samples: 5560832. Policy #0 lag: (min: 47.0, avg: 50.0, max: 111.0)
[2026-01-26 14:09:38,120][144664] Avg episode reward: [(0, '1405.015')]
[2026-01-26 14:09:43,012][144664] Fps is (10 sec: 3283.3, 60 sec: 3278.3, 300 sec: 3443.9). Total num frames: 5570560. Throughput: 0: 3472.7. Samples: 5582336. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 14:09:43,012][144664] Avg episode reward: [(0, '1460.306')]
[2026-01-26 14:09:48,050][144664] Fps is (10 sec: 3299.8, 60 sec: 3277.6, 300 sec: 3443.2). Total num frames: 5586944. Throughput: 0: 3420.8. Samples: 5591552. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 14:09:48,050][144664] Avg episode reward: [(0, '1455.363')]
[2026-01-26 14:09:53,102][144664] Fps is (10 sec: 3247.8, 60 sec: 3273.7, 300 sec: 3442.3). Total num frames: 5603328. Throughput: 0: 3456.7. Samples: 5612544. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 14:09:53,102][144664] Avg episode reward: [(0, '1513.690')]
[2026-01-26 14:09:53,240][144664] Saving new best policy, reward=1513.690!
[2026-01-26 14:09:58,114][144664] Fps is (10 sec: 3255.8, 60 sec: 3273.0, 300 sec: 3442.8). Total num frames: 5619712. Throughput: 0: 3471.8. Samples: 5634048. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 14:09:58,114][144664] Avg episode reward: [(0, '1454.829')]
[2026-01-26 14:10:03,004][144664] Fps is (10 sec: 3309.0, 60 sec: 3276.5, 300 sec: 3443.4). Total num frames: 5636096. Throughput: 0: 3453.7. Samples: 5643776. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 14:10:03,004][144664] Avg episode reward: [(0, '1462.532')]
[2026-01-26 14:10:03,372][144664] Saving /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_accel_policy1_26012026/checkpoint_p0/checkpoint_000022048_5644288.pth...
[2026-01-26 14:10:03,376][144664] Removing /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_accel_policy1_26012026/checkpoint_p0/checkpoint_000018816_4816896.pth
[2026-01-26 14:10:08,120][144664] Fps is (10 sec: 4093.8, 60 sec: 3410.7, 300 sec: 3471.2). Total num frames: 5660672. Throughput: 0: 3464.6. Samples: 5664768. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 14:10:08,120][144664] Avg episode reward: [(0, '1452.701')]
[2026-01-26 14:10:13,135][144664] Fps is (10 sec: 4851.7, 60 sec: 3549.9, 300 sec: 3497.5). Total num frames: 5685248. Throughput: 0: 3459.8. Samples: 5686272. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 14:10:13,135][144664] Avg episode reward: [(0, '1447.629')]
[2026-01-26 14:10:18,076][144664] Fps is (10 sec: 4113.9, 60 sec: 3550.4, 300 sec: 3499.2). Total num frames: 5701632. Throughput: 0: 3489.6. Samples: 5696000. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 14:10:18,076][144664] Avg episode reward: [(0, '1499.851')]
[2026-01-26 14:10:23,083][144664] Fps is (10 sec: 3294.0, 60 sec: 3547.7, 300 sec: 3498.6). Total num frames: 5718016. Throughput: 0: 3473.1. Samples: 5716992. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 14:10:23,083][144664] Avg episode reward: [(0, '1509.451')]
[2026-01-26 14:10:28,095][144664] Fps is (10 sec: 3270.7, 60 sec: 3544.2, 300 sec: 3473.6). Total num frames: 5734400. Throughput: 0: 3418.4. Samples: 5736448. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 14:10:28,095][144664] Avg episode reward: [(0, '1489.230')]
[2026-01-26 14:10:31,501][144664] Signal inference workers to stop experience collection... (1050 times)
[2026-01-26 14:10:31,867][144664] InferenceWorker_p0-w0: stopping experience collection (1050 times)
[2026-01-26 14:10:31,870][144664] Signal inference workers to resume experience collection... (1050 times)
[2026-01-26 14:10:32,006][144664] InferenceWorker_p0-w0: resuming experience collection (1050 times)
[2026-01-26 14:10:33,051][144664] Fps is (10 sec: 3287.4, 60 sec: 3548.8, 300 sec: 3470.8). Total num frames: 5750784. Throughput: 0: 3470.2. Samples: 5747712. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 14:10:33,051][144664] Avg episode reward: [(0, '1430.778')]
[2026-01-26 14:10:38,044][144664] Fps is (10 sec: 3293.5, 60 sec: 3554.3, 300 sec: 3443.4). Total num frames: 5767168. Throughput: 0: 3463.3. Samples: 5768192. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 14:10:38,044][144664] Avg episode reward: [(0, '1425.825')]
[2026-01-26 14:10:43,017][144664] Fps is (10 sec: 3287.7, 60 sec: 3549.6, 300 sec: 3444.0). Total num frames: 5783552. Throughput: 0: 3432.1. Samples: 5788160. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 14:10:43,018][144664] Avg episode reward: [(0, '1465.483')]
[2026-01-26 14:10:48,005][144664] Fps is (10 sec: 3289.8, 60 sec: 3552.5, 300 sec: 3443.6). Total num frames: 5799936. Throughput: 0: 3447.4. Samples: 5798912. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 14:10:48,005][144664] Avg episode reward: [(0, '1507.149')]
[2026-01-26 14:10:53,094][144664] Fps is (10 sec: 3251.8, 60 sec: 3550.3, 300 sec: 3442.6). Total num frames: 5816320. Throughput: 0: 3426.6. Samples: 5818880. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 14:10:53,095][144664] Avg episode reward: [(0, '1555.246')]
[2026-01-26 14:10:53,240][144664] Saving new best policy, reward=1555.246!
[2026-01-26 14:10:58,072][144664] Fps is (10 sec: 3254.9, 60 sec: 3552.4, 300 sec: 3444.1). Total num frames: 5832704. Throughput: 0: 3406.7. Samples: 5839360. Policy #0 lag: (min: 7.0, avg: 10.0, max: 71.0)
[2026-01-26 14:10:58,072][144664] Avg episode reward: [(0, '1496.816')]
[2026-01-26 14:11:03,064][144664] Fps is (10 sec: 3286.9, 60 sec: 3546.3, 300 sec: 3443.8). Total num frames: 5849088. Throughput: 0: 3425.6. Samples: 5850112. Policy #0 lag: (min: 7.0, avg: 10.0, max: 71.0)
[2026-01-26 14:11:03,064][144664] Avg episode reward: [(0, '1502.215')]
[2026-01-26 14:11:08,077][144664] Fps is (10 sec: 3275.0, 60 sec: 3415.7, 300 sec: 3443.0). Total num frames: 5865472. Throughput: 0: 3402.4. Samples: 5870080. Policy #0 lag: (min: 7.0, avg: 10.0, max: 71.0)
[2026-01-26 14:11:08,078][144664] Avg episode reward: [(0, '1446.511')]
[2026-01-26 14:11:13,088][144664] Fps is (10 sec: 3268.8, 60 sec: 3279.4, 300 sec: 3442.6). Total num frames: 5881856. Throughput: 0: 3448.0. Samples: 5891584. Policy #0 lag: (min: 7.0, avg: 10.0, max: 71.0)
[2026-01-26 14:11:13,088][144664] Avg episode reward: [(0, '1541.237')]
[2026-01-26 14:11:18,124][144664] Fps is (10 sec: 3261.5, 60 sec: 3274.2, 300 sec: 3443.2). Total num frames: 5898240. Throughput: 0: 3407.7. Samples: 5901312. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 14:11:18,125][144664] Avg episode reward: [(0, '1524.061')]
[2026-01-26 14:11:23,122][144664] Fps is (10 sec: 3265.8, 60 sec: 3274.7, 300 sec: 3442.7). Total num frames: 5914624. Throughput: 0: 3418.8. Samples: 5922304. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 14:11:23,122][144664] Avg episode reward: [(0, '1533.189')]
[2026-01-26 14:11:28,077][144664] Fps is (10 sec: 3292.2, 60 sec: 3277.7, 300 sec: 3442.6). Total num frames: 5931008. Throughput: 0: 3454.2. Samples: 5943808. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 14:11:28,078][144664] Avg episode reward: [(0, '1510.103')]
[2026-01-26 14:11:33,020][144664] Fps is (10 sec: 3310.5, 60 sec: 3278.5, 300 sec: 3444.1). Total num frames: 5947392. Throughput: 0: 3434.9. Samples: 5953536. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 14:11:33,020][144664] Avg episode reward: [(0, '1533.593')]
[2026-01-26 14:11:38,089][144664] Fps is (10 sec: 3273.0, 60 sec: 3274.3, 300 sec: 3442.5). Total num frames: 5963776. Throughput: 0: 3470.6. Samples: 5975040. Policy #0 lag: (min: 1.0, avg: 4.0, max: 65.0)
[2026-01-26 14:11:38,089][144664] Avg episode reward: [(0, '1556.561')]
[2026-01-26 14:11:38,455][144664] Saving new best policy, reward=1556.561!
[2026-01-26 14:11:43,279][144664] Fps is (10 sec: 3992.4, 60 sec: 3398.5, 300 sec: 3469.3). Total num frames: 5988352. Throughput: 0: 3454.3. Samples: 5995520. Policy #0 lag: (min: 1.0, avg: 4.0, max: 65.0)
[2026-01-26 14:11:43,280][144664] Avg episode reward: [(0, '1530.137')]
[2026-01-26 14:11:48,096][144664] Signal inference workers to stop experience collection... (1100 times)
[2026-01-26 14:11:48,097][144664] Fps is (10 sec: 4092.9, 60 sec: 3408.1, 300 sec: 3471.0). Total num frames: 6004736. Throughput: 0: 3444.9. Samples: 6005248. Policy #0 lag: (min: 1.0, avg: 4.0, max: 65.0)
[2026-01-26 14:11:48,097][144664] Avg episode reward: [(0, '1494.754')]
[2026-01-26 14:11:48,452][144664] InferenceWorker_p0-w0: stopping experience collection (1100 times)
[2026-01-26 14:11:48,452][144664] Signal inference workers to resume experience collection... (1100 times)
[2026-01-26 14:11:48,452][144664] InferenceWorker_p0-w0: resuming experience collection (1100 times)
[2026-01-26 14:11:53,339][144664] Fps is (10 sec: 4071.8, 60 sec: 3535.5, 300 sec: 3469.1). Total num frames: 6029312. Throughput: 0: 3438.9. Samples: 6025728. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 14:11:53,339][144664] Avg episode reward: [(0, '1503.398')]
[2026-01-26 14:11:58,072][144664] Fps is (10 sec: 4106.3, 60 sec: 3549.9, 300 sec: 3444.6). Total num frames: 6045696. Throughput: 0: 3448.7. Samples: 6046720. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 14:11:58,072][144664] Avg episode reward: [(0, '1512.292')]
[2026-01-26 14:12:03,088][144664] Fps is (10 sec: 3360.9, 60 sec: 3548.4, 300 sec: 3443.8). Total num frames: 6062080. Throughput: 0: 3461.6. Samples: 6056960. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 14:12:03,089][144664] Avg episode reward: [(0, '1524.646')]
[2026-01-26 14:12:03,232][144664] Saving /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_accel_policy1_26012026/checkpoint_p0/checkpoint_000023680_6062080.pth...
[2026-01-26 14:12:03,236][144664] Removing /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_accel_policy1_26012026/checkpoint_p0/checkpoint_000020416_5226496.pth
[2026-01-26 14:12:08,018][144664] Fps is (10 sec: 3294.5, 60 sec: 3553.4, 300 sec: 3444.1). Total num frames: 6078464. Throughput: 0: 3455.4. Samples: 6077440. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 14:12:08,018][144664] Avg episode reward: [(0, '1517.150')]
[2026-01-26 14:12:13,065][144664] Fps is (10 sec: 3284.6, 60 sec: 3551.3, 300 sec: 3442.7). Total num frames: 6094848. Throughput: 0: 3402.9. Samples: 6096896. Policy #0 lag: (min: 10.0, avg: 13.0, max: 74.0)
[2026-01-26 14:12:13,065][144664] Avg episode reward: [(0, '1488.144')]
[2026-01-26 14:12:18,042][144664] Fps is (10 sec: 3268.9, 60 sec: 3554.7, 300 sec: 3444.1). Total num frames: 6111232. Throughput: 0: 3434.4. Samples: 6108160. Policy #0 lag: (min: 10.0, avg: 13.0, max: 74.0)
[2026-01-26 14:12:18,042][144664] Avg episode reward: [(0, '1505.969')]
[2026-01-26 14:12:23,005][144664] Fps is (10 sec: 3296.4, 60 sec: 3556.8, 300 sec: 3444.8). Total num frames: 6127616. Throughput: 0: 3419.7. Samples: 6128640. Policy #0 lag: (min: 10.0, avg: 13.0, max: 74.0)
[2026-01-26 14:12:23,006][144664] Avg episode reward: [(0, '1494.511')]
[2026-01-26 14:12:28,132][144664] Fps is (10 sec: 3247.6, 60 sec: 3546.6, 300 sec: 3443.1). Total num frames: 6144000. Throughput: 0: 3436.0. Samples: 6149632. Policy #0 lag: (min: 10.0, avg: 13.0, max: 74.0)
[2026-01-26 14:12:28,132][144664] Avg episode reward: [(0, '1558.595')]
[2026-01-26 14:12:28,134][144664] Saving new best policy, reward=1558.595!
[2026-01-26 14:12:33,035][144664] Fps is (10 sec: 3267.1, 60 sec: 3549.0, 300 sec: 3444.1). Total num frames: 6160384. Throughput: 0: 3463.6. Samples: 6160896. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 14:12:33,035][144664] Avg episode reward: [(0, '1562.556')]
[2026-01-26 14:12:33,184][144664] Saving new best policy, reward=1562.556!
[2026-01-26 14:12:38,120][144664] Fps is (10 sec: 3280.8, 60 sec: 3548.0, 300 sec: 3442.2). Total num frames: 6176768. Throughput: 0: 3441.4. Samples: 6179840. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 14:12:38,120][144664] Avg episode reward: [(0, '1549.856')]
[2026-01-26 14:12:43,009][144664] Fps is (10 sec: 3285.3, 60 sec: 3428.8, 300 sec: 3443.4). Total num frames: 6193152. Throughput: 0: 3429.5. Samples: 6200832. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 14:12:43,009][144664] Avg episode reward: [(0, '1510.327')]
[2026-01-26 14:12:48,093][144664] Fps is (10 sec: 3285.7, 60 sec: 3413.6, 300 sec: 3443.6). Total num frames: 6209536. Throughput: 0: 3413.0. Samples: 6210560. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 14:12:48,093][144664] Avg episode reward: [(0, '1500.670')]
[2026-01-26 14:12:53,058][144664] Fps is (10 sec: 3260.9, 60 sec: 3292.2, 300 sec: 3443.0). Total num frames: 6225920. Throughput: 0: 3421.7. Samples: 6231552. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 14:12:53,058][144664] Avg episode reward: [(0, '1534.973')]
[2026-01-26 14:12:58,041][144664] Fps is (10 sec: 3293.9, 60 sec: 3278.5, 300 sec: 3443.6). Total num frames: 6242304. Throughput: 0: 3460.7. Samples: 6252544. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 14:12:58,041][144664] Avg episode reward: [(0, '1579.293')]
[2026-01-26 14:12:58,187][144664] Saving new best policy, reward=1579.293!
[2026-01-26 14:13:03,070][144664] Fps is (10 sec: 3272.9, 60 sec: 3277.8, 300 sec: 3442.8). Total num frames: 6258688. Throughput: 0: 3422.6. Samples: 6262272. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 14:13:03,070][144664] Avg episode reward: [(0, '1629.609')]
[2026-01-26 14:13:03,215][144664] Saving new best policy, reward=1629.609!
[2026-01-26 14:13:08,105][144664] Fps is (10 sec: 3256.0, 60 sec: 3272.1, 300 sec: 3443.6). Total num frames: 6275072. Throughput: 0: 3428.5. Samples: 6283264. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 14:13:08,105][144664] Avg episode reward: [(0, '1637.008')]
[2026-01-26 14:13:08,248][144664] Saving new best policy, reward=1637.008!
[2026-01-26 14:13:09,163][144664] Signal inference workers to stop experience collection... (1150 times)
[2026-01-26 14:13:09,170][144664] Signal inference workers to resume experience collection... (1150 times)
[2026-01-26 14:13:09,411][144664] InferenceWorker_p0-w0: stopping experience collection (1150 times)
[2026-01-26 14:13:09,411][144664] InferenceWorker_p0-w0: resuming experience collection (1150 times)
[2026-01-26 14:13:13,050][144664] Fps is (10 sec: 3283.2, 60 sec: 3277.6, 300 sec: 3443.6). Total num frames: 6291456. Throughput: 0: 3442.3. Samples: 6304256. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 14:13:13,050][144664] Avg episode reward: [(0, '1634.633')]
[2026-01-26 14:13:18,090][144664] Fps is (10 sec: 3281.7, 60 sec: 3274.2, 300 sec: 3443.2). Total num frames: 6307840. Throughput: 0: 3397.8. Samples: 6313984. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 14:13:18,090][144664] Avg episode reward: [(0, '1566.419')]
[2026-01-26 14:13:23,065][144664] Fps is (10 sec: 3272.1, 60 sec: 3273.6, 300 sec: 3444.0). Total num frames: 6324224. Throughput: 0: 3463.1. Samples: 6335488. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 14:13:23,065][144664] Avg episode reward: [(0, '1543.285')]
[2026-01-26 14:13:28,127][144664] Fps is (10 sec: 4081.1, 60 sec: 3413.6, 300 sec: 3444.4). Total num frames: 6348800. Throughput: 0: 3461.2. Samples: 6356992. Policy #0 lag: (min: 11.0, avg: 14.0, max: 75.0)
[2026-01-26 14:13:28,127][144664] Avg episode reward: [(0, '1487.699')]
[2026-01-26 14:13:33,210][144664] Fps is (10 sec: 4844.8, 60 sec: 3539.5, 300 sec: 3444.0). Total num frames: 6373376. Throughput: 0: 3449.9. Samples: 6366208. Policy #0 lag: (min: 11.0, avg: 14.0, max: 75.0)
[2026-01-26 14:13:33,210][144664] Avg episode reward: [(0, '1516.345')]
[2026-01-26 14:13:38,051][144664] Fps is (10 sec: 4127.2, 60 sec: 3554.0, 300 sec: 3443.3). Total num frames: 6389760. Throughput: 0: 3470.7. Samples: 6387712. Policy #0 lag: (min: 11.0, avg: 14.0, max: 75.0)
[2026-01-26 14:13:38,051][144664] Avg episode reward: [(0, '1515.963')]
[2026-01-26 14:13:43,015][144664] Fps is (10 sec: 3341.8, 60 sec: 3549.5, 300 sec: 3444.0). Total num frames: 6406144. Throughput: 0: 3438.1. Samples: 6407168. Policy #0 lag: (min: 11.0, avg: 14.0, max: 75.0)
[2026-01-26 14:13:43,016][144664] Avg episode reward: [(0, '1564.194')]
[2026-01-26 14:13:48,113][144664] Fps is (10 sec: 3256.5, 60 sec: 3548.7, 300 sec: 3442.6). Total num frames: 6422528. Throughput: 0: 3466.9. Samples: 6418432. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 14:13:48,113][144664] Avg episode reward: [(0, '1590.016')]
[2026-01-26 14:13:53,087][144664] Fps is (10 sec: 3253.4, 60 sec: 3548.1, 300 sec: 3442.9). Total num frames: 6438912. Throughput: 0: 3471.6. Samples: 6439424. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 14:13:53,088][144664] Avg episode reward: [(0, '1595.397')]
[2026-01-26 14:13:58,113][144664] Fps is (10 sec: 3276.9, 60 sec: 3545.6, 300 sec: 3442.1). Total num frames: 6455296. Throughput: 0: 3442.7. Samples: 6459392. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 14:13:58,113][144664] Avg episode reward: [(0, '1593.310')]
[2026-01-26 14:14:03,073][144664] Fps is (10 sec: 3281.7, 60 sec: 3549.7, 300 sec: 3443.4). Total num frames: 6471680. Throughput: 0: 3482.9. Samples: 6470656. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 14:14:03,073][144664] Avg episode reward: [(0, '1594.150')]
[2026-01-26 14:14:03,213][144664] Saving /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_accel_policy1_26012026/checkpoint_p0/checkpoint_000025280_6471680.pth...
[2026-01-26 14:14:03,217][144664] Removing /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_accel_policy1_26012026/checkpoint_p0/checkpoint_000022048_5644288.pth
[2026-01-26 14:14:08,094][144664] Fps is (10 sec: 3283.0, 60 sec: 3550.5, 300 sec: 3443.9). Total num frames: 6488064. Throughput: 0: 3433.8. Samples: 6490112. Policy #0 lag: (min: 2.0, avg: 5.0, max: 66.0)
[2026-01-26 14:14:08,094][144664] Avg episode reward: [(0, '1583.892')]
[2026-01-26 14:14:13,051][144664] Fps is (10 sec: 3284.0, 60 sec: 3549.8, 300 sec: 3443.8). Total num frames: 6504448. Throughput: 0: 3441.9. Samples: 6511616. Policy #0 lag: (min: 2.0, avg: 5.0, max: 66.0)
[2026-01-26 14:14:13,056][144664] Avg episode reward: [(0, '1576.106')]
[2026-01-26 14:14:18,075][144664] Fps is (10 sec: 3283.0, 60 sec: 3550.7, 300 sec: 3443.1). Total num frames: 6520832. Throughput: 0: 3469.2. Samples: 6521856. Policy #0 lag: (min: 2.0, avg: 5.0, max: 66.0)
[2026-01-26 14:14:18,075][144664] Avg episode reward: [(0, '1580.396')]
[2026-01-26 14:14:23,043][144664] Fps is (10 sec: 3279.2, 60 sec: 3551.1, 300 sec: 3442.9). Total num frames: 6537216. Throughput: 0: 3448.0. Samples: 6542848. Policy #0 lag: (min: 2.0, avg: 5.0, max: 66.0)
[2026-01-26 14:14:23,044][144664] Avg episode reward: [(0, '1549.656')]
[2026-01-26 14:14:27,996][144664] Fps is (10 sec: 3302.9, 60 sec: 3420.8, 300 sec: 3443.8). Total num frames: 6553600. Throughput: 0: 3494.5. Samples: 6564352. Policy #0 lag: (min: 4.0, avg: 7.0, max: 68.0)
[2026-01-26 14:14:27,996][144664] Avg episode reward: [(0, '1535.769')]
[2026-01-26 14:14:29,219][144664] Signal inference workers to stop experience collection... (1200 times)
[2026-01-26 14:14:29,566][144664] InferenceWorker_p0-w0: stopping experience collection (1200 times)
[2026-01-26 14:14:29,568][144664] Signal inference workers to resume experience collection... (1200 times)
[2026-01-26 14:14:29,699][144664] InferenceWorker_p0-w0: resuming experience collection (1200 times)
[2026-01-26 14:14:33,107][144664] Fps is (10 sec: 3256.1, 60 sec: 3282.4, 300 sec: 3443.6). Total num frames: 6569984. Throughput: 0: 3459.3. Samples: 6574080. Policy #0 lag: (min: 4.0, avg: 7.0, max: 68.0)
[2026-01-26 14:14:33,107][144664] Avg episode reward: [(0, '1516.038')]
[2026-01-26 14:14:38,057][144664] Fps is (10 sec: 3257.0, 60 sec: 3276.5, 300 sec: 3442.9). Total num frames: 6586368. Throughput: 0: 3472.6. Samples: 6595584. Policy #0 lag: (min: 4.0, avg: 7.0, max: 68.0)
[2026-01-26 14:14:38,057][144664] Avg episode reward: [(0, '1560.590')]
[2026-01-26 14:14:43,021][144664] Fps is (10 sec: 3305.0, 60 sec: 3276.5, 300 sec: 3443.7). Total num frames: 6602752. Throughput: 0: 3488.7. Samples: 6616064. Policy #0 lag: (min: 4.0, avg: 7.0, max: 68.0)
[2026-01-26 14:14:43,022][144664] Avg episode reward: [(0, '1552.307')]
[2026-01-26 14:14:48,026][144664] Fps is (10 sec: 3287.0, 60 sec: 3281.6, 300 sec: 3444.3). Total num frames: 6619136. Throughput: 0: 3462.4. Samples: 6626304. Policy #0 lag: (min: 0.0, avg: 3.0, max: 64.0)
[2026-01-26 14:14:48,026][144664] Avg episode reward: [(0, '1519.298')]
[2026-01-26 14:14:53,139][144664] Fps is (10 sec: 4048.4, 60 sec: 3410.4, 300 sec: 3470.9). Total num frames: 6643712. Throughput: 0: 3500.8. Samples: 6647808. Policy #0 lag: (min: 0.0, avg: 3.0, max: 64.0)
[2026-01-26 14:14:53,139][144664] Avg episode reward: [(0, '1466.043')]
[2026-01-26 14:14:58,268][144664] Fps is (10 sec: 4799.0, 60 sec: 3540.7, 300 sec: 3495.8). Total num frames: 6668288. Throughput: 0: 3476.2. Samples: 6668800. Policy #0 lag: (min: 0.0, avg: 3.0, max: 64.0)
[2026-01-26 14:14:58,268][144664] Avg episode reward: [(0, '1494.585')]
[2026-01-26 14:15:03,081][144664] Fps is (10 sec: 4119.8, 60 sec: 3549.3, 300 sec: 3471.6). Total num frames: 6684672. Throughput: 0: 3481.1. Samples: 6678528. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 14:15:03,082][144664] Avg episode reward: [(0, '1539.018')]
[2026-01-26 14:15:08,030][144664] Fps is (10 sec: 3356.7, 60 sec: 3553.7, 300 sec: 3444.6). Total num frames: 6701056. Throughput: 0: 3471.2. Samples: 6699008. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 14:15:08,030][144664] Avg episode reward: [(0, '1546.764')]
[2026-01-26 14:15:13,116][144664] Fps is (10 sec: 3265.4, 60 sec: 3546.0, 300 sec: 3442.9). Total num frames: 6717440. Throughput: 0: 3415.6. Samples: 6718464. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 14:15:13,116][144664] Avg episode reward: [(0, '1523.987')]
[2026-01-26 14:15:18,035][144664] Fps is (10 sec: 3275.1, 60 sec: 3552.2, 300 sec: 3444.0). Total num frames: 6733824. Throughput: 0: 3464.4. Samples: 6729728. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 14:15:18,035][144664] Avg episode reward: [(0, '1536.544')]
[2026-01-26 14:15:23,090][144664] Fps is (10 sec: 3285.5, 60 sec: 3547.1, 300 sec: 3443.5). Total num frames: 6750208. Throughput: 0: 3444.9. Samples: 6750720. Policy #0 lag: (min: 4.0, avg: 7.0, max: 68.0)
[2026-01-26 14:15:23,090][144664] Avg episode reward: [(0, '1560.477')]
[2026-01-26 14:15:28,129][144664] Fps is (10 sec: 3246.5, 60 sec: 3542.1, 300 sec: 3442.5). Total num frames: 6766592. Throughput: 0: 3427.9. Samples: 6770688. Policy #0 lag: (min: 4.0, avg: 7.0, max: 68.0)
[2026-01-26 14:15:28,129][144664] Avg episode reward: [(0, '1531.770')]
[2026-01-26 14:15:33,056][144664] Fps is (10 sec: 3287.9, 60 sec: 3552.9, 300 sec: 3443.3). Total num frames: 6782976. Throughput: 0: 3445.2. Samples: 6781440. Policy #0 lag: (min: 4.0, avg: 7.0, max: 68.0)
[2026-01-26 14:15:33,056][144664] Avg episode reward: [(0, '1493.244')]
[2026-01-26 14:15:38,091][144664] Fps is (10 sec: 3289.1, 60 sec: 3547.8, 300 sec: 3442.6). Total num frames: 6799360. Throughput: 0: 3394.2. Samples: 6800384. Policy #0 lag: (min: 4.0, avg: 7.0, max: 68.0)
[2026-01-26 14:15:38,091][144664] Avg episode reward: [(0, '1484.979')]
[2026-01-26 14:15:43,080][144664] Fps is (10 sec: 3269.0, 60 sec: 3546.4, 300 sec: 3442.5). Total num frames: 6815744. Throughput: 0: 3393.4. Samples: 6820864. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 14:15:43,080][144664] Avg episode reward: [(0, '1492.142')]
[2026-01-26 14:15:45,986][144664] Signal inference workers to stop experience collection... (1250 times)
[2026-01-26 14:15:46,341][144664] InferenceWorker_p0-w0: stopping experience collection (1250 times)
[2026-01-26 14:15:46,341][144664] Signal inference workers to resume experience collection... (1250 times)
[2026-01-26 14:15:46,341][144664] InferenceWorker_p0-w0: resuming experience collection (1250 times)
[2026-01-26 14:15:48,137][144664] Fps is (10 sec: 3261.8, 60 sec: 3543.3, 300 sec: 3442.9). Total num frames: 6832128. Throughput: 0: 3409.1. Samples: 6832128. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 14:15:48,137][144664] Avg episode reward: [(0, '1506.579')]
[2026-01-26 14:15:53,064][144664] Fps is (10 sec: 3282.1, 60 sec: 3417.6, 300 sec: 3443.5). Total num frames: 6848512. Throughput: 0: 3376.7. Samples: 6851072. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 14:15:53,064][144664] Avg episode reward: [(0, '1547.113')]
[2026-01-26 14:15:58,108][144664] Fps is (10 sec: 3286.3, 60 sec: 3285.5, 300 sec: 3442.9). Total num frames: 6864896. Throughput: 0: 3436.7. Samples: 6873088. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 14:15:58,108][144664] Avg episode reward: [(0, '1550.981')]
[2026-01-26 14:16:03,001][144664] Fps is (10 sec: 3297.3, 60 sec: 3281.2, 300 sec: 3444.3). Total num frames: 6881280. Throughput: 0: 3393.1. Samples: 6882304. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 14:16:03,001][144664] Avg episode reward: [(0, '1532.067')]
[2026-01-26 14:16:03,142][144664] Saving /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_accel_policy1_26012026/checkpoint_p0/checkpoint_000026880_6881280.pth...
[2026-01-26 14:16:03,146][144664] Removing /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_accel_policy1_26012026/checkpoint_p0/checkpoint_000023680_6062080.pth
[2026-01-26 14:16:08,047][144664] Fps is (10 sec: 3297.1, 60 sec: 3275.9, 300 sec: 3443.9). Total num frames: 6897664. Throughput: 0: 3405.2. Samples: 6903808. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 14:16:08,047][144664] Avg episode reward: [(0, '1493.582')]
[2026-01-26 14:16:13,015][144664] Fps is (10 sec: 3272.3, 60 sec: 3282.3, 300 sec: 3444.7). Total num frames: 6914048. Throughput: 0: 3433.4. Samples: 6924800. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 14:16:13,015][144664] Avg episode reward: [(0, '1546.165')]
[2026-01-26 14:16:18,123][144664] Fps is (10 sec: 3251.8, 60 sec: 3272.0, 300 sec: 3443.4). Total num frames: 6930432. Throughput: 0: 3408.2. Samples: 6935040. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 14:16:18,124][144664] Avg episode reward: [(0, '1550.606')]
[2026-01-26 14:16:23,067][144664] Fps is (10 sec: 3259.9, 60 sec: 3278.0, 300 sec: 3443.5). Total num frames: 6946816. Throughput: 0: 3460.7. Samples: 6956032. Policy #0 lag: (min: 0.0, avg: 3.0, max: 64.0)
[2026-01-26 14:16:23,067][144664] Avg episode reward: [(0, '1552.334')]
[2026-01-26 14:16:28,116][144664] Fps is (10 sec: 3279.1, 60 sec: 3277.5, 300 sec: 3442.3). Total num frames: 6963200. Throughput: 0: 3478.8. Samples: 6977536. Policy #0 lag: (min: 0.0, avg: 3.0, max: 64.0)
[2026-01-26 14:16:28,117][144664] Avg episode reward: [(0, '1508.952')]
[2026-01-26 14:16:33,024][144664] Fps is (10 sec: 3290.8, 60 sec: 3278.5, 300 sec: 3444.2). Total num frames: 6979584. Throughput: 0: 3456.1. Samples: 6987264. Policy #0 lag: (min: 0.0, avg: 3.0, max: 64.0)
[2026-01-26 14:16:33,025][144664] Avg episode reward: [(0, '1475.999')]
[2026-01-26 14:16:38,051][144664] Fps is (10 sec: 4122.8, 60 sec: 3415.6, 300 sec: 3446.1). Total num frames: 7004160. Throughput: 0: 3493.9. Samples: 7008256. Policy #0 lag: (min: 5.0, avg: 8.0, max: 69.0)
[2026-01-26 14:16:38,051][144664] Avg episode reward: [(0, '1488.316')]
[2026-01-26 14:16:43,132][144664] Fps is (10 sec: 4862.9, 60 sec: 3546.8, 300 sec: 3470.8). Total num frames: 7028736. Throughput: 0: 3479.8. Samples: 7029760. Policy #0 lag: (min: 5.0, avg: 8.0, max: 69.0)
[2026-01-26 14:16:43,132][144664] Avg episode reward: [(0, '1474.020')]
[2026-01-26 14:16:47,995][144664] Fps is (10 sec: 4119.1, 60 sec: 3558.3, 300 sec: 3447.4). Total num frames: 7045120. Throughput: 0: 3493.5. Samples: 7039488. Policy #0 lag: (min: 5.0, avg: 8.0, max: 69.0)
[2026-01-26 14:16:47,995][144664] Avg episode reward: [(0, '1521.108')]
[2026-01-26 14:16:53,055][144664] Fps is (10 sec: 3302.1, 60 sec: 3550.4, 300 sec: 3443.6). Total num frames: 7061504. Throughput: 0: 3480.9. Samples: 7060480. Policy #0 lag: (min: 5.0, avg: 8.0, max: 69.0)
[2026-01-26 14:16:53,055][144664] Avg episode reward: [(0, '1482.982')]
[2026-01-26 14:16:58,115][144664] Fps is (10 sec: 3237.9, 60 sec: 3549.5, 300 sec: 3443.1). Total num frames: 7077888. Throughput: 0: 3439.8. Samples: 7079936. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 14:16:58,115][144664] Avg episode reward: [(0, '1463.833')]
[2026-01-26 14:17:03,066][144664] Fps is (10 sec: 3273.3, 60 sec: 3546.0, 300 sec: 3442.9). Total num frames: 7094272. Throughput: 0: 3474.6. Samples: 7091200. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 14:17:03,066][144664] Avg episode reward: [(0, '1484.121')]
[2026-01-26 14:17:06,490][144664] Signal inference workers to stop experience collection... (1300 times)
[2026-01-26 14:17:06,491][144664] Signal inference workers to resume experience collection... (1300 times)
[2026-01-26 14:17:06,747][144664] InferenceWorker_p0-w0: stopping experience collection (1300 times)
[2026-01-26 14:17:06,747][144664] InferenceWorker_p0-w0: resuming experience collection (1300 times)
[2026-01-26 14:17:08,078][144664] Fps is (10 sec: 3289.0, 60 sec: 3548.0, 300 sec: 3443.3). Total num frames: 7110656. Throughput: 0: 3458.0. Samples: 7111680. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 14:17:08,078][144664] Avg episode reward: [(0, '1487.719')]
[2026-01-26 14:17:13,017][144664] Fps is (10 sec: 3292.8, 60 sec: 3549.7, 300 sec: 3443.7). Total num frames: 7127040. Throughput: 0: 3443.7. Samples: 7132160. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 14:17:13,018][144664] Avg episode reward: [(0, '1497.530')]
[2026-01-26 14:17:18,045][144664] Fps is (10 sec: 3287.6, 60 sec: 3554.5, 300 sec: 3442.9). Total num frames: 7143424. Throughput: 0: 3468.6. Samples: 7143424. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 14:17:18,046][144664] Avg episode reward: [(0, '1486.677')]
[2026-01-26 14:17:23,089][144664] Fps is (10 sec: 3253.6, 60 sec: 3548.6, 300 sec: 3443.9). Total num frames: 7159808. Throughput: 0: 3421.9. Samples: 7162368. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 14:17:23,089][144664] Avg episode reward: [(0, '1477.933')]
[2026-01-26 14:17:28,017][144664] Fps is (10 sec: 3286.1, 60 sec: 3555.7, 300 sec: 3443.6). Total num frames: 7176192. Throughput: 0: 3433.5. Samples: 7183872. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 14:17:28,017][144664] Avg episode reward: [(0, '1464.749')]
[2026-01-26 14:17:33,070][144664] Fps is (10 sec: 3283.0, 60 sec: 3547.2, 300 sec: 3444.0). Total num frames: 7192576. Throughput: 0: 3419.0. Samples: 7193600. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 14:17:33,070][144664] Avg episode reward: [(0, '1476.896')]
[2026-01-26 14:17:38,036][144664] Fps is (10 sec: 3270.6, 60 sec: 3414.2, 300 sec: 3443.1). Total num frames: 7208960. Throughput: 0: 3448.9. Samples: 7215616. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 14:17:38,036][144664] Avg episode reward: [(0, '1524.613')]
[2026-01-26 14:17:43,123][144664] Fps is (10 sec: 3259.6, 60 sec: 3277.3, 300 sec: 3443.1). Total num frames: 7225344. Throughput: 0: 3492.4. Samples: 7237120. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 14:17:43,123][144664] Avg episode reward: [(0, '1514.174')]
[2026-01-26 14:17:48,051][144664] Fps is (10 sec: 3271.8, 60 sec: 3273.7, 300 sec: 3443.5). Total num frames: 7241728. Throughput: 0: 3460.0. Samples: 7246848. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 14:17:48,052][144664] Avg episode reward: [(0, '1518.931')]
[2026-01-26 14:17:53,103][144664] Fps is (10 sec: 3283.3, 60 sec: 3274.2, 300 sec: 3442.7). Total num frames: 7258112. Throughput: 0: 3468.3. Samples: 7267840. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 14:17:53,103][144664] Avg episode reward: [(0, '1508.553')]
[2026-01-26 14:17:58,126][144664] Fps is (10 sec: 3252.6, 60 sec: 3276.2, 300 sec: 3442.8). Total num frames: 7274496. Throughput: 0: 3473.2. Samples: 7288832. Policy #0 lag: (min: 4.0, avg: 7.0, max: 68.0)
[2026-01-26 14:17:58,126][144664] Avg episode reward: [(0, '1508.305')]
[2026-01-26 14:18:03,209][144664] Fps is (10 sec: 4053.1, 60 sec: 3405.2, 300 sec: 3470.0). Total num frames: 7299072. Throughput: 0: 3446.3. Samples: 7299072. Policy #0 lag: (min: 4.0, avg: 7.0, max: 68.0)
[2026-01-26 14:18:03,209][144664] Avg episode reward: [(0, '1533.727')]
[2026-01-26 14:18:03,567][144664] Saving /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_accel_policy1_26012026/checkpoint_p0/checkpoint_000028544_7307264.pth...
[2026-01-26 14:18:03,571][144664] Removing /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_accel_policy1_26012026/checkpoint_p0/checkpoint_000025280_6471680.pth
[2026-01-26 14:18:08,348][144664] Fps is (10 sec: 4007.0, 60 sec: 3398.0, 300 sec: 3467.7). Total num frames: 7315456. Throughput: 0: 3484.3. Samples: 7320064. Policy #0 lag: (min: 4.0, avg: 7.0, max: 68.0)
[2026-01-26 14:18:08,348][144664] Avg episode reward: [(0, '1554.451')]
[2026-01-26 14:18:13,136][144664] Fps is (10 sec: 4126.1, 60 sec: 3542.9, 300 sec: 3498.4). Total num frames: 7340032. Throughput: 0: 3483.8. Samples: 7341056. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 14:18:13,136][144664] Avg episode reward: [(0, '1584.077')]
[2026-01-26 14:18:18,014][144664] Fps is (10 sec: 4237.6, 60 sec: 3551.7, 300 sec: 3499.6). Total num frames: 7356416. Throughput: 0: 3497.3. Samples: 7350784. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 14:18:18,014][144664] Avg episode reward: [(0, '1622.384')]
[2026-01-26 14:18:23,099][144664] Fps is (10 sec: 3288.9, 60 sec: 3549.3, 300 sec: 3471.5). Total num frames: 7372800. Throughput: 0: 3465.4. Samples: 7371776. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 14:18:23,099][144664] Avg episode reward: [(0, '1576.649')]
[2026-01-26 14:18:26,552][144664] Signal inference workers to stop experience collection... (1350 times)
[2026-01-26 14:18:26,910][144664] InferenceWorker_p0-w0: stopping experience collection (1350 times)
[2026-01-26 14:18:26,912][144664] Signal inference workers to resume experience collection... (1350 times)
[2026-01-26 14:18:27,052][144664] InferenceWorker_p0-w0: resuming experience collection (1350 times)
[2026-01-26 14:18:28,091][144664] Fps is (10 sec: 3251.9, 60 sec: 3545.5, 300 sec: 3444.8). Total num frames: 7389184. Throughput: 0: 3438.5. Samples: 7391744. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 14:18:28,091][144664] Avg episode reward: [(0, '1581.314')]
[2026-01-26 14:18:33,130][144664] Fps is (10 sec: 3266.8, 60 sec: 3546.3, 300 sec: 3442.5). Total num frames: 7405568. Throughput: 0: 3464.2. Samples: 7403008. Policy #0 lag: (min: 8.0, avg: 11.0, max: 72.0)
[2026-01-26 14:18:33,130][144664] Avg episode reward: [(0, '1586.847')]
[2026-01-26 14:18:38,122][144664] Fps is (10 sec: 3266.7, 60 sec: 3544.8, 300 sec: 3442.2). Total num frames: 7421952. Throughput: 0: 3446.0. Samples: 7422976. Policy #0 lag: (min: 8.0, avg: 11.0, max: 72.0)
[2026-01-26 14:18:38,122][144664] Avg episode reward: [(0, '1674.631')]
[2026-01-26 14:18:38,124][144664] Saving new best policy, reward=1674.631!
[2026-01-26 14:18:43,044][144664] Fps is (10 sec: 3305.2, 60 sec: 3554.5, 300 sec: 3444.2). Total num frames: 7438336. Throughput: 0: 3442.4. Samples: 7443456. Policy #0 lag: (min: 8.0, avg: 11.0, max: 72.0)
[2026-01-26 14:18:43,044][144664] Avg episode reward: [(0, '1621.945')]
[2026-01-26 14:18:48,045][144664] Fps is (10 sec: 3301.9, 60 sec: 3550.2, 300 sec: 3443.9). Total num frames: 7454720. Throughput: 0: 3471.4. Samples: 7454720. Policy #0 lag: (min: 8.0, avg: 11.0, max: 72.0)
[2026-01-26 14:18:48,046][144664] Avg episode reward: [(0, '1604.836')]
[2026-01-26 14:18:53,103][144664] Fps is (10 sec: 3257.4, 60 sec: 3549.8, 300 sec: 3443.5). Total num frames: 7471104. Throughput: 0: 3443.4. Samples: 7474176. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 14:18:53,104][144664] Avg episode reward: [(0, '1536.151')]
[2026-01-26 14:18:58,065][144664] Fps is (10 sec: 3270.3, 60 sec: 3553.5, 300 sec: 3443.5). Total num frames: 7487488. Throughput: 0: 3430.1. Samples: 7495168. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 14:18:58,066][144664] Avg episode reward: [(0, '1594.551')]
[2026-01-26 14:19:03,060][144664] Fps is (10 sec: 3291.2, 60 sec: 3421.8, 300 sec: 3443.8). Total num frames: 7503872. Throughput: 0: 3421.2. Samples: 7504896. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 14:19:03,060][144664] Avg episode reward: [(0, '1586.212')]
[2026-01-26 14:19:08,004][144664] Fps is (10 sec: 3297.0, 60 sec: 3433.0, 300 sec: 3444.0). Total num frames: 7520256. Throughput: 0: 3409.1. Samples: 7524864. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 14:19:08,005][144664] Avg episode reward: [(0, '1644.758')]
[2026-01-26 14:19:13,027][144664] Fps is (10 sec: 3287.5, 60 sec: 3282.8, 300 sec: 3444.0). Total num frames: 7536640. Throughput: 0: 3429.6. Samples: 7545856. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 14:19:13,027][144664] Avg episode reward: [(0, '1613.741')]
[2026-01-26 14:19:18,129][144664] Fps is (10 sec: 3236.3, 60 sec: 3270.5, 300 sec: 3442.4). Total num frames: 7553024. Throughput: 0: 3390.6. Samples: 7555584. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 14:19:18,130][144664] Avg episode reward: [(0, '1579.515')]
[2026-01-26 14:19:23,057][144664] Fps is (10 sec: 3267.0, 60 sec: 3279.1, 300 sec: 3442.7). Total num frames: 7569408. Throughput: 0: 3406.8. Samples: 7576064. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 14:19:23,057][144664] Avg episode reward: [(0, '1537.353')]
[2026-01-26 14:19:28,089][144664] Fps is (10 sec: 3290.1, 60 sec: 3276.9, 300 sec: 3443.6). Total num frames: 7585792. Throughput: 0: 3398.6. Samples: 7596544. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 14:19:28,089][144664] Avg episode reward: [(0, '1550.224')]
[2026-01-26 14:19:33,134][144664] Fps is (10 sec: 3251.8, 60 sec: 3276.6, 300 sec: 3442.5). Total num frames: 7602176. Throughput: 0: 3349.9. Samples: 7605760. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 14:19:33,134][144664] Avg episode reward: [(0, '1553.384')]
[2026-01-26 14:19:38,027][144664] Fps is (10 sec: 3297.2, 60 sec: 3282.0, 300 sec: 3443.4). Total num frames: 7618560. Throughput: 0: 3362.1. Samples: 7625216. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 14:19:38,027][144664] Avg episode reward: [(0, '1600.205')]
[2026-01-26 14:19:43,067][144664] Fps is (10 sec: 3298.8, 60 sec: 3275.5, 300 sec: 3442.9). Total num frames: 7634944. Throughput: 0: 3333.6. Samples: 7645184. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 14:19:43,067][144664] Avg episode reward: [(0, '1523.557')]
[2026-01-26 14:19:44,645][144664] Signal inference workers to stop experience collection... (1400 times)
[2026-01-26 14:19:45,000][144664] InferenceWorker_p0-w0: stopping experience collection (1400 times)
[2026-01-26 14:19:45,000][144664] Signal inference workers to resume experience collection... (1400 times)
[2026-01-26 14:19:45,001][144664] InferenceWorker_p0-w0: resuming experience collection (1400 times)
[2026-01-26 14:19:48,089][144664] Fps is (10 sec: 3256.5, 60 sec: 3274.4, 300 sec: 3416.2). Total num frames: 7651328. Throughput: 0: 3331.5. Samples: 7654912. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 14:19:48,090][144664] Avg episode reward: [(0, '1537.602')]
[2026-01-26 14:19:53,039][144664] Fps is (10 sec: 3286.0, 60 sec: 3280.3, 300 sec: 3390.5). Total num frames: 7667712. Throughput: 0: 3365.2. Samples: 7676416. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 14:19:53,039][144664] Avg episode reward: [(0, '1527.387')]
[2026-01-26 14:19:58,077][144664] Fps is (10 sec: 3280.8, 60 sec: 3276.2, 300 sec: 3387.9). Total num frames: 7684096. Throughput: 0: 3364.1. Samples: 7697408. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 14:19:58,077][144664] Avg episode reward: [(0, '1545.459')]
[2026-01-26 14:20:03,052][144664] Fps is (10 sec: 3272.6, 60 sec: 3277.2, 300 sec: 3387.6). Total num frames: 7700480. Throughput: 0: 3373.6. Samples: 7707136. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 14:20:03,052][144664] Avg episode reward: [(0, '1568.863')]
[2026-01-26 14:20:03,200][144664] Saving /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_accel_policy1_26012026/checkpoint_p0/checkpoint_000030080_7700480.pth...
[2026-01-26 14:20:03,204][144664] Removing /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_accel_policy1_26012026/checkpoint_p0/checkpoint_000026880_6881280.pth
[2026-01-26 14:20:08,267][144664] Fps is (10 sec: 4019.6, 60 sec: 3398.4, 300 sec: 3413.9). Total num frames: 7725056. Throughput: 0: 3374.8. Samples: 7728640. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 14:20:08,267][144664] Avg episode reward: [(0, '1570.019')]
[2026-01-26 14:20:13,289][144664] Fps is (10 sec: 4801.1, 60 sec: 3534.4, 300 sec: 3440.5). Total num frames: 7749632. Throughput: 0: 3398.2. Samples: 7750144. Policy #0 lag: (min: 13.0, avg: 16.0, max: 77.0)
[2026-01-26 14:20:13,290][144664] Avg episode reward: [(0, '1631.281')]
[2026-01-26 14:20:18,102][144664] Fps is (10 sec: 4165.0, 60 sec: 3551.5, 300 sec: 3443.3). Total num frames: 7766016. Throughput: 0: 3415.8. Samples: 7759360. Policy #0 lag: (min: 13.0, avg: 16.0, max: 77.0)
[2026-01-26 14:20:18,102][144664] Avg episode reward: [(0, '1631.892')]
[2026-01-26 14:20:23,068][144664] Fps is (10 sec: 3351.0, 60 sec: 3549.2, 300 sec: 3444.1). Total num frames: 7782400. Throughput: 0: 3455.7. Samples: 7780864. Policy #0 lag: (min: 13.0, avg: 16.0, max: 77.0)
[2026-01-26 14:20:23,068][144664] Avg episode reward: [(0, '1591.529')]
[2026-01-26 14:20:28,047][144664] Fps is (10 sec: 3294.9, 60 sec: 3552.4, 300 sec: 3443.5). Total num frames: 7798784. Throughput: 0: 3437.7. Samples: 7799808. Policy #0 lag: (min: 13.0, avg: 16.0, max: 77.0)
[2026-01-26 14:20:28,047][144664] Avg episode reward: [(0, '1582.039')]
[2026-01-26 14:20:33,011][144664] Fps is (10 sec: 3295.5, 60 sec: 3557.1, 300 sec: 3444.4). Total num frames: 7815168. Throughput: 0: 3487.7. Samples: 7811584. Policy #0 lag: (min: 13.0, avg: 16.0, max: 77.0)
[2026-01-26 14:20:33,011][144664] Avg episode reward: [(0, '1574.870')]
[2026-01-26 14:20:38,016][144664] Fps is (10 sec: 3286.7, 60 sec: 3550.5, 300 sec: 3444.2). Total num frames: 7831552. Throughput: 0: 3472.0. Samples: 7832576. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 14:20:38,017][144664] Avg episode reward: [(0, '1642.651')]
[2026-01-26 14:20:43,121][144664] Fps is (10 sec: 3241.2, 60 sec: 3546.7, 300 sec: 3443.6). Total num frames: 7847936. Throughput: 0: 3444.1. Samples: 7852544. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 14:20:43,121][144664] Avg episode reward: [(0, '1634.852')]
[2026-01-26 14:20:48,036][144664] Fps is (10 sec: 3270.4, 60 sec: 3553.0, 300 sec: 3443.7). Total num frames: 7864320. Throughput: 0: 3482.8. Samples: 7863808. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 14:20:48,036][144664] Avg episode reward: [(0, '1656.590')]
[2026-01-26 14:20:53,027][144664] Fps is (10 sec: 3307.8, 60 sec: 3550.6, 300 sec: 3444.4). Total num frames: 7880704. Throughput: 0: 3454.5. Samples: 7883264. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 14:20:53,027][144664] Avg episode reward: [(0, '1627.507')]
[2026-01-26 14:20:58,080][144664] Fps is (10 sec: 3262.5, 60 sec: 3549.7, 300 sec: 3442.5). Total num frames: 7897088. Throughput: 0: 3452.2. Samples: 7904768. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 14:20:58,080][144664] Avg episode reward: [(0, '1603.035')]
[2026-01-26 14:21:03,053][144664] Fps is (10 sec: 3268.3, 60 sec: 3549.8, 300 sec: 3443.3). Total num frames: 7913472. Throughput: 0: 3451.2. Samples: 7914496. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 14:21:03,054][144664] Avg episode reward: [(0, '1600.224')]
[2026-01-26 14:21:05,095][144664] Signal inference workers to stop experience collection... (1450 times)
[2026-01-26 14:21:05,095][144664] Signal inference workers to resume experience collection... (1450 times)
[2026-01-26 14:21:05,337][144664] InferenceWorker_p0-w0: stopping experience collection (1450 times)
[2026-01-26 14:21:05,337][144664] InferenceWorker_p0-w0: resuming experience collection (1450 times)
[2026-01-26 14:21:08,118][144664] Fps is (10 sec: 3264.3, 60 sec: 3421.8, 300 sec: 3442.2). Total num frames: 7929856. Throughput: 0: 3432.3. Samples: 7935488. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 14:21:08,118][144664] Avg episode reward: [(0, '1573.489')]
[2026-01-26 14:21:13,020][144664] Fps is (10 sec: 3287.9, 60 sec: 3291.6, 300 sec: 3444.6). Total num frames: 7946240. Throughput: 0: 3495.1. Samples: 7956992. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 14:21:13,020][144664] Avg episode reward: [(0, '1580.657')]
[2026-01-26 14:21:18,107][144664] Fps is (10 sec: 3280.5, 60 sec: 3276.5, 300 sec: 3442.9). Total num frames: 7962624. Throughput: 0: 3451.5. Samples: 7967232. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 14:21:18,107][144664] Avg episode reward: [(0, '1545.211')]
[2026-01-26 14:21:23,051][144664] Fps is (10 sec: 3266.5, 60 sec: 3277.7, 300 sec: 3444.2). Total num frames: 7979008. Throughput: 0: 3456.2. Samples: 7988224. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 14:21:23,051][144664] Avg episode reward: [(0, '1565.133')]
[2026-01-26 14:21:28,087][144664] Fps is (10 sec: 3283.3, 60 sec: 3274.6, 300 sec: 3442.7). Total num frames: 7995392. Throughput: 0: 3484.2. Samples: 8009216. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 14:21:28,088][144664] Avg episode reward: [(0, '1534.409')]
[2026-01-26 14:21:33,038][144664] Fps is (10 sec: 3281.1, 60 sec: 3275.3, 300 sec: 3415.8). Total num frames: 8011776. Throughput: 0: 3447.3. Samples: 8018944. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 14:21:33,038][144664] Avg episode reward: [(0, '1500.931')]
[2026-01-26 14:21:38,122][144664] Fps is (10 sec: 4081.8, 60 sec: 3407.3, 300 sec: 3415.8). Total num frames: 8036352. Throughput: 0: 3485.6. Samples: 8040448. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 14:21:38,122][144664] Avg episode reward: [(0, '1465.166')]
[2026-01-26 14:21:43,211][144664] Fps is (10 sec: 4831.7, 60 sec: 3544.6, 300 sec: 3440.9). Total num frames: 8060928. Throughput: 0: 3471.5. Samples: 8061440. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 14:21:43,211][144664] Avg episode reward: [(0, '1470.640')]
[2026-01-26 14:21:48,081][144664] Fps is (10 sec: 4113.0, 60 sec: 3547.2, 300 sec: 3443.1). Total num frames: 8077312. Throughput: 0: 3490.9. Samples: 8071680. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 14:21:48,081][144664] Avg episode reward: [(0, '1492.403')]
[2026-01-26 14:21:53,079][144664] Fps is (10 sec: 3320.6, 60 sec: 3546.8, 300 sec: 3443.8). Total num frames: 8093696. Throughput: 0: 3496.0. Samples: 8092672. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 14:21:53,079][144664] Avg episode reward: [(0, '1541.971')]
[2026-01-26 14:21:58,000][144664] Fps is (10 sec: 3303.6, 60 sec: 3554.6, 300 sec: 3444.2). Total num frames: 8110080. Throughput: 0: 3449.0. Samples: 8112128. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 14:21:58,000][144664] Avg episode reward: [(0, '1525.392')]
[2026-01-26 14:22:03,110][144664] Fps is (10 sec: 3266.8, 60 sec: 3546.5, 300 sec: 3443.1). Total num frames: 8126464. Throughput: 0: 3470.0. Samples: 8123392. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 14:22:03,110][144664] Avg episode reward: [(0, '1489.749')]
[2026-01-26 14:22:03,259][144664] Saving /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_accel_policy1_26012026/checkpoint_p0/checkpoint_000031744_8126464.pth...
[2026-01-26 14:22:03,263][144664] Removing /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_accel_policy1_26012026/checkpoint_p0/checkpoint_000028544_7307264.pth
[2026-01-26 14:22:07,996][144664] Fps is (10 sec: 3277.9, 60 sec: 3557.1, 300 sec: 3443.7). Total num frames: 8142848. Throughput: 0: 3463.1. Samples: 8143872. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 14:22:07,997][144664] Avg episode reward: [(0, '1464.166')]
[2026-01-26 14:22:13,057][144664] Fps is (10 sec: 3294.2, 60 sec: 3547.7, 300 sec: 3443.3). Total num frames: 8159232. Throughput: 0: 3438.4. Samples: 8163840. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 14:22:13,057][144664] Avg episode reward: [(0, '1474.574')]
[2026-01-26 14:22:18,092][144664] Fps is (10 sec: 3245.9, 60 sec: 3550.8, 300 sec: 3443.4). Total num frames: 8175616. Throughput: 0: 3466.1. Samples: 8175104. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 14:22:18,092][144664] Avg episode reward: [(0, '1490.129')]
[2026-01-26 14:22:23,103][144664] Fps is (10 sec: 3261.7, 60 sec: 3546.8, 300 sec: 3442.4). Total num frames: 8192000. Throughput: 0: 3426.2. Samples: 8194560. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 14:22:23,103][144664] Avg episode reward: [(0, '1484.328')]
[2026-01-26 14:22:25,495][144664] Signal inference workers to stop experience collection... (1500 times)
[2026-01-26 14:22:25,860][144664] InferenceWorker_p0-w0: stopping experience collection (1500 times)
[2026-01-26 14:22:25,862][144664] Signal inference workers to resume experience collection... (1500 times)
[2026-01-26 14:22:25,996][144664] InferenceWorker_p0-w0: resuming experience collection (1500 times)
[2026-01-26 14:22:28,079][144664] Fps is (10 sec: 3281.0, 60 sec: 3550.4, 300 sec: 3443.3). Total num frames: 8208384. Throughput: 0: 3423.4. Samples: 8215040. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 14:22:28,079][144664] Avg episode reward: [(0, '1495.738')]
[2026-01-26 14:22:33,108][144664] Fps is (10 sec: 3275.1, 60 sec: 3545.7, 300 sec: 3442.6). Total num frames: 8224768. Throughput: 0: 3422.6. Samples: 8225792. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 14:22:33,108][144664] Avg episode reward: [(0, '1521.836')]
[2026-01-26 14:22:38,026][144664] Fps is (10 sec: 3294.0, 60 sec: 3418.8, 300 sec: 3444.5). Total num frames: 8241152. Throughput: 0: 3405.9. Samples: 8245760. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 14:22:38,027][144664] Avg episode reward: [(0, '1581.271')]
[2026-01-26 14:22:43,128][144664] Fps is (10 sec: 3270.3, 60 sec: 3281.3, 300 sec: 3442.5). Total num frames: 8257536. Throughput: 0: 3415.0. Samples: 8266240. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 14:22:43,128][144664] Avg episode reward: [(0, '1568.684')]
[2026-01-26 14:22:48,102][144664] Fps is (10 sec: 3252.1, 60 sec: 3275.6, 300 sec: 3443.4). Total num frames: 8273920. Throughput: 0: 3391.1. Samples: 8275968. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 14:22:48,103][144664] Avg episode reward: [(0, '1558.106')]
[2026-01-26 14:22:53,037][144664] Fps is (10 sec: 3307.0, 60 sec: 3279.1, 300 sec: 3444.5). Total num frames: 8290304. Throughput: 0: 3410.3. Samples: 8297472. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 14:22:53,037][144664] Avg episode reward: [(0, '1534.579')]
[2026-01-26 14:22:58,033][144664] Fps is (10 sec: 3299.5, 60 sec: 3275.0, 300 sec: 3417.7). Total num frames: 8306688. Throughput: 0: 3437.9. Samples: 8318464. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 14:22:58,034][144664] Avg episode reward: [(0, '1610.132')]
[2026-01-26 14:23:03,121][144664] Fps is (10 sec: 3249.5, 60 sec: 3276.2, 300 sec: 3418.3). Total num frames: 8323072. Throughput: 0: 3388.4. Samples: 8327680. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 14:23:03,121][144664] Avg episode reward: [(0, '1640.890')]
[2026-01-26 14:23:08,031][144664] Fps is (10 sec: 3277.6, 60 sec: 3274.9, 300 sec: 3389.1). Total num frames: 8339456. Throughput: 0: 3441.6. Samples: 8349184. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 14:23:08,031][144664] Avg episode reward: [(0, '1595.277')]
[2026-01-26 14:23:13,089][144664] Fps is (10 sec: 3287.3, 60 sec: 3275.0, 300 sec: 3387.0). Total num frames: 8355840. Throughput: 0: 3435.3. Samples: 8369664. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 14:23:13,089][144664] Avg episode reward: [(0, '1530.345')]
[2026-01-26 14:23:18,055][144664] Fps is (10 sec: 3268.9, 60 sec: 3278.8, 300 sec: 3388.4). Total num frames: 8372224. Throughput: 0: 3417.4. Samples: 8379392. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 14:23:18,055][144664] Avg episode reward: [(0, '1546.896')]
[2026-01-26 14:23:23,275][144664] Fps is (10 sec: 4021.2, 60 sec: 3403.6, 300 sec: 3413.5). Total num frames: 8396800. Throughput: 0: 3417.2. Samples: 8400384. Policy #0 lag: (min: 2.0, avg: 5.0, max: 66.0)
[2026-01-26 14:23:23,275][144664] Avg episode reward: [(0, '1586.813')]
[2026-01-26 14:23:28,057][144664] Fps is (10 sec: 3276.3, 60 sec: 3278.0, 300 sec: 3388.7). Total num frames: 8404992. Throughput: 0: 3418.8. Samples: 8419840. Policy #0 lag: (min: 2.0, avg: 5.0, max: 66.0)
[2026-01-26 14:23:28,057][144664] Avg episode reward: [(0, '1577.738')]
[2026-01-26 14:23:33,304][144664] Fps is (10 sec: 3267.5, 60 sec: 3402.3, 300 sec: 3413.5). Total num frames: 8429568. Throughput: 0: 3386.8. Samples: 8429056. Policy #0 lag: (min: 2.0, avg: 5.0, max: 66.0)
[2026-01-26 14:23:33,304][144664] Avg episode reward: [(0, '1474.249')]
[2026-01-26 14:23:38,193][144664] Fps is (10 sec: 4040.8, 60 sec: 3403.9, 300 sec: 3413.9). Total num frames: 8445952. Throughput: 0: 3367.5. Samples: 8449536. Policy #0 lag: (min: 2.0, avg: 5.0, max: 66.0)
[2026-01-26 14:23:38,193][144664] Avg episode reward: [(0, '1490.751')]
[2026-01-26 14:23:42,912][144664] Signal inference workers to stop experience collection... (1550 times)
[2026-01-26 14:23:43,274][144664] InferenceWorker_p0-w0: stopping experience collection (1550 times)
[2026-01-26 14:23:43,274][144664] Signal inference workers to resume experience collection... (1550 times)
[2026-01-26 14:23:43,274][144664] Fps is (10 sec: 4108.0, 60 sec: 3541.2, 300 sec: 3440.7). Total num frames: 8470528. Throughput: 0: 3372.5. Samples: 8471040. Policy #0 lag: (min: 2.0, avg: 5.0, max: 66.0)
[2026-01-26 14:23:43,274][144664] Avg episode reward: [(0, '1507.214')]
[2026-01-26 14:23:43,277][144664] InferenceWorker_p0-w0: resuming experience collection (1550 times)
[2026-01-26 14:23:48,094][144664] Fps is (10 sec: 4137.2, 60 sec: 3550.4, 300 sec: 3443.5). Total num frames: 8486912. Throughput: 0: 3404.0. Samples: 8480768. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 14:23:48,094][144664] Avg episode reward: [(0, '1570.202')]
[2026-01-26 14:23:53,113][144664] Fps is (10 sec: 3330.5, 60 sec: 3545.4, 300 sec: 3442.9). Total num frames: 8503296. Throughput: 0: 3373.1. Samples: 8501248. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 14:23:53,113][144664] Avg episode reward: [(0, '1557.044')]
[2026-01-26 14:23:57,995][144664] Fps is (10 sec: 3309.5, 60 sec: 3552.1, 300 sec: 3444.2). Total num frames: 8519680. Throughput: 0: 3363.5. Samples: 8520704. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 14:23:57,995][144664] Avg episode reward: [(0, '1553.080')]
[2026-01-26 14:24:03,102][144664] Fps is (10 sec: 3280.3, 60 sec: 3551.0, 300 sec: 3442.3). Total num frames: 8536064. Throughput: 0: 3375.7. Samples: 8531456. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 14:24:03,103][144664] Avg episode reward: [(0, '1558.116')]
[2026-01-26 14:24:03,239][144664] Saving /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_accel_policy1_26012026/checkpoint_p0/checkpoint_000033344_8536064.pth...
[2026-01-26 14:24:03,243][144664] Removing /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_accel_policy1_26012026/checkpoint_p0/checkpoint_000030080_7700480.pth
[2026-01-26 14:24:08,010][144664] Fps is (10 sec: 3271.9, 60 sec: 3551.1, 300 sec: 3443.6). Total num frames: 8552448. Throughput: 0: 3410.7. Samples: 8552960. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 14:24:08,010][144664] Avg episode reward: [(0, '1562.583')]
[2026-01-26 14:24:13,034][144664] Fps is (10 sec: 3299.4, 60 sec: 3553.1, 300 sec: 3444.5). Total num frames: 8568832. Throughput: 0: 3380.9. Samples: 8571904. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 14:24:13,034][144664] Avg episode reward: [(0, '1594.374')]
[2026-01-26 14:24:18,034][144664] Fps is (10 sec: 3268.9, 60 sec: 3551.1, 300 sec: 3443.7). Total num frames: 8585216. Throughput: 0: 3445.3. Samples: 8583168. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 14:24:18,034][144664] Avg episode reward: [(0, '1609.534')]
[2026-01-26 14:24:23,012][144664] Fps is (10 sec: 3283.9, 60 sec: 3428.3, 300 sec: 3444.3). Total num frames: 8601600. Throughput: 0: 3415.7. Samples: 8602624. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 14:24:23,013][144664] Avg episode reward: [(0, '1636.866')]
[2026-01-26 14:24:28,034][144664] Fps is (10 sec: 3276.8, 60 sec: 3551.2, 300 sec: 3444.6). Total num frames: 8617984. Throughput: 0: 3363.0. Samples: 8621568. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 14:24:28,034][144664] Avg episode reward: [(0, '1578.336')]
[2026-01-26 14:24:33,059][144664] Fps is (10 sec: 3261.6, 60 sec: 3427.3, 300 sec: 3443.0). Total num frames: 8634368. Throughput: 0: 3393.2. Samples: 8633344. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 14:24:33,059][144664] Avg episode reward: [(0, '1570.895')]
[2026-01-26 14:24:38,045][144664] Fps is (10 sec: 3273.2, 60 sec: 3421.8, 300 sec: 3443.7). Total num frames: 8650752. Throughput: 0: 3350.1. Samples: 8651776. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 14:24:38,045][144664] Avg episode reward: [(0, '1552.756')]
[2026-01-26 14:24:43,044][144664] Fps is (10 sec: 3281.7, 60 sec: 3289.4, 300 sec: 3443.9). Total num frames: 8667136. Throughput: 0: 3398.2. Samples: 8673792. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 14:24:43,044][144664] Avg episode reward: [(0, '1571.524')]
[2026-01-26 14:24:48,125][144664] Fps is (10 sec: 3250.7, 60 sec: 3275.1, 300 sec: 3442.4). Total num frames: 8683520. Throughput: 0: 3400.2. Samples: 8684544. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 14:24:48,126][144664] Avg episode reward: [(0, '1562.350')]
[2026-01-26 14:24:53,080][144664] Fps is (10 sec: 3265.0, 60 sec: 3278.6, 300 sec: 3443.4). Total num frames: 8699904. Throughput: 0: 3351.2. Samples: 8704000. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 14:24:53,081][144664] Avg episode reward: [(0, '1603.842')]
[2026-01-26 14:24:58,051][144664] Fps is (10 sec: 3301.5, 60 sec: 3273.8, 300 sec: 3443.4). Total num frames: 8716288. Throughput: 0: 3412.1. Samples: 8725504. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 14:24:58,051][144664] Avg episode reward: [(0, '1617.404')]
[2026-01-26 14:25:02,996][144664] Fps is (10 sec: 3304.6, 60 sec: 3282.6, 300 sec: 3418.8). Total num frames: 8732672. Throughput: 0: 3382.0. Samples: 8735232. Policy #0 lag: (min: 12.0, avg: 15.0, max: 76.0)
[2026-01-26 14:25:02,997][144664] Avg episode reward: [(0, '1631.974')]
[2026-01-26 14:25:04,604][144664] Signal inference workers to stop experience collection... (1600 times)
[2026-01-26 14:25:04,604][144664] Signal inference workers to resume experience collection... (1600 times)
[2026-01-26 14:25:04,857][144664] InferenceWorker_p0-w0: stopping experience collection (1600 times)
[2026-01-26 14:25:04,857][144664] InferenceWorker_p0-w0: resuming experience collection (1600 times)
[2026-01-26 14:25:08,124][144664] Fps is (10 sec: 3252.9, 60 sec: 3270.6, 300 sec: 3389.8). Total num frames: 8749056. Throughput: 0: 3404.9. Samples: 8756224. Policy #0 lag: (min: 12.0, avg: 15.0, max: 76.0)
[2026-01-26 14:25:08,125][144664] Avg episode reward: [(0, '1590.468')]
[2026-01-26 14:25:13,112][144664] Fps is (10 sec: 3239.3, 60 sec: 3272.5, 300 sec: 3387.8). Total num frames: 8765440. Throughput: 0: 3464.2. Samples: 8777728. Policy #0 lag: (min: 12.0, avg: 15.0, max: 76.0)
[2026-01-26 14:25:13,113][144664] Avg episode reward: [(0, '1633.677')]
[2026-01-26 14:25:18,064][144664] Fps is (10 sec: 3296.7, 60 sec: 3275.2, 300 sec: 3387.9). Total num frames: 8781824. Throughput: 0: 3424.3. Samples: 8787456. Policy #0 lag: (min: 12.0, avg: 15.0, max: 76.0)
[2026-01-26 14:25:18,064][144664] Avg episode reward: [(0, '1648.694')]
[2026-01-26 14:25:23,077][144664] Fps is (10 sec: 3288.5, 60 sec: 3273.3, 300 sec: 3387.5). Total num frames: 8798208. Throughput: 0: 3479.2. Samples: 8808448. Policy #0 lag: (min: 12.0, avg: 15.0, max: 76.0)
[2026-01-26 14:25:23,077][144664] Avg episode reward: [(0, '1640.982')]
[2026-01-26 14:25:28,070][144664] Fps is (10 sec: 3274.7, 60 sec: 3274.8, 300 sec: 3387.2). Total num frames: 8814592. Throughput: 0: 3445.5. Samples: 8828928. Policy #0 lag: (min: 4.0, avg: 7.0, max: 68.0)
[2026-01-26 14:25:28,071][144664] Avg episode reward: [(0, '1609.503')]
[2026-01-26 14:25:33,268][144664] Fps is (10 sec: 4019.3, 60 sec: 3401.5, 300 sec: 3412.7). Total num frames: 8839168. Throughput: 0: 3413.9. Samples: 8838656. Policy #0 lag: (min: 4.0, avg: 7.0, max: 68.0)
[2026-01-26 14:25:33,268][144664] Avg episode reward: [(0, '1634.776')]
[2026-01-26 14:25:38,088][144664] Fps is (10 sec: 4088.8, 60 sec: 3410.9, 300 sec: 3416.0). Total num frames: 8855552. Throughput: 0: 3458.3. Samples: 8859648. Policy #0 lag: (min: 4.0, avg: 7.0, max: 68.0)
[2026-01-26 14:25:38,088][144664] Avg episode reward: [(0, '1680.181')]
[2026-01-26 14:25:38,445][144664] Saving new best policy, reward=1680.181!
[2026-01-26 14:25:43,268][144664] Fps is (10 sec: 4096.0, 60 sec: 3536.7, 300 sec: 3440.7). Total num frames: 8880128. Throughput: 0: 3430.9. Samples: 8880640. Policy #0 lag: (min: 4.0, avg: 7.0, max: 68.0)
[2026-01-26 14:25:43,268][144664] Avg episode reward: [(0, '1683.678')]
[2026-01-26 14:25:43,271][144664] Saving new best policy, reward=1683.678!
[2026-01-26 14:25:48,018][144664] Fps is (10 sec: 4124.9, 60 sec: 3556.3, 300 sec: 3443.5). Total num frames: 8896512. Throughput: 0: 3445.8. Samples: 8890368. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 14:25:48,018][144664] Avg episode reward: [(0, '1680.235')]
[2026-01-26 14:25:53,008][144664] Fps is (10 sec: 3364.1, 60 sec: 3554.2, 300 sec: 3444.3). Total num frames: 8912896. Throughput: 0: 3456.4. Samples: 8911360. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 14:25:53,008][144664] Avg episode reward: [(0, '1660.764')]
[2026-01-26 14:25:58,006][144664] Fps is (10 sec: 3280.8, 60 sec: 3552.5, 300 sec: 3444.0). Total num frames: 8929280. Throughput: 0: 3398.6. Samples: 8930304. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 14:25:58,006][144664] Avg episode reward: [(0, '1619.103')]
[2026-01-26 14:26:03,094][144664] Fps is (10 sec: 3248.9, 60 sec: 3544.1, 300 sec: 3443.7). Total num frames: 8945664. Throughput: 0: 3433.8. Samples: 8942080. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 14:26:03,094][144664] Avg episode reward: [(0, '1638.510')]
[2026-01-26 14:26:03,247][144664] Saving /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_accel_policy1_26012026/checkpoint_p0/checkpoint_000034944_8945664.pth...
[2026-01-26 14:26:03,251][144664] Removing /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_accel_policy1_26012026/checkpoint_p0/checkpoint_000031744_8126464.pth
[2026-01-26 14:26:08,122][144664] Fps is (10 sec: 3239.2, 60 sec: 3550.0, 300 sec: 3442.2). Total num frames: 8962048. Throughput: 0: 3432.7. Samples: 8963072. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 14:26:08,122][144664] Avg episode reward: [(0, '1627.872')]
[2026-01-26 14:26:13,134][144664] Fps is (10 sec: 3263.8, 60 sec: 3548.6, 300 sec: 3443.1). Total num frames: 8978432. Throughput: 0: 3419.9. Samples: 8983040. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 14:26:13,134][144664] Avg episode reward: [(0, '1615.690')]
[2026-01-26 14:26:18,029][144664] Fps is (10 sec: 3307.4, 60 sec: 3551.9, 300 sec: 3443.7). Total num frames: 8994816. Throughput: 0: 3477.3. Samples: 8994304. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 14:26:18,029][144664] Avg episode reward: [(0, '1606.993')]
[2026-01-26 14:26:23,019][144664] Fps is (10 sec: 3314.9, 60 sec: 3553.3, 300 sec: 3444.2). Total num frames: 9011200. Throughput: 0: 3430.0. Samples: 9013760. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 14:26:23,019][144664] Avg episode reward: [(0, '1605.919')]
[2026-01-26 14:26:25,339][144664] Signal inference workers to stop experience collection... (1650 times)
[2026-01-26 14:26:25,697][144664] InferenceWorker_p0-w0: stopping experience collection (1650 times)
[2026-01-26 14:26:25,699][144664] Signal inference workers to resume experience collection... (1650 times)
[2026-01-26 14:26:25,830][144664] InferenceWorker_p0-w0: resuming experience collection (1650 times)
[2026-01-26 14:26:28,049][144664] Fps is (10 sec: 3270.4, 60 sec: 3551.2, 300 sec: 3443.3). Total num frames: 9027584. Throughput: 0: 3441.5. Samples: 9034752. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 14:26:28,049][144664] Avg episode reward: [(0, '1582.382')]
[2026-01-26 14:26:33,099][144664] Fps is (10 sec: 3250.9, 60 sec: 3423.0, 300 sec: 3415.9). Total num frames: 9043968. Throughput: 0: 3429.9. Samples: 9044992. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 14:26:33,099][144664] Avg episode reward: [(0, '1635.712')]
[2026-01-26 14:26:37,997][144664] Fps is (10 sec: 3293.9, 60 sec: 3418.5, 300 sec: 3390.3). Total num frames: 9060352. Throughput: 0: 3425.6. Samples: 9065472. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 14:26:37,997][144664] Avg episode reward: [(0, '1642.657')]
[2026-01-26 14:26:43,072][144664] Fps is (10 sec: 3285.6, 60 sec: 3287.5, 300 sec: 3388.0). Total num frames: 9076736. Throughput: 0: 3453.8. Samples: 9085952. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 14:26:43,072][144664] Avg episode reward: [(0, '1624.114')]
[2026-01-26 14:26:48,051][144664] Fps is (10 sec: 3259.0, 60 sec: 3275.0, 300 sec: 3388.2). Total num frames: 9093120. Throughput: 0: 3416.6. Samples: 9095680. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 14:26:48,052][144664] Avg episode reward: [(0, '1519.670')]
[2026-01-26 14:26:53,060][144664] Fps is (10 sec: 3280.6, 60 sec: 3274.0, 300 sec: 3387.2). Total num frames: 9109504. Throughput: 0: 3406.6. Samples: 9116160. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 14:26:53,060][144664] Avg episode reward: [(0, '1527.819')]
[2026-01-26 14:26:58,026][144664] Fps is (10 sec: 3285.0, 60 sec: 3275.7, 300 sec: 3388.8). Total num frames: 9125888. Throughput: 0: 3432.9. Samples: 9137152. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 14:26:58,027][144664] Avg episode reward: [(0, '1518.713')]
[2026-01-26 14:27:03,040][144664] Fps is (10 sec: 3283.4, 60 sec: 3279.8, 300 sec: 3387.4). Total num frames: 9142272. Throughput: 0: 3401.1. Samples: 9147392. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 14:27:03,040][144664] Avg episode reward: [(0, '1580.668')]
[2026-01-26 14:27:08,118][144664] Fps is (10 sec: 3247.1, 60 sec: 3277.0, 300 sec: 3387.2). Total num frames: 9158656. Throughput: 0: 3417.2. Samples: 9167872. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 14:27:08,118][144664] Avg episode reward: [(0, '1572.711')]
[2026-01-26 14:27:13,100][144664] Fps is (10 sec: 3257.2, 60 sec: 3278.6, 300 sec: 3387.8). Total num frames: 9175040. Throughput: 0: 3432.2. Samples: 9189376. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 14:27:13,100][144664] Avg episode reward: [(0, '1620.443')]
[2026-01-26 14:27:18,195][144664] Fps is (10 sec: 4064.8, 60 sec: 3403.9, 300 sec: 3414.6). Total num frames: 9199616. Throughput: 0: 3417.4. Samples: 9199104. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 14:27:18,195][144664] Avg episode reward: [(0, '1610.413')]
[2026-01-26 14:27:23,221][144664] Fps is (10 sec: 4856.6, 60 sec: 3538.0, 300 sec: 3441.8). Total num frames: 9224192. Throughput: 0: 3441.7. Samples: 9221120. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 14:27:23,221][144664] Avg episode reward: [(0, '1572.993')]
[2026-01-26 14:27:28,063][144664] Fps is (10 sec: 4150.8, 60 sec: 3549.0, 300 sec: 3443.9). Total num frames: 9240576. Throughput: 0: 3459.5. Samples: 9241600. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 14:27:28,063][144664] Avg episode reward: [(0, '1600.405')]
[2026-01-26 14:27:33,041][144664] Fps is (10 sec: 3336.8, 60 sec: 3553.3, 300 sec: 3443.2). Total num frames: 9256960. Throughput: 0: 3482.4. Samples: 9252352. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 14:27:33,041][144664] Avg episode reward: [(0, '1593.803')]
[2026-01-26 14:27:38,057][144664] Fps is (10 sec: 3278.7, 60 sec: 3546.3, 300 sec: 3444.2). Total num frames: 9273344. Throughput: 0: 3504.6. Samples: 9273856. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 14:27:38,057][144664] Avg episode reward: [(0, '1646.714')]
[2026-01-26 14:27:41,796][144664] Signal inference workers to stop experience collection... (1700 times)
[2026-01-26 14:27:42,180][144664] InferenceWorker_p0-w0: stopping experience collection (1700 times)
[2026-01-26 14:27:42,180][144664] Signal inference workers to resume experience collection... (1700 times)
[2026-01-26 14:27:42,180][144664] InferenceWorker_p0-w0: resuming experience collection (1700 times)
[2026-01-26 14:27:43,113][144664] Fps is (10 sec: 3253.3, 60 sec: 3547.4, 300 sec: 3443.3). Total num frames: 9289728. Throughput: 0: 3440.8. Samples: 9292288. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 14:27:43,113][144664] Avg episode reward: [(0, '1650.025')]
[2026-01-26 14:27:48,146][144664] Fps is (10 sec: 3247.7, 60 sec: 3544.3, 300 sec: 3442.1). Total num frames: 9306112. Throughput: 0: 3462.0. Samples: 9303552. Policy #0 lag: (min: 2.0, avg: 5.0, max: 66.0)
[2026-01-26 14:27:48,147][144664] Avg episode reward: [(0, '1618.178')]
[2026-01-26 14:27:53,100][144664] Fps is (10 sec: 3281.0, 60 sec: 3547.5, 300 sec: 3442.6). Total num frames: 9322496. Throughput: 0: 3448.8. Samples: 9323008. Policy #0 lag: (min: 2.0, avg: 5.0, max: 66.0)
[2026-01-26 14:27:53,101][144664] Avg episode reward: [(0, '1598.847')]
[2026-01-26 14:27:58,087][144664] Fps is (10 sec: 3296.4, 60 sec: 3546.3, 300 sec: 3443.8). Total num frames: 9338880. Throughput: 0: 3346.0. Samples: 9339904. Policy #0 lag: (min: 2.0, avg: 5.0, max: 66.0)
[2026-01-26 14:27:58,087][144664] Avg episode reward: [(0, '1572.003')]
[2026-01-26 14:28:03,060][144664] Fps is (10 sec: 3290.1, 60 sec: 3548.7, 300 sec: 3443.1). Total num frames: 9355264. Throughput: 0: 3389.3. Samples: 9351168. Policy #0 lag: (min: 2.0, avg: 5.0, max: 66.0)
[2026-01-26 14:28:03,060][144664] Avg episode reward: [(0, '1620.322')]
[2026-01-26 14:28:03,211][144664] Saving /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_accel_policy1_26012026/checkpoint_p0/checkpoint_000036544_9355264.pth...
[2026-01-26 14:28:03,215][144664] Removing /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_accel_policy1_26012026/checkpoint_p0/checkpoint_000033344_8536064.pth
[2026-01-26 14:28:08,044][144664] Fps is (10 sec: 3291.0, 60 sec: 3554.2, 300 sec: 3443.9). Total num frames: 9371648. Throughput: 0: 3381.1. Samples: 9372672. Policy #0 lag: (min: 2.0, avg: 5.0, max: 66.0)
[2026-01-26 14:28:08,044][144664] Avg episode reward: [(0, '1657.633')]
[2026-01-26 14:28:13,105][144664] Fps is (10 sec: 3262.2, 60 sec: 3549.6, 300 sec: 3442.8). Total num frames: 9388032. Throughput: 0: 3330.6. Samples: 9391616. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 14:28:13,105][144664] Avg episode reward: [(0, '1662.724')]
[2026-01-26 14:28:18,025][144664] Fps is (10 sec: 3283.1, 60 sec: 3423.0, 300 sec: 3418.5). Total num frames: 9404416. Throughput: 0: 3323.5. Samples: 9401856. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 14:28:18,025][144664] Avg episode reward: [(0, '1638.158')]
[2026-01-26 14:28:23,107][144664] Fps is (10 sec: 3276.1, 60 sec: 3283.0, 300 sec: 3442.8). Total num frames: 9420800. Throughput: 0: 3284.5. Samples: 9421824. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 14:28:23,107][144664] Avg episode reward: [(0, '1660.765')]
[2026-01-26 14:28:28,056][144664] Fps is (10 sec: 3266.6, 60 sec: 3277.2, 300 sec: 3418.5). Total num frames: 9437184. Throughput: 0: 3292.3. Samples: 9440256. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 14:28:28,056][144664] Avg episode reward: [(0, '1623.607')]
[2026-01-26 14:28:33,112][144664] Fps is (10 sec: 3275.1, 60 sec: 3272.9, 300 sec: 3416.6). Total num frames: 9453568. Throughput: 0: 3279.3. Samples: 9451008. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 14:28:33,112][144664] Avg episode reward: [(0, '1578.268')]
[2026-01-26 14:28:38,104][144664] Fps is (10 sec: 3261.3, 60 sec: 3274.2, 300 sec: 3389.8). Total num frames: 9469952. Throughput: 0: 3287.9. Samples: 9470976. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 14:28:38,104][144664] Avg episode reward: [(0, '1553.422')]
[2026-01-26 14:28:43,127][144664] Fps is (10 sec: 3272.0, 60 sec: 3276.0, 300 sec: 3387.5). Total num frames: 9486336. Throughput: 0: 3353.5. Samples: 9490944. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 14:28:43,127][144664] Avg episode reward: [(0, '1582.048')]
[2026-01-26 14:28:48,066][144664] Fps is (10 sec: 3289.3, 60 sec: 3281.2, 300 sec: 3388.4). Total num frames: 9502720. Throughput: 0: 3356.0. Samples: 9502208. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 14:28:48,066][144664] Avg episode reward: [(0, '1606.816')]
[2026-01-26 14:28:53,107][144664] Fps is (10 sec: 3283.4, 60 sec: 3276.5, 300 sec: 3386.6). Total num frames: 9519104. Throughput: 0: 3272.2. Samples: 9520128. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 14:28:53,107][144664] Avg episode reward: [(0, '1649.637')]
[2026-01-26 14:28:57,999][144664] Fps is (10 sec: 3298.9, 60 sec: 3281.6, 300 sec: 3389.1). Total num frames: 9535488. Throughput: 0: 3295.9. Samples: 9539584. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 14:28:57,999][144664] Avg episode reward: [(0, '1640.093')]
[2026-01-26 14:29:03,101][144664] Fps is (10 sec: 3278.9, 60 sec: 3274.6, 300 sec: 3386.8). Total num frames: 9551872. Throughput: 0: 3294.0. Samples: 9550336. Policy #0 lag: (min: 7.0, avg: 10.0, max: 71.0)
[2026-01-26 14:29:03,101][144664] Avg episode reward: [(0, '1635.218')]
[2026-01-26 14:29:06,446][144664] Signal inference workers to stop experience collection... (1750 times)
[2026-01-26 14:29:06,446][144664] Signal inference workers to resume experience collection... (1750 times)
[2026-01-26 14:29:06,708][144664] InferenceWorker_p0-w0: stopping experience collection (1750 times)
[2026-01-26 14:29:06,708][144664] InferenceWorker_p0-w0: resuming experience collection (1750 times)
[2026-01-26 14:29:08,064][144664] Fps is (10 sec: 3255.6, 60 sec: 3275.7, 300 sec: 3387.5). Total num frames: 9568256. Throughput: 0: 3279.9. Samples: 9569280. Policy #0 lag: (min: 7.0, avg: 10.0, max: 71.0)
[2026-01-26 14:29:08,065][144664] Avg episode reward: [(0, '1608.282')]
[2026-01-26 14:29:13,096][144664] Fps is (10 sec: 3278.2, 60 sec: 3277.3, 300 sec: 3387.2). Total num frames: 9584640. Throughput: 0: 3319.4. Samples: 9589760. Policy #0 lag: (min: 7.0, avg: 10.0, max: 71.0)
[2026-01-26 14:29:13,097][144664] Avg episode reward: [(0, '1537.950')]
[2026-01-26 14:29:18,120][144664] Fps is (10 sec: 3258.6, 60 sec: 3271.6, 300 sec: 3386.6). Total num frames: 9601024. Throughput: 0: 3321.7. Samples: 9600512. Policy #0 lag: (min: 7.0, avg: 10.0, max: 71.0)
[2026-01-26 14:29:18,120][144664] Avg episode reward: [(0, '1556.750')]
[2026-01-26 14:29:23,056][144664] Fps is (10 sec: 3290.1, 60 sec: 3279.6, 300 sec: 3387.6). Total num frames: 9617408. Throughput: 0: 3314.5. Samples: 9619968. Policy #0 lag: (min: 7.0, avg: 10.0, max: 71.0)
[2026-01-26 14:29:23,056][144664] Avg episode reward: [(0, '1551.432')]
[2026-01-26 14:29:28,118][144664] Fps is (10 sec: 3277.4, 60 sec: 3273.4, 300 sec: 3387.2). Total num frames: 9633792. Throughput: 0: 3334.3. Samples: 9640960. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 14:29:28,118][144664] Avg episode reward: [(0, '1610.437')]
[2026-01-26 14:29:33,044][144664] Fps is (10 sec: 3280.8, 60 sec: 3280.5, 300 sec: 3387.9). Total num frames: 9650176. Throughput: 0: 3312.6. Samples: 9651200. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 14:29:33,044][144664] Avg episode reward: [(0, '1634.984')]
[2026-01-26 14:29:38,088][144664] Fps is (10 sec: 3286.7, 60 sec: 3277.7, 300 sec: 3387.4). Total num frames: 9666560. Throughput: 0: 3369.2. Samples: 9671680. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 14:29:38,088][144664] Avg episode reward: [(0, '1673.861')]
[2026-01-26 14:29:43,010][144664] Fps is (10 sec: 3287.9, 60 sec: 3283.2, 300 sec: 3389.2). Total num frames: 9682944. Throughput: 0: 3401.1. Samples: 9692672. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 14:29:43,010][144664] Avg episode reward: [(0, '1687.596')]
[2026-01-26 14:29:43,153][144664] Saving new best policy, reward=1687.596!
[2026-01-26 14:29:48,121][144664] Fps is (10 sec: 3266.1, 60 sec: 3273.8, 300 sec: 3387.4). Total num frames: 9699328. Throughput: 0: 3366.3. Samples: 9701888. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 14:29:48,121][144664] Avg episode reward: [(0, '1671.217')]
[2026-01-26 14:29:53,112][144664] Fps is (10 sec: 3243.9, 60 sec: 3276.5, 300 sec: 3387.2). Total num frames: 9715712. Throughput: 0: 3409.7. Samples: 9722880. Policy #0 lag: (min: 35.0, avg: 38.0, max: 99.0)
[2026-01-26 14:29:53,112][144664] Avg episode reward: [(0, '1631.353')]
[2026-01-26 14:29:58,109][144664] Fps is (10 sec: 3280.6, 60 sec: 3270.8, 300 sec: 3386.6). Total num frames: 9732096. Throughput: 0: 3401.0. Samples: 9742848. Policy #0 lag: (min: 35.0, avg: 38.0, max: 99.0)
[2026-01-26 14:29:58,109][144664] Avg episode reward: [(0, '1628.483')]
[2026-01-26 14:30:03,020][144664] Fps is (10 sec: 3307.0, 60 sec: 3281.2, 300 sec: 3389.1). Total num frames: 9748480. Throughput: 0: 3363.9. Samples: 9751552. Policy #0 lag: (min: 35.0, avg: 38.0, max: 99.0)
[2026-01-26 14:30:03,025][144664] Avg episode reward: [(0, '1614.785')]
[2026-01-26 14:30:03,166][144664] Saving /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_accel_policy1_26012026/checkpoint_p0/checkpoint_000038080_9748480.pth...
[2026-01-26 14:30:03,170][144664] Removing /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_accel_policy1_26012026/checkpoint_p0/checkpoint_000034944_8945664.pth
[2026-01-26 14:30:08,011][144664] Fps is (10 sec: 3309.4, 60 sec: 3279.7, 300 sec: 3389.0). Total num frames: 9764864. Throughput: 0: 3371.2. Samples: 9771520. Policy #0 lag: (min: 35.0, avg: 38.0, max: 99.0)
[2026-01-26 14:30:08,011][144664] Avg episode reward: [(0, '1589.939')]
[2026-01-26 14:30:13,061][144664] Fps is (10 sec: 3263.6, 60 sec: 3278.7, 300 sec: 3387.9). Total num frames: 9781248. Throughput: 0: 3337.9. Samples: 9790976. Policy #0 lag: (min: 35.0, avg: 38.0, max: 99.0)
[2026-01-26 14:30:13,061][144664] Avg episode reward: [(0, '1561.612')]
[2026-01-26 14:30:18,016][144664] Fps is (10 sec: 3275.0, 60 sec: 3282.5, 300 sec: 3388.6). Total num frames: 9797632. Throughput: 0: 3301.6. Samples: 9799680. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 14:30:18,016][144664] Avg episode reward: [(0, '1532.524')]
[2026-01-26 14:30:23,037][144664] Fps is (10 sec: 3284.7, 60 sec: 3277.8, 300 sec: 3388.3). Total num frames: 9814016. Throughput: 0: 3269.1. Samples: 9818624. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-26 14:30:23,037][144664] Avg episode reward: [(0, '1554.950')]
[2026-01-26 14:30:27,754][144664] Keyboard interrupt detected in the event loop EvtLoop [Runner_EvtLoop, process=main process 144664], exiting...
[2026-01-26 14:30:27,754][144664] Runner profile tree view:
main_loop: 2886.6949
[2026-01-26 14:30:27,754][144664] Collected {0: 9830400}, FPS: 3405.4
