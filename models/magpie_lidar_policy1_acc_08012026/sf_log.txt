[2026-01-08 15:08:10,307][103907] Saving configuration to /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_lidar_policy1_acc_08012026/config.json...
[2026-01-08 15:08:10,346][103907] Using GPUs [0] for process 0 (actually maps to GPUs [0])
[2026-01-08 15:08:10,346][103907] Rollout worker 0 uses device cuda:0
[2026-01-08 15:08:10,739][103907] Using GPUs [0] for process 0 (actually maps to GPUs [0])
[2026-01-08 15:08:10,739][103907] InferenceWorker_p0-w0: min num requests: 1
[2026-01-08 15:08:10,740][103907] Using GPUs [0] for process 0 (actually maps to GPUs [0])
[2026-01-08 15:08:10,740][103907] Starting seed is not provided
[2026-01-08 15:08:10,740][103907] Using GPUs [0] for process 0 (actually maps to GPUs [0])
[2026-01-08 15:08:10,740][103907] Initializing actor-critic model on device cuda:0
[2026-01-08 15:08:10,741][103907] RunningMeanStd input shape: (337,)
[2026-01-08 15:08:10,741][103907] RunningMeanStd input shape: (1,)
[2026-01-08 15:08:10,753][103907] Created Actor Critic model with architecture:
[2026-01-08 15:08:10,753][103907] ActorCriticSharedWeights(
  (obs_normalizer): ObservationNormalizer(
    (running_mean_std): RunningMeanStdDictInPlace(
      (running_mean_std): ModuleDict(
        (observations): RunningMeanStdInPlace()
      )
    )
  )
  (returns_normalizer): RecursiveScriptModule(original_name=RunningMeanStdInPlace)
  (encoder): CustomEncoder(
    (encoders): ModuleDict(
      (obs_image): Sequential(
        (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): ELU(alpha=1.0)
        (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
        (3): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (4): ELU(alpha=1.0)
        (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
        (6): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (7): ELU(alpha=1.0)
        (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        (9): Flatten(start_dim=1, end_dim=-1)
      )
    )
    (mlp_head_custom): Sequential(
      (0): Linear(in_features=145, out_features=256, bias=True)
      (1): ELU(alpha=1.0)
      (2): Linear(in_features=256, out_features=128, bias=True)
      (3): ELU(alpha=1.0)
      (4): Linear(in_features=128, out_features=64, bias=True)
      (5): ELU(alpha=1.0)
    )
  )
  (core): ModelCoreRNN(
    (core): GRU(64, 128)
  )
  (decoder): MlpDecoder(
    (mlp): Identity()
  )
  (critic_linear): Linear(in_features=128, out_features=1, bias=True)
  (action_parameterization): ActionParameterizationDefault(
    (distribution_linear): Linear(in_features=128, out_features=8, bias=True)
  )
)
[2026-01-08 15:08:11,151][103907] Using optimizer <class 'torch.optim.adam.Adam'>
[2026-01-08 15:08:11,152][103907] No checkpoints found
[2026-01-08 15:08:11,152][103907] Did not load from checkpoint, starting from scratch!
[2026-01-08 15:08:11,152][103907] Initialized policy 0 weights for model version 0
[2026-01-08 15:08:11,152][103907] LearnerWorker_p0 finished initialization!
[2026-01-08 15:08:11,153][103907] Using GPUs [0] for process 0 (actually maps to GPUs [0])
[2026-01-08 15:08:11,164][103907] Fps is (10 sec: nan, 60 sec: nan, 300 sec: nan). Total num frames: 0. Throughput: 0: nan. Samples: 0. Policy #0 lag: (min: -1.0, avg: -1.0, max: -1.0)
[2026-01-08 15:08:11,164][103907] Inference worker 0-0 is ready!
[2026-01-08 15:08:11,164][103907] All inference workers are ready! Signal rollout workers to start!
[2026-01-08 15:08:11,164][103907] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 0.0). Total num frames: 0. Throughput: 0: 0.0. Samples: 0. Policy #0 lag: (min: -1.0, avg: -1.0, max: -1.0)
[2026-01-08 15:08:11,164][103907] EnvRunner 0-0 uses policy 0
[2026-01-08 15:08:24,505][103907] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 0.0). Total num frames: 0. Throughput: 0: 0.0. Samples: 0. Policy #0 lag: (min: -1.0, avg: -1.0, max: -1.0)
[2026-01-08 15:08:28,830][103907] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 0.0). Total num frames: 0. Throughput: 0: 0.0. Samples: 0. Policy #0 lag: (min: -1.0, avg: -1.0, max: -1.0)
[2026-01-08 15:08:28,934][103907] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 0.0). Total num frames: 0. Throughput: 0: 28.8. Samples: 512. Policy #0 lag: (min: -1.0, avg: -1.0, max: -1.0)
[2026-01-08 15:08:28,934][103907] Avg episode reward: [(0, '-10.000')]
[2026-01-08 15:08:30,350][103907] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 0.0). Total num frames: 0. Throughput: 0: 53.4. Samples: 1024. Policy #0 lag: (min: -1.0, avg: -1.0, max: -1.0)
[2026-01-08 15:08:30,350][103907] Avg episode reward: [(0, '-10.000')]
[2026-01-08 15:08:30,921][103907] Heartbeat connected on Batcher_0
[2026-01-08 15:08:30,921][103907] Heartbeat connected on LearnerWorker_p0
[2026-01-08 15:08:30,921][103907] Heartbeat connected on InferenceWorker_p0-w0
[2026-01-08 15:08:30,921][103907] Heartbeat connected on RolloutWorker_w0
[2026-01-08 15:08:33,153][103907] Fps is (10 sec: 0.0, 60 sec: 0.0, 300 sec: 0.0). Total num frames: 0. Throughput: 0: 279.4. Samples: 6144. Policy #0 lag: (min: -1.0, avg: -1.0, max: -1.0)
[2026-01-08 15:08:33,154][103907] Avg episode reward: [(0, '-10.442')]
[2026-01-08 15:08:36,300][103907] Signal inference workers to stop experience collection...
[2026-01-08 15:08:37,633][103907] InferenceWorker_p0-w0: stopping experience collection
[2026-01-08 15:08:37,635][103907] Signal inference workers to resume experience collection...
[2026-01-08 15:08:37,790][103907] InferenceWorker_p0-w0: resuming experience collection
[2026-01-08 15:08:38,175][103907] Fps is (10 sec: 2094.0, 60 sec: 606.6, 300 sec: 606.6). Total num frames: 16384. Throughput: 0: 511.8. Samples: 13824. Policy #0 lag: (min: 12.0, avg: 12.0, max: 12.0)
[2026-01-08 15:08:38,175][103907] Avg episode reward: [(0, '-17.264')]
[2026-01-08 15:08:43,151][103907] Fps is (10 sec: 3277.5, 60 sec: 1024.4, 300 sec: 1024.4). Total num frames: 32768. Throughput: 0: 912.4. Samples: 29184. Policy #0 lag: (min: 3.0, avg: 6.0, max: 67.0)
[2026-01-08 15:08:43,151][103907] Avg episode reward: [(0, '-23.867')]
[2026-01-08 15:08:48,133][103907] Fps is (10 sec: 3290.5, 60 sec: 1329.6, 300 sec: 1329.6). Total num frames: 49152. Throughput: 0: 1357.2. Samples: 50176. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:08:48,133][103907] Avg episode reward: [(0, '-29.223')]
[2026-01-08 15:08:53,237][103907] Fps is (10 sec: 3248.9, 60 sec: 1557.7, 300 sec: 1557.7). Total num frames: 65536. Throughput: 0: 1448.2. Samples: 60928. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:08:53,237][103907] Avg episode reward: [(0, '-331.018')]
[2026-01-08 15:08:58,175][103907] Fps is (10 sec: 3262.9, 60 sec: 1742.6, 300 sec: 1742.6). Total num frames: 81920. Throughput: 0: 2448.2. Samples: 82432. Policy #0 lag: (min: 7.0, avg: 10.0, max: 71.0)
[2026-01-08 15:08:58,176][103907] Avg episode reward: [(0, '-195.266')]
[2026-01-08 15:09:03,161][103907] Fps is (10 sec: 3301.8, 60 sec: 1890.6, 300 sec: 1890.6). Total num frames: 98304. Throughput: 0: 3027.4. Samples: 103936. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:09:03,162][103907] Avg episode reward: [(0, '-65.029')]
[2026-01-08 15:09:08,217][103907] Fps is (10 sec: 3263.2, 60 sec: 2010.2, 300 sec: 2010.2). Total num frames: 114688. Throughput: 0: 2906.5. Samples: 114688. Policy #0 lag: (min: 10.0, avg: 13.0, max: 74.0)
[2026-01-08 15:09:08,217][103907] Avg episode reward: [(0, '-196.071')]
[2026-01-08 15:09:08,347][103907] Saving new best policy, reward=-196.071!
[2026-01-08 15:09:13,210][103907] Fps is (10 sec: 3260.8, 60 sec: 2691.1, 300 sec: 2112.5). Total num frames: 131072. Throughput: 0: 3105.9. Samples: 134144. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:09:13,211][103907] Avg episode reward: [(0, '-167.097')]
[2026-01-08 15:09:13,340][103907] Saving new best policy, reward=-167.097!
[2026-01-08 15:09:18,225][103907] Fps is (10 sec: 3274.1, 60 sec: 2985.2, 300 sec: 2198.8). Total num frames: 147456. Throughput: 0: 3339.7. Samples: 156672. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:09:18,226][103907] Avg episode reward: [(0, '-81.639')]
[2026-01-08 15:09:18,332][103907] Saving new best policy, reward=-81.639!
[2026-01-08 15:09:23,220][103907] Fps is (10 sec: 3273.6, 60 sec: 3018.1, 300 sec: 2273.8). Total num frames: 163840. Throughput: 0: 3432.6. Samples: 168448. Policy #0 lag: (min: 11.0, avg: 14.0, max: 75.0)
[2026-01-08 15:09:23,220][103907] Avg episode reward: [(0, '-46.394')]
[2026-01-08 15:09:23,349][103907] Saving new best policy, reward=-46.394!
[2026-01-08 15:09:28,463][103907] Fps is (10 sec: 4001.1, 60 sec: 3242.3, 300 sec: 2437.5). Total num frames: 188416. Throughput: 0: 3536.8. Samples: 189440. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:09:28,463][103907] Avg episode reward: [(0, '-40.371')]
[2026-01-08 15:09:28,809][103907] Saving new best policy, reward=-40.371!
[2026-01-08 15:09:33,189][103907] Fps is (10 sec: 4930.4, 60 sec: 3547.8, 300 sec: 2596.7). Total num frames: 212992. Throughput: 0: 3602.3. Samples: 212480. Policy #0 lag: (min: 5.0, avg: 8.0, max: 69.0)
[2026-01-08 15:09:33,189][103907] Avg episode reward: [(0, '-19.868')]
[2026-01-08 15:09:33,193][103907] Saving new best policy, reward=-19.868!
[2026-01-08 15:09:38,150][103907] Fps is (10 sec: 4228.0, 60 sec: 3551.3, 300 sec: 2636.9). Total num frames: 229376. Throughput: 0: 3625.1. Samples: 223744. Policy #0 lag: (min: 11.0, avg: 14.0, max: 75.0)
[2026-01-08 15:09:38,151][103907] Avg episode reward: [(0, '-6.876')]
[2026-01-08 15:09:38,275][103907] Saving new best policy, reward=-6.876!
[2026-01-08 15:09:43,238][103907] Fps is (10 sec: 3260.9, 60 sec: 3544.7, 300 sec: 2669.2). Total num frames: 245760. Throughput: 0: 3635.8. Samples: 246272. Policy #0 lag: (min: 3.0, avg: 6.0, max: 67.0)
[2026-01-08 15:09:43,238][103907] Avg episode reward: [(0, '-5.062')]
[2026-01-08 15:09:43,369][103907] Saving new best policy, reward=-5.062!
[2026-01-08 15:09:48,215][103907] Fps is (10 sec: 3255.7, 60 sec: 3545.0, 300 sec: 2701.1). Total num frames: 262144. Throughput: 0: 3636.5. Samples: 267776. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:09:48,216][103907] Avg episode reward: [(0, '-1.557')]
[2026-01-08 15:09:48,337][103907] Saving new best policy, reward=-1.557!
[2026-01-08 15:09:50,225][103907] Signal inference workers to stop experience collection... (50 times)
[2026-01-08 15:09:50,564][103907] InferenceWorker_p0-w0: stopping experience collection (50 times)
[2026-01-08 15:09:50,565][103907] Signal inference workers to resume experience collection... (50 times)
[2026-01-08 15:09:50,565][103907] InferenceWorker_p0-w0: resuming experience collection (50 times)
[2026-01-08 15:09:53,202][103907] Fps is (10 sec: 3288.5, 60 sec: 3551.9, 300 sec: 2729.6). Total num frames: 278528. Throughput: 0: 3664.8. Samples: 279552. Policy #0 lag: (min: 3.0, avg: 6.0, max: 67.0)
[2026-01-08 15:09:53,203][103907] Avg episode reward: [(0, '4.066')]
[2026-01-08 15:09:53,331][103907] Saving /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_lidar_policy1_acc_08012026/checkpoint_p0/checkpoint_000001088_278528.pth...
[2026-01-08 15:09:53,335][103907] Saving new best policy, reward=4.066!
[2026-01-08 15:09:58,230][103907] Fps is (10 sec: 3272.0, 60 sec: 3546.6, 300 sec: 2754.5). Total num frames: 294912. Throughput: 0: 3673.4. Samples: 299520. Policy #0 lag: (min: 12.0, avg: 15.0, max: 76.0)
[2026-01-08 15:09:58,230][103907] Avg episode reward: [(0, '14.740')]
[2026-01-08 15:09:58,360][103907] Saving new best policy, reward=14.740!
[2026-01-08 15:10:03,148][103907] Fps is (10 sec: 3294.6, 60 sec: 3550.6, 300 sec: 2779.8). Total num frames: 311296. Throughput: 0: 3681.3. Samples: 322048. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:10:03,148][103907] Avg episode reward: [(0, '26.097')]
[2026-01-08 15:10:03,277][103907] Saving new best policy, reward=26.097!
[2026-01-08 15:10:08,250][103907] Fps is (10 sec: 3270.3, 60 sec: 3547.9, 300 sec: 2798.6). Total num frames: 327680. Throughput: 0: 3638.5. Samples: 332288. Policy #0 lag: (min: 9.0, avg: 12.0, max: 73.0)
[2026-01-08 15:10:08,250][103907] Avg episode reward: [(0, '39.478')]
[2026-01-08 15:10:08,385][103907] Saving new best policy, reward=39.478!
[2026-01-08 15:10:13,422][103907] Fps is (10 sec: 3987.0, 60 sec: 3673.5, 300 sec: 2881.3). Total num frames: 352256. Throughput: 0: 3655.6. Samples: 353792. Policy #0 lag: (min: 4.0, avg: 7.0, max: 68.0)
[2026-01-08 15:10:13,422][103907] Avg episode reward: [(0, '42.760')]
[2026-01-08 15:10:13,784][103907] Saving new best policy, reward=42.760!
[2026-01-08 15:10:18,169][103907] Fps is (10 sec: 4129.4, 60 sec: 3689.9, 300 sec: 2902.6). Total num frames: 368640. Throughput: 0: 3619.8. Samples: 375296. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:10:18,169][103907] Avg episode reward: [(0, '51.267')]
[2026-01-08 15:10:18,533][103907] Saving new best policy, reward=51.267!
[2026-01-08 15:10:23,213][103907] Fps is (10 sec: 4183.4, 60 sec: 3823.4, 300 sec: 2977.8). Total num frames: 393216. Throughput: 0: 3579.0. Samples: 385024. Policy #0 lag: (min: 8.0, avg: 11.0, max: 72.0)
[2026-01-08 15:10:23,213][103907] Avg episode reward: [(0, '58.555')]
[2026-01-08 15:10:23,217][103907] Saving new best policy, reward=58.555!
[2026-01-08 15:10:28,153][103907] Fps is (10 sec: 4102.6, 60 sec: 3705.5, 300 sec: 2990.0). Total num frames: 409600. Throughput: 0: 3556.6. Samples: 406016. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:10:28,153][103907] Avg episode reward: [(0, '70.216')]
[2026-01-08 15:10:28,285][103907] Saving new best policy, reward=70.216!
[2026-01-08 15:10:33,180][103907] Fps is (10 sec: 3287.4, 60 sec: 3550.4, 300 sec: 2999.5). Total num frames: 425984. Throughput: 0: 3541.2. Samples: 427008. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:10:33,181][103907] Avg episode reward: [(0, '77.215')]
[2026-01-08 15:10:33,323][103907] Saving new best policy, reward=77.215!
[2026-01-08 15:10:38,173][103907] Fps is (10 sec: 3270.3, 60 sec: 3548.5, 300 sec: 3009.1). Total num frames: 442368. Throughput: 0: 3495.3. Samples: 436736. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:10:38,173][103907] Avg episode reward: [(0, '80.312')]
[2026-01-08 15:10:38,312][103907] Saving new best policy, reward=80.312!
[2026-01-08 15:10:43,196][103907] Fps is (10 sec: 3271.8, 60 sec: 3552.4, 300 sec: 3017.5). Total num frames: 458752. Throughput: 0: 3518.4. Samples: 457728. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:10:43,196][103907] Avg episode reward: [(0, '87.253')]
[2026-01-08 15:10:43,325][103907] Saving new best policy, reward=87.253!
[2026-01-08 15:10:48,228][103907] Fps is (10 sec: 3258.9, 60 sec: 3549.1, 300 sec: 3025.1). Total num frames: 475136. Throughput: 0: 3452.7. Samples: 477696. Policy #0 lag: (min: 14.0, avg: 17.0, max: 78.0)
[2026-01-08 15:10:48,228][103907] Avg episode reward: [(0, '93.554')]
[2026-01-08 15:10:48,373][103907] Saving new best policy, reward=93.554!
[2026-01-08 15:10:53,180][103907] Fps is (10 sec: 3281.9, 60 sec: 3551.2, 300 sec: 3033.8). Total num frames: 491520. Throughput: 0: 3475.6. Samples: 488448. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:10:53,180][103907] Avg episode reward: [(0, '100.085')]
[2026-01-08 15:10:53,318][103907] Saving new best policy, reward=100.085!
[2026-01-08 15:10:58,242][103907] Fps is (10 sec: 3272.2, 60 sec: 3549.2, 300 sec: 3039.9). Total num frames: 507904. Throughput: 0: 3461.3. Samples: 508928. Policy #0 lag: (min: 5.0, avg: 8.0, max: 69.0)
[2026-01-08 15:10:58,242][103907] Avg episode reward: [(0, '104.469')]
[2026-01-08 15:10:58,384][103907] Saving new best policy, reward=104.469!
[2026-01-08 15:11:03,151][103907] Fps is (10 sec: 3286.5, 60 sec: 3549.7, 300 sec: 3048.4). Total num frames: 524288. Throughput: 0: 3414.7. Samples: 528896. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:11:03,151][103907] Avg episode reward: [(0, '107.841')]
[2026-01-08 15:11:03,290][103907] Saving new best policy, reward=107.841!
[2026-01-08 15:11:08,188][103907] Fps is (10 sec: 3294.5, 60 sec: 3553.5, 300 sec: 3054.2). Total num frames: 540672. Throughput: 0: 3449.4. Samples: 540160. Policy #0 lag: (min: 11.0, avg: 14.0, max: 75.0)
[2026-01-08 15:11:08,188][103907] Avg episode reward: [(0, '114.906')]
[2026-01-08 15:11:08,318][103907] Saving new best policy, reward=114.906!
[2026-01-08 15:11:10,649][103907] Signal inference workers to stop experience collection... (100 times)
[2026-01-08 15:11:10,656][103907] Signal inference workers to resume experience collection... (100 times)
[2026-01-08 15:11:10,935][103907] InferenceWorker_p0-w0: stopping experience collection (100 times)
[2026-01-08 15:11:10,935][103907] InferenceWorker_p0-w0: resuming experience collection (100 times)
[2026-01-08 15:11:13,147][103907] Fps is (10 sec: 3278.0, 60 sec: 3429.0, 300 sec: 3061.0). Total num frames: 557056. Throughput: 0: 3402.4. Samples: 559104. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:11:13,147][103907] Avg episode reward: [(0, '119.292')]
[2026-01-08 15:11:13,307][103907] Saving new best policy, reward=119.292!
[2026-01-08 15:11:18,147][103907] Fps is (10 sec: 3290.2, 60 sec: 3414.6, 300 sec: 3066.8). Total num frames: 573440. Throughput: 0: 3336.1. Samples: 577024. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:11:18,148][103907] Avg episode reward: [(0, '124.143')]
[2026-01-08 15:11:18,286][103907] Saving new best policy, reward=124.143!
[2026-01-08 15:11:23,226][103907] Fps is (10 sec: 3251.2, 60 sec: 3276.1, 300 sec: 3071.0). Total num frames: 589824. Throughput: 0: 3363.9. Samples: 588288. Policy #0 lag: (min: 13.0, avg: 16.0, max: 77.0)
[2026-01-08 15:11:23,226][103907] Avg episode reward: [(0, '127.610')]
[2026-01-08 15:11:23,364][103907] Saving new best policy, reward=127.610!
[2026-01-08 15:11:28,207][103907] Fps is (10 sec: 3257.3, 60 sec: 3273.8, 300 sec: 3076.5). Total num frames: 606208. Throughput: 0: 3321.5. Samples: 607232. Policy #0 lag: (min: 11.0, avg: 14.0, max: 75.0)
[2026-01-08 15:11:28,207][103907] Avg episode reward: [(0, '130.326')]
[2026-01-08 15:11:28,350][103907] Saving new best policy, reward=130.326!
[2026-01-08 15:11:33,247][103907] Fps is (10 sec: 3269.9, 60 sec: 3273.2, 300 sec: 3080.9). Total num frames: 622592. Throughput: 0: 3309.5. Samples: 626688. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:11:33,247][103907] Avg episode reward: [(0, '132.750')]
[2026-01-08 15:11:33,412][103907] Saving new best policy, reward=132.750!
[2026-01-08 15:11:38,164][103907] Fps is (10 sec: 3290.9, 60 sec: 3277.3, 300 sec: 3086.8). Total num frames: 638976. Throughput: 0: 3289.3. Samples: 636416. Policy #0 lag: (min: 10.0, avg: 13.0, max: 74.0)
[2026-01-08 15:11:38,165][103907] Avg episode reward: [(0, '134.733')]
[2026-01-08 15:11:38,334][103907] Saving new best policy, reward=134.733!
[2026-01-08 15:11:43,257][103907] Fps is (10 sec: 3273.5, 60 sec: 3273.5, 300 sec: 3090.0). Total num frames: 655360. Throughput: 0: 3218.8. Samples: 653824. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:11:43,257][103907] Avg episode reward: [(0, '139.540')]
[2026-01-08 15:11:43,424][103907] Saving new best policy, reward=139.540!
[2026-01-08 15:11:48,140][103907] Fps is (10 sec: 3284.8, 60 sec: 3281.6, 300 sec: 3095.9). Total num frames: 671744. Throughput: 0: 3175.2. Samples: 671744. Policy #0 lag: (min: 4.0, avg: 7.0, max: 68.0)
[2026-01-08 15:11:48,140][103907] Avg episode reward: [(0, '149.322')]
[2026-01-08 15:11:48,140][103907] Saving new best policy, reward=149.322!
[2026-01-08 15:11:53,354][103907] Fps is (10 sec: 2434.0, 60 sec: 3131.2, 300 sec: 3060.2). Total num frames: 679936. Throughput: 0: 3094.7. Samples: 679936. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:11:53,354][103907] Avg episode reward: [(0, '156.998')]
[2026-01-08 15:11:53,747][103907] Saving /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_lidar_policy1_acc_08012026/checkpoint_p0/checkpoint_000002688_688128.pth...
[2026-01-08 15:11:53,751][103907] Saving new best policy, reward=156.998!
[2026-01-08 15:11:58,176][103907] Fps is (10 sec: 1632.5, 60 sec: 3007.0, 300 sec: 3031.2). Total num frames: 688128. Throughput: 0: 3081.4. Samples: 697856. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:11:58,176][103907] Avg episode reward: [(0, '162.098')]
[2026-01-08 15:11:58,331][103907] Saving new best policy, reward=162.098!
[2026-01-08 15:12:03,218][103907] Fps is (10 sec: 2491.4, 60 sec: 3000.3, 300 sec: 3036.0). Total num frames: 704512. Throughput: 0: 3078.5. Samples: 715776. Policy #0 lag: (min: 1.0, avg: 4.0, max: 65.0)
[2026-01-08 15:12:03,219][103907] Avg episode reward: [(0, '163.095')]
[2026-01-08 15:12:03,381][103907] Saving new best policy, reward=163.095!
[2026-01-08 15:12:08,220][103907] Fps is (10 sec: 3262.6, 60 sec: 3002.2, 300 sec: 3041.0). Total num frames: 720896. Throughput: 0: 3015.5. Samples: 723968. Policy #0 lag: (min: 0.0, avg: 3.0, max: 64.0)
[2026-01-08 15:12:08,220][103907] Avg episode reward: [(0, '164.055')]
[2026-01-08 15:12:08,375][103907] Saving new best policy, reward=164.055!
[2026-01-08 15:12:13,135][103907] Fps is (10 sec: 3304.4, 60 sec: 3004.3, 300 sec: 3047.0). Total num frames: 737280. Throughput: 0: 2997.2. Samples: 741888. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:12:13,135][103907] Avg episode reward: [(0, '164.502')]
[2026-01-08 15:12:13,292][103907] Saving new best policy, reward=164.502!
[2026-01-08 15:12:18,256][103907] Fps is (10 sec: 3265.0, 60 sec: 2998.3, 300 sec: 3050.1). Total num frames: 753664. Throughput: 0: 2957.7. Samples: 759808. Policy #0 lag: (min: 12.0, avg: 15.0, max: 76.0)
[2026-01-08 15:12:18,256][103907] Avg episode reward: [(0, '164.828')]
[2026-01-08 15:12:18,385][103907] Saving new best policy, reward=164.828!
[2026-01-08 15:12:23,151][103907] Fps is (10 sec: 3271.5, 60 sec: 3007.5, 300 sec: 3055.9). Total num frames: 770048. Throughput: 0: 2993.2. Samples: 771072. Policy #0 lag: (min: 1.0, avg: 4.0, max: 65.0)
[2026-01-08 15:12:23,151][103907] Avg episode reward: [(0, '172.689')]
[2026-01-08 15:12:23,286][103907] Saving new best policy, reward=172.689!
[2026-01-08 15:12:28,157][103907] Fps is (10 sec: 3309.5, 60 sec: 3006.3, 300 sec: 3060.1). Total num frames: 786432. Throughput: 0: 3044.7. Samples: 790528. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:12:28,157][103907] Avg episode reward: [(0, '177.876')]
[2026-01-08 15:12:28,301][103907] Saving new best policy, reward=177.876!
[2026-01-08 15:12:33,228][103907] Fps is (10 sec: 3251.8, 60 sec: 3004.7, 300 sec: 3063.4). Total num frames: 802816. Throughput: 0: 3088.7. Samples: 811008. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:12:33,228][103907] Avg episode reward: [(0, '183.780')]
[2026-01-08 15:12:33,365][103907] Saving new best policy, reward=183.780!
[2026-01-08 15:12:38,151][103907] Fps is (10 sec: 3278.8, 60 sec: 3004.4, 300 sec: 3068.3). Total num frames: 819200. Throughput: 0: 3131.7. Samples: 820224. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:12:38,151][103907] Avg episode reward: [(0, '182.865')]
[2026-01-08 15:12:39,271][103907] Signal inference workers to stop experience collection... (150 times)
[2026-01-08 15:12:39,672][103907] InferenceWorker_p0-w0: stopping experience collection (150 times)
[2026-01-08 15:12:39,675][103907] Signal inference workers to resume experience collection... (150 times)
[2026-01-08 15:12:39,815][103907] InferenceWorker_p0-w0: resuming experience collection (150 times)
[2026-01-08 15:12:43,210][103907] Fps is (10 sec: 3282.9, 60 sec: 3006.1, 300 sec: 3071.5). Total num frames: 835584. Throughput: 0: 3183.4. Samples: 841216. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:12:43,210][103907] Avg episode reward: [(0, '189.231')]
[2026-01-08 15:12:43,380][103907] Saving new best policy, reward=189.231!
[2026-01-08 15:12:48,259][103907] Fps is (10 sec: 3241.8, 60 sec: 2997.8, 300 sec: 3074.6). Total num frames: 851968. Throughput: 0: 3228.4. Samples: 861184. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:12:48,259][103907] Avg episode reward: [(0, '193.556')]
[2026-01-08 15:12:48,261][103907] Saving new best policy, reward=193.556!
[2026-01-08 15:12:53,211][103907] Fps is (10 sec: 3276.3, 60 sec: 3147.8, 300 sec: 3078.7). Total num frames: 868352. Throughput: 0: 3266.0. Samples: 870912. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:12:53,211][103907] Avg episode reward: [(0, '195.421')]
[2026-01-08 15:12:53,355][103907] Saving new best policy, reward=195.421!
[2026-01-08 15:12:58,210][103907] Fps is (10 sec: 3292.8, 60 sec: 3274.9, 300 sec: 3082.2). Total num frames: 884736. Throughput: 0: 3328.1. Samples: 891904. Policy #0 lag: (min: 14.0, avg: 17.0, max: 78.0)
[2026-01-08 15:12:58,210][103907] Avg episode reward: [(0, '196.733')]
[2026-01-08 15:12:58,357][103907] Saving new best policy, reward=196.733!
[2026-01-08 15:13:03,134][103907] Fps is (10 sec: 3302.2, 60 sec: 3281.4, 300 sec: 3086.3). Total num frames: 901120. Throughput: 0: 3388.3. Samples: 911872. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:13:03,134][103907] Avg episode reward: [(0, '196.283')]
[2026-01-08 15:13:08,159][103907] Fps is (10 sec: 3293.5, 60 sec: 3280.1, 300 sec: 3234.6). Total num frames: 917504. Throughput: 0: 3333.1. Samples: 921088. Policy #0 lag: (min: 9.0, avg: 12.0, max: 73.0)
[2026-01-08 15:13:08,159][103907] Avg episode reward: [(0, '199.337')]
[2026-01-08 15:13:08,302][103907] Saving new best policy, reward=199.337!
[2026-01-08 15:13:13,236][103907] Fps is (10 sec: 3243.9, 60 sec: 3271.3, 300 sec: 3283.6). Total num frames: 933888. Throughput: 0: 3361.9. Samples: 942080. Policy #0 lag: (min: 0.0, avg: 3.0, max: 64.0)
[2026-01-08 15:13:13,236][103907] Avg episode reward: [(0, '203.702')]
[2026-01-08 15:13:13,378][103907] Saving new best policy, reward=203.702!
[2026-01-08 15:13:18,170][103907] Fps is (10 sec: 3273.3, 60 sec: 3281.5, 300 sec: 3285.5). Total num frames: 950272. Throughput: 0: 3383.6. Samples: 963072. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:13:18,170][103907] Avg episode reward: [(0, '209.124')]
[2026-01-08 15:13:18,334][103907] Saving new best policy, reward=209.124!
[2026-01-08 15:13:23,467][103907] Fps is (10 sec: 4003.4, 60 sec: 3395.5, 300 sec: 3325.8). Total num frames: 974848. Throughput: 0: 3366.9. Samples: 972800. Policy #0 lag: (min: 12.0, avg: 15.0, max: 76.0)
[2026-01-08 15:13:23,467][103907] Avg episode reward: [(0, '212.355')]
[2026-01-08 15:13:23,832][103907] Saving new best policy, reward=212.355!
[2026-01-08 15:13:28,325][103907] Fps is (10 sec: 4033.4, 60 sec: 3403.8, 300 sec: 3358.2). Total num frames: 991232. Throughput: 0: 3370.5. Samples: 993280. Policy #0 lag: (min: 6.0, avg: 9.0, max: 70.0)
[2026-01-08 15:13:28,325][103907] Avg episode reward: [(0, '219.514')]
[2026-01-08 15:13:28,690][103907] Saving new best policy, reward=219.514!
[2026-01-08 15:13:33,189][103907] Fps is (10 sec: 3370.6, 60 sec: 3415.6, 300 sec: 3359.9). Total num frames: 1007616. Throughput: 0: 3407.2. Samples: 1014272. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:13:33,189][103907] Avg episode reward: [(0, '222.343')]
[2026-01-08 15:13:33,561][103907] Saving new best policy, reward=222.343!
[2026-01-08 15:13:38,381][103907] Fps is (10 sec: 4073.3, 60 sec: 3536.3, 300 sec: 3385.2). Total num frames: 1032192. Throughput: 0: 3377.8. Samples: 1023488. Policy #0 lag: (min: 10.0, avg: 13.0, max: 74.0)
[2026-01-08 15:13:38,381][103907] Avg episode reward: [(0, '227.779')]
[2026-01-08 15:13:38,382][103907] Saving new best policy, reward=227.779!
[2026-01-08 15:13:43,247][103907] Fps is (10 sec: 4072.1, 60 sec: 3547.6, 300 sec: 3386.6). Total num frames: 1048576. Throughput: 0: 3387.8. Samples: 1044480. Policy #0 lag: (min: 0.0, avg: 3.0, max: 64.0)
[2026-01-08 15:13:43,248][103907] Avg episode reward: [(0, '233.190')]
[2026-01-08 15:13:43,388][103907] Saving new best policy, reward=233.190!
[2026-01-08 15:13:48,231][103907] Fps is (10 sec: 3326.7, 60 sec: 3551.5, 300 sec: 3387.9). Total num frames: 1064960. Throughput: 0: 3406.0. Samples: 1065472. Policy #0 lag: (min: 11.0, avg: 14.0, max: 75.0)
[2026-01-08 15:13:48,231][103907] Avg episode reward: [(0, '239.444')]
[2026-01-08 15:13:48,369][103907] Saving new best policy, reward=239.444!
[2026-01-08 15:13:53,229][103907] Fps is (10 sec: 3282.8, 60 sec: 3548.8, 300 sec: 3387.3). Total num frames: 1081344. Throughput: 0: 3419.4. Samples: 1075200. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:13:53,229][103907] Avg episode reward: [(0, '244.018')]
[2026-01-08 15:13:53,374][103907] Saving /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_lidar_policy1_acc_08012026/checkpoint_p0/checkpoint_000004224_1081344.pth...
[2026-01-08 15:13:53,378][103907] Removing /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_lidar_policy1_acc_08012026/checkpoint_p0/checkpoint_000001088_278528.pth
[2026-01-08 15:13:53,379][103907] Saving new best policy, reward=244.018!
[2026-01-08 15:13:57,250][103907] Signal inference workers to stop experience collection... (200 times)
[2026-01-08 15:13:57,611][103907] InferenceWorker_p0-w0: stopping experience collection (200 times)
[2026-01-08 15:13:57,611][103907] Signal inference workers to resume experience collection... (200 times)
[2026-01-08 15:13:57,612][103907] InferenceWorker_p0-w0: resuming experience collection (200 times)
[2026-01-08 15:13:58,158][103907] Fps is (10 sec: 3300.8, 60 sec: 3552.9, 300 sec: 3387.9). Total num frames: 1097728. Throughput: 0: 3419.2. Samples: 1095680. Policy #0 lag: (min: 1.0, avg: 4.0, max: 65.0)
[2026-01-08 15:13:58,158][103907] Avg episode reward: [(0, '247.200')]
[2026-01-08 15:13:58,295][103907] Saving new best policy, reward=247.200!
[2026-01-08 15:14:03,217][103907] Fps is (10 sec: 3280.7, 60 sec: 3545.0, 300 sec: 3387.9). Total num frames: 1114112. Throughput: 0: 3375.6. Samples: 1115136. Policy #0 lag: (min: 3.0, avg: 6.0, max: 67.0)
[2026-01-08 15:14:03,218][103907] Avg episode reward: [(0, '247.119')]
[2026-01-08 15:14:08,211][103907] Fps is (10 sec: 3259.4, 60 sec: 3546.8, 300 sec: 3387.9). Total num frames: 1130496. Throughput: 0: 3421.4. Samples: 1125888. Policy #0 lag: (min: 7.0, avg: 10.0, max: 71.0)
[2026-01-08 15:14:08,212][103907] Avg episode reward: [(0, '245.672')]
[2026-01-08 15:14:13,160][103907] Fps is (10 sec: 3295.7, 60 sec: 3554.3, 300 sec: 3388.6). Total num frames: 1146880. Throughput: 0: 3425.9. Samples: 1146880. Policy #0 lag: (min: 13.0, avg: 16.0, max: 77.0)
[2026-01-08 15:14:13,160][103907] Avg episode reward: [(0, '248.404')]
[2026-01-08 15:14:13,302][103907] Saving new best policy, reward=248.404!
[2026-01-08 15:14:18,213][103907] Fps is (10 sec: 3276.2, 60 sec: 3547.3, 300 sec: 3388.0). Total num frames: 1163264. Throughput: 0: 3377.4. Samples: 1166336. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:14:18,213][103907] Avg episode reward: [(0, '247.663')]
[2026-01-08 15:14:23,179][103907] Fps is (10 sec: 3270.6, 60 sec: 3429.8, 300 sec: 3363.3). Total num frames: 1179648. Throughput: 0: 3440.1. Samples: 1177600. Policy #0 lag: (min: 0.0, avg: 3.0, max: 64.0)
[2026-01-08 15:14:23,179][103907] Avg episode reward: [(0, '249.723')]
[2026-01-08 15:14:23,319][103907] Saving new best policy, reward=249.723!
[2026-01-08 15:14:28,147][103907] Fps is (10 sec: 3298.8, 60 sec: 3423.5, 300 sec: 3332.8). Total num frames: 1196032. Throughput: 0: 3398.2. Samples: 1197056. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:14:28,147][103907] Avg episode reward: [(0, '251.692')]
[2026-01-08 15:14:28,287][103907] Saving new best policy, reward=251.692!
[2026-01-08 15:14:33,208][103907] Fps is (10 sec: 3267.3, 60 sec: 3412.2, 300 sec: 3331.7). Total num frames: 1212416. Throughput: 0: 3380.9. Samples: 1217536. Policy #0 lag: (min: 31.0, avg: 34.0, max: 95.0)
[2026-01-08 15:14:33,208][103907] Avg episode reward: [(0, '252.087')]
[2026-01-08 15:14:33,348][103907] Saving new best policy, reward=252.087!
[2026-01-08 15:14:38,147][103907] Fps is (10 sec: 3276.6, 60 sec: 3289.6, 300 sec: 3333.4). Total num frames: 1228800. Throughput: 0: 3419.6. Samples: 1228800. Policy #0 lag: (min: 47.0, avg: 50.0, max: 111.0)
[2026-01-08 15:14:38,148][103907] Avg episode reward: [(0, '254.749')]
[2026-01-08 15:14:38,282][103907] Saving new best policy, reward=254.749!
[2026-01-08 15:14:43,260][103907] Fps is (10 sec: 3259.7, 60 sec: 3276.1, 300 sec: 3331.8). Total num frames: 1245184. Throughput: 0: 3371.5. Samples: 1247744. Policy #0 lag: (min: 50.0, avg: 53.0, max: 114.0)
[2026-01-08 15:14:43,261][103907] Avg episode reward: [(0, '260.297')]
[2026-01-08 15:14:43,397][103907] Saving new best policy, reward=260.297!
[2026-01-08 15:14:48,212][103907] Fps is (10 sec: 3255.9, 60 sec: 3277.9, 300 sec: 3332.2). Total num frames: 1261568. Throughput: 0: 3413.8. Samples: 1268736. Policy #0 lag: (min: 50.0, avg: 53.0, max: 114.0)
[2026-01-08 15:14:48,212][103907] Avg episode reward: [(0, '266.565')]
[2026-01-08 15:14:48,344][103907] Saving new best policy, reward=266.565!
[2026-01-08 15:14:53,185][103907] Fps is (10 sec: 3301.8, 60 sec: 3279.2, 300 sec: 3332.9). Total num frames: 1277952. Throughput: 0: 3404.0. Samples: 1278976. Policy #0 lag: (min: 9.0, avg: 12.0, max: 73.0)
[2026-01-08 15:14:53,185][103907] Avg episode reward: [(0, '271.324')]
[2026-01-08 15:14:53,333][103907] Saving new best policy, reward=271.324!
[2026-01-08 15:14:58,165][103907] Fps is (10 sec: 3292.2, 60 sec: 3276.4, 300 sec: 3332.2). Total num frames: 1294336. Throughput: 0: 3378.9. Samples: 1298944. Policy #0 lag: (min: 47.0, avg: 50.0, max: 111.0)
[2026-01-08 15:14:58,165][103907] Avg episode reward: [(0, '272.779')]
[2026-01-08 15:14:58,302][103907] Saving new best policy, reward=272.779!
[2026-01-08 15:15:03,251][103907] Fps is (10 sec: 3255.1, 60 sec: 3275.0, 300 sec: 3332.3). Total num frames: 1310720. Throughput: 0: 3399.1. Samples: 1319424. Policy #0 lag: (min: 47.0, avg: 50.0, max: 111.0)
[2026-01-08 15:15:03,251][103907] Avg episode reward: [(0, '272.685')]
[2026-01-08 15:15:08,206][103907] Fps is (10 sec: 3263.3, 60 sec: 3277.1, 300 sec: 3307.0). Total num frames: 1327104. Throughput: 0: 3365.8. Samples: 1329152. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:15:08,206][103907] Avg episode reward: [(0, '276.303')]
[2026-01-08 15:15:08,342][103907] Saving new best policy, reward=276.303!
[2026-01-08 15:15:13,195][103907] Fps is (10 sec: 3295.5, 60 sec: 3274.9, 300 sec: 3304.3). Total num frames: 1343488. Throughput: 0: 3398.3. Samples: 1350144. Policy #0 lag: (min: 44.0, avg: 47.0, max: 108.0)
[2026-01-08 15:15:13,195][103907] Avg episode reward: [(0, '279.683')]
[2026-01-08 15:15:13,337][103907] Saving new best policy, reward=279.683!
[2026-01-08 15:15:18,135][103907] Fps is (10 sec: 3300.3, 60 sec: 3281.1, 300 sec: 3277.7). Total num frames: 1359872. Throughput: 0: 3407.5. Samples: 1370624. Policy #0 lag: (min: 44.0, avg: 47.0, max: 108.0)
[2026-01-08 15:15:18,135][103907] Avg episode reward: [(0, '287.234')]
[2026-01-08 15:15:18,274][103907] Saving new best policy, reward=287.234!
[2026-01-08 15:15:19,201][103907] Signal inference workers to stop experience collection... (250 times)
[2026-01-08 15:15:19,206][103907] Signal inference workers to resume experience collection... (250 times)
[2026-01-08 15:15:19,455][103907] InferenceWorker_p0-w0: stopping experience collection (250 times)
[2026-01-08 15:15:19,455][103907] InferenceWorker_p0-w0: resuming experience collection (250 times)
[2026-01-08 15:15:23,253][103907] Fps is (10 sec: 3257.7, 60 sec: 3272.8, 300 sec: 3275.7). Total num frames: 1376256. Throughput: 0: 3359.9. Samples: 1380352. Policy #0 lag: (min: 12.0, avg: 15.0, max: 76.0)
[2026-01-08 15:15:23,253][103907] Avg episode reward: [(0, '290.820')]
[2026-01-08 15:15:23,394][103907] Saving new best policy, reward=290.820!
[2026-01-08 15:15:28,141][103907] Fps is (10 sec: 3274.7, 60 sec: 3277.1, 300 sec: 3277.2). Total num frames: 1392640. Throughput: 0: 3411.0. Samples: 1400832. Policy #0 lag: (min: 63.0, avg: 66.0, max: 127.0)
[2026-01-08 15:15:28,141][103907] Avg episode reward: [(0, '289.330')]
[2026-01-08 15:15:33,226][103907] Fps is (10 sec: 3285.9, 60 sec: 3275.8, 300 sec: 3276.2). Total num frames: 1409024. Throughput: 0: 3400.9. Samples: 1421824. Policy #0 lag: (min: 63.0, avg: 66.0, max: 127.0)
[2026-01-08 15:15:33,226][103907] Avg episode reward: [(0, '283.751')]
[2026-01-08 15:15:38,214][103907] Fps is (10 sec: 3253.0, 60 sec: 3273.1, 300 sec: 3276.6). Total num frames: 1425408. Throughput: 0: 3377.0. Samples: 1431040. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:15:38,215][103907] Avg episode reward: [(0, '287.513')]
[2026-01-08 15:15:43,419][103907] Fps is (10 sec: 4018.3, 60 sec: 3404.3, 300 sec: 3302.4). Total num frames: 1449984. Throughput: 0: 3382.8. Samples: 1452032. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:15:43,419][103907] Avg episode reward: [(0, '290.827')]
[2026-01-08 15:15:43,794][103907] Saving new best policy, reward=290.827!
[2026-01-08 15:15:48,307][103907] Fps is (10 sec: 4058.4, 60 sec: 3407.9, 300 sec: 3303.1). Total num frames: 1466368. Throughput: 0: 3397.7. Samples: 1472512. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:15:48,307][103907] Avg episode reward: [(0, '299.105')]
[2026-01-08 15:15:48,689][103907] Saving new best policy, reward=299.105!
[2026-01-08 15:15:53,519][103907] Fps is (10 sec: 3244.5, 60 sec: 3394.4, 300 sec: 3301.5). Total num frames: 1482752. Throughput: 0: 3367.2. Samples: 1481728. Policy #0 lag: (min: 3.0, avg: 6.0, max: 67.0)
[2026-01-08 15:15:53,519][103907] Avg episode reward: [(0, '297.807')]
[2026-01-08 15:15:53,910][103907] Saving /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_lidar_policy1_acc_08012026/checkpoint_p0/checkpoint_000005824_1490944.pth...
[2026-01-08 15:15:53,914][103907] Removing /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_lidar_policy1_acc_08012026/checkpoint_p0/checkpoint_000002688_688128.pth
[2026-01-08 15:15:58,208][103907] Fps is (10 sec: 2482.1, 60 sec: 3274.4, 300 sec: 3276.2). Total num frames: 1490944. Throughput: 0: 3321.3. Samples: 1499648. Policy #0 lag: (min: 3.0, avg: 6.0, max: 67.0)
[2026-01-08 15:15:58,209][103907] Avg episode reward: [(0, '290.997')]
[2026-01-08 15:16:03,223][103907] Fps is (10 sec: 2532.4, 60 sec: 3278.3, 300 sec: 3276.4). Total num frames: 1507328. Throughput: 0: 3304.4. Samples: 1519616. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:16:03,223][103907] Avg episode reward: [(0, '285.806')]
[2026-01-08 15:16:08,152][103907] Fps is (10 sec: 3295.5, 60 sec: 3279.8, 300 sec: 3276.8). Total num frames: 1523712. Throughput: 0: 3307.0. Samples: 1528832. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:16:08,152][103907] Avg episode reward: [(0, '288.243')]
[2026-01-08 15:16:13,463][103907] Fps is (10 sec: 4000.0, 60 sec: 3398.1, 300 sec: 3301.0). Total num frames: 1548288. Throughput: 0: 3287.4. Samples: 1549824. Policy #0 lag: (min: 2.0, avg: 5.0, max: 66.0)
[2026-01-08 15:16:13,463][103907] Avg episode reward: [(0, '288.899')]
[2026-01-08 15:16:18,301][103907] Fps is (10 sec: 4035.8, 60 sec: 3403.9, 300 sec: 3303.7). Total num frames: 1564672. Throughput: 0: 3305.4. Samples: 1570816. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:16:18,301][103907] Avg episode reward: [(0, '292.905')]
[2026-01-08 15:16:23,164][103907] Fps is (10 sec: 3377.7, 60 sec: 3418.4, 300 sec: 3305.0). Total num frames: 1581056. Throughput: 0: 3314.6. Samples: 1580032. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:16:23,165][103907] Avg episode reward: [(0, '297.216')]
[2026-01-08 15:16:28,343][103907] Fps is (10 sec: 4078.9, 60 sec: 3538.0, 300 sec: 3331.3). Total num frames: 1605632. Throughput: 0: 3316.6. Samples: 1601024. Policy #0 lag: (min: 5.0, avg: 8.0, max: 69.0)
[2026-01-08 15:16:28,343][103907] Avg episode reward: [(0, '301.035')]
[2026-01-08 15:16:28,343][103907] Saving new best policy, reward=301.035!
[2026-01-08 15:16:33,157][103907] Fps is (10 sec: 4099.0, 60 sec: 3553.9, 300 sec: 3332.4). Total num frames: 1622016. Throughput: 0: 3333.4. Samples: 1622016. Policy #0 lag: (min: 5.0, avg: 8.0, max: 69.0)
[2026-01-08 15:16:33,157][103907] Avg episode reward: [(0, '300.465')]
[2026-01-08 15:16:38,379][103907] Fps is (10 sec: 3265.0, 60 sec: 3540.2, 300 sec: 3331.0). Total num frames: 1638400. Throughput: 0: 3332.7. Samples: 1631232. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:16:38,379][103907] Avg episode reward: [(0, '303.909')]
[2026-01-08 15:16:38,380][103907] Saving new best policy, reward=303.909!
[2026-01-08 15:16:43,118][103907] Signal inference workers to stop experience collection... (300 times)
[2026-01-08 15:16:43,500][103907] InferenceWorker_p0-w0: stopping experience collection (300 times)
[2026-01-08 15:16:43,502][103907] Signal inference workers to resume experience collection... (300 times)
[2026-01-08 15:16:43,503][103907] Fps is (10 sec: 2375.5, 60 sec: 3272.2, 300 sec: 3300.5). Total num frames: 1646592. Throughput: 0: 3300.7. Samples: 1649152. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:16:43,503][103907] Avg episode reward: [(0, '311.394')]
[2026-01-08 15:16:43,663][103907] InferenceWorker_p0-w0: resuming experience collection (300 times)
[2026-01-08 15:16:43,902][103907] Saving new best policy, reward=311.394!
[2026-01-08 15:16:48,161][103907] Fps is (10 sec: 1674.8, 60 sec: 3147.9, 300 sec: 3306.7). Total num frames: 1654784. Throughput: 0: 3281.3. Samples: 1667072. Policy #0 lag: (min: 47.0, avg: 50.0, max: 111.0)
[2026-01-08 15:16:48,162][103907] Avg episode reward: [(0, '312.515')]
[2026-01-08 15:16:48,311][103907] Saving new best policy, reward=312.515!
[2026-01-08 15:16:53,223][103907] Fps is (10 sec: 2528.4, 60 sec: 3155.8, 300 sec: 3331.8). Total num frames: 1671168. Throughput: 0: 3248.9. Samples: 1675264. Policy #0 lag: (min: 47.0, avg: 50.0, max: 111.0)
[2026-01-08 15:16:53,223][103907] Avg episode reward: [(0, '322.568')]
[2026-01-08 15:16:53,391][103907] Saving new best policy, reward=322.568!
[2026-01-08 15:16:58,160][103907] Fps is (10 sec: 3277.2, 60 sec: 3279.4, 300 sec: 3333.0). Total num frames: 1687552. Throughput: 0: 3207.4. Samples: 1693184. Policy #0 lag: (min: 6.0, avg: 9.0, max: 70.0)
[2026-01-08 15:16:58,160][103907] Avg episode reward: [(0, '326.374')]
[2026-01-08 15:16:58,326][103907] Saving new best policy, reward=326.374!
[2026-01-08 15:17:03,161][103907] Fps is (10 sec: 3297.0, 60 sec: 3280.2, 300 sec: 3333.0). Total num frames: 1703936. Throughput: 0: 3138.6. Samples: 1711616. Policy #0 lag: (min: 63.0, avg: 66.0, max: 127.0)
[2026-01-08 15:17:03,162][103907] Avg episode reward: [(0, '325.677')]
[2026-01-08 15:17:08,183][103907] Fps is (10 sec: 3269.4, 60 sec: 3275.1, 300 sec: 3331.8). Total num frames: 1720320. Throughput: 0: 3139.0. Samples: 1721344. Policy #0 lag: (min: 63.0, avg: 66.0, max: 127.0)
[2026-01-08 15:17:08,183][103907] Avg episode reward: [(0, '329.131')]
[2026-01-08 15:17:08,322][103907] Saving new best policy, reward=329.131!
[2026-01-08 15:17:13,207][103907] Fps is (10 sec: 3261.8, 60 sec: 3153.7, 300 sec: 3332.9). Total num frames: 1736704. Throughput: 0: 3138.3. Samples: 1741824. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:17:13,208][103907] Avg episode reward: [(0, '320.231')]
[2026-01-08 15:17:18,181][103907] Fps is (10 sec: 3277.4, 60 sec: 3146.5, 300 sec: 3332.0). Total num frames: 1753088. Throughput: 0: 3115.9. Samples: 1762304. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:17:18,181][103907] Avg episode reward: [(0, '326.040')]
[2026-01-08 15:17:23,152][103907] Fps is (10 sec: 3295.2, 60 sec: 3140.9, 300 sec: 3332.4). Total num frames: 1769472. Throughput: 0: 3133.3. Samples: 1771520. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:17:23,152][103907] Avg episode reward: [(0, '326.753')]
[2026-01-08 15:17:28,192][103907] Fps is (10 sec: 3273.3, 60 sec: 3011.3, 300 sec: 3332.7). Total num frames: 1785856. Throughput: 0: 3208.0. Samples: 1792512. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:17:28,192][103907] Avg episode reward: [(0, '332.301')]
[2026-01-08 15:17:28,331][103907] Saving new best policy, reward=332.301!
[2026-01-08 15:17:33,165][103907] Fps is (10 sec: 3272.3, 60 sec: 3003.3, 300 sec: 3332.2). Total num frames: 1802240. Throughput: 0: 3253.7. Samples: 1813504. Policy #0 lag: (min: 6.0, avg: 9.0, max: 70.0)
[2026-01-08 15:17:33,166][103907] Avg episode reward: [(0, '337.374')]
[2026-01-08 15:17:33,314][103907] Saving new best policy, reward=337.374!
[2026-01-08 15:17:38,132][103907] Fps is (10 sec: 3296.6, 60 sec: 3016.2, 300 sec: 3333.2). Total num frames: 1818624. Throughput: 0: 3294.9. Samples: 1823232. Policy #0 lag: (min: 6.0, avg: 9.0, max: 70.0)
[2026-01-08 15:17:38,132][103907] Avg episode reward: [(0, '345.957')]
[2026-01-08 15:17:38,273][103907] Saving new best policy, reward=345.957!
[2026-01-08 15:17:43,228][103907] Fps is (10 sec: 3256.5, 60 sec: 3154.7, 300 sec: 3332.7). Total num frames: 1835008. Throughput: 0: 3340.0. Samples: 1843712. Policy #0 lag: (min: 1.0, avg: 4.0, max: 65.0)
[2026-01-08 15:17:43,228][103907] Avg episode reward: [(0, '351.298')]
[2026-01-08 15:17:43,369][103907] Saving new best policy, reward=351.298!
[2026-01-08 15:17:48,260][103907] Fps is (10 sec: 3235.2, 60 sec: 3271.4, 300 sec: 3331.8). Total num frames: 1851392. Throughput: 0: 3383.2. Samples: 1864192. Policy #0 lag: (min: 1.0, avg: 4.0, max: 65.0)
[2026-01-08 15:17:48,260][103907] Avg episode reward: [(0, '361.683')]
[2026-01-08 15:17:48,631][103907] Saving new best policy, reward=361.683!
[2026-01-08 15:17:53,487][103907] Fps is (10 sec: 3992.7, 60 sec: 3398.4, 300 sec: 3357.0). Total num frames: 1875968. Throughput: 0: 3367.8. Samples: 1873920. Policy #0 lag: (min: 9.0, avg: 12.0, max: 73.0)
[2026-01-08 15:17:53,487][103907] Avg episode reward: [(0, '369.980')]
[2026-01-08 15:17:53,850][103907] Saving /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_lidar_policy1_acc_08012026/checkpoint_p0/checkpoint_000007360_1884160.pth...
[2026-01-08 15:17:53,854][103907] Removing /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_lidar_policy1_acc_08012026/checkpoint_p0/checkpoint_000004224_1081344.pth
[2026-01-08 15:17:53,854][103907] Saving new best policy, reward=369.980!
[2026-01-08 15:17:58,356][103907] Fps is (10 sec: 4056.9, 60 sec: 3402.2, 300 sec: 3357.6). Total num frames: 1892352. Throughput: 0: 3379.4. Samples: 1894400. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:17:58,357][103907] Avg episode reward: [(0, '379.110')]
[2026-01-08 15:17:58,719][103907] Saving new best policy, reward=379.110!
[2026-01-08 15:18:03,220][103907] Signal inference workers to stop experience collection... (350 times)
[2026-01-08 15:18:03,220][103907] Fps is (10 sec: 3366.5, 60 sec: 3410.0, 300 sec: 3359.4). Total num frames: 1908736. Throughput: 0: 3387.6. Samples: 1914880. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:18:03,220][103907] Avg episode reward: [(0, '372.122')]
[2026-01-08 15:18:03,593][103907] InferenceWorker_p0-w0: stopping experience collection (350 times)
[2026-01-08 15:18:03,593][103907] Signal inference workers to resume experience collection... (350 times)
[2026-01-08 15:18:03,593][103907] InferenceWorker_p0-w0: resuming experience collection (350 times)
[2026-01-08 15:18:08,440][103907] Fps is (10 sec: 4062.1, 60 sec: 3534.7, 300 sec: 3385.5). Total num frames: 1933312. Throughput: 0: 3380.3. Samples: 1924608. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:18:08,440][103907] Avg episode reward: [(0, '368.970')]
[2026-01-08 15:18:13,243][103907] Fps is (10 sec: 4086.7, 60 sec: 3547.8, 300 sec: 3387.0). Total num frames: 1949696. Throughput: 0: 3398.1. Samples: 1945600. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:18:13,243][103907] Avg episode reward: [(0, '370.955')]
[2026-01-08 15:18:18,300][103907] Fps is (10 sec: 2492.6, 60 sec: 3406.6, 300 sec: 3334.2). Total num frames: 1957888. Throughput: 0: 3346.5. Samples: 1964544. Policy #0 lag: (min: 13.0, avg: 16.0, max: 77.0)
[2026-01-08 15:18:18,300][103907] Avg episode reward: [(0, '367.911')]
[2026-01-08 15:18:23,139][103907] Fps is (10 sec: 1655.7, 60 sec: 3277.5, 300 sec: 3306.7). Total num frames: 1966080. Throughput: 0: 3321.8. Samples: 1972736. Policy #0 lag: (min: 13.0, avg: 16.0, max: 77.0)
[2026-01-08 15:18:23,139][103907] Avg episode reward: [(0, '371.489')]
[2026-01-08 15:18:28,210][103907] Fps is (10 sec: 2479.7, 60 sec: 3275.8, 300 sec: 3304.3). Total num frames: 1982464. Throughput: 0: 3255.3. Samples: 1990144. Policy #0 lag: (min: 13.0, avg: 16.0, max: 77.0)
[2026-01-08 15:18:28,211][103907] Avg episode reward: [(0, '377.918')]
[2026-01-08 15:18:33,269][103907] Fps is (10 sec: 3234.8, 60 sec: 3271.2, 300 sec: 3278.0). Total num frames: 1998848. Throughput: 0: 3196.5. Samples: 2008064. Policy #0 lag: (min: 2.0, avg: 5.0, max: 66.0)
[2026-01-08 15:18:33,269][103907] Avg episode reward: [(0, '382.166')]
[2026-01-08 15:18:33,426][103907] Saving new best policy, reward=382.166!
[2026-01-08 15:18:38,132][103907] Fps is (10 sec: 3302.8, 60 sec: 3276.8, 300 sec: 3278.1). Total num frames: 2015232. Throughput: 0: 3188.2. Samples: 2016256. Policy #0 lag: (min: 2.0, avg: 5.0, max: 66.0)
[2026-01-08 15:18:38,132][103907] Avg episode reward: [(0, '384.309')]
[2026-01-08 15:18:38,294][103907] Saving new best policy, reward=384.309!
[2026-01-08 15:18:43,249][103907] Fps is (10 sec: 3283.1, 60 sec: 3275.6, 300 sec: 3276.6). Total num frames: 2031616. Throughput: 0: 3113.5. Samples: 2034176. Policy #0 lag: (min: 1.0, avg: 4.0, max: 65.0)
[2026-01-08 15:18:43,250][103907] Avg episode reward: [(0, '386.049')]
[2026-01-08 15:18:43,414][103907] Saving new best policy, reward=386.049!
[2026-01-08 15:18:48,145][103907] Fps is (10 sec: 3272.4, 60 sec: 3283.1, 300 sec: 3277.7). Total num frames: 2048000. Throughput: 0: 3054.3. Samples: 2052096. Policy #0 lag: (min: 1.0, avg: 4.0, max: 65.0)
[2026-01-08 15:18:48,145][103907] Avg episode reward: [(0, '385.563')]
[2026-01-08 15:18:53,183][103907] Fps is (10 sec: 3298.8, 60 sec: 3156.3, 300 sec: 3276.5). Total num frames: 2064384. Throughput: 0: 3066.8. Samples: 2061824. Policy #0 lag: (min: 9.0, avg: 12.0, max: 73.0)
[2026-01-08 15:18:53,183][103907] Avg episode reward: [(0, '394.602')]
[2026-01-08 15:18:53,344][103907] Saving new best policy, reward=394.602!
[2026-01-08 15:18:58,190][103907] Fps is (10 sec: 3262.0, 60 sec: 3149.0, 300 sec: 3277.1). Total num frames: 2080768. Throughput: 0: 2984.5. Samples: 2079744. Policy #0 lag: (min: 9.0, avg: 12.0, max: 73.0)
[2026-01-08 15:18:58,191][103907] Avg episode reward: [(0, '405.311')]
[2026-01-08 15:18:58,325][103907] Saving new best policy, reward=405.311!
[2026-01-08 15:19:03,200][103907] Fps is (10 sec: 3271.2, 60 sec: 3141.3, 300 sec: 3276.9). Total num frames: 2097152. Throughput: 0: 2976.2. Samples: 2098176. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:19:03,200][103907] Avg episode reward: [(0, '420.921')]
[2026-01-08 15:19:03,348][103907] Saving new best policy, reward=420.921!
[2026-01-08 15:19:08,157][103907] Fps is (10 sec: 3287.7, 60 sec: 3018.0, 300 sec: 3276.8). Total num frames: 2113536. Throughput: 0: 3036.6. Samples: 2109440. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:19:08,157][103907] Avg episode reward: [(0, '422.498')]
[2026-01-08 15:19:08,302][103907] Saving new best policy, reward=422.498!
[2026-01-08 15:19:13,219][103907] Fps is (10 sec: 3270.7, 60 sec: 3005.0, 300 sec: 3276.7). Total num frames: 2129920. Throughput: 0: 3105.6. Samples: 2129920. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:19:13,219][103907] Avg episode reward: [(0, '422.980')]
[2026-01-08 15:19:13,375][103907] Saving new best policy, reward=422.980!
[2026-01-08 15:19:18,167][103907] Fps is (10 sec: 3273.5, 60 sec: 3147.2, 300 sec: 3276.9). Total num frames: 2146304. Throughput: 0: 3136.0. Samples: 2148864. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:19:18,168][103907] Avg episode reward: [(0, '410.620')]
[2026-01-08 15:19:23,253][103907] Fps is (10 sec: 3265.4, 60 sec: 3270.5, 300 sec: 3275.6). Total num frames: 2162688. Throughput: 0: 3188.5. Samples: 2160128. Policy #0 lag: (min: 4.0, avg: 7.0, max: 68.0)
[2026-01-08 15:19:23,254][103907] Avg episode reward: [(0, '412.306')]
[2026-01-08 15:19:28,219][103907] Fps is (10 sec: 3260.1, 60 sec: 3276.4, 300 sec: 3276.7). Total num frames: 2179072. Throughput: 0: 3244.9. Samples: 2180096. Policy #0 lag: (min: 4.0, avg: 7.0, max: 68.0)
[2026-01-08 15:19:28,219][103907] Avg episode reward: [(0, '410.591')]
[2026-01-08 15:19:31,029][103907] Signal inference workers to stop experience collection... (400 times)
[2026-01-08 15:19:31,036][103907] Signal inference workers to resume experience collection... (400 times)
[2026-01-08 15:19:31,287][103907] InferenceWorker_p0-w0: stopping experience collection (400 times)
[2026-01-08 15:19:31,287][103907] InferenceWorker_p0-w0: resuming experience collection (400 times)
[2026-01-08 15:19:33,192][103907] Fps is (10 sec: 3297.0, 60 sec: 3281.0, 300 sec: 3276.3). Total num frames: 2195456. Throughput: 0: 3284.7. Samples: 2200064. Policy #0 lag: (min: 11.0, avg: 14.0, max: 75.0)
[2026-01-08 15:19:33,192][103907] Avg episode reward: [(0, '414.618')]
[2026-01-08 15:19:38,167][103907] Fps is (10 sec: 3294.0, 60 sec: 3274.9, 300 sec: 3277.8). Total num frames: 2211840. Throughput: 0: 3300.7. Samples: 2210304. Policy #0 lag: (min: 11.0, avg: 14.0, max: 75.0)
[2026-01-08 15:19:38,167][103907] Avg episode reward: [(0, '413.779')]
[2026-01-08 15:19:43,254][103907] Fps is (10 sec: 3256.6, 60 sec: 3276.5, 300 sec: 3276.3). Total num frames: 2228224. Throughput: 0: 3283.5. Samples: 2227712. Policy #0 lag: (min: 2.0, avg: 5.0, max: 66.0)
[2026-01-08 15:19:43,254][103907] Avg episode reward: [(0, '418.345')]
[2026-01-08 15:19:48,185][103907] Fps is (10 sec: 3270.6, 60 sec: 3274.6, 300 sec: 3276.8). Total num frames: 2244608. Throughput: 0: 3277.9. Samples: 2245632. Policy #0 lag: (min: 2.0, avg: 5.0, max: 66.0)
[2026-01-08 15:19:48,186][103907] Avg episode reward: [(0, '420.966')]
[2026-01-08 15:19:53,416][103907] Fps is (10 sec: 3224.6, 60 sec: 3264.1, 300 sec: 3274.0). Total num frames: 2260992. Throughput: 0: 3190.2. Samples: 2253824. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:19:53,416][103907] Avg episode reward: [(0, '432.810')]
[2026-01-08 15:19:53,422][103907] Saving /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_lidar_policy1_acc_08012026/checkpoint_p0/checkpoint_000008832_2260992.pth...
[2026-01-08 15:19:53,426][103907] Removing /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_lidar_policy1_acc_08012026/checkpoint_p0/checkpoint_000005824_1490944.pth
[2026-01-08 15:19:53,426][103907] Saving new best policy, reward=432.810!
[2026-01-08 15:19:58,227][103907] Fps is (10 sec: 1631.6, 60 sec: 3001.9, 300 sec: 3221.5). Total num frames: 2260992. Throughput: 0: 3151.1. Samples: 2271744. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:19:58,227][103907] Avg episode reward: [(0, '438.781')]
[2026-01-08 15:19:58,618][103907] Saving new best policy, reward=438.781!
[2026-01-08 15:20:03,285][103907] Fps is (10 sec: 1660.3, 60 sec: 2999.5, 300 sec: 3220.4). Total num frames: 2277376. Throughput: 0: 3109.4. Samples: 2289152. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:20:03,285][103907] Avg episode reward: [(0, '440.725')]
[2026-01-08 15:20:03,448][103907] Saving new best policy, reward=440.725!
[2026-01-08 15:20:08,211][103907] Fps is (10 sec: 3282.2, 60 sec: 3001.1, 300 sec: 3221.1). Total num frames: 2293760. Throughput: 0: 3052.1. Samples: 2297344. Policy #0 lag: (min: 4.0, avg: 7.0, max: 68.0)
[2026-01-08 15:20:08,211][103907] Avg episode reward: [(0, '445.031')]
[2026-01-08 15:20:08,369][103907] Saving new best policy, reward=445.031!
[2026-01-08 15:20:13,139][103907] Fps is (10 sec: 3325.1, 60 sec: 3007.7, 300 sec: 3221.2). Total num frames: 2310144. Throughput: 0: 3009.0. Samples: 2315264. Policy #0 lag: (min: 4.0, avg: 7.0, max: 68.0)
[2026-01-08 15:20:13,140][103907] Avg episode reward: [(0, '447.464')]
[2026-01-08 15:20:13,307][103907] Saving new best policy, reward=447.464!
[2026-01-08 15:20:18,229][103907] Fps is (10 sec: 3271.0, 60 sec: 3000.7, 300 sec: 3221.5). Total num frames: 2326528. Throughput: 0: 2955.8. Samples: 2333184. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:20:18,229][103907] Avg episode reward: [(0, '450.452')]
[2026-01-08 15:20:18,385][103907] Saving new best policy, reward=450.452!
[2026-01-08 15:20:23,219][103907] Fps is (10 sec: 3250.8, 60 sec: 3005.5, 300 sec: 3220.4). Total num frames: 2342912. Throughput: 0: 2943.4. Samples: 2342912. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:20:23,219][103907] Avg episode reward: [(0, '452.417')]
[2026-01-08 15:20:23,382][103907] Saving new best policy, reward=452.417!
[2026-01-08 15:20:28,155][103907] Fps is (10 sec: 3301.1, 60 sec: 3006.9, 300 sec: 3222.0). Total num frames: 2359296. Throughput: 0: 2953.4. Samples: 2360320. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:20:28,155][103907] Avg episode reward: [(0, '447.152')]
[2026-01-08 15:20:33,240][103907] Fps is (10 sec: 3269.9, 60 sec: 3001.3, 300 sec: 3221.0). Total num frames: 2375680. Throughput: 0: 2909.2. Samples: 2376704. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:20:33,240][103907] Avg episode reward: [(0, '446.209')]
[2026-01-08 15:20:38,214][103907] Fps is (10 sec: 3257.5, 60 sec: 3001.4, 300 sec: 3195.7). Total num frames: 2392064. Throughput: 0: 2948.7. Samples: 2385920. Policy #0 lag: (min: 5.0, avg: 8.0, max: 69.0)
[2026-01-08 15:20:38,214][103907] Avg episode reward: [(0, '450.961')]
[2026-01-08 15:20:43,193][103907] Fps is (10 sec: 3292.2, 60 sec: 3006.8, 300 sec: 3194.7). Total num frames: 2408448. Throughput: 0: 2971.8. Samples: 2405376. Policy #0 lag: (min: 5.0, avg: 8.0, max: 69.0)
[2026-01-08 15:20:43,194][103907] Avg episode reward: [(0, '461.456')]
[2026-01-08 15:20:43,322][103907] Saving new best policy, reward=461.456!
[2026-01-08 15:20:48,156][103907] Fps is (10 sec: 3295.8, 60 sec: 3005.2, 300 sec: 3197.4). Total num frames: 2424832. Throughput: 0: 3046.5. Samples: 2425856. Policy #0 lag: (min: 4.0, avg: 7.0, max: 68.0)
[2026-01-08 15:20:48,157][103907] Avg episode reward: [(0, '460.742')]
[2026-01-08 15:20:53,170][103907] Fps is (10 sec: 3284.6, 60 sec: 3016.1, 300 sec: 3221.7). Total num frames: 2441216. Throughput: 0: 3074.8. Samples: 2435584. Policy #0 lag: (min: 4.0, avg: 7.0, max: 68.0)
[2026-01-08 15:20:53,170][103907] Avg episode reward: [(0, '464.008')]
[2026-01-08 15:20:53,314][103907] Saving new best policy, reward=464.008!
[2026-01-08 15:20:58,188][103907] Fps is (10 sec: 3266.5, 60 sec: 3278.9, 300 sec: 3221.6). Total num frames: 2457600. Throughput: 0: 3125.5. Samples: 2456064. Policy #0 lag: (min: 6.0, avg: 9.0, max: 70.0)
[2026-01-08 15:20:58,188][103907] Avg episode reward: [(0, '473.769')]
[2026-01-08 15:20:58,331][103907] Saving new best policy, reward=473.769!
[2026-01-08 15:21:01,606][103907] Signal inference workers to stop experience collection... (450 times)
[2026-01-08 15:21:01,982][103907] InferenceWorker_p0-w0: stopping experience collection (450 times)
[2026-01-08 15:21:01,984][103907] Signal inference workers to resume experience collection... (450 times)
[2026-01-08 15:21:02,114][103907] InferenceWorker_p0-w0: resuming experience collection (450 times)
[2026-01-08 15:21:03,170][103907] Fps is (10 sec: 3276.6, 60 sec: 3283.1, 300 sec: 3221.1). Total num frames: 2473984. Throughput: 0: 3155.7. Samples: 2475008. Policy #0 lag: (min: 6.0, avg: 9.0, max: 70.0)
[2026-01-08 15:21:03,171][103907] Avg episode reward: [(0, '479.533')]
[2026-01-08 15:21:03,308][103907] Saving new best policy, reward=479.533!
[2026-01-08 15:21:08,186][103907] Fps is (10 sec: 3277.4, 60 sec: 3278.2, 300 sec: 3196.5). Total num frames: 2490368. Throughput: 0: 3188.1. Samples: 2486272. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:21:08,186][103907] Avg episode reward: [(0, '497.135')]
[2026-01-08 15:21:08,328][103907] Saving new best policy, reward=497.135!
[2026-01-08 15:21:13,171][103907] Fps is (10 sec: 3276.6, 60 sec: 3275.1, 300 sec: 3194.9). Total num frames: 2506752. Throughput: 0: 3252.9. Samples: 2506752. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:21:13,171][103907] Avg episode reward: [(0, '505.073')]
[2026-01-08 15:21:13,322][103907] Saving new best policy, reward=505.073!
[2026-01-08 15:21:18,205][103907] Fps is (10 sec: 3270.7, 60 sec: 3278.1, 300 sec: 3193.1). Total num frames: 2523136. Throughput: 0: 3313.5. Samples: 2525696. Policy #0 lag: (min: 0.0, avg: 3.0, max: 64.0)
[2026-01-08 15:21:18,205][103907] Avg episode reward: [(0, '510.586')]
[2026-01-08 15:21:18,344][103907] Saving new best policy, reward=510.586!
[2026-01-08 15:21:23,151][103907] Fps is (10 sec: 3283.4, 60 sec: 3280.5, 300 sec: 3167.8). Total num frames: 2539520. Throughput: 0: 3361.1. Samples: 2536960. Policy #0 lag: (min: 0.0, avg: 3.0, max: 64.0)
[2026-01-08 15:21:23,151][103907] Avg episode reward: [(0, '514.325')]
[2026-01-08 15:21:23,298][103907] Saving new best policy, reward=514.325!
[2026-01-08 15:21:28,154][103907] Fps is (10 sec: 3293.5, 60 sec: 3276.8, 300 sec: 3165.8). Total num frames: 2555904. Throughput: 0: 3370.8. Samples: 2556928. Policy #0 lag: (min: 3.0, avg: 6.0, max: 67.0)
[2026-01-08 15:21:28,154][103907] Avg episode reward: [(0, '515.630')]
[2026-01-08 15:21:28,289][103907] Saving new best policy, reward=515.630!
[2026-01-08 15:21:33,154][103907] Fps is (10 sec: 3275.7, 60 sec: 3281.5, 300 sec: 3168.1). Total num frames: 2572288. Throughput: 0: 3345.2. Samples: 2576384. Policy #0 lag: (min: 3.0, avg: 6.0, max: 67.0)
[2026-01-08 15:21:33,155][103907] Avg episode reward: [(0, '515.622')]
[2026-01-08 15:21:38,260][103907] Fps is (10 sec: 3242.3, 60 sec: 3274.3, 300 sec: 3196.1). Total num frames: 2588672. Throughput: 0: 3372.4. Samples: 2587648. Policy #0 lag: (min: 1.0, avg: 4.0, max: 65.0)
[2026-01-08 15:21:38,261][103907] Avg episode reward: [(0, '510.529')]
[2026-01-08 15:21:43,268][103907] Fps is (10 sec: 3240.0, 60 sec: 3272.7, 300 sec: 3220.1). Total num frames: 2605056. Throughput: 0: 3327.8. Samples: 2606080. Policy #0 lag: (min: 1.0, avg: 4.0, max: 65.0)
[2026-01-08 15:21:43,268][103907] Avg episode reward: [(0, '505.761')]
[2026-01-08 15:21:48,142][103907] Fps is (10 sec: 3315.9, 60 sec: 3277.6, 300 sec: 3222.1). Total num frames: 2621440. Throughput: 0: 3392.7. Samples: 2627584. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:21:48,143][103907] Avg episode reward: [(0, '502.460')]
[2026-01-08 15:21:53,243][103907] Fps is (10 sec: 3284.9, 60 sec: 3272.8, 300 sec: 3220.4). Total num frames: 2637824. Throughput: 0: 3374.9. Samples: 2638336. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:21:53,243][103907] Avg episode reward: [(0, '492.886')]
[2026-01-08 15:21:53,391][103907] Saving /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_lidar_policy1_acc_08012026/checkpoint_p0/checkpoint_000010304_2637824.pth...
[2026-01-08 15:21:53,396][103907] Removing /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_lidar_policy1_acc_08012026/checkpoint_p0/checkpoint_000007360_1884160.pth
[2026-01-08 15:21:58,241][103907] Fps is (10 sec: 3244.9, 60 sec: 3273.9, 300 sec: 3220.4). Total num frames: 2654208. Throughput: 0: 3339.9. Samples: 2657280. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:21:58,241][103907] Avg episode reward: [(0, '490.247')]
[2026-01-08 15:22:03,197][103907] Fps is (10 sec: 3292.0, 60 sec: 3275.3, 300 sec: 3221.1). Total num frames: 2670592. Throughput: 0: 3391.2. Samples: 2678272. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:22:03,197][103907] Avg episode reward: [(0, '498.189')]
[2026-01-08 15:22:08,210][103907] Fps is (10 sec: 3287.0, 60 sec: 3275.5, 300 sec: 3221.2). Total num frames: 2686976. Throughput: 0: 3352.1. Samples: 2688000. Policy #0 lag: (min: 4.0, avg: 7.0, max: 68.0)
[2026-01-08 15:22:08,210][103907] Avg episode reward: [(0, '510.187')]
[2026-01-08 15:22:13,188][103907] Fps is (10 sec: 3279.8, 60 sec: 3275.9, 300 sec: 3221.2). Total num frames: 2703360. Throughput: 0: 3365.3. Samples: 2708480. Policy #0 lag: (min: 4.0, avg: 7.0, max: 68.0)
[2026-01-08 15:22:13,188][103907] Avg episode reward: [(0, '529.275')]
[2026-01-08 15:22:13,324][103907] Saving new best policy, reward=529.275!
[2026-01-08 15:22:18,213][103907] Fps is (10 sec: 3275.7, 60 sec: 3276.3, 300 sec: 3220.6). Total num frames: 2719744. Throughput: 0: 3386.1. Samples: 2728960. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:22:18,213][103907] Avg episode reward: [(0, '539.435')]
[2026-01-08 15:22:18,351][103907] Saving new best policy, reward=539.435!
[2026-01-08 15:22:19,834][103907] Signal inference workers to stop experience collection... (500 times)
[2026-01-08 15:22:20,217][103907] InferenceWorker_p0-w0: stopping experience collection (500 times)
[2026-01-08 15:22:20,217][103907] Signal inference workers to resume experience collection... (500 times)
[2026-01-08 15:22:20,217][103907] InferenceWorker_p0-w0: resuming experience collection (500 times)
[2026-01-08 15:22:23,262][103907] Fps is (10 sec: 3252.5, 60 sec: 3270.7, 300 sec: 3220.5). Total num frames: 2736128. Throughput: 0: 3322.2. Samples: 2737152. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:22:23,263][103907] Avg episode reward: [(0, '547.349')]
[2026-01-08 15:22:23,429][103907] Saving new best policy, reward=547.349!
[2026-01-08 15:22:28,241][103907] Fps is (10 sec: 3267.6, 60 sec: 3272.0, 300 sec: 3220.4). Total num frames: 2752512. Throughput: 0: 3312.9. Samples: 2755072. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:22:28,242][103907] Avg episode reward: [(0, '542.949')]
[2026-01-08 15:22:33,168][103907] Fps is (10 sec: 3308.0, 60 sec: 3276.0, 300 sec: 3220.9). Total num frames: 2768896. Throughput: 0: 3229.4. Samples: 2772992. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:22:33,168][103907] Avg episode reward: [(0, '554.735')]
[2026-01-08 15:22:33,340][103907] Saving new best policy, reward=554.735!
[2026-01-08 15:22:38,275][103907] Fps is (10 sec: 3265.7, 60 sec: 3276.0, 300 sec: 3220.7). Total num frames: 2785280. Throughput: 0: 3206.2. Samples: 2782720. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:22:38,276][103907] Avg episode reward: [(0, '557.589')]
[2026-01-08 15:22:38,435][103907] Saving new best policy, reward=557.589!
[2026-01-08 15:22:43,200][103907] Fps is (10 sec: 3266.4, 60 sec: 3280.5, 300 sec: 3221.9). Total num frames: 2801664. Throughput: 0: 3188.7. Samples: 2800640. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:22:43,200][103907] Avg episode reward: [(0, '556.728')]
[2026-01-08 15:22:48,142][103907] Fps is (10 sec: 3320.9, 60 sec: 3276.8, 300 sec: 3197.2). Total num frames: 2818048. Throughput: 0: 3109.9. Samples: 2818048. Policy #0 lag: (min: 11.0, avg: 14.0, max: 75.0)
[2026-01-08 15:22:48,143][103907] Avg episode reward: [(0, '553.580')]
[2026-01-08 15:22:53,215][103907] Fps is (10 sec: 3271.7, 60 sec: 3278.3, 300 sec: 3195.0). Total num frames: 2834432. Throughput: 0: 3094.4. Samples: 2827264. Policy #0 lag: (min: 11.0, avg: 14.0, max: 75.0)
[2026-01-08 15:22:53,216][103907] Avg episode reward: [(0, '545.229')]
[2026-01-08 15:22:58,254][103907] Fps is (10 sec: 3240.8, 60 sec: 3276.1, 300 sec: 3193.1). Total num frames: 2850816. Throughput: 0: 3090.2. Samples: 2847744. Policy #0 lag: (min: 1.0, avg: 4.0, max: 65.0)
[2026-01-08 15:22:58,254][103907] Avg episode reward: [(0, '549.461')]
[2026-01-08 15:23:03,208][103907] Fps is (10 sec: 3279.1, 60 sec: 3276.2, 300 sec: 3168.2). Total num frames: 2867200. Throughput: 0: 3095.1. Samples: 2868224. Policy #0 lag: (min: 1.0, avg: 4.0, max: 65.0)
[2026-01-08 15:23:03,209][103907] Avg episode reward: [(0, '548.085')]
[2026-01-08 15:23:08,240][103907] Fps is (10 sec: 3281.3, 60 sec: 3275.2, 300 sec: 3165.8). Total num frames: 2883584. Throughput: 0: 3130.5. Samples: 2877952. Policy #0 lag: (min: 4.0, avg: 7.0, max: 68.0)
[2026-01-08 15:23:08,240][103907] Avg episode reward: [(0, '552.010')]
[2026-01-08 15:23:13,157][103907] Fps is (10 sec: 3293.9, 60 sec: 3278.5, 300 sec: 3195.0). Total num frames: 2899968. Throughput: 0: 3180.4. Samples: 2897920. Policy #0 lag: (min: 4.0, avg: 7.0, max: 68.0)
[2026-01-08 15:23:13,157][103907] Avg episode reward: [(0, '564.654')]
[2026-01-08 15:23:13,304][103907] Saving new best policy, reward=564.654!
[2026-01-08 15:23:18,144][103907] Fps is (10 sec: 3308.4, 60 sec: 3280.6, 300 sec: 3221.2). Total num frames: 2916352. Throughput: 0: 3210.2. Samples: 2917376. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:23:18,144][103907] Avg episode reward: [(0, '583.910')]
[2026-01-08 15:23:18,283][103907] Saving new best policy, reward=583.910!
[2026-01-08 15:23:23,160][103907] Fps is (10 sec: 3275.8, 60 sec: 3282.4, 300 sec: 3221.8). Total num frames: 2932736. Throughput: 0: 3239.6. Samples: 2928128. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:23:23,160][103907] Avg episode reward: [(0, '594.716')]
[2026-01-08 15:23:23,304][103907] Saving new best policy, reward=594.716!
[2026-01-08 15:23:28,169][103907] Fps is (10 sec: 3268.6, 60 sec: 3280.7, 300 sec: 3222.3). Total num frames: 2949120. Throughput: 0: 3290.4. Samples: 2948608. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:23:28,170][103907] Avg episode reward: [(0, '602.217')]
[2026-01-08 15:23:28,311][103907] Saving new best policy, reward=602.217!
[2026-01-08 15:23:33,193][103907] Fps is (10 sec: 3265.8, 60 sec: 3275.4, 300 sec: 3220.6). Total num frames: 2965504. Throughput: 0: 3318.6. Samples: 2967552. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:23:33,194][103907] Avg episode reward: [(0, '607.585')]
[2026-01-08 15:23:33,335][103907] Saving new best policy, reward=607.585!
[2026-01-08 15:23:38,192][103907] Fps is (10 sec: 3269.2, 60 sec: 3281.3, 300 sec: 3221.9). Total num frames: 2981888. Throughput: 0: 3369.5. Samples: 2978816. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:23:38,193][103907] Avg episode reward: [(0, '598.275')]
[2026-01-08 15:23:43,197][103907] Fps is (10 sec: 3275.5, 60 sec: 3276.9, 300 sec: 3220.7). Total num frames: 2998272. Throughput: 0: 3372.0. Samples: 2999296. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:23:43,197][103907] Avg episode reward: [(0, '608.200')]
[2026-01-08 15:23:43,340][103907] Saving new best policy, reward=608.200!
[2026-01-08 15:23:46,325][103907] Signal inference workers to stop experience collection... (550 times)
[2026-01-08 15:23:46,331][103907] Signal inference workers to resume experience collection... (550 times)
[2026-01-08 15:23:46,587][103907] InferenceWorker_p0-w0: stopping experience collection (550 times)
[2026-01-08 15:23:46,588][103907] InferenceWorker_p0-w0: resuming experience collection (550 times)
[2026-01-08 15:23:48,220][103907] Fps is (10 sec: 3267.7, 60 sec: 3272.6, 300 sec: 3220.9). Total num frames: 3014656. Throughput: 0: 3332.8. Samples: 3018240. Policy #0 lag: (min: 11.0, avg: 14.0, max: 75.0)
[2026-01-08 15:23:48,221][103907] Avg episode reward: [(0, '607.405')]
[2026-01-08 15:23:53,191][103907] Fps is (10 sec: 3278.9, 60 sec: 3278.1, 300 sec: 3221.3). Total num frames: 3031040. Throughput: 0: 3371.5. Samples: 3029504. Policy #0 lag: (min: 11.0, avg: 14.0, max: 75.0)
[2026-01-08 15:23:53,191][103907] Avg episode reward: [(0, '606.495')]
[2026-01-08 15:23:53,338][103907] Saving /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_lidar_policy1_acc_08012026/checkpoint_p0/checkpoint_000011840_3031040.pth...
[2026-01-08 15:23:53,341][103907] Removing /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_lidar_policy1_acc_08012026/checkpoint_p0/checkpoint_000008832_2260992.pth
[2026-01-08 15:23:58,212][103907] Fps is (10 sec: 3279.6, 60 sec: 3279.1, 300 sec: 3221.1). Total num frames: 3047424. Throughput: 0: 3341.0. Samples: 3048448. Policy #0 lag: (min: 5.0, avg: 8.0, max: 69.0)
[2026-01-08 15:23:58,212][103907] Avg episode reward: [(0, '603.223')]
[2026-01-08 15:24:03,136][103907] Fps is (10 sec: 3294.8, 60 sec: 3280.8, 300 sec: 3221.5). Total num frames: 3063808. Throughput: 0: 3368.4. Samples: 3068928. Policy #0 lag: (min: 5.0, avg: 8.0, max: 69.0)
[2026-01-08 15:24:03,136][103907] Avg episode reward: [(0, '592.471')]
[2026-01-08 15:24:08,214][103907] Fps is (10 sec: 3276.1, 60 sec: 3278.2, 300 sec: 3221.3). Total num frames: 3080192. Throughput: 0: 3352.4. Samples: 3079168. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:24:08,214][103907] Avg episode reward: [(0, '601.490')]
[2026-01-08 15:24:13,164][103907] Fps is (10 sec: 3267.5, 60 sec: 3276.4, 300 sec: 3221.3). Total num frames: 3096576. Throughput: 0: 3299.9. Samples: 3097088. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:24:13,165][103907] Avg episode reward: [(0, '604.451')]
[2026-01-08 15:24:18,283][103907] Fps is (10 sec: 3254.4, 60 sec: 3269.2, 300 sec: 3220.9). Total num frames: 3112960. Throughput: 0: 3247.6. Samples: 3113984. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:24:18,283][103907] Avg episode reward: [(0, '598.512')]
[2026-01-08 15:24:23,193][103907] Fps is (10 sec: 3267.6, 60 sec: 3275.0, 300 sec: 3221.5). Total num frames: 3129344. Throughput: 0: 3197.1. Samples: 3122688. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:24:23,193][103907] Avg episode reward: [(0, '598.946')]
[2026-01-08 15:24:28,452][103907] Fps is (10 sec: 2416.8, 60 sec: 3125.6, 300 sec: 3190.7). Total num frames: 3137536. Throughput: 0: 3122.6. Samples: 3140608. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:24:28,452][103907] Avg episode reward: [(0, '611.910')]
[2026-01-08 15:24:28,856][103907] Saving new best policy, reward=611.910!
[2026-01-08 15:24:33,278][103907] Fps is (10 sec: 1624.4, 60 sec: 2999.5, 300 sec: 3164.5). Total num frames: 3145728. Throughput: 0: 3090.8. Samples: 3157504. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:24:33,279][103907] Avg episode reward: [(0, '624.357')]
[2026-01-08 15:24:33,451][103907] Saving new best policy, reward=624.357!
[2026-01-08 15:24:38,255][103907] Fps is (10 sec: 2506.9, 60 sec: 3000.6, 300 sec: 3165.7). Total num frames: 3162112. Throughput: 0: 3022.2. Samples: 3165696. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:24:38,255][103907] Avg episode reward: [(0, '643.986')]
[2026-01-08 15:24:38,414][103907] Saving new best policy, reward=643.986!
[2026-01-08 15:24:43,199][103907] Fps is (10 sec: 3303.1, 60 sec: 3003.7, 300 sec: 3165.6). Total num frames: 3178496. Throughput: 0: 3004.6. Samples: 3183616. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:24:43,199][103907] Avg episode reward: [(0, '651.024')]
[2026-01-08 15:24:43,359][103907] Saving new best policy, reward=651.024!
[2026-01-08 15:24:48,284][103907] Fps is (10 sec: 3267.3, 60 sec: 3000.5, 300 sec: 3167.1). Total num frames: 3194880. Throughput: 0: 2925.8. Samples: 3201024. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:24:48,284][103907] Avg episode reward: [(0, '651.549')]
[2026-01-08 15:24:48,287][103907] Saving new best policy, reward=651.549!
[2026-01-08 15:24:53,251][103907] Fps is (10 sec: 3259.9, 60 sec: 3000.7, 300 sec: 3221.0). Total num frames: 3211264. Throughput: 0: 2921.7. Samples: 3210752. Policy #0 lag: (min: 9.0, avg: 12.0, max: 73.0)
[2026-01-08 15:24:53,251][103907] Avg episode reward: [(0, '650.316')]
[2026-01-08 15:24:58,155][103907] Fps is (10 sec: 3319.6, 60 sec: 3006.6, 300 sec: 3222.7). Total num frames: 3227648. Throughput: 0: 2924.7. Samples: 3228672. Policy #0 lag: (min: 9.0, avg: 12.0, max: 73.0)
[2026-01-08 15:24:58,156][103907] Avg episode reward: [(0, '645.700')]
[2026-01-08 15:25:03,280][103907] Fps is (10 sec: 3267.2, 60 sec: 2996.5, 300 sec: 3220.5). Total num frames: 3244032. Throughput: 0: 2912.9. Samples: 3245056. Policy #0 lag: (min: 8.0, avg: 11.0, max: 72.0)
[2026-01-08 15:25:03,280][103907] Avg episode reward: [(0, '653.269')]
[2026-01-08 15:25:03,454][103907] Saving new best policy, reward=653.269!
[2026-01-08 15:25:08,245][103907] Fps is (10 sec: 3247.6, 60 sec: 3002.2, 300 sec: 3220.1). Total num frames: 3260416. Throughput: 0: 2920.7. Samples: 3254272. Policy #0 lag: (min: 8.0, avg: 11.0, max: 72.0)
[2026-01-08 15:25:08,246][103907] Avg episode reward: [(0, '653.675')]
[2026-01-08 15:25:08,413][103907] Saving new best policy, reward=653.675!
[2026-01-08 15:25:13,231][103907] Fps is (10 sec: 3292.9, 60 sec: 3000.4, 300 sec: 3221.2). Total num frames: 3276800. Throughput: 0: 2961.4. Samples: 3273216. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:25:13,231][103907] Avg episode reward: [(0, '650.501')]
[2026-01-08 15:25:17,188][103907] Signal inference workers to stop experience collection... (600 times)
[2026-01-08 15:25:17,556][103907] InferenceWorker_p0-w0: stopping experience collection (600 times)
[2026-01-08 15:25:17,559][103907] Signal inference workers to resume experience collection... (600 times)
[2026-01-08 15:25:17,698][103907] InferenceWorker_p0-w0: resuming experience collection (600 times)
[2026-01-08 15:25:18,192][103907] Fps is (10 sec: 3294.5, 60 sec: 3008.3, 300 sec: 3221.6). Total num frames: 3293184. Throughput: 0: 3032.3. Samples: 3293696. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:25:18,192][103907] Avg episode reward: [(0, '638.139')]
[2026-01-08 15:25:23,187][103907] Fps is (10 sec: 3291.3, 60 sec: 3004.0, 300 sec: 3220.9). Total num frames: 3309568. Throughput: 0: 3065.3. Samples: 3303424. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:25:23,187][103907] Avg episode reward: [(0, '632.335')]
[2026-01-08 15:25:28,240][103907] Fps is (10 sec: 3261.1, 60 sec: 3151.4, 300 sec: 3221.3). Total num frames: 3325952. Throughput: 0: 3114.7. Samples: 3323904. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:25:28,240][103907] Avg episode reward: [(0, '641.013')]
[2026-01-08 15:25:33,224][103907] Fps is (10 sec: 3264.8, 60 sec: 3279.8, 300 sec: 3221.2). Total num frames: 3342336. Throughput: 0: 3167.3. Samples: 3343360. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:25:33,224][103907] Avg episode reward: [(0, '646.005')]
[2026-01-08 15:25:38,146][103907] Fps is (10 sec: 3307.7, 60 sec: 3282.7, 300 sec: 3221.8). Total num frames: 3358720. Throughput: 0: 3181.8. Samples: 3353600. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:25:38,147][103907] Avg episode reward: [(0, '669.437')]
[2026-01-08 15:25:38,283][103907] Saving new best policy, reward=669.437!
[2026-01-08 15:25:43,176][103907] Fps is (10 sec: 3292.7, 60 sec: 3278.1, 300 sec: 3221.1). Total num frames: 3375104. Throughput: 0: 3229.8. Samples: 3374080. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:25:43,176][103907] Avg episode reward: [(0, '676.136')]
[2026-01-08 15:25:43,321][103907] Saving new best policy, reward=676.136!
[2026-01-08 15:25:48,163][103907] Fps is (10 sec: 3271.5, 60 sec: 3283.5, 300 sec: 3221.3). Total num frames: 3391488. Throughput: 0: 3285.4. Samples: 3392512. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:25:48,163][103907] Avg episode reward: [(0, '682.867')]
[2026-01-08 15:25:48,311][103907] Saving new best policy, reward=682.867!
[2026-01-08 15:25:53,203][103907] Fps is (10 sec: 3267.9, 60 sec: 3279.4, 300 sec: 3221.1). Total num frames: 3407872. Throughput: 0: 3336.8. Samples: 3404288. Policy #0 lag: (min: 31.0, avg: 34.0, max: 95.0)
[2026-01-08 15:25:53,203][103907] Avg episode reward: [(0, '684.243')]
[2026-01-08 15:25:53,347][103907] Saving /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_lidar_policy1_acc_08012026/checkpoint_p0/checkpoint_000013312_3407872.pth...
[2026-01-08 15:25:53,353][103907] Removing /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_lidar_policy1_acc_08012026/checkpoint_p0/checkpoint_000010304_2637824.pth
[2026-01-08 15:25:53,353][103907] Saving new best policy, reward=684.243!
[2026-01-08 15:25:58,243][103907] Fps is (10 sec: 3250.7, 60 sec: 3272.0, 300 sec: 3220.5). Total num frames: 3424256. Throughput: 0: 3366.9. Samples: 3424768. Policy #0 lag: (min: 31.0, avg: 34.0, max: 95.0)
[2026-01-08 15:25:58,243][103907] Avg episode reward: [(0, '686.235')]
[2026-01-08 15:25:58,382][103907] Saving new best policy, reward=686.235!
[2026-01-08 15:26:03,253][103907] Fps is (10 sec: 3260.6, 60 sec: 3278.3, 300 sec: 3220.5). Total num frames: 3440640. Throughput: 0: 3317.8. Samples: 3443200. Policy #0 lag: (min: 47.0, avg: 50.0, max: 111.0)
[2026-01-08 15:26:03,253][103907] Avg episode reward: [(0, '688.079')]
[2026-01-08 15:26:03,394][103907] Saving new best policy, reward=688.079!
[2026-01-08 15:26:08,217][103907] Fps is (10 sec: 3285.4, 60 sec: 3278.4, 300 sec: 3220.8). Total num frames: 3457024. Throughput: 0: 3354.2. Samples: 3454464. Policy #0 lag: (min: 47.0, avg: 50.0, max: 111.0)
[2026-01-08 15:26:08,217][103907] Avg episode reward: [(0, '681.767')]
[2026-01-08 15:26:13,245][103907] Fps is (10 sec: 3279.1, 60 sec: 3276.0, 300 sec: 3220.8). Total num frames: 3473408. Throughput: 0: 3344.7. Samples: 3474432. Policy #0 lag: (min: 47.0, avg: 50.0, max: 111.0)
[2026-01-08 15:26:13,246][103907] Avg episode reward: [(0, '684.111')]
[2026-01-08 15:26:18,144][103907] Fps is (10 sec: 3300.8, 60 sec: 3279.4, 300 sec: 3221.3). Total num frames: 3489792. Throughput: 0: 3351.0. Samples: 3493888. Policy #0 lag: (min: 0.0, avg: 3.0, max: 64.0)
[2026-01-08 15:26:18,144][103907] Avg episode reward: [(0, '689.922')]
[2026-01-08 15:26:18,284][103907] Saving new best policy, reward=689.922!
[2026-01-08 15:26:23,167][103907] Fps is (10 sec: 3302.6, 60 sec: 3277.9, 300 sec: 3221.1). Total num frames: 3506176. Throughput: 0: 3366.3. Samples: 3505152. Policy #0 lag: (min: 0.0, avg: 3.0, max: 64.0)
[2026-01-08 15:26:23,167][103907] Avg episode reward: [(0, '691.472')]
[2026-01-08 15:26:23,316][103907] Saving new best policy, reward=691.472!
[2026-01-08 15:26:28,187][103907] Fps is (10 sec: 3262.8, 60 sec: 3279.7, 300 sec: 3220.9). Total num frames: 3522560. Throughput: 0: 3321.5. Samples: 3523584. Policy #0 lag: (min: 40.0, avg: 43.0, max: 104.0)
[2026-01-08 15:26:28,187][103907] Avg episode reward: [(0, '694.778')]
[2026-01-08 15:26:28,320][103907] Saving new best policy, reward=694.778!
[2026-01-08 15:26:33,231][103907] Fps is (10 sec: 3256.1, 60 sec: 3276.4, 300 sec: 3221.6). Total num frames: 3538944. Throughput: 0: 3362.7. Samples: 3544064. Policy #0 lag: (min: 40.0, avg: 43.0, max: 104.0)
[2026-01-08 15:26:33,231][103907] Avg episode reward: [(0, '698.167')]
[2026-01-08 15:26:33,392][103907] Saving new best policy, reward=698.167!
[2026-01-08 15:26:36,402][103907] Signal inference workers to stop experience collection... (650 times)
[2026-01-08 15:26:36,794][103907] InferenceWorker_p0-w0: stopping experience collection (650 times)
[2026-01-08 15:26:36,794][103907] Signal inference workers to resume experience collection... (650 times)
[2026-01-08 15:26:36,794][103907] InferenceWorker_p0-w0: resuming experience collection (650 times)
[2026-01-08 15:26:38,163][103907] Fps is (10 sec: 3284.6, 60 sec: 3275.9, 300 sec: 3222.4). Total num frames: 3555328. Throughput: 0: 3313.8. Samples: 3553280. Policy #0 lag: (min: 11.0, avg: 14.0, max: 75.0)
[2026-01-08 15:26:38,164][103907] Avg episode reward: [(0, '704.062')]
[2026-01-08 15:26:38,309][103907] Saving new best policy, reward=704.062!
[2026-01-08 15:26:43,159][103907] Fps is (10 sec: 3300.5, 60 sec: 3277.7, 300 sec: 3221.1). Total num frames: 3571712. Throughput: 0: 3294.3. Samples: 3572736. Policy #0 lag: (min: 11.0, avg: 14.0, max: 75.0)
[2026-01-08 15:26:43,159][103907] Avg episode reward: [(0, '707.634')]
[2026-01-08 15:26:43,317][103907] Saving new best policy, reward=707.634!
[2026-01-08 15:26:48,137][103907] Fps is (10 sec: 3285.6, 60 sec: 3278.2, 300 sec: 3222.4). Total num frames: 3588096. Throughput: 0: 3308.1. Samples: 3591680. Policy #0 lag: (min: 47.0, avg: 50.0, max: 111.0)
[2026-01-08 15:26:48,137][103907] Avg episode reward: [(0, '697.758')]
[2026-01-08 15:26:53,244][103907] Fps is (10 sec: 3249.1, 60 sec: 3274.6, 300 sec: 3221.2). Total num frames: 3604480. Throughput: 0: 3286.2. Samples: 3602432. Policy #0 lag: (min: 47.0, avg: 50.0, max: 111.0)
[2026-01-08 15:26:53,244][103907] Avg episode reward: [(0, '718.143')]
[2026-01-08 15:26:53,399][103907] Saving new best policy, reward=718.143!
[2026-01-08 15:26:58,188][103907] Fps is (10 sec: 3260.2, 60 sec: 3279.8, 300 sec: 3221.4). Total num frames: 3620864. Throughput: 0: 3281.0. Samples: 3621888. Policy #0 lag: (min: 47.0, avg: 50.0, max: 111.0)
[2026-01-08 15:26:58,188][103907] Avg episode reward: [(0, '729.784')]
[2026-01-08 15:26:58,336][103907] Saving new best policy, reward=729.784!
[2026-01-08 15:27:03,192][103907] Fps is (10 sec: 3293.9, 60 sec: 3280.1, 300 sec: 3221.5). Total num frames: 3637248. Throughput: 0: 3273.3. Samples: 3641344. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:27:03,192][103907] Avg episode reward: [(0, '752.333')]
[2026-01-08 15:27:03,335][103907] Saving new best policy, reward=752.333!
[2026-01-08 15:27:08,135][103907] Fps is (10 sec: 3294.0, 60 sec: 3281.3, 300 sec: 3221.8). Total num frames: 3653632. Throughput: 0: 3279.1. Samples: 3652608. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:27:08,136][103907] Avg episode reward: [(0, '757.821')]
[2026-01-08 15:27:08,289][103907] Saving new best policy, reward=757.821!
[2026-01-08 15:27:13,152][103907] Fps is (10 sec: 3289.9, 60 sec: 3281.9, 300 sec: 3221.9). Total num frames: 3670016. Throughput: 0: 3279.3. Samples: 3671040. Policy #0 lag: (min: 63.0, avg: 66.0, max: 127.0)
[2026-01-08 15:27:13,152][103907] Avg episode reward: [(0, '765.258')]
[2026-01-08 15:27:13,294][103907] Saving new best policy, reward=765.258!
[2026-01-08 15:27:18,199][103907] Fps is (10 sec: 3256.2, 60 sec: 3273.8, 300 sec: 3222.0). Total num frames: 3686400. Throughput: 0: 3267.8. Samples: 3691008. Policy #0 lag: (min: 63.0, avg: 66.0, max: 127.0)
[2026-01-08 15:27:18,199][103907] Avg episode reward: [(0, '778.434')]
[2026-01-08 15:27:18,344][103907] Saving new best policy, reward=778.434!
[2026-01-08 15:27:23,217][103907] Fps is (10 sec: 3255.8, 60 sec: 3274.1, 300 sec: 3221.5). Total num frames: 3702784. Throughput: 0: 3295.7. Samples: 3701760. Policy #0 lag: (min: 63.0, avg: 66.0, max: 127.0)
[2026-01-08 15:27:23,217][103907] Avg episode reward: [(0, '788.588')]
[2026-01-08 15:27:23,367][103907] Saving new best policy, reward=788.588!
[2026-01-08 15:27:28,223][103907] Fps is (10 sec: 3268.9, 60 sec: 3274.8, 300 sec: 3220.7). Total num frames: 3719168. Throughput: 0: 3272.1. Samples: 3720192. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:27:28,223][103907] Avg episode reward: [(0, '774.087')]
[2026-01-08 15:27:33,243][103907] Fps is (10 sec: 3268.3, 60 sec: 3276.1, 300 sec: 3221.6). Total num frames: 3735552. Throughput: 0: 3303.1. Samples: 3740672. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:27:33,243][103907] Avg episode reward: [(0, '767.600')]
[2026-01-08 15:27:38,143][103907] Fps is (10 sec: 3303.0, 60 sec: 3277.9, 300 sec: 3221.9). Total num frames: 3751936. Throughput: 0: 3329.7. Samples: 3751936. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:27:38,144][103907] Avg episode reward: [(0, '761.001')]
[2026-01-08 15:27:43,143][103907] Fps is (10 sec: 3309.9, 60 sec: 3277.7, 300 sec: 3221.3). Total num frames: 3768320. Throughput: 0: 3280.1. Samples: 3769344. Policy #0 lag: (min: 3.0, avg: 6.0, max: 67.0)
[2026-01-08 15:27:43,143][103907] Avg episode reward: [(0, '776.107')]
[2026-01-08 15:27:48,227][103907] Fps is (10 sec: 3249.8, 60 sec: 3271.9, 300 sec: 3221.1). Total num frames: 3784704. Throughput: 0: 3308.4. Samples: 3790336. Policy #0 lag: (min: 3.0, avg: 6.0, max: 67.0)
[2026-01-08 15:27:48,227][103907] Avg episode reward: [(0, '782.569')]
[2026-01-08 15:27:53,197][103907] Fps is (10 sec: 3259.2, 60 sec: 3279.4, 300 sec: 3221.9). Total num frames: 3801088. Throughput: 0: 3295.1. Samples: 3801088. Policy #0 lag: (min: 3.0, avg: 6.0, max: 67.0)
[2026-01-08 15:27:53,197][103907] Avg episode reward: [(0, '789.591')]
[2026-01-08 15:27:53,340][103907] Saving /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_lidar_policy1_acc_08012026/checkpoint_p0/checkpoint_000014848_3801088.pth...
[2026-01-08 15:27:53,343][103907] Removing /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_lidar_policy1_acc_08012026/checkpoint_p0/checkpoint_000011840_3031040.pth
[2026-01-08 15:27:53,344][103907] Saving new best policy, reward=789.591!
[2026-01-08 15:27:58,179][103907] Fps is (10 sec: 3292.6, 60 sec: 3277.3, 300 sec: 3221.6). Total num frames: 3817472. Throughput: 0: 3274.9. Samples: 3818496. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:27:58,179][103907] Avg episode reward: [(0, '809.471')]
[2026-01-08 15:27:58,341][103907] Saving new best policy, reward=809.471!
[2026-01-08 15:28:01,457][103907] Signal inference workers to stop experience collection... (700 times)
[2026-01-08 15:28:01,457][103907] Signal inference workers to resume experience collection... (700 times)
[2026-01-08 15:28:01,734][103907] InferenceWorker_p0-w0: stopping experience collection (700 times)
[2026-01-08 15:28:01,734][103907] InferenceWorker_p0-w0: resuming experience collection (700 times)
[2026-01-08 15:28:03,151][103907] Fps is (10 sec: 3291.8, 60 sec: 3279.0, 300 sec: 3222.2). Total num frames: 3833856. Throughput: 0: 3234.7. Samples: 3836416. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:28:03,151][103907] Avg episode reward: [(0, '808.380')]
[2026-01-08 15:28:08,132][103907] Fps is (10 sec: 3292.2, 60 sec: 3277.0, 300 sec: 3221.5). Total num frames: 3850240. Throughput: 0: 3214.6. Samples: 3846144. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:28:08,132][103907] Avg episode reward: [(0, '807.033')]
[2026-01-08 15:28:13,252][103907] Fps is (10 sec: 3244.1, 60 sec: 3271.4, 300 sec: 3220.1). Total num frames: 3866624. Throughput: 0: 3183.7. Samples: 3863552. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:28:13,252][103907] Avg episode reward: [(0, '808.107')]
[2026-01-08 15:28:18,502][103907] Fps is (10 sec: 2369.9, 60 sec: 3124.5, 300 sec: 3189.8). Total num frames: 3874816. Throughput: 0: 3099.6. Samples: 3880960. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:28:18,502][103907] Avg episode reward: [(0, '792.521')]
[2026-01-08 15:28:23,132][103907] Fps is (10 sec: 1658.3, 60 sec: 3008.0, 300 sec: 3166.1). Total num frames: 3883008. Throughput: 0: 3038.6. Samples: 3888640. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:28:23,132][103907] Avg episode reward: [(0, '807.141')]
[2026-01-08 15:28:28,205][103907] Fps is (10 sec: 2532.8, 60 sec: 3004.6, 300 sec: 3165.6). Total num frames: 3899392. Throughput: 0: 3033.7. Samples: 3906048. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:28:28,205][103907] Avg episode reward: [(0, '814.326')]
[2026-01-08 15:28:28,363][103907] Saving new best policy, reward=814.326!
[2026-01-08 15:28:33,214][103907] Fps is (10 sec: 3250.2, 60 sec: 3005.2, 300 sec: 3165.5). Total num frames: 3915776. Throughput: 0: 2959.1. Samples: 3923456. Policy #0 lag: (min: 4.0, avg: 7.0, max: 68.0)
[2026-01-08 15:28:33,214][103907] Avg episode reward: [(0, '822.000')]
[2026-01-08 15:28:33,385][103907] Saving new best policy, reward=822.000!
[2026-01-08 15:28:38,146][103907] Fps is (10 sec: 3296.4, 60 sec: 3003.6, 300 sec: 3166.3). Total num frames: 3932160. Throughput: 0: 2938.8. Samples: 3933184. Policy #0 lag: (min: 4.0, avg: 7.0, max: 68.0)
[2026-01-08 15:28:38,146][103907] Avg episode reward: [(0, '845.014')]
[2026-01-08 15:28:38,286][103907] Saving new best policy, reward=845.014!
[2026-01-08 15:28:43,182][103907] Fps is (10 sec: 3287.2, 60 sec: 3001.8, 300 sec: 3166.1). Total num frames: 3948544. Throughput: 0: 2958.0. Samples: 3951616. Policy #0 lag: (min: 63.0, avg: 66.0, max: 127.0)
[2026-01-08 15:28:43,182][103907] Avg episode reward: [(0, '846.763')]
[2026-01-08 15:28:43,325][103907] Saving new best policy, reward=846.763!
[2026-01-08 15:28:48,162][103907] Fps is (10 sec: 3271.6, 60 sec: 3007.0, 300 sec: 3166.0). Total num frames: 3964928. Throughput: 0: 3003.0. Samples: 3971584. Policy #0 lag: (min: 63.0, avg: 66.0, max: 127.0)
[2026-01-08 15:28:48,162][103907] Avg episode reward: [(0, '869.608')]
[2026-01-08 15:28:48,308][103907] Saving new best policy, reward=869.608!
[2026-01-08 15:28:53,237][103907] Fps is (10 sec: 3258.8, 60 sec: 3001.7, 300 sec: 3165.4). Total num frames: 3981312. Throughput: 0: 3019.4. Samples: 3982336. Policy #0 lag: (min: 63.0, avg: 66.0, max: 127.0)
[2026-01-08 15:28:53,238][103907] Avg episode reward: [(0, '856.184')]
[2026-01-08 15:28:58,247][103907] Fps is (10 sec: 3249.0, 60 sec: 3000.3, 300 sec: 3164.5). Total num frames: 3997696. Throughput: 0: 3060.9. Samples: 4001280. Policy #0 lag: (min: 4.0, avg: 7.0, max: 68.0)
[2026-01-08 15:28:58,247][103907] Avg episode reward: [(0, '899.729')]
[2026-01-08 15:28:58,391][103907] Saving new best policy, reward=899.729!
[2026-01-08 15:29:03,145][103907] Fps is (10 sec: 3307.5, 60 sec: 3004.1, 300 sec: 3166.5). Total num frames: 4014080. Throughput: 0: 3142.5. Samples: 4021248. Policy #0 lag: (min: 4.0, avg: 7.0, max: 68.0)
[2026-01-08 15:29:03,145][103907] Avg episode reward: [(0, '900.489')]
[2026-01-08 15:29:03,299][103907] Saving new best policy, reward=900.489!
[2026-01-08 15:29:08,156][103907] Fps is (10 sec: 3306.9, 60 sec: 3002.5, 300 sec: 3165.8). Total num frames: 4030464. Throughput: 0: 3172.7. Samples: 4031488. Policy #0 lag: (min: 4.0, avg: 7.0, max: 68.0)
[2026-01-08 15:29:08,157][103907] Avg episode reward: [(0, '926.521')]
[2026-01-08 15:29:08,295][103907] Saving new best policy, reward=926.521!
[2026-01-08 15:29:13,216][103907] Fps is (10 sec: 3253.7, 60 sec: 3005.6, 300 sec: 3166.4). Total num frames: 4046848. Throughput: 0: 3207.8. Samples: 4050432. Policy #0 lag: (min: 3.0, avg: 6.0, max: 67.0)
[2026-01-08 15:29:13,216][103907] Avg episode reward: [(0, '932.371')]
[2026-01-08 15:29:13,366][103907] Saving new best policy, reward=932.371!
[2026-01-08 15:29:18,165][103907] Fps is (10 sec: 3274.1, 60 sec: 3158.0, 300 sec: 3166.0). Total num frames: 4063232. Throughput: 0: 3269.0. Samples: 4070400. Policy #0 lag: (min: 3.0, avg: 6.0, max: 67.0)
[2026-01-08 15:29:18,165][103907] Avg episode reward: [(0, '927.142')]
[2026-01-08 15:29:23,213][103907] Fps is (10 sec: 3277.5, 60 sec: 3272.4, 300 sec: 3196.1). Total num frames: 4079616. Throughput: 0: 3271.9. Samples: 4080640. Policy #0 lag: (min: 3.0, avg: 6.0, max: 67.0)
[2026-01-08 15:29:23,213][103907] Avg episode reward: [(0, '914.366')]
[2026-01-08 15:29:28,185][103907] Fps is (10 sec: 3270.1, 60 sec: 3277.9, 300 sec: 3222.3). Total num frames: 4096000. Throughput: 0: 3299.3. Samples: 4100096. Policy #0 lag: (min: 12.0, avg: 15.0, max: 76.0)
[2026-01-08 15:29:28,185][103907] Avg episode reward: [(0, '906.128')]
[2026-01-08 15:29:29,757][103907] Signal inference workers to stop experience collection... (750 times)
[2026-01-08 15:29:30,135][103907] InferenceWorker_p0-w0: stopping experience collection (750 times)
[2026-01-08 15:29:30,137][103907] Signal inference workers to resume experience collection... (750 times)
[2026-01-08 15:29:30,267][103907] InferenceWorker_p0-w0: resuming experience collection (750 times)
[2026-01-08 15:29:33,180][103907] Fps is (10 sec: 3287.6, 60 sec: 3278.6, 300 sec: 3222.1). Total num frames: 4112384. Throughput: 0: 3298.2. Samples: 4120064. Policy #0 lag: (min: 12.0, avg: 15.0, max: 76.0)
[2026-01-08 15:29:33,181][103907] Avg episode reward: [(0, '898.921')]
[2026-01-08 15:29:38,149][103907] Fps is (10 sec: 3288.7, 60 sec: 3276.6, 300 sec: 3221.8). Total num frames: 4128768. Throughput: 0: 3283.2. Samples: 4129792. Policy #0 lag: (min: 12.0, avg: 15.0, max: 76.0)
[2026-01-08 15:29:38,149][103907] Avg episode reward: [(0, '909.560')]
[2026-01-08 15:29:43,199][103907] Fps is (10 sec: 3270.8, 60 sec: 3275.9, 300 sec: 3222.2). Total num frames: 4145152. Throughput: 0: 3303.1. Samples: 4149760. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:29:43,199][103907] Avg episode reward: [(0, '936.832')]
[2026-01-08 15:29:43,343][103907] Saving new best policy, reward=936.832!
[2026-01-08 15:29:48,254][103907] Fps is (10 sec: 3242.8, 60 sec: 3271.8, 300 sec: 3221.2). Total num frames: 4161536. Throughput: 0: 3302.9. Samples: 4170240. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:29:48,254][103907] Avg episode reward: [(0, '943.853')]
[2026-01-08 15:29:48,388][103907] Saving new best policy, reward=943.853!
[2026-01-08 15:29:53,171][103907] Fps is (10 sec: 3286.0, 60 sec: 3280.4, 300 sec: 3221.1). Total num frames: 4177920. Throughput: 0: 3275.8. Samples: 4178944. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:29:53,171][103907] Avg episode reward: [(0, '937.154')]
[2026-01-08 15:29:53,315][103907] Saving /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_lidar_policy1_acc_08012026/checkpoint_p0/checkpoint_000016320_4177920.pth...
[2026-01-08 15:29:53,319][103907] Removing /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_lidar_policy1_acc_08012026/checkpoint_p0/checkpoint_000013312_3407872.pth
[2026-01-08 15:29:58,139][103907] Fps is (10 sec: 3314.9, 60 sec: 3282.7, 300 sec: 3222.8). Total num frames: 4194304. Throughput: 0: 3316.6. Samples: 4199424. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:29:58,139][103907] Avg episode reward: [(0, '924.923')]
[2026-01-08 15:30:03,195][103907] Fps is (10 sec: 3268.7, 60 sec: 3274.0, 300 sec: 3221.8). Total num frames: 4210688. Throughput: 0: 3320.0. Samples: 4219904. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:30:03,196][103907] Avg episode reward: [(0, '948.823')]
[2026-01-08 15:30:03,339][103907] Saving new best policy, reward=948.823!
[2026-01-08 15:30:08,239][103907] Fps is (10 sec: 3244.3, 60 sec: 3272.3, 300 sec: 3221.2). Total num frames: 4227072. Throughput: 0: 3297.7. Samples: 4229120. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:30:08,239][103907] Avg episode reward: [(0, '969.980')]
[2026-01-08 15:30:08,383][103907] Saving new best policy, reward=969.980!
[2026-01-08 15:30:13,136][103907] Fps is (10 sec: 3296.2, 60 sec: 3281.1, 300 sec: 3221.9). Total num frames: 4243456. Throughput: 0: 3325.9. Samples: 4249600. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:30:13,137][103907] Avg episode reward: [(0, '992.530')]
[2026-01-08 15:30:13,287][103907] Saving new best policy, reward=992.530!
[2026-01-08 15:30:18,203][103907] Fps is (10 sec: 3288.6, 60 sec: 3274.7, 300 sec: 3221.1). Total num frames: 4259840. Throughput: 0: 3309.2. Samples: 4269056. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:30:18,204][103907] Avg episode reward: [(0, '985.516')]
[2026-01-08 15:30:23,195][103907] Fps is (10 sec: 3257.8, 60 sec: 3277.8, 300 sec: 3221.8). Total num frames: 4276224. Throughput: 0: 3296.2. Samples: 4278272. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:30:23,195][103907] Avg episode reward: [(0, '969.273')]
[2026-01-08 15:30:28,269][103907] Fps is (10 sec: 3255.4, 60 sec: 3272.2, 300 sec: 3220.8). Total num frames: 4292608. Throughput: 0: 3305.8. Samples: 4298752. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:30:28,269][103907] Avg episode reward: [(0, '983.590')]
[2026-01-08 15:30:33,135][103907] Fps is (10 sec: 3296.4, 60 sec: 3279.3, 300 sec: 3221.4). Total num frames: 4308992. Throughput: 0: 3296.9. Samples: 4318208. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:30:33,135][103907] Avg episode reward: [(0, '1011.225')]
[2026-01-08 15:30:33,284][103907] Saving new best policy, reward=1011.225!
[2026-01-08 15:30:38,250][103907] Fps is (10 sec: 3283.0, 60 sec: 3271.3, 300 sec: 3220.4). Total num frames: 4325376. Throughput: 0: 3305.1. Samples: 4327936. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:30:38,250][103907] Avg episode reward: [(0, '1023.407')]
[2026-01-08 15:30:38,399][103907] Saving new best policy, reward=1023.407!
[2026-01-08 15:30:43,217][103907] Fps is (10 sec: 3250.2, 60 sec: 3275.8, 300 sec: 3220.7). Total num frames: 4341760. Throughput: 0: 3293.8. Samples: 4347904. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:30:43,217][103907] Avg episode reward: [(0, '1028.425')]
[2026-01-08 15:30:43,361][103907] Saving new best policy, reward=1028.425!
[2026-01-08 15:30:48,158][103907] Fps is (10 sec: 3307.2, 60 sec: 3282.0, 300 sec: 3221.8). Total num frames: 4358144. Throughput: 0: 3290.9. Samples: 4367872. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:30:48,158][103907] Avg episode reward: [(0, '1032.504')]
[2026-01-08 15:30:48,312][103907] Saving new best policy, reward=1032.504!
[2026-01-08 15:30:49,532][103907] Signal inference workers to stop experience collection... (800 times)
[2026-01-08 15:30:49,903][103907] InferenceWorker_p0-w0: stopping experience collection (800 times)
[2026-01-08 15:30:49,903][103907] Signal inference workers to resume experience collection... (800 times)
[2026-01-08 15:30:49,903][103907] InferenceWorker_p0-w0: resuming experience collection (800 times)
[2026-01-08 15:30:53,232][103907] Fps is (10 sec: 3271.7, 60 sec: 3273.4, 300 sec: 3221.4). Total num frames: 4374528. Throughput: 0: 3288.7. Samples: 4377088. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:30:53,233][103907] Avg episode reward: [(0, '1033.942')]
[2026-01-08 15:30:53,382][103907] Saving new best policy, reward=1033.942!
[2026-01-08 15:30:58,178][103907] Fps is (10 sec: 3270.4, 60 sec: 3274.7, 300 sec: 3222.1). Total num frames: 4390912. Throughput: 0: 3285.2. Samples: 4397568. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:30:58,178][103907] Avg episode reward: [(0, '1037.641')]
[2026-01-08 15:30:58,315][103907] Saving new best policy, reward=1037.641!
[2026-01-08 15:31:03,171][103907] Fps is (10 sec: 3297.0, 60 sec: 3278.1, 300 sec: 3221.8). Total num frames: 4407296. Throughput: 0: 3313.3. Samples: 4418048. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:31:03,171][103907] Avg episode reward: [(0, '1058.956')]
[2026-01-08 15:31:03,318][103907] Saving new best policy, reward=1058.956!
[2026-01-08 15:31:08,229][103907] Fps is (10 sec: 3260.2, 60 sec: 3277.4, 300 sec: 3221.4). Total num frames: 4423680. Throughput: 0: 3319.8. Samples: 4427776. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:31:08,229][103907] Avg episode reward: [(0, '1048.329')]
[2026-01-08 15:31:13,216][103907] Fps is (10 sec: 3262.2, 60 sec: 3272.5, 300 sec: 3220.5). Total num frames: 4440064. Throughput: 0: 3314.8. Samples: 4447744. Policy #0 lag: (min: 8.0, avg: 11.0, max: 72.0)
[2026-01-08 15:31:13,216][103907] Avg episode reward: [(0, '1031.698')]
[2026-01-08 15:31:18,252][103907] Fps is (10 sec: 3269.2, 60 sec: 3274.1, 300 sec: 3220.3). Total num frames: 4456448. Throughput: 0: 3325.0. Samples: 4468224. Policy #0 lag: (min: 8.0, avg: 11.0, max: 72.0)
[2026-01-08 15:31:18,252][103907] Avg episode reward: [(0, '1052.042')]
[2026-01-08 15:31:23,205][103907] Fps is (10 sec: 3280.3, 60 sec: 3276.2, 300 sec: 3221.1). Total num frames: 4472832. Throughput: 0: 3325.6. Samples: 4477440. Policy #0 lag: (min: 8.0, avg: 11.0, max: 72.0)
[2026-01-08 15:31:23,205][103907] Avg episode reward: [(0, '1048.694')]
[2026-01-08 15:31:28,171][103907] Fps is (10 sec: 3303.7, 60 sec: 3282.2, 300 sec: 3221.9). Total num frames: 4489216. Throughput: 0: 3325.7. Samples: 4497408. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:31:28,171][103907] Avg episode reward: [(0, '1106.185')]
[2026-01-08 15:31:28,312][103907] Saving new best policy, reward=1106.185!
[2026-01-08 15:31:33,214][103907] Fps is (10 sec: 3273.9, 60 sec: 3272.5, 300 sec: 3220.7). Total num frames: 4505600. Throughput: 0: 3329.6. Samples: 4517888. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:31:33,214][103907] Avg episode reward: [(0, '1120.806')]
[2026-01-08 15:31:33,360][103907] Saving new best policy, reward=1120.806!
[2026-01-08 15:31:38,245][103907] Fps is (10 sec: 3252.7, 60 sec: 3277.1, 300 sec: 3220.3). Total num frames: 4521984. Throughput: 0: 3332.8. Samples: 4527104. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:31:38,245][103907] Avg episode reward: [(0, '1115.608')]
[2026-01-08 15:31:43,258][103907] Fps is (10 sec: 3262.4, 60 sec: 3274.5, 300 sec: 3219.9). Total num frames: 4538368. Throughput: 0: 3282.3. Samples: 4545536. Policy #0 lag: (min: 2.0, avg: 5.0, max: 66.0)
[2026-01-08 15:31:43,258][103907] Avg episode reward: [(0, '1128.820')]
[2026-01-08 15:31:43,420][103907] Saving new best policy, reward=1128.820!
[2026-01-08 15:31:48,250][103907] Fps is (10 sec: 3275.3, 60 sec: 3271.8, 300 sec: 3221.2). Total num frames: 4554752. Throughput: 0: 3214.3. Samples: 4562944. Policy #0 lag: (min: 2.0, avg: 5.0, max: 66.0)
[2026-01-08 15:31:48,250][103907] Avg episode reward: [(0, '1103.267')]
[2026-01-08 15:31:53,193][103907] Fps is (10 sec: 3298.4, 60 sec: 3279.0, 300 sec: 3221.2). Total num frames: 4571136. Throughput: 0: 3211.1. Samples: 4572160. Policy #0 lag: (min: 2.0, avg: 5.0, max: 66.0)
[2026-01-08 15:31:53,193][103907] Avg episode reward: [(0, '1114.593')]
[2026-01-08 15:31:53,363][103907] Saving /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_lidar_policy1_acc_08012026/checkpoint_p0/checkpoint_000017856_4571136.pth...
[2026-01-08 15:31:53,367][103907] Removing /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_lidar_policy1_acc_08012026/checkpoint_p0/checkpoint_000014848_3801088.pth
[2026-01-08 15:31:58,200][103907] Fps is (10 sec: 3293.0, 60 sec: 3275.6, 300 sec: 3221.2). Total num frames: 4587520. Throughput: 0: 3152.7. Samples: 4589568. Policy #0 lag: (min: 6.0, avg: 9.0, max: 70.0)
[2026-01-08 15:31:58,201][103907] Avg episode reward: [(0, '1089.710')]
[2026-01-08 15:32:03,237][103907] Fps is (10 sec: 3262.4, 60 sec: 3273.2, 300 sec: 3220.2). Total num frames: 4603904. Throughput: 0: 3152.7. Samples: 4610048. Policy #0 lag: (min: 6.0, avg: 9.0, max: 70.0)
[2026-01-08 15:32:03,237][103907] Avg episode reward: [(0, '1075.774')]
[2026-01-08 15:32:08,159][103907] Fps is (10 sec: 3290.5, 60 sec: 3280.6, 300 sec: 3221.2). Total num frames: 4620288. Throughput: 0: 3189.1. Samples: 4620800. Policy #0 lag: (min: 6.0, avg: 9.0, max: 70.0)
[2026-01-08 15:32:08,159][103907] Avg episode reward: [(0, '1089.714')]
[2026-01-08 15:32:13,241][103907] Fps is (10 sec: 3275.4, 60 sec: 3275.4, 300 sec: 3220.8). Total num frames: 4636672. Throughput: 0: 3158.1. Samples: 4639744. Policy #0 lag: (min: 3.0, avg: 6.0, max: 67.0)
[2026-01-08 15:32:13,241][103907] Avg episode reward: [(0, '1134.742')]
[2026-01-08 15:32:13,388][103907] Saving new best policy, reward=1134.742!
[2026-01-08 15:32:15,453][103907] Signal inference workers to stop experience collection... (850 times)
[2026-01-08 15:32:15,453][103907] Signal inference workers to resume experience collection... (850 times)
[2026-01-08 15:32:15,712][103907] InferenceWorker_p0-w0: stopping experience collection (850 times)
[2026-01-08 15:32:15,712][103907] InferenceWorker_p0-w0: resuming experience collection (850 times)
[2026-01-08 15:32:18,173][103907] Fps is (10 sec: 3272.0, 60 sec: 3281.1, 300 sec: 3221.7). Total num frames: 4653056. Throughput: 0: 3154.5. Samples: 4659712. Policy #0 lag: (min: 3.0, avg: 6.0, max: 67.0)
[2026-01-08 15:32:18,174][103907] Avg episode reward: [(0, '1158.410')]
[2026-01-08 15:32:18,320][103907] Saving new best policy, reward=1158.410!
[2026-01-08 15:32:23,156][103907] Fps is (10 sec: 3304.8, 60 sec: 3279.5, 300 sec: 3222.0). Total num frames: 4669440. Throughput: 0: 3192.1. Samples: 4670464. Policy #0 lag: (min: 3.0, avg: 6.0, max: 67.0)
[2026-01-08 15:32:23,157][103907] Avg episode reward: [(0, '1179.633')]
[2026-01-08 15:32:23,296][103907] Saving new best policy, reward=1179.633!
[2026-01-08 15:32:28,259][103907] Fps is (10 sec: 3249.1, 60 sec: 3272.0, 300 sec: 3221.1). Total num frames: 4685824. Throughput: 0: 3197.1. Samples: 4689408. Policy #0 lag: (min: 5.0, avg: 8.0, max: 69.0)
[2026-01-08 15:32:28,259][103907] Avg episode reward: [(0, '1176.260')]
[2026-01-08 15:32:33,185][103907] Fps is (10 sec: 3267.3, 60 sec: 3278.4, 300 sec: 3220.8). Total num frames: 4702208. Throughput: 0: 3258.7. Samples: 4709376. Policy #0 lag: (min: 5.0, avg: 8.0, max: 69.0)
[2026-01-08 15:32:33,186][103907] Avg episode reward: [(0, '1158.731')]
[2026-01-08 15:32:38,241][103907] Fps is (10 sec: 3282.5, 60 sec: 3277.0, 300 sec: 3220.2). Total num frames: 4718592. Throughput: 0: 3273.3. Samples: 4719616. Policy #0 lag: (min: 5.0, avg: 8.0, max: 69.0)
[2026-01-08 15:32:38,242][103907] Avg episode reward: [(0, '1155.878')]
[2026-01-08 15:32:43,164][103907] Fps is (10 sec: 3283.8, 60 sec: 3282.0, 300 sec: 3221.9). Total num frames: 4734976. Throughput: 0: 3325.0. Samples: 4739072. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:32:43,164][103907] Avg episode reward: [(0, '1150.927')]
[2026-01-08 15:32:48,269][103907] Fps is (10 sec: 3267.6, 60 sec: 3275.7, 300 sec: 3220.5). Total num frames: 4751360. Throughput: 0: 3319.9. Samples: 4759552. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:32:48,270][103907] Avg episode reward: [(0, '1162.728')]
[2026-01-08 15:32:53,186][103907] Fps is (10 sec: 3269.5, 60 sec: 3277.2, 300 sec: 3221.2). Total num frames: 4767744. Throughput: 0: 3286.2. Samples: 4768768. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:32:53,187][103907] Avg episode reward: [(0, '1143.078')]
[2026-01-08 15:32:58,168][103907] Fps is (10 sec: 3310.2, 60 sec: 3278.5, 300 sec: 3221.1). Total num frames: 4784128. Throughput: 0: 3316.3. Samples: 4788736. Policy #0 lag: (min: 6.0, avg: 9.0, max: 70.0)
[2026-01-08 15:32:58,169][103907] Avg episode reward: [(0, '1169.315')]
[2026-01-08 15:33:03,257][103907] Fps is (10 sec: 3253.7, 60 sec: 3275.7, 300 sec: 3219.9). Total num frames: 4800512. Throughput: 0: 3316.1. Samples: 4809216. Policy #0 lag: (min: 6.0, avg: 9.0, max: 70.0)
[2026-01-08 15:33:03,258][103907] Avg episode reward: [(0, '1183.673')]
[2026-01-08 15:33:03,405][103907] Saving new best policy, reward=1183.673!
[2026-01-08 15:33:08,187][103907] Fps is (10 sec: 3270.7, 60 sec: 3275.3, 300 sec: 3222.0). Total num frames: 4816896. Throughput: 0: 3274.6. Samples: 4817920. Policy #0 lag: (min: 6.0, avg: 9.0, max: 70.0)
[2026-01-08 15:33:08,187][103907] Avg episode reward: [(0, '1197.763')]
[2026-01-08 15:33:08,325][103907] Saving new best policy, reward=1197.763!
[2026-01-08 15:33:13,156][103907] Fps is (10 sec: 3310.2, 60 sec: 3281.4, 300 sec: 3252.8). Total num frames: 4833280. Throughput: 0: 3318.5. Samples: 4838400. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:33:13,157][103907] Avg episode reward: [(0, '1185.829')]
[2026-01-08 15:33:18,220][103907] Fps is (10 sec: 3266.2, 60 sec: 3274.3, 300 sec: 3275.8). Total num frames: 4849664. Throughput: 0: 3319.8. Samples: 4858880. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:33:18,220][103907] Avg episode reward: [(0, '1178.297')]
[2026-01-08 15:33:23,170][103907] Fps is (10 sec: 3272.2, 60 sec: 3276.0, 300 sec: 3277.2). Total num frames: 4866048. Throughput: 0: 3304.8. Samples: 4868096. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:33:23,171][103907] Avg episode reward: [(0, '1181.909')]
[2026-01-08 15:33:28,230][103907] Fps is (10 sec: 3273.3, 60 sec: 3278.3, 300 sec: 3276.6). Total num frames: 4882432. Throughput: 0: 3317.4. Samples: 4888576. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:33:28,230][103907] Avg episode reward: [(0, '1203.348')]
[2026-01-08 15:33:28,372][103907] Saving new best policy, reward=1203.348!
[2026-01-08 15:33:33,178][103907] Fps is (10 sec: 3274.3, 60 sec: 3277.2, 300 sec: 3276.4). Total num frames: 4898816. Throughput: 0: 3317.7. Samples: 4908544. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:33:33,183][103907] Avg episode reward: [(0, '1189.300')]
[2026-01-08 15:33:38,234][103907] Fps is (10 sec: 3275.5, 60 sec: 3277.2, 300 sec: 3276.2). Total num frames: 4915200. Throughput: 0: 3307.4. Samples: 4917760. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:33:38,235][103907] Avg episode reward: [(0, '1183.131')]
[2026-01-08 15:33:39,092][103907] Signal inference workers to stop experience collection... (900 times)
[2026-01-08 15:33:39,462][103907] InferenceWorker_p0-w0: stopping experience collection (900 times)
[2026-01-08 15:33:39,465][103907] Signal inference workers to resume experience collection... (900 times)
[2026-01-08 15:33:39,611][103907] InferenceWorker_p0-w0: resuming experience collection (900 times)
[2026-01-08 15:33:43,188][103907] Fps is (10 sec: 3273.6, 60 sec: 3275.5, 300 sec: 3276.5). Total num frames: 4931584. Throughput: 0: 3320.9. Samples: 4938240. Policy #0 lag: (min: 1.0, avg: 4.0, max: 65.0)
[2026-01-08 15:33:43,188][103907] Avg episode reward: [(0, '1183.966')]
[2026-01-08 15:33:48,260][103907] Fps is (10 sec: 3268.3, 60 sec: 3277.3, 300 sec: 3276.5). Total num frames: 4947968. Throughput: 0: 3322.1. Samples: 4958720. Policy #0 lag: (min: 1.0, avg: 4.0, max: 65.0)
[2026-01-08 15:33:48,260][103907] Avg episode reward: [(0, '1208.887')]
[2026-01-08 15:33:48,400][103907] Saving new best policy, reward=1208.887!
[2026-01-08 15:33:53,173][103907] Fps is (10 sec: 3281.5, 60 sec: 3277.5, 300 sec: 3277.6). Total num frames: 4964352. Throughput: 0: 3334.7. Samples: 4967936. Policy #0 lag: (min: 1.0, avg: 4.0, max: 65.0)
[2026-01-08 15:33:53,174][103907] Avg episode reward: [(0, '1217.733')]
[2026-01-08 15:33:53,311][103907] Saving /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_lidar_policy1_acc_08012026/checkpoint_p0/checkpoint_000019392_4964352.pth...
[2026-01-08 15:33:53,315][103907] Removing /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_lidar_policy1_acc_08012026/checkpoint_p0/checkpoint_000016320_4177920.pth
[2026-01-08 15:33:53,315][103907] Saving new best policy, reward=1217.733!
[2026-01-08 15:33:58,185][103907] Fps is (10 sec: 3301.6, 60 sec: 3275.9, 300 sec: 3276.3). Total num frames: 4980736. Throughput: 0: 3320.2. Samples: 4987904. Policy #0 lag: (min: 11.0, avg: 14.0, max: 75.0)
[2026-01-08 15:33:58,185][103907] Avg episode reward: [(0, '1234.777')]
[2026-01-08 15:33:58,323][103907] Saving new best policy, reward=1234.777!
[2026-01-08 15:34:03,243][103907] Fps is (10 sec: 3254.2, 60 sec: 3277.6, 300 sec: 3275.8). Total num frames: 4997120. Throughput: 0: 3320.6. Samples: 5008384. Policy #0 lag: (min: 11.0, avg: 14.0, max: 75.0)
[2026-01-08 15:34:03,243][103907] Avg episode reward: [(0, '1231.942')]
[2026-01-08 15:34:08,213][103907] Fps is (10 sec: 3267.7, 60 sec: 3275.4, 300 sec: 3276.8). Total num frames: 5013504. Throughput: 0: 3319.2. Samples: 5017600. Policy #0 lag: (min: 11.0, avg: 14.0, max: 75.0)
[2026-01-08 15:34:08,213][103907] Avg episode reward: [(0, '1227.459')]
[2026-01-08 15:34:13,137][103907] Fps is (10 sec: 3311.8, 60 sec: 3277.8, 300 sec: 3277.1). Total num frames: 5029888. Throughput: 0: 3317.8. Samples: 5037568. Policy #0 lag: (min: 4.0, avg: 7.0, max: 68.0)
[2026-01-08 15:34:13,137][103907] Avg episode reward: [(0, '1189.000')]
[2026-01-08 15:34:18,186][103907] Fps is (10 sec: 3285.8, 60 sec: 3278.7, 300 sec: 3277.1). Total num frames: 5046272. Throughput: 0: 3321.8. Samples: 5058048. Policy #0 lag: (min: 4.0, avg: 7.0, max: 68.0)
[2026-01-08 15:34:18,186][103907] Avg episode reward: [(0, '1198.439')]
[2026-01-08 15:34:23,153][103907] Fps is (10 sec: 3271.5, 60 sec: 3277.7, 300 sec: 3277.2). Total num frames: 5062656. Throughput: 0: 3328.3. Samples: 5067264. Policy #0 lag: (min: 4.0, avg: 7.0, max: 68.0)
[2026-01-08 15:34:23,154][103907] Avg episode reward: [(0, '1206.509')]
[2026-01-08 15:34:28,204][103907] Fps is (10 sec: 3270.8, 60 sec: 3278.2, 300 sec: 3276.5). Total num frames: 5079040. Throughput: 0: 3321.1. Samples: 5087744. Policy #0 lag: (min: 0.0, avg: 3.0, max: 64.0)
[2026-01-08 15:34:28,204][103907] Avg episode reward: [(0, '1264.277')]
[2026-01-08 15:34:28,345][103907] Saving new best policy, reward=1264.277!
[2026-01-08 15:34:33,141][103907] Fps is (10 sec: 3280.9, 60 sec: 3278.8, 300 sec: 3276.9). Total num frames: 5095424. Throughput: 0: 3319.7. Samples: 5107712. Policy #0 lag: (min: 0.0, avg: 3.0, max: 64.0)
[2026-01-08 15:34:33,141][103907] Avg episode reward: [(0, '1267.390')]
[2026-01-08 15:34:33,280][103907] Saving new best policy, reward=1267.390!
[2026-01-08 15:34:38,156][103907] Fps is (10 sec: 3292.5, 60 sec: 3281.1, 300 sec: 3277.3). Total num frames: 5111808. Throughput: 0: 3323.6. Samples: 5117440. Policy #0 lag: (min: 0.0, avg: 3.0, max: 64.0)
[2026-01-08 15:34:38,157][103907] Avg episode reward: [(0, '1256.289')]
[2026-01-08 15:34:43,265][103907] Fps is (10 sec: 3236.7, 60 sec: 3272.6, 300 sec: 3276.7). Total num frames: 5128192. Throughput: 0: 3316.4. Samples: 5137408. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:34:43,265][103907] Avg episode reward: [(0, '1232.692')]
[2026-01-08 15:34:48,252][103907] Fps is (10 sec: 3245.8, 60 sec: 3277.2, 300 sec: 3275.9). Total num frames: 5144576. Throughput: 0: 3321.6. Samples: 5157888. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:34:48,252][103907] Avg episode reward: [(0, '1217.344')]
[2026-01-08 15:34:53,507][103907] Fps is (10 sec: 3999.2, 60 sec: 3394.4, 300 sec: 3300.4). Total num frames: 5169152. Throughput: 0: 3300.7. Samples: 5167104. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:34:53,507][103907] Avg episode reward: [(0, '1227.731')]
[2026-01-08 15:34:58,449][103907] Signal inference workers to stop experience collection... (950 times)
[2026-01-08 15:34:58,449][103907] Fps is (10 sec: 4016.7, 60 sec: 3398.4, 300 sec: 3301.7). Total num frames: 5185536. Throughput: 0: 3310.7. Samples: 5187584. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:34:58,450][103907] Avg episode reward: [(0, '1242.079')]
[2026-01-08 15:34:58,819][103907] InferenceWorker_p0-w0: stopping experience collection (950 times)
[2026-01-08 15:34:58,819][103907] Signal inference workers to resume experience collection... (950 times)
[2026-01-08 15:34:58,820][103907] InferenceWorker_p0-w0: resuming experience collection (950 times)
[2026-01-08 15:35:03,391][103907] Fps is (10 sec: 3315.2, 60 sec: 3404.9, 300 sec: 3302.9). Total num frames: 5201920. Throughput: 0: 3307.2. Samples: 5207552. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:35:03,392][103907] Avg episode reward: [(0, '1283.321')]
[2026-01-08 15:35:03,759][103907] Saving new best policy, reward=1283.321!
[2026-01-08 15:35:08,345][103907] Fps is (10 sec: 3311.5, 60 sec: 3405.9, 300 sec: 3302.2). Total num frames: 5218304. Throughput: 0: 3308.3. Samples: 5216768. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:35:08,345][103907] Avg episode reward: [(0, '1285.288')]
[2026-01-08 15:35:08,703][103907] Saving new best policy, reward=1285.288!
[2026-01-08 15:35:13,320][103907] Fps is (10 sec: 3300.2, 60 sec: 3402.9, 300 sec: 3303.3). Total num frames: 5234688. Throughput: 0: 3313.7. Samples: 5237248. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:35:13,321][103907] Avg episode reward: [(0, '1291.173')]
[2026-01-08 15:35:13,696][103907] Saving new best policy, reward=1291.173!
[2026-01-08 15:35:18,272][103907] Fps is (10 sec: 3300.9, 60 sec: 3408.5, 300 sec: 3303.7). Total num frames: 5251072. Throughput: 0: 3312.7. Samples: 5257216. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:35:18,272][103907] Avg episode reward: [(0, '1268.715')]
[2026-01-08 15:35:23,199][103907] Fps is (10 sec: 3317.2, 60 sec: 3410.8, 300 sec: 3305.4). Total num frames: 5267456. Throughput: 0: 3307.8. Samples: 5266432. Policy #0 lag: (min: 7.0, avg: 10.0, max: 71.0)
[2026-01-08 15:35:23,199][103907] Avg episode reward: [(0, '1272.398')]
[2026-01-08 15:35:28,468][103907] Fps is (10 sec: 4016.9, 60 sec: 3534.3, 300 sec: 3328.6). Total num frames: 5292032. Throughput: 0: 3307.4. Samples: 5286912. Policy #0 lag: (min: 7.0, avg: 10.0, max: 71.0)
[2026-01-08 15:35:28,469][103907] Avg episode reward: [(0, '1317.457')]
[2026-01-08 15:35:28,469][103907] Saving new best policy, reward=1317.457!
[2026-01-08 15:35:33,423][103907] Fps is (10 sec: 4006.2, 60 sec: 3533.3, 300 sec: 3330.4). Total num frames: 5308416. Throughput: 0: 3309.7. Samples: 5307392. Policy #0 lag: (min: 7.0, avg: 10.0, max: 71.0)
[2026-01-08 15:35:33,423][103907] Avg episode reward: [(0, '1328.464')]
[2026-01-08 15:35:33,426][103907] Saving new best policy, reward=1328.464!
[2026-01-08 15:35:38,420][103907] Fps is (10 sec: 3292.6, 60 sec: 3534.3, 300 sec: 3330.0). Total num frames: 5324800. Throughput: 0: 3328.7. Samples: 5316608. Policy #0 lag: (min: 9.0, avg: 12.0, max: 73.0)
[2026-01-08 15:35:38,421][103907] Avg episode reward: [(0, '1362.479')]
[2026-01-08 15:35:38,421][103907] Saving new best policy, reward=1362.479!
[2026-01-08 15:35:43,317][103907] Fps is (10 sec: 3311.8, 60 sec: 3546.8, 300 sec: 3330.5). Total num frames: 5341184. Throughput: 0: 3320.7. Samples: 5336576. Policy #0 lag: (min: 9.0, avg: 12.0, max: 73.0)
[2026-01-08 15:35:43,317][103907] Avg episode reward: [(0, '1359.714')]
[2026-01-08 15:35:48,240][103907] Fps is (10 sec: 3337.1, 60 sec: 3550.6, 300 sec: 3332.3). Total num frames: 5357568. Throughput: 0: 3333.6. Samples: 5357056. Policy #0 lag: (min: 9.0, avg: 12.0, max: 73.0)
[2026-01-08 15:35:48,240][103907] Avg episode reward: [(0, '1313.306')]
[2026-01-08 15:35:53,169][103907] Fps is (10 sec: 3326.1, 60 sec: 3432.7, 300 sec: 3332.4). Total num frames: 5373952. Throughput: 0: 3335.3. Samples: 5366272. Policy #0 lag: (min: 4.0, avg: 7.0, max: 68.0)
[2026-01-08 15:35:53,169][103907] Avg episode reward: [(0, '1336.733')]
[2026-01-08 15:35:53,173][103907] Saving /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_lidar_policy1_acc_08012026/checkpoint_p0/checkpoint_000020992_5373952.pth...
[2026-01-08 15:35:53,177][103907] Removing /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_lidar_policy1_acc_08012026/checkpoint_p0/checkpoint_000017856_4571136.pth
[2026-01-08 15:35:58,221][103907] Fps is (10 sec: 3282.8, 60 sec: 3426.4, 300 sec: 3331.8). Total num frames: 5390336. Throughput: 0: 3329.6. Samples: 5386752. Policy #0 lag: (min: 4.0, avg: 7.0, max: 68.0)
[2026-01-08 15:35:58,222][103907] Avg episode reward: [(0, '1339.917')]
[2026-01-08 15:36:03,167][103907] Fps is (10 sec: 3277.2, 60 sec: 3426.1, 300 sec: 3333.0). Total num frames: 5406720. Throughput: 0: 3341.4. Samples: 5407232. Policy #0 lag: (min: 4.0, avg: 7.0, max: 68.0)
[2026-01-08 15:36:03,168][103907] Avg episode reward: [(0, '1343.872')]
[2026-01-08 15:36:08,240][103907] Fps is (10 sec: 3270.6, 60 sec: 3419.3, 300 sec: 3332.1). Total num frames: 5423104. Throughput: 0: 3330.6. Samples: 5416448. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:36:08,241][103907] Avg episode reward: [(0, '1361.906')]
[2026-01-08 15:36:13,199][103907] Fps is (10 sec: 3266.7, 60 sec: 3420.3, 300 sec: 3332.9). Total num frames: 5439488. Throughput: 0: 3342.4. Samples: 5436416. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:36:13,199][103907] Avg episode reward: [(0, '1330.596')]
[2026-01-08 15:36:18,241][103907] Fps is (10 sec: 3276.6, 60 sec: 3415.1, 300 sec: 3331.9). Total num frames: 5455872. Throughput: 0: 3335.8. Samples: 5456896. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:36:18,241][103907] Avg episode reward: [(0, '1312.099')]
[2026-01-08 15:36:22,387][103907] Signal inference workers to stop experience collection... (1000 times)
[2026-01-08 15:36:22,392][103907] Signal inference workers to resume experience collection... (1000 times)
[2026-01-08 15:36:22,648][103907] InferenceWorker_p0-w0: stopping experience collection (1000 times)
[2026-01-08 15:36:22,648][103907] InferenceWorker_p0-w0: resuming experience collection (1000 times)
[2026-01-08 15:36:23,181][103907] Fps is (10 sec: 3282.5, 60 sec: 3414.3, 300 sec: 3332.2). Total num frames: 5472256. Throughput: 0: 3340.1. Samples: 5466112. Policy #0 lag: (min: 0.0, avg: 3.0, max: 64.0)
[2026-01-08 15:36:23,181][103907] Avg episode reward: [(0, '1328.305')]
[2026-01-08 15:36:28,133][103907] Fps is (10 sec: 3312.5, 60 sec: 3295.2, 300 sec: 3333.3). Total num frames: 5488640. Throughput: 0: 3347.4. Samples: 5486592. Policy #0 lag: (min: 0.0, avg: 3.0, max: 64.0)
[2026-01-08 15:36:28,133][103907] Avg episode reward: [(0, '1321.504')]
[2026-01-08 15:36:33,193][103907] Fps is (10 sec: 3272.8, 60 sec: 3289.4, 300 sec: 3332.9). Total num frames: 5505024. Throughput: 0: 3314.3. Samples: 5506048. Policy #0 lag: (min: 0.0, avg: 3.0, max: 64.0)
[2026-01-08 15:36:33,194][103907] Avg episode reward: [(0, '1370.238')]
[2026-01-08 15:36:33,337][103907] Saving new best policy, reward=1370.238!
[2026-01-08 15:36:38,138][103907] Fps is (10 sec: 3275.3, 60 sec: 3292.3, 300 sec: 3333.7). Total num frames: 5521408. Throughput: 0: 3336.0. Samples: 5516288. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:36:38,138][103907] Avg episode reward: [(0, '1385.188')]
[2026-01-08 15:36:38,279][103907] Saving new best policy, reward=1385.188!
[2026-01-08 15:36:43,237][103907] Fps is (10 sec: 3262.7, 60 sec: 3281.2, 300 sec: 3332.5). Total num frames: 5537792. Throughput: 0: 3321.2. Samples: 5536256. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:36:43,237][103907] Avg episode reward: [(0, '1369.435')]
[2026-01-08 15:36:48,215][103907] Fps is (10 sec: 3251.6, 60 sec: 3278.1, 300 sec: 3332.1). Total num frames: 5554176. Throughput: 0: 3284.7. Samples: 5555200. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:36:48,215][103907] Avg episode reward: [(0, '1348.370')]
[2026-01-08 15:36:53,269][103907] Fps is (10 sec: 3266.3, 60 sec: 3271.3, 300 sec: 3331.6). Total num frames: 5570560. Throughput: 0: 3320.2. Samples: 5565952. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:36:53,269][103907] Avg episode reward: [(0, '1325.168')]
[2026-01-08 15:36:58,192][103907] Fps is (10 sec: 3284.3, 60 sec: 3278.4, 300 sec: 3332.8). Total num frames: 5586944. Throughput: 0: 3322.8. Samples: 5585920. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:36:58,193][103907] Avg episode reward: [(0, '1329.525')]
[2026-01-08 15:37:03,147][103907] Fps is (10 sec: 3317.3, 60 sec: 3277.9, 300 sec: 3332.5). Total num frames: 5603328. Throughput: 0: 3283.7. Samples: 5604352. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:37:03,147][103907] Avg episode reward: [(0, '1325.419')]
[2026-01-08 15:37:08,241][103907] Fps is (10 sec: 3261.0, 60 sec: 3276.8, 300 sec: 3332.3). Total num frames: 5619712. Throughput: 0: 3317.9. Samples: 5615616. Policy #0 lag: (min: 25.0, avg: 28.0, max: 89.0)
[2026-01-08 15:37:08,241][103907] Avg episode reward: [(0, '1358.534')]
[2026-01-08 15:37:13,221][103907] Fps is (10 sec: 3252.7, 60 sec: 3275.6, 300 sec: 3331.8). Total num frames: 5636096. Throughput: 0: 3304.5. Samples: 5635584. Policy #0 lag: (min: 25.0, avg: 28.0, max: 89.0)
[2026-01-08 15:37:13,221][103907] Avg episode reward: [(0, '1304.066')]
[2026-01-08 15:37:18,184][103907] Fps is (10 sec: 3295.5, 60 sec: 3279.9, 300 sec: 3332.0). Total num frames: 5652480. Throughput: 0: 3277.5. Samples: 5653504. Policy #0 lag: (min: 25.0, avg: 28.0, max: 89.0)
[2026-01-08 15:37:18,184][103907] Avg episode reward: [(0, '1279.366')]
[2026-01-08 15:37:23,249][103907] Fps is (10 sec: 3267.7, 60 sec: 3273.1, 300 sec: 3332.5). Total num frames: 5668864. Throughput: 0: 3291.4. Samples: 5664768. Policy #0 lag: (min: 23.0, avg: 26.0, max: 87.0)
[2026-01-08 15:37:23,249][103907] Avg episode reward: [(0, '1254.018')]
[2026-01-08 15:37:28,135][103907] Fps is (10 sec: 3293.0, 60 sec: 3276.7, 300 sec: 3332.9). Total num frames: 5685248. Throughput: 0: 3318.4. Samples: 5685248. Policy #0 lag: (min: 23.0, avg: 26.0, max: 87.0)
[2026-01-08 15:37:28,135][103907] Avg episode reward: [(0, '1283.323')]
[2026-01-08 15:37:33,247][103907] Fps is (10 sec: 3277.2, 60 sec: 3273.9, 300 sec: 3332.3). Total num frames: 5701632. Throughput: 0: 3308.6. Samples: 5704192. Policy #0 lag: (min: 23.0, avg: 26.0, max: 87.0)
[2026-01-08 15:37:33,248][103907] Avg episode reward: [(0, '1323.637')]
[2026-01-08 15:37:38,173][103907] Fps is (10 sec: 3264.4, 60 sec: 3274.9, 300 sec: 3332.2). Total num frames: 5718016. Throughput: 0: 3318.0. Samples: 5714944. Policy #0 lag: (min: 40.0, avg: 43.0, max: 104.0)
[2026-01-08 15:37:38,173][103907] Avg episode reward: [(0, '1363.562')]
[2026-01-08 15:37:43,245][103907] Fps is (10 sec: 3277.6, 60 sec: 3276.3, 300 sec: 3332.6). Total num frames: 5734400. Throughput: 0: 3318.4. Samples: 5735424. Policy #0 lag: (min: 40.0, avg: 43.0, max: 104.0)
[2026-01-08 15:37:43,245][103907] Avg episode reward: [(0, '1403.675')]
[2026-01-08 15:37:43,392][103907] Saving new best policy, reward=1403.675!
[2026-01-08 15:37:46,078][103907] Signal inference workers to stop experience collection... (1050 times)
[2026-01-08 15:37:46,451][103907] InferenceWorker_p0-w0: stopping experience collection (1050 times)
[2026-01-08 15:37:46,453][103907] Signal inference workers to resume experience collection... (1050 times)
[2026-01-08 15:37:46,591][103907] InferenceWorker_p0-w0: resuming experience collection (1050 times)
[2026-01-08 15:37:48,242][103907] Fps is (10 sec: 3254.2, 60 sec: 3275.3, 300 sec: 3331.7). Total num frames: 5750784. Throughput: 0: 3315.3. Samples: 5753856. Policy #0 lag: (min: 40.0, avg: 43.0, max: 104.0)
[2026-01-08 15:37:48,242][103907] Avg episode reward: [(0, '1414.476')]
[2026-01-08 15:37:48,377][103907] Saving new best policy, reward=1414.476!
[2026-01-08 15:37:53,173][103907] Fps is (10 sec: 3300.5, 60 sec: 3282.0, 300 sec: 3332.3). Total num frames: 5767168. Throughput: 0: 3315.9. Samples: 5764608. Policy #0 lag: (min: 40.0, avg: 43.0, max: 104.0)
[2026-01-08 15:37:53,173][103907] Avg episode reward: [(0, '1417.648')]
[2026-01-08 15:37:53,330][103907] Saving /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_lidar_policy1_acc_08012026/checkpoint_p0/checkpoint_000022528_5767168.pth...
[2026-01-08 15:37:53,334][103907] Removing /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_lidar_policy1_acc_08012026/checkpoint_p0/checkpoint_000019392_4964352.pth
[2026-01-08 15:37:53,334][103907] Saving new best policy, reward=1417.648!
[2026-01-08 15:37:58,135][103907] Fps is (10 sec: 3312.1, 60 sec: 3279.9, 300 sec: 3333.7). Total num frames: 5783552. Throughput: 0: 3317.2. Samples: 5784576. Policy #0 lag: (min: 3.0, avg: 6.0, max: 67.0)
[2026-01-08 15:37:58,136][103907] Avg episode reward: [(0, '1402.180')]
[2026-01-08 15:38:03,261][103907] Fps is (10 sec: 3248.2, 60 sec: 3270.6, 300 sec: 3331.5). Total num frames: 5799936. Throughput: 0: 3328.0. Samples: 5803520. Policy #0 lag: (min: 3.0, avg: 6.0, max: 67.0)
[2026-01-08 15:38:03,262][103907] Avg episode reward: [(0, '1386.511')]
[2026-01-08 15:38:08,264][103907] Fps is (10 sec: 3235.3, 60 sec: 3275.6, 300 sec: 3331.1). Total num frames: 5816320. Throughput: 0: 3321.2. Samples: 5814272. Policy #0 lag: (min: 3.0, avg: 6.0, max: 67.0)
[2026-01-08 15:38:08,264][103907] Avg episode reward: [(0, '1371.987')]
[2026-01-08 15:38:13,245][103907] Fps is (10 sec: 3282.1, 60 sec: 3275.5, 300 sec: 3332.0). Total num frames: 5832704. Throughput: 0: 3291.5. Samples: 5833728. Policy #0 lag: (min: 47.0, avg: 50.0, max: 111.0)
[2026-01-08 15:38:13,245][103907] Avg episode reward: [(0, '1389.534')]
[2026-01-08 15:38:18,203][103907] Fps is (10 sec: 3296.8, 60 sec: 3275.8, 300 sec: 3332.0). Total num frames: 5849088. Throughput: 0: 3302.8. Samples: 5852672. Policy #0 lag: (min: 47.0, avg: 50.0, max: 111.0)
[2026-01-08 15:38:18,203][103907] Avg episode reward: [(0, '1391.456')]
[2026-01-08 15:38:23,148][103907] Fps is (10 sec: 3309.0, 60 sec: 3282.3, 300 sec: 3333.3). Total num frames: 5865472. Throughput: 0: 3301.4. Samples: 5863424. Policy #0 lag: (min: 47.0, avg: 50.0, max: 111.0)
[2026-01-08 15:38:23,148][103907] Avg episode reward: [(0, '1397.737')]
[2026-01-08 15:38:28,243][103907] Fps is (10 sec: 3263.6, 60 sec: 3270.9, 300 sec: 3331.6). Total num frames: 5881856. Throughput: 0: 3276.9. Samples: 5882880. Policy #0 lag: (min: 47.0, avg: 50.0, max: 111.0)
[2026-01-08 15:38:28,244][103907] Avg episode reward: [(0, '1403.448')]
[2026-01-08 15:38:33,200][103907] Fps is (10 sec: 3259.9, 60 sec: 3279.4, 300 sec: 3332.7). Total num frames: 5898240. Throughput: 0: 3302.7. Samples: 5902336. Policy #0 lag: (min: 2.0, avg: 5.0, max: 66.0)
[2026-01-08 15:38:33,200][103907] Avg episode reward: [(0, '1381.648')]
[2026-01-08 15:38:38,148][103907] Fps is (10 sec: 3308.3, 60 sec: 3278.1, 300 sec: 3332.8). Total num frames: 5914624. Throughput: 0: 3301.4. Samples: 5913088. Policy #0 lag: (min: 2.0, avg: 5.0, max: 66.0)
[2026-01-08 15:38:38,148][103907] Avg episode reward: [(0, '1408.263')]
[2026-01-08 15:38:43,253][103907] Fps is (10 sec: 3259.4, 60 sec: 3276.4, 300 sec: 3332.4). Total num frames: 5931008. Throughput: 0: 3268.3. Samples: 5932032. Policy #0 lag: (min: 2.0, avg: 5.0, max: 66.0)
[2026-01-08 15:38:43,253][103907] Avg episode reward: [(0, '1365.383')]
[2026-01-08 15:38:48,228][103907] Fps is (10 sec: 3250.9, 60 sec: 3277.6, 300 sec: 3331.7). Total num frames: 5947392. Throughput: 0: 3302.0. Samples: 5952000. Policy #0 lag: (min: 2.0, avg: 5.0, max: 66.0)
[2026-01-08 15:38:48,228][103907] Avg episode reward: [(0, '1390.418')]
[2026-01-08 15:38:53,172][103907] Fps is (10 sec: 3303.6, 60 sec: 3276.9, 300 sec: 3332.5). Total num frames: 5963776. Throughput: 0: 3306.3. Samples: 5962752. Policy #0 lag: (min: 8.0, avg: 11.0, max: 72.0)
[2026-01-08 15:38:53,172][103907] Avg episode reward: [(0, '1343.430')]
[2026-01-08 15:38:58,136][103907] Fps is (10 sec: 3307.1, 60 sec: 3276.8, 300 sec: 3333.5). Total num frames: 5980160. Throughput: 0: 3284.7. Samples: 5981184. Policy #0 lag: (min: 8.0, avg: 11.0, max: 72.0)
[2026-01-08 15:38:58,137][103907] Avg episode reward: [(0, '1310.676')]
[2026-01-08 15:39:03,259][103907] Fps is (10 sec: 3248.6, 60 sec: 3277.0, 300 sec: 3331.8). Total num frames: 5996544. Throughput: 0: 3306.8. Samples: 6001664. Policy #0 lag: (min: 8.0, avg: 11.0, max: 72.0)
[2026-01-08 15:39:03,259][103907] Avg episode reward: [(0, '1311.256')]
[2026-01-08 15:39:05,887][103907] Signal inference workers to stop experience collection... (1100 times)
[2026-01-08 15:39:06,254][103907] InferenceWorker_p0-w0: stopping experience collection (1100 times)
[2026-01-08 15:39:06,254][103907] Signal inference workers to resume experience collection... (1100 times)
[2026-01-08 15:39:06,254][103907] InferenceWorker_p0-w0: resuming experience collection (1100 times)
[2026-01-08 15:39:08,229][103907] Fps is (10 sec: 3246.7, 60 sec: 3278.7, 300 sec: 3331.3). Total num frames: 6012928. Throughput: 0: 3305.0. Samples: 6012416. Policy #0 lag: (min: 8.0, avg: 11.0, max: 72.0)
[2026-01-08 15:39:08,229][103907] Avg episode reward: [(0, '1352.031')]
[2026-01-08 15:39:13,146][103907] Fps is (10 sec: 3314.2, 60 sec: 3282.2, 300 sec: 3332.8). Total num frames: 6029312. Throughput: 0: 3283.9. Samples: 6030336. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:39:13,146][103907] Avg episode reward: [(0, '1361.258')]
[2026-01-08 15:39:18,133][103907] Fps is (10 sec: 3308.4, 60 sec: 3280.6, 300 sec: 3332.6). Total num frames: 6045696. Throughput: 0: 3315.8. Samples: 6051328. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:39:18,134][103907] Avg episode reward: [(0, '1399.207')]
[2026-01-08 15:39:23,214][103907] Fps is (10 sec: 3254.5, 60 sec: 3273.2, 300 sec: 3332.2). Total num frames: 6062080. Throughput: 0: 3306.1. Samples: 6062080. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:39:23,214][103907] Avg episode reward: [(0, '1399.726')]
[2026-01-08 15:39:28,132][103907] Fps is (10 sec: 3277.4, 60 sec: 3282.9, 300 sec: 3332.4). Total num frames: 6078464. Throughput: 0: 3308.5. Samples: 6080512. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:39:28,132][103907] Avg episode reward: [(0, '1425.097')]
[2026-01-08 15:39:28,290][103907] Saving new best policy, reward=1425.097!
[2026-01-08 15:39:33,184][103907] Fps is (10 sec: 3286.7, 60 sec: 3277.7, 300 sec: 3332.0). Total num frames: 6094848. Throughput: 0: 3245.9. Samples: 6097920. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:39:33,184][103907] Avg episode reward: [(0, '1423.977')]
[2026-01-08 15:39:38,159][103907] Fps is (10 sec: 3267.8, 60 sec: 3276.2, 300 sec: 3333.5). Total num frames: 6111232. Throughput: 0: 3220.8. Samples: 6107648. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:39:38,159][103907] Avg episode reward: [(0, '1444.500')]
[2026-01-08 15:39:38,334][103907] Saving new best policy, reward=1444.500!
[2026-01-08 15:39:43,216][103907] Fps is (10 sec: 3266.3, 60 sec: 3278.8, 300 sec: 3332.7). Total num frames: 6127616. Throughput: 0: 3191.5. Samples: 6125056. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:39:43,216][103907] Avg episode reward: [(0, '1429.963')]
[2026-01-08 15:39:48,356][103907] Fps is (10 sec: 2410.1, 60 sec: 3133.6, 300 sec: 3278.5). Total num frames: 6135808. Throughput: 0: 3122.1. Samples: 6142464. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:39:48,356][103907] Avg episode reward: [(0, '1376.769')]
[2026-01-08 15:39:53,178][103907] Fps is (10 sec: 1644.6, 60 sec: 3003.4, 300 sec: 3252.0). Total num frames: 6144000. Throughput: 0: 3064.1. Samples: 6150144. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:39:53,179][103907] Avg episode reward: [(0, '1387.418')]
[2026-01-08 15:39:53,354][103907] Saving /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_lidar_policy1_acc_08012026/checkpoint_p0/checkpoint_000024000_6144000.pth...
[2026-01-08 15:39:53,359][103907] Removing /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_lidar_policy1_acc_08012026/checkpoint_p0/checkpoint_000020992_5373952.pth
[2026-01-08 15:39:58,210][103907] Fps is (10 sec: 2494.1, 60 sec: 3000.1, 300 sec: 3251.0). Total num frames: 6160384. Throughput: 0: 3044.9. Samples: 6167552. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:39:58,210][103907] Avg episode reward: [(0, '1376.741')]
[2026-01-08 15:40:03,211][103907] Fps is (10 sec: 3266.1, 60 sec: 3006.1, 300 sec: 3250.5). Total num frames: 6176768. Throughput: 0: 2964.5. Samples: 6184960. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:40:03,211][103907] Avg episode reward: [(0, '1404.979')]
[2026-01-08 15:40:08,249][103907] Fps is (10 sec: 3263.8, 60 sec: 3002.7, 300 sec: 3249.8). Total num frames: 6193152. Throughput: 0: 2933.2. Samples: 6194176. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:40:08,250][103907] Avg episode reward: [(0, '1441.751')]
[2026-01-08 15:40:13,228][103907] Fps is (10 sec: 3271.2, 60 sec: 2999.6, 300 sec: 3249.5). Total num frames: 6209536. Throughput: 0: 2883.7. Samples: 6210560. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:40:13,229][103907] Avg episode reward: [(0, '1451.124')]
[2026-01-08 15:40:13,406][103907] Saving new best policy, reward=1451.124!
[2026-01-08 15:40:18,253][103907] Fps is (10 sec: 3275.6, 60 sec: 2997.8, 300 sec: 3248.4). Total num frames: 6225920. Throughput: 0: 2885.5. Samples: 6227968. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:40:18,253][103907] Avg episode reward: [(0, '1419.550')]
[2026-01-08 15:40:23,288][103907] Fps is (10 sec: 3257.3, 60 sec: 3000.0, 300 sec: 3223.2). Total num frames: 6242304. Throughput: 0: 2870.3. Samples: 6237184. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:40:23,289][103907] Avg episode reward: [(0, '1403.040')]
[2026-01-08 15:40:28,454][103907] Fps is (10 sec: 3212.2, 60 sec: 2987.7, 300 sec: 3220.9). Total num frames: 6258688. Throughput: 0: 2863.4. Samples: 6254592. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:40:28,454][103907] Avg episode reward: [(0, '1430.547')]
[2026-01-08 15:40:33,165][103907] Fps is (10 sec: 1658.9, 60 sec: 2731.5, 300 sec: 3168.5). Total num frames: 6258688. Throughput: 0: 2890.8. Samples: 6272000. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:40:33,165][103907] Avg episode reward: [(0, '1423.510')]
[2026-01-08 15:40:38,185][103907] Fps is (10 sec: 1683.8, 60 sec: 2729.5, 300 sec: 3167.1). Total num frames: 6275072. Throughput: 0: 2889.6. Samples: 6280192. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:40:38,185][103907] Avg episode reward: [(0, '1413.575')]
[2026-01-08 15:40:39,392][103907] Signal inference workers to stop experience collection... (1150 times)
[2026-01-08 15:40:39,399][103907] Signal inference workers to resume experience collection... (1150 times)
[2026-01-08 15:40:39,678][103907] InferenceWorker_p0-w0: stopping experience collection (1150 times)
[2026-01-08 15:40:39,679][103907] InferenceWorker_p0-w0: resuming experience collection (1150 times)
[2026-01-08 15:40:43,183][103907] Fps is (10 sec: 3270.9, 60 sec: 2732.2, 300 sec: 3166.3). Total num frames: 6291456. Throughput: 0: 2891.6. Samples: 6297600. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:40:43,183][103907] Avg episode reward: [(0, '1397.549')]
[2026-01-08 15:40:48,173][103907] Fps is (10 sec: 3280.7, 60 sec: 2876.0, 300 sec: 3165.7). Total num frames: 6307840. Throughput: 0: 2892.4. Samples: 6315008. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:40:48,173][103907] Avg episode reward: [(0, '1382.162')]
[2026-01-08 15:40:53,179][103907] Fps is (10 sec: 3278.2, 60 sec: 3003.7, 300 sec: 3166.2). Total num frames: 6324224. Throughput: 0: 2905.9. Samples: 6324736. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:40:53,179][103907] Avg episode reward: [(0, '1398.478')]
[2026-01-08 15:40:58,218][103907] Fps is (10 sec: 3262.0, 60 sec: 3003.3, 300 sec: 3165.2). Total num frames: 6340608. Throughput: 0: 2913.4. Samples: 6341632. Policy #0 lag: (min: 10.0, avg: 13.0, max: 74.0)
[2026-01-08 15:40:58,218][103907] Avg episode reward: [(0, '1428.088')]
[2026-01-08 15:41:03,253][103907] Fps is (10 sec: 3252.9, 60 sec: 3001.7, 300 sec: 3165.6). Total num frames: 6356992. Throughput: 0: 2890.0. Samples: 6358016. Policy #0 lag: (min: 10.0, avg: 13.0, max: 74.0)
[2026-01-08 15:41:03,253][103907] Avg episode reward: [(0, '1455.489')]
[2026-01-08 15:41:03,416][103907] Saving new best policy, reward=1455.489!
[2026-01-08 15:41:08,237][103907] Fps is (10 sec: 3270.7, 60 sec: 3004.4, 300 sec: 3165.3). Total num frames: 6373376. Throughput: 0: 2893.3. Samples: 6367232. Policy #0 lag: (min: 10.0, avg: 13.0, max: 74.0)
[2026-01-08 15:41:08,237][103907] Avg episode reward: [(0, '1427.414')]
[2026-01-08 15:41:13,351][103907] Fps is (10 sec: 2433.7, 60 sec: 2861.4, 300 sec: 3136.8). Total num frames: 6381568. Throughput: 0: 2896.6. Samples: 6384640. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:41:13,351][103907] Avg episode reward: [(0, '1430.836')]
[2026-01-08 15:41:18,153][103907] Fps is (10 sec: 1652.2, 60 sec: 2735.2, 300 sec: 3110.5). Total num frames: 6389760. Throughput: 0: 2890.7. Samples: 6402048. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:41:18,154][103907] Avg episode reward: [(0, '1419.062')]
[2026-01-08 15:41:23,165][103907] Fps is (10 sec: 2504.1, 60 sec: 2736.3, 300 sec: 3109.8). Total num frames: 6406144. Throughput: 0: 2891.2. Samples: 6410240. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:41:23,165][103907] Avg episode reward: [(0, '1438.871')]
[2026-01-08 15:41:28,178][103907] Fps is (10 sec: 3268.7, 60 sec: 2743.3, 300 sec: 3110.3). Total num frames: 6422528. Throughput: 0: 2890.3. Samples: 6427648. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:41:28,179][103907] Avg episode reward: [(0, '1427.838')]
[2026-01-08 15:41:33,175][103907] Fps is (10 sec: 3273.4, 60 sec: 3003.2, 300 sec: 3109.8). Total num frames: 6438912. Throughput: 0: 2889.8. Samples: 6445056. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:41:33,175][103907] Avg episode reward: [(0, '1417.623')]
[2026-01-08 15:41:38,261][103907] Fps is (10 sec: 3250.1, 60 sec: 2999.9, 300 sec: 3109.9). Total num frames: 6455296. Throughput: 0: 2884.7. Samples: 6454784. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:41:38,261][103907] Avg episode reward: [(0, '1457.551')]
[2026-01-08 15:41:38,436][103907] Saving new best policy, reward=1457.551!
[2026-01-08 15:41:43,288][103907] Fps is (10 sec: 3240.2, 60 sec: 2998.5, 300 sec: 3109.4). Total num frames: 6471680. Throughput: 0: 2885.5. Samples: 6471680. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:41:43,288][103907] Avg episode reward: [(0, '1461.831')]
[2026-01-08 15:41:43,459][103907] Saving new best policy, reward=1461.650!
[2026-01-08 15:41:48,139][103907] Fps is (10 sec: 3317.1, 60 sec: 3005.4, 300 sec: 3111.6). Total num frames: 6488064. Throughput: 0: 2920.1. Samples: 6489088. Policy #0 lag: (min: 9.0, avg: 12.0, max: 73.0)
[2026-01-08 15:41:48,139][103907] Avg episode reward: [(0, '1461.670')]
[2026-01-08 15:41:48,296][103907] Saving new best policy, reward=1461.670!
[2026-01-08 15:41:53,464][103907] Fps is (10 sec: 3220.1, 60 sec: 2989.5, 300 sec: 3107.3). Total num frames: 6504448. Throughput: 0: 2875.4. Samples: 6497280. Policy #0 lag: (min: 9.0, avg: 12.0, max: 73.0)
[2026-01-08 15:41:53,464][103907] Avg episode reward: [(0, '1461.423')]
[2026-01-08 15:41:53,469][103907] Saving /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_lidar_policy1_acc_08012026/checkpoint_p0/checkpoint_000025408_6504448.pth...
[2026-01-08 15:41:53,473][103907] Removing /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_lidar_policy1_acc_08012026/checkpoint_p0/checkpoint_000022528_5767168.pth
[2026-01-08 15:41:58,200][103907] Fps is (10 sec: 1628.6, 60 sec: 2731.5, 300 sec: 3054.1). Total num frames: 6504448. Throughput: 0: 2899.7. Samples: 6514688. Policy #0 lag: (min: 9.0, avg: 12.0, max: 73.0)
[2026-01-08 15:41:58,200][103907] Avg episode reward: [(0, '1452.985')]
[2026-01-08 15:42:03,256][103907] Fps is (10 sec: 1673.1, 60 sec: 2730.5, 300 sec: 3054.5). Total num frames: 6520832. Throughput: 0: 2883.4. Samples: 6532096. Policy #0 lag: (min: 9.0, avg: 12.0, max: 73.0)
[2026-01-08 15:42:03,257][103907] Avg episode reward: [(0, '1476.011')]
[2026-01-08 15:42:03,421][103907] Saving new best policy, reward=1476.011!
[2026-01-08 15:42:08,155][103907] Fps is (10 sec: 3291.6, 60 sec: 2734.4, 300 sec: 3055.3). Total num frames: 6537216. Throughput: 0: 2879.2. Samples: 6539776. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:42:08,155][103907] Avg episode reward: [(0, '1493.866')]
[2026-01-08 15:42:08,328][103907] Saving new best policy, reward=1493.866!
[2026-01-08 15:42:13,181][103907] Fps is (10 sec: 3301.6, 60 sec: 2875.3, 300 sec: 3054.7). Total num frames: 6553600. Throughput: 0: 2878.4. Samples: 6557184. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:42:13,182][103907] Avg episode reward: [(0, '1496.142')]
[2026-01-08 15:42:13,353][103907] Saving new best policy, reward=1496.142!
[2026-01-08 15:42:15,477][103907] Signal inference workers to stop experience collection... (1200 times)
[2026-01-08 15:42:15,878][103907] InferenceWorker_p0-w0: stopping experience collection (1200 times)
[2026-01-08 15:42:15,880][103907] Signal inference workers to resume experience collection... (1200 times)
[2026-01-08 15:42:16,039][103907] InferenceWorker_p0-w0: resuming experience collection (1200 times)
[2026-01-08 15:42:18,227][103907] Fps is (10 sec: 3253.2, 60 sec: 3000.1, 300 sec: 3054.9). Total num frames: 6569984. Throughput: 0: 2875.3. Samples: 6574592. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:42:18,227][103907] Avg episode reward: [(0, '1475.208')]
[2026-01-08 15:42:23,236][103907] Fps is (10 sec: 3259.0, 60 sec: 3000.2, 300 sec: 3053.6). Total num frames: 6586368. Throughput: 0: 2868.7. Samples: 6583808. Policy #0 lag: (min: 2.0, avg: 5.0, max: 66.0)
[2026-01-08 15:42:23,236][103907] Avg episode reward: [(0, '1429.624')]
[2026-01-08 15:42:28,263][103907] Fps is (10 sec: 3265.1, 60 sec: 2999.5, 300 sec: 3054.5). Total num frames: 6602752. Throughput: 0: 2880.2. Samples: 6601216. Policy #0 lag: (min: 2.0, avg: 5.0, max: 66.0)
[2026-01-08 15:42:28,263][103907] Avg episode reward: [(0, '1402.722')]
[2026-01-08 15:42:33,235][103907] Fps is (10 sec: 3277.2, 60 sec: 3000.7, 300 sec: 3054.0). Total num frames: 6619136. Throughput: 0: 2883.8. Samples: 6619136. Policy #0 lag: (min: 2.0, avg: 5.0, max: 66.0)
[2026-01-08 15:42:33,235][103907] Avg episode reward: [(0, '1437.568')]
[2026-01-08 15:42:38,187][103907] Fps is (10 sec: 1650.8, 60 sec: 2734.0, 300 sec: 2999.7). Total num frames: 6619136. Throughput: 0: 2896.4. Samples: 6626816. Policy #0 lag: (min: 2.0, avg: 5.0, max: 66.0)
[2026-01-08 15:42:38,188][103907] Avg episode reward: [(0, '1393.863')]
[2026-01-08 15:42:43,220][103907] Fps is (10 sec: 1641.0, 60 sec: 2733.8, 300 sec: 2999.3). Total num frames: 6635520. Throughput: 0: 2877.3. Samples: 6644224. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:42:43,220][103907] Avg episode reward: [(0, '1416.150')]
[2026-01-08 15:42:48,200][103907] Fps is (10 sec: 3272.7, 60 sec: 2727.9, 300 sec: 2998.8). Total num frames: 6651904. Throughput: 0: 2882.2. Samples: 6661632. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:42:48,200][103907] Avg episode reward: [(0, '1390.571')]
[2026-01-08 15:42:53,197][103907] Fps is (10 sec: 3284.3, 60 sec: 2742.9, 300 sec: 2998.5). Total num frames: 6668288. Throughput: 0: 2875.9. Samples: 6669312. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:42:53,197][103907] Avg episode reward: [(0, '1404.403')]
[2026-01-08 15:42:58,180][103907] Fps is (10 sec: 3283.5, 60 sec: 3004.7, 300 sec: 2999.9). Total num frames: 6684672. Throughput: 0: 2890.1. Samples: 6687232. Policy #0 lag: (min: 41.0, avg: 44.0, max: 105.0)
[2026-01-08 15:42:58,180][103907] Avg episode reward: [(0, '1436.201')]
[2026-01-08 15:43:03,263][103907] Fps is (10 sec: 3255.2, 60 sec: 3003.4, 300 sec: 2999.1). Total num frames: 6701056. Throughput: 0: 2887.7. Samples: 6704640. Policy #0 lag: (min: 41.0, avg: 44.0, max: 105.0)
[2026-01-08 15:43:03,263][103907] Avg episode reward: [(0, '1438.235')]
[2026-01-08 15:43:08,293][103907] Fps is (10 sec: 3240.2, 60 sec: 2996.8, 300 sec: 2998.6). Total num frames: 6717440. Throughput: 0: 2886.3. Samples: 6713856. Policy #0 lag: (min: 41.0, avg: 44.0, max: 105.0)
[2026-01-08 15:43:08,293][103907] Avg episode reward: [(0, '1461.679')]
[2026-01-08 15:43:13,155][103907] Fps is (10 sec: 3312.6, 60 sec: 3005.1, 300 sec: 2999.6). Total num frames: 6733824. Throughput: 0: 2896.9. Samples: 6731264. Policy #0 lag: (min: 41.0, avg: 44.0, max: 105.0)
[2026-01-08 15:43:13,155][103907] Avg episode reward: [(0, '1446.819')]
[2026-01-08 15:43:18,232][103907] Fps is (10 sec: 2472.7, 60 sec: 2867.0, 300 sec: 2970.5). Total num frames: 6742016. Throughput: 0: 2878.8. Samples: 6748672. Policy #0 lag: (min: 11.0, avg: 14.0, max: 75.0)
[2026-01-08 15:43:18,232][103907] Avg episode reward: [(0, '1422.620')]
[2026-01-08 15:43:23,213][103907] Fps is (10 sec: 1628.9, 60 sec: 2731.7, 300 sec: 2943.9). Total num frames: 6750208. Throughput: 0: 2888.3. Samples: 6756864. Policy #0 lag: (min: 11.0, avg: 14.0, max: 75.0)
[2026-01-08 15:43:23,214][103907] Avg episode reward: [(0, '1511.031')]
[2026-01-08 15:43:23,383][103907] Saving new best policy, reward=1511.031!
[2026-01-08 15:43:28,167][103907] Fps is (10 sec: 2473.5, 60 sec: 2735.0, 300 sec: 2943.9). Total num frames: 6766592. Throughput: 0: 2893.3. Samples: 6774272. Policy #0 lag: (min: 11.0, avg: 14.0, max: 75.0)
[2026-01-08 15:43:28,167][103907] Avg episode reward: [(0, '1516.752')]
[2026-01-08 15:43:28,334][103907] Saving new best policy, reward=1516.752!
[2026-01-08 15:43:33,188][103907] Fps is (10 sec: 3285.3, 60 sec: 2732.8, 300 sec: 2943.2). Total num frames: 6782976. Throughput: 0: 2890.8. Samples: 6791680. Policy #0 lag: (min: 11.0, avg: 14.0, max: 75.0)
[2026-01-08 15:43:33,188][103907] Avg episode reward: [(0, '1558.199')]
[2026-01-08 15:43:33,348][103907] Saving new best policy, reward=1558.199!
[2026-01-08 15:43:38,185][103907] Fps is (10 sec: 3270.9, 60 sec: 3003.8, 300 sec: 2944.2). Total num frames: 6799360. Throughput: 0: 2913.5. Samples: 6800384. Policy #0 lag: (min: 63.0, avg: 66.0, max: 127.0)
[2026-01-08 15:43:38,185][103907] Avg episode reward: [(0, '1522.470')]
[2026-01-08 15:43:43,220][103907] Fps is (10 sec: 3266.2, 60 sec: 3003.7, 300 sec: 2943.6). Total num frames: 6815744. Throughput: 0: 2876.0. Samples: 6816768. Policy #0 lag: (min: 63.0, avg: 66.0, max: 127.0)
[2026-01-08 15:43:43,220][103907] Avg episode reward: [(0, '1486.486')]
[2026-01-08 15:43:46,534][103907] Signal inference workers to stop experience collection... (1250 times)
[2026-01-08 15:43:46,916][103907] InferenceWorker_p0-w0: stopping experience collection (1250 times)
[2026-01-08 15:43:46,917][103907] Signal inference workers to resume experience collection... (1250 times)
[2026-01-08 15:43:46,917][103907] InferenceWorker_p0-w0: resuming experience collection (1250 times)
[2026-01-08 15:43:48,206][103907] Fps is (10 sec: 3270.0, 60 sec: 3003.4, 300 sec: 2943.2). Total num frames: 6832128. Throughput: 0: 2893.6. Samples: 6834688. Policy #0 lag: (min: 63.0, avg: 66.0, max: 127.0)
[2026-01-08 15:43:48,206][103907] Avg episode reward: [(0, '1476.412')]
[2026-01-08 15:43:53,237][103907] Fps is (10 sec: 3271.3, 60 sec: 3001.7, 300 sec: 2942.6). Total num frames: 6848512. Throughput: 0: 2893.5. Samples: 6843904. Policy #0 lag: (min: 63.0, avg: 66.0, max: 127.0)
[2026-01-08 15:43:53,237][103907] Avg episode reward: [(0, '1444.723')]
[2026-01-08 15:43:53,409][103907] Saving /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_lidar_policy1_acc_08012026/checkpoint_p0/checkpoint_000026752_6848512.pth...
[2026-01-08 15:43:53,413][103907] Removing /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_lidar_policy1_acc_08012026/checkpoint_p0/checkpoint_000024000_6144000.pth
[2026-01-08 15:43:58,227][103907] Fps is (10 sec: 3270.1, 60 sec: 3001.4, 300 sec: 2943.9). Total num frames: 6864896. Throughput: 0: 2896.7. Samples: 6861824. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:43:58,227][103907] Avg episode reward: [(0, '1481.439')]
[2026-01-08 15:44:03,141][103907] Fps is (10 sec: 1654.4, 60 sec: 2736.2, 300 sec: 2888.9). Total num frames: 6864896. Throughput: 0: 2907.2. Samples: 6879232. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:44:03,141][103907] Avg episode reward: [(0, '1549.863')]
[2026-01-08 15:44:08,284][103907] Fps is (10 sec: 1629.0, 60 sec: 2731.0, 300 sec: 2886.7). Total num frames: 6881280. Throughput: 0: 2885.4. Samples: 6886912. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:44:08,284][103907] Avg episode reward: [(0, '1543.665')]
[2026-01-08 15:44:13,189][103907] Fps is (10 sec: 3261.0, 60 sec: 2729.1, 300 sec: 2887.5). Total num frames: 6897664. Throughput: 0: 2888.6. Samples: 6904320. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:44:13,189][103907] Avg episode reward: [(0, '1565.433')]
[2026-01-08 15:44:13,365][103907] Saving new best policy, reward=1565.433!
[2026-01-08 15:44:18,248][103907] Fps is (10 sec: 3288.8, 60 sec: 2866.4, 300 sec: 2887.7). Total num frames: 6914048. Throughput: 0: 2886.1. Samples: 6921728. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:44:18,248][103907] Avg episode reward: [(0, '1563.154')]
[2026-01-08 15:44:23,135][103907] Fps is (10 sec: 3294.7, 60 sec: 3007.7, 300 sec: 2888.0). Total num frames: 6930432. Throughput: 0: 2904.6. Samples: 6930944. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:44:23,135][103907] Avg episode reward: [(0, '1537.259')]
[2026-01-08 15:44:28,263][103907] Fps is (10 sec: 3271.7, 60 sec: 2998.9, 300 sec: 2887.2). Total num frames: 6946816. Throughput: 0: 2909.9. Samples: 6947840. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:44:28,263][103907] Avg episode reward: [(0, '1554.653')]
[2026-01-08 15:44:33,163][103907] Fps is (10 sec: 3267.5, 60 sec: 3004.9, 300 sec: 2888.0). Total num frames: 6963200. Throughput: 0: 2881.3. Samples: 6964224. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:44:33,164][103907] Avg episode reward: [(0, '1519.630')]
[2026-01-08 15:44:38,147][103907] Fps is (10 sec: 3315.2, 60 sec: 3005.6, 300 sec: 2888.7). Total num frames: 6979584. Throughput: 0: 2895.7. Samples: 6973952. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:44:38,148][103907] Avg episode reward: [(0, '1542.547')]
[2026-01-08 15:44:43,301][103907] Fps is (10 sec: 2424.3, 60 sec: 2863.4, 300 sec: 2888.6). Total num frames: 6987776. Throughput: 0: 2873.9. Samples: 6991360. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:44:43,301][103907] Avg episode reward: [(0, '1566.779')]
[2026-01-08 15:44:43,701][103907] Saving new best policy, reward=1566.779!
[2026-01-08 15:44:48,206][103907] Fps is (10 sec: 1628.9, 60 sec: 2730.7, 300 sec: 2887.8). Total num frames: 6995968. Throughput: 0: 2874.4. Samples: 7008768. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:44:48,206][103907] Avg episode reward: [(0, '1548.084')]
[2026-01-08 15:44:53,203][103907] Fps is (10 sec: 2481.8, 60 sec: 2732.2, 300 sec: 2888.1). Total num frames: 7012352. Throughput: 0: 2895.2. Samples: 7016960. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:44:53,203][103907] Avg episode reward: [(0, '1564.523')]
[2026-01-08 15:44:58,198][103907] Fps is (10 sec: 3279.5, 60 sec: 2732.0, 300 sec: 2888.2). Total num frames: 7028736. Throughput: 0: 2889.4. Samples: 7034368. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:44:58,198][103907] Avg episode reward: [(0, '1551.979')]
[2026-01-08 15:45:03,235][103907] Fps is (10 sec: 3266.5, 60 sec: 2999.0, 300 sec: 2888.2). Total num frames: 7045120. Throughput: 0: 2890.8. Samples: 7051776. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:45:03,235][103907] Avg episode reward: [(0, '1570.271')]
[2026-01-08 15:45:03,414][103907] Saving new best policy, reward=1570.271!
[2026-01-08 15:45:08,260][103907] Fps is (10 sec: 3256.6, 60 sec: 3005.0, 300 sec: 2887.7). Total num frames: 7061504. Throughput: 0: 2882.0. Samples: 7060992. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:45:08,260][103907] Avg episode reward: [(0, '1550.913')]
[2026-01-08 15:45:13,154][103907] Fps is (10 sec: 3303.6, 60 sec: 3005.5, 300 sec: 2889.0). Total num frames: 7077888. Throughput: 0: 2908.4. Samples: 7078400. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:45:13,154][103907] Avg episode reward: [(0, '1534.975')]
[2026-01-08 15:45:18,155][103907] Fps is (10 sec: 3311.4, 60 sec: 3008.4, 300 sec: 2889.3). Total num frames: 7094272. Throughput: 0: 2913.2. Samples: 7095296. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:45:18,155][103907] Avg episode reward: [(0, '1540.602')]
[2026-01-08 15:45:22,933][103907] Signal inference workers to stop experience collection... (1300 times)
[2026-01-08 15:45:22,934][103907] Signal inference workers to resume experience collection... (1300 times)
[2026-01-08 15:45:23,208][103907] InferenceWorker_p0-w0: stopping experience collection (1300 times)
[2026-01-08 15:45:23,208][103907] InferenceWorker_p0-w0: resuming experience collection (1300 times)
[2026-01-08 15:45:23,318][103907] Fps is (10 sec: 3223.8, 60 sec: 2994.6, 300 sec: 2889.4). Total num frames: 7110656. Throughput: 0: 2879.0. Samples: 7104000. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:45:23,318][103907] Avg episode reward: [(0, '1533.110')]
[2026-01-08 15:45:28,177][103907] Fps is (10 sec: 1634.9, 60 sec: 2734.6, 300 sec: 2887.9). Total num frames: 7110656. Throughput: 0: 2897.9. Samples: 7121408. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:45:28,177][103907] Avg episode reward: [(0, '1560.477')]
[2026-01-08 15:45:33,200][103907] Fps is (10 sec: 1658.0, 60 sec: 2729.0, 300 sec: 2887.9). Total num frames: 7127040. Throughput: 0: 2890.3. Samples: 7138816. Policy #0 lag: (min: 3.0, avg: 6.0, max: 67.0)
[2026-01-08 15:45:33,200][103907] Avg episode reward: [(0, '1575.549')]
[2026-01-08 15:45:33,378][103907] Saving new best policy, reward=1575.549!
[2026-01-08 15:45:38,251][103907] Fps is (10 sec: 3252.4, 60 sec: 2725.9, 300 sec: 2887.4). Total num frames: 7143424. Throughput: 0: 2886.9. Samples: 7147008. Policy #0 lag: (min: 3.0, avg: 6.0, max: 67.0)
[2026-01-08 15:45:38,252][103907] Avg episode reward: [(0, '1545.952')]
[2026-01-08 15:45:43,265][103907] Fps is (10 sec: 3255.7, 60 sec: 2868.9, 300 sec: 2887.1). Total num frames: 7159808. Throughput: 0: 2885.7. Samples: 7164416. Policy #0 lag: (min: 3.0, avg: 6.0, max: 67.0)
[2026-01-08 15:45:43,265][103907] Avg episode reward: [(0, '1558.900')]
[2026-01-08 15:45:48,268][103907] Fps is (10 sec: 3271.4, 60 sec: 3000.6, 300 sec: 2887.2). Total num frames: 7176192. Throughput: 0: 2887.8. Samples: 7181824. Policy #0 lag: (min: 3.0, avg: 6.0, max: 67.0)
[2026-01-08 15:45:48,268][103907] Avg episode reward: [(0, '1561.730')]
[2026-01-08 15:45:53,163][103907] Fps is (10 sec: 3310.3, 60 sec: 3005.7, 300 sec: 2888.6). Total num frames: 7192576. Throughput: 0: 2896.1. Samples: 7191040. Policy #0 lag: (min: 2.0, avg: 5.0, max: 66.0)
[2026-01-08 15:45:53,164][103907] Avg episode reward: [(0, '1551.178')]
[2026-01-08 15:45:53,340][103907] Saving /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_lidar_policy1_acc_08012026/checkpoint_p0/checkpoint_000028096_7192576.pth...
[2026-01-08 15:45:53,344][103907] Removing /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_lidar_policy1_acc_08012026/checkpoint_p0/checkpoint_000025408_6504448.pth
[2026-01-08 15:45:58,171][103907] Fps is (10 sec: 3308.8, 60 sec: 3005.1, 300 sec: 2888.8). Total num frames: 7208960. Throughput: 0: 2888.8. Samples: 7208448. Policy #0 lag: (min: 2.0, avg: 5.0, max: 66.0)
[2026-01-08 15:45:58,171][103907] Avg episode reward: [(0, '1546.021')]
[2026-01-08 15:46:03,179][103907] Fps is (10 sec: 3271.8, 60 sec: 3006.5, 300 sec: 2888.6). Total num frames: 7225344. Throughput: 0: 2899.8. Samples: 7225856. Policy #0 lag: (min: 2.0, avg: 5.0, max: 66.0)
[2026-01-08 15:46:03,179][103907] Avg episode reward: [(0, '1602.285')]
[2026-01-08 15:46:03,352][103907] Saving new best policy, reward=1602.285!
[2026-01-08 15:46:08,315][103907] Fps is (10 sec: 2422.8, 60 sec: 2864.6, 300 sec: 2888.4). Total num frames: 7233536. Throughput: 0: 2890.2. Samples: 7234048. Policy #0 lag: (min: 2.0, avg: 5.0, max: 66.0)
[2026-01-08 15:46:08,315][103907] Avg episode reward: [(0, '1621.157')]
[2026-01-08 15:46:08,708][103907] Saving new best policy, reward=1621.157!
[2026-01-08 15:46:13,148][103907] Fps is (10 sec: 1643.5, 60 sec: 2730.9, 300 sec: 2888.1). Total num frames: 7241728. Throughput: 0: 2880.4. Samples: 7250944. Policy #0 lag: (min: 2.0, avg: 5.0, max: 66.0)
[2026-01-08 15:46:13,148][103907] Avg episode reward: [(0, '1632.192')]
[2026-01-08 15:46:13,314][103907] Saving new best policy, reward=1632.192!
[2026-01-08 15:46:18,156][103907] Fps is (10 sec: 2497.2, 60 sec: 2730.6, 300 sec: 2888.1). Total num frames: 7258112. Throughput: 0: 2881.4. Samples: 7268352. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:46:18,156][103907] Avg episode reward: [(0, '1614.456')]
[2026-01-08 15:46:23,139][103907] Fps is (10 sec: 3279.7, 60 sec: 2738.8, 300 sec: 2888.4). Total num frames: 7274496. Throughput: 0: 2885.8. Samples: 7276544. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:46:23,139][103907] Avg episode reward: [(0, '1605.832')]
[2026-01-08 15:46:28,205][103907] Fps is (10 sec: 3260.7, 60 sec: 3002.3, 300 sec: 2887.7). Total num frames: 7290880. Throughput: 0: 2882.4. Samples: 7293952. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:46:28,206][103907] Avg episode reward: [(0, '1570.553')]
[2026-01-08 15:46:33,252][103907] Fps is (10 sec: 3240.3, 60 sec: 3001.1, 300 sec: 2888.1). Total num frames: 7307264. Throughput: 0: 2879.6. Samples: 7311360. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:46:33,252][103907] Avg episode reward: [(0, '1624.046')]
[2026-01-08 15:46:38,235][103907] Fps is (10 sec: 3267.1, 60 sec: 3004.6, 300 sec: 2888.5). Total num frames: 7323648. Throughput: 0: 2874.0. Samples: 7320576. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:46:38,235][103907] Avg episode reward: [(0, '1591.765')]
[2026-01-08 15:46:43,248][103907] Fps is (10 sec: 3277.8, 60 sec: 3004.5, 300 sec: 2887.0). Total num frames: 7340032. Throughput: 0: 2873.6. Samples: 7337984. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:46:43,249][103907] Avg episode reward: [(0, '1554.509')]
[2026-01-08 15:46:48,435][103907] Fps is (10 sec: 3212.5, 60 sec: 2995.4, 300 sec: 2888.3). Total num frames: 7356416. Throughput: 0: 2862.3. Samples: 7355392. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:46:48,435][103907] Avg episode reward: [(0, '1558.079')]
[2026-01-08 15:46:53,212][103907] Fps is (10 sec: 1644.4, 60 sec: 2728.5, 300 sec: 2887.9). Total num frames: 7356416. Throughput: 0: 2885.2. Samples: 7363584. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:46:53,212][103907] Avg episode reward: [(0, '1591.667')]
[2026-01-08 15:46:58,208][103907] Fps is (10 sec: 1676.6, 60 sec: 2729.0, 300 sec: 2888.5). Total num frames: 7372800. Throughput: 0: 2886.1. Samples: 7380992. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:46:58,208][103907] Avg episode reward: [(0, '1588.006')]
[2026-01-08 15:46:59,023][103907] Signal inference workers to stop experience collection... (1350 times)
[2026-01-08 15:46:59,422][103907] InferenceWorker_p0-w0: stopping experience collection (1350 times)
[2026-01-08 15:46:59,424][103907] Signal inference workers to resume experience collection... (1350 times)
[2026-01-08 15:46:59,591][103907] InferenceWorker_p0-w0: resuming experience collection (1350 times)
[2026-01-08 15:47:03,281][103907] Fps is (10 sec: 3254.2, 60 sec: 2726.0, 300 sec: 2886.8). Total num frames: 7389184. Throughput: 0: 2881.9. Samples: 7398400. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:47:03,282][103907] Avg episode reward: [(0, '1640.257')]
[2026-01-08 15:47:03,444][103907] Saving new best policy, reward=1640.257!
[2026-01-08 15:47:08,136][103907] Fps is (10 sec: 3300.5, 60 sec: 2875.8, 300 sec: 2888.5). Total num frames: 7405568. Throughput: 0: 2890.1. Samples: 7406592. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:47:08,136][103907] Avg episode reward: [(0, '1582.167')]
[2026-01-08 15:47:13,164][103907] Fps is (10 sec: 3315.8, 60 sec: 3002.9, 300 sec: 2888.6). Total num frames: 7421952. Throughput: 0: 2869.9. Samples: 7422976. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:47:13,164][103907] Avg episode reward: [(0, '1603.954')]
[2026-01-08 15:47:18,142][103907] Fps is (10 sec: 3274.9, 60 sec: 3004.5, 300 sec: 2889.0). Total num frames: 7438336. Throughput: 0: 2885.6. Samples: 7440896. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:47:18,142][103907] Avg episode reward: [(0, '1584.281')]
[2026-01-08 15:47:23,215][103907] Fps is (10 sec: 3260.0, 60 sec: 2999.9, 300 sec: 2888.5). Total num frames: 7454720. Throughput: 0: 2891.2. Samples: 7450624. Policy #0 lag: (min: 14.0, avg: 17.0, max: 78.0)
[2026-01-08 15:47:23,216][103907] Avg episode reward: [(0, '1544.678')]
[2026-01-08 15:47:28,186][103907] Fps is (10 sec: 3262.3, 60 sec: 3004.7, 300 sec: 2888.5). Total num frames: 7471104. Throughput: 0: 2894.0. Samples: 7468032. Policy #0 lag: (min: 14.0, avg: 17.0, max: 78.0)
[2026-01-08 15:47:28,187][103907] Avg episode reward: [(0, '1513.457')]
[2026-01-08 15:47:33,458][103907] Fps is (10 sec: 2399.3, 60 sec: 2857.4, 300 sec: 2913.1). Total num frames: 7479296. Throughput: 0: 2888.5. Samples: 7485440. Policy #0 lag: (min: 14.0, avg: 17.0, max: 78.0)
[2026-01-08 15:47:33,458][103907] Avg episode reward: [(0, '1558.389')]
[2026-01-08 15:47:38,213][103907] Fps is (10 sec: 1634.0, 60 sec: 2731.7, 300 sec: 2888.1). Total num frames: 7487488. Throughput: 0: 2889.9. Samples: 7493632. Policy #0 lag: (min: 14.0, avg: 17.0, max: 78.0)
[2026-01-08 15:47:38,213][103907] Avg episode reward: [(0, '1588.078')]
[2026-01-08 15:47:43,277][103907] Fps is (10 sec: 2503.0, 60 sec: 2729.4, 300 sec: 2887.3). Total num frames: 7503872. Throughput: 0: 2885.5. Samples: 7511040. Policy #0 lag: (min: 14.0, avg: 17.0, max: 78.0)
[2026-01-08 15:47:43,277][103907] Avg episode reward: [(0, '1618.719')]
[2026-01-08 15:47:48,270][103907] Fps is (10 sec: 3258.1, 60 sec: 2738.2, 300 sec: 2887.3). Total num frames: 7520256. Throughput: 0: 2890.7. Samples: 7528448. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:47:48,271][103907] Avg episode reward: [(0, '1627.003')]
[2026-01-08 15:47:53,245][103907] Fps is (10 sec: 3287.3, 60 sec: 3002.1, 300 sec: 2887.4). Total num frames: 7536640. Throughput: 0: 2905.7. Samples: 7537664. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:47:53,245][103907] Avg episode reward: [(0, '1625.968')]
[2026-01-08 15:47:53,413][103907] Saving /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_lidar_policy1_acc_08012026/checkpoint_p0/checkpoint_000029440_7536640.pth...
[2026-01-08 15:47:53,417][103907] Removing /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_lidar_policy1_acc_08012026/checkpoint_p0/checkpoint_000026752_6848512.pth
[2026-01-08 15:47:58,274][103907] Fps is (10 sec: 3275.5, 60 sec: 3000.4, 300 sec: 2887.9). Total num frames: 7553024. Throughput: 0: 2905.6. Samples: 7554048. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:47:58,275][103907] Avg episode reward: [(0, '1623.762')]
[2026-01-08 15:48:03,155][103907] Fps is (10 sec: 3306.5, 60 sec: 3010.1, 300 sec: 2889.4). Total num frames: 7569408. Throughput: 0: 2877.7. Samples: 7570432. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:48:03,155][103907] Avg episode reward: [(0, '1571.148')]
[2026-01-08 15:48:08,198][103907] Fps is (10 sec: 3301.9, 60 sec: 3000.6, 300 sec: 2887.6). Total num frames: 7585792. Throughput: 0: 2891.1. Samples: 7580672. Policy #0 lag: (min: 2.0, avg: 5.0, max: 66.0)
[2026-01-08 15:48:08,199][103907] Avg episode reward: [(0, '1569.550')]
[2026-01-08 15:48:13,159][103907] Fps is (10 sec: 2456.7, 60 sec: 2867.4, 300 sec: 2888.7). Total num frames: 7593984. Throughput: 0: 2891.7. Samples: 7598080. Policy #0 lag: (min: 2.0, avg: 5.0, max: 66.0)
[2026-01-08 15:48:13,159][103907] Avg episode reward: [(0, '1600.396')]
[2026-01-08 15:48:18,249][103907] Fps is (10 sec: 1630.2, 60 sec: 2725.8, 300 sec: 2887.7). Total num frames: 7602176. Throughput: 0: 2903.5. Samples: 7615488. Policy #0 lag: (min: 2.0, avg: 5.0, max: 66.0)
[2026-01-08 15:48:18,249][103907] Avg episode reward: [(0, '1600.490')]
[2026-01-08 15:48:23,272][103907] Fps is (10 sec: 2430.2, 60 sec: 2728.1, 300 sec: 2887.0). Total num frames: 7618560. Throughput: 0: 2874.8. Samples: 7623168. Policy #0 lag: (min: 2.0, avg: 5.0, max: 66.0)
[2026-01-08 15:48:23,272][103907] Avg episode reward: [(0, '1589.613')]
[2026-01-08 15:48:28,169][103907] Fps is (10 sec: 3303.2, 60 sec: 2731.5, 300 sec: 2888.2). Total num frames: 7634944. Throughput: 0: 2885.5. Samples: 7640576. Policy #0 lag: (min: 2.0, avg: 5.0, max: 66.0)
[2026-01-08 15:48:28,169][103907] Avg episode reward: [(0, '1565.756')]
[2026-01-08 15:48:30,177][103907] Signal inference workers to stop experience collection... (1400 times)
[2026-01-08 15:48:30,562][103907] InferenceWorker_p0-w0: stopping experience collection (1400 times)
[2026-01-08 15:48:30,562][103907] Signal inference workers to resume experience collection... (1400 times)
[2026-01-08 15:48:30,563][103907] InferenceWorker_p0-w0: resuming experience collection (1400 times)
[2026-01-08 15:48:33,134][103907] Fps is (10 sec: 3322.6, 60 sec: 2882.8, 300 sec: 2888.5). Total num frames: 7651328. Throughput: 0: 2887.3. Samples: 7657984. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:48:33,134][103907] Avg episode reward: [(0, '1562.632')]
[2026-01-08 15:48:38,205][103907] Fps is (10 sec: 3265.2, 60 sec: 3004.2, 300 sec: 2888.2). Total num frames: 7667712. Throughput: 0: 2881.2. Samples: 7667200. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:48:38,205][103907] Avg episode reward: [(0, '1545.292')]
[2026-01-08 15:48:43,225][103907] Fps is (10 sec: 3247.2, 60 sec: 3006.3, 300 sec: 2887.8). Total num frames: 7684096. Throughput: 0: 2904.5. Samples: 7684608. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:48:43,225][103907] Avg episode reward: [(0, '1585.588')]
[2026-01-08 15:48:48,262][103907] Fps is (10 sec: 3258.1, 60 sec: 3004.2, 300 sec: 2887.8). Total num frames: 7700480. Throughput: 0: 2905.8. Samples: 7701504. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:48:48,262][103907] Avg episode reward: [(0, '1588.688')]
[2026-01-08 15:48:53,231][103907] Fps is (10 sec: 3274.8, 60 sec: 3004.4, 300 sec: 2888.0). Total num frames: 7716864. Throughput: 0: 2876.5. Samples: 7710208. Policy #0 lag: (min: 2.0, avg: 5.0, max: 66.0)
[2026-01-08 15:48:53,231][103907] Avg episode reward: [(0, '1585.142')]
[2026-01-08 15:48:58,501][103907] Fps is (10 sec: 2400.2, 60 sec: 2856.4, 300 sec: 2912.2). Total num frames: 7725056. Throughput: 0: 2868.2. Samples: 7728128. Policy #0 lag: (min: 2.0, avg: 5.0, max: 66.0)
[2026-01-08 15:48:58,501][103907] Avg episode reward: [(0, '1577.049')]
[2026-01-08 15:49:03,269][103907] Fps is (10 sec: 1632.2, 60 sec: 2725.5, 300 sec: 2888.2). Total num frames: 7733248. Throughput: 0: 2888.7. Samples: 7745536. Policy #0 lag: (min: 2.0, avg: 5.0, max: 66.0)
[2026-01-08 15:49:03,269][103907] Avg episode reward: [(0, '1601.792')]
[2026-01-08 15:49:08,283][103907] Fps is (10 sec: 2512.4, 60 sec: 2726.8, 300 sec: 2887.1). Total num frames: 7749632. Throughput: 0: 2889.2. Samples: 7753216. Policy #0 lag: (min: 2.0, avg: 5.0, max: 66.0)
[2026-01-08 15:49:08,283][103907] Avg episode reward: [(0, '1597.520')]
[2026-01-08 15:49:13,284][103907] Fps is (10 sec: 3272.1, 60 sec: 2861.3, 300 sec: 2887.7). Total num frames: 7766016. Throughput: 0: 2882.6. Samples: 7770624. Policy #0 lag: (min: 2.0, avg: 5.0, max: 66.0)
[2026-01-08 15:49:13,284][103907] Avg episode reward: [(0, '1613.856')]
[2026-01-08 15:49:18,216][103907] Fps is (10 sec: 3298.8, 60 sec: 3005.4, 300 sec: 2887.2). Total num frames: 7782400. Throughput: 0: 2884.7. Samples: 7788032. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:49:18,216][103907] Avg episode reward: [(0, '1597.307')]
[2026-01-08 15:49:23,278][103907] Fps is (10 sec: 3278.5, 60 sec: 3003.4, 300 sec: 2887.9). Total num frames: 7798784. Throughput: 0: 2885.2. Samples: 7797248. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:49:23,279][103907] Avg episode reward: [(0, '1597.017')]
[2026-01-08 15:49:28,153][103907] Fps is (10 sec: 3297.8, 60 sec: 3004.6, 300 sec: 2888.1). Total num frames: 7815168. Throughput: 0: 2894.6. Samples: 7814656. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:49:28,153][103907] Avg episode reward: [(0, '1626.912')]
[2026-01-08 15:49:33,213][103907] Fps is (10 sec: 3298.5, 60 sec: 2999.8, 300 sec: 2887.4). Total num frames: 7831552. Throughput: 0: 2904.5. Samples: 7832064. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:49:33,213][103907] Avg episode reward: [(0, '1639.402')]
[2026-01-08 15:49:38,414][103907] Fps is (10 sec: 2394.9, 60 sec: 2857.2, 300 sec: 2886.9). Total num frames: 7839744. Throughput: 0: 2866.9. Samples: 7839744. Policy #0 lag: (min: 8.0, avg: 11.0, max: 72.0)
[2026-01-08 15:49:38,415][103907] Avg episode reward: [(0, '1668.297')]
[2026-01-08 15:49:38,821][103907] Saving new best policy, reward=1668.297!
[2026-01-08 15:49:43,144][103907] Fps is (10 sec: 1649.8, 60 sec: 2734.4, 300 sec: 2888.6). Total num frames: 7847936. Throughput: 0: 2878.7. Samples: 7856640. Policy #0 lag: (min: 8.0, avg: 11.0, max: 72.0)
[2026-01-08 15:49:43,144][103907] Avg episode reward: [(0, '1628.010')]
[2026-01-08 15:49:48,170][103907] Fps is (10 sec: 2519.3, 60 sec: 2734.9, 300 sec: 2888.4). Total num frames: 7864320. Throughput: 0: 2862.2. Samples: 7874048. Policy #0 lag: (min: 8.0, avg: 11.0, max: 72.0)
[2026-01-08 15:49:48,170][103907] Avg episode reward: [(0, '1626.810')]
[2026-01-08 15:49:53,178][103907] Fps is (10 sec: 3265.5, 60 sec: 2733.1, 300 sec: 2888.2). Total num frames: 7880704. Throughput: 0: 2862.5. Samples: 7881728. Policy #0 lag: (min: 8.0, avg: 11.0, max: 72.0)
[2026-01-08 15:49:53,179][103907] Avg episode reward: [(0, '1605.048')]
[2026-01-08 15:49:53,351][103907] Saving /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_lidar_policy1_acc_08012026/checkpoint_p0/checkpoint_000030784_7880704.pth...
[2026-01-08 15:49:53,355][103907] Removing /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_lidar_policy1_acc_08012026/checkpoint_p0/checkpoint_000028096_7192576.pth
[2026-01-08 15:49:58,206][103907] Fps is (10 sec: 3264.9, 60 sec: 2881.4, 300 sec: 2888.3). Total num frames: 7897088. Throughput: 0: 2872.2. Samples: 7899648. Policy #0 lag: (min: 8.0, avg: 11.0, max: 72.0)
[2026-01-08 15:49:58,206][103907] Avg episode reward: [(0, '1611.958')]
[2026-01-08 15:50:03,251][103907] Fps is (10 sec: 3253.2, 60 sec: 3004.6, 300 sec: 2888.1). Total num frames: 7913472. Throughput: 0: 2865.0. Samples: 7917056. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:50:03,251][103907] Avg episode reward: [(0, '1664.835')]
[2026-01-08 15:50:06,914][103907] Signal inference workers to stop experience collection... (1450 times)
[2026-01-08 15:50:06,914][103907] Signal inference workers to resume experience collection... (1450 times)
[2026-01-08 15:50:07,193][103907] InferenceWorker_p0-w0: stopping experience collection (1450 times)
[2026-01-08 15:50:07,193][103907] InferenceWorker_p0-w0: resuming experience collection (1450 times)
[2026-01-08 15:50:08,269][103907] Fps is (10 sec: 3256.1, 60 sec: 3004.4, 300 sec: 2886.9). Total num frames: 7929856. Throughput: 0: 2867.8. Samples: 7926272. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:50:08,270][103907] Avg episode reward: [(0, '1688.054')]
[2026-01-08 15:50:08,430][103907] Saving new best policy, reward=1688.054!
[2026-01-08 15:50:13,150][103907] Fps is (10 sec: 3310.3, 60 sec: 3010.4, 300 sec: 2888.1). Total num frames: 7946240. Throughput: 0: 2867.4. Samples: 7943680. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:50:13,150][103907] Avg episode reward: [(0, '1682.416')]
[2026-01-08 15:50:18,295][103907] Fps is (10 sec: 2451.2, 60 sec: 2863.4, 300 sec: 2860.5). Total num frames: 7954432. Throughput: 0: 2861.9. Samples: 7961088. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:50:18,296][103907] Avg episode reward: [(0, '1651.247')]
[2026-01-08 15:50:23,144][103907] Fps is (10 sec: 1639.4, 60 sec: 2736.8, 300 sec: 2888.3). Total num frames: 7962624. Throughput: 0: 2884.6. Samples: 7968768. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:50:23,144][103907] Avg episode reward: [(0, '1655.486')]
[2026-01-08 15:50:28,175][103907] Fps is (10 sec: 2487.4, 60 sec: 2729.6, 300 sec: 2888.3). Total num frames: 7979008. Throughput: 0: 2876.6. Samples: 7986176. Policy #0 lag: (min: 14.0, avg: 17.0, max: 78.0)
[2026-01-08 15:50:28,176][103907] Avg episode reward: [(0, '1629.833')]
[2026-01-08 15:50:33,205][103907] Fps is (10 sec: 3257.0, 60 sec: 2731.0, 300 sec: 2888.5). Total num frames: 7995392. Throughput: 0: 2876.3. Samples: 8003584. Policy #0 lag: (min: 14.0, avg: 17.0, max: 78.0)
[2026-01-08 15:50:33,205][103907] Avg episode reward: [(0, '1645.155')]
[2026-01-08 15:50:38,267][103907] Fps is (10 sec: 3247.0, 60 sec: 2874.3, 300 sec: 2888.0). Total num frames: 8011776. Throughput: 0: 2907.0. Samples: 8012800. Policy #0 lag: (min: 14.0, avg: 17.0, max: 78.0)
[2026-01-08 15:50:38,267][103907] Avg episode reward: [(0, '1605.578')]
[2026-01-08 15:50:43,179][103907] Fps is (10 sec: 3285.2, 60 sec: 3002.0, 300 sec: 2888.9). Total num frames: 8028160. Throughput: 0: 2880.3. Samples: 8029184. Policy #0 lag: (min: 14.0, avg: 17.0, max: 78.0)
[2026-01-08 15:50:43,179][103907] Avg episode reward: [(0, '1585.609')]
[2026-01-08 15:50:48,180][103907] Fps is (10 sec: 3305.6, 60 sec: 3003.2, 300 sec: 2887.9). Total num frames: 8044544. Throughput: 0: 2860.3. Samples: 8045568. Policy #0 lag: (min: 3.0, avg: 6.0, max: 67.0)
[2026-01-08 15:50:48,180][103907] Avg episode reward: [(0, '1591.437')]
[2026-01-08 15:50:53,263][103907] Fps is (10 sec: 3249.4, 60 sec: 2999.5, 300 sec: 2887.1). Total num frames: 8060928. Throughput: 0: 2867.6. Samples: 8055296. Policy #0 lag: (min: 3.0, avg: 6.0, max: 67.0)
[2026-01-08 15:50:53,264][103907] Avg episode reward: [(0, '1590.788')]
[2026-01-08 15:50:58,199][103907] Fps is (10 sec: 3270.7, 60 sec: 3004.1, 300 sec: 2887.8). Total num frames: 8077312. Throughput: 0: 2886.8. Samples: 8073728. Policy #0 lag: (min: 3.0, avg: 6.0, max: 67.0)
[2026-01-08 15:50:58,199][103907] Avg episode reward: [(0, '1639.090')]
[2026-01-08 15:51:03,232][103907] Fps is (10 sec: 3287.2, 60 sec: 3004.7, 300 sec: 2916.6). Total num frames: 8093696. Throughput: 0: 2951.0. Samples: 8093696. Policy #0 lag: (min: 3.0, avg: 6.0, max: 67.0)
[2026-01-08 15:51:03,232][103907] Avg episode reward: [(0, '1640.025')]
[2026-01-08 15:51:08,258][103907] Fps is (10 sec: 3257.3, 60 sec: 3004.3, 300 sec: 2942.5). Total num frames: 8110080. Throughput: 0: 2973.4. Samples: 8102912. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:51:08,259][103907] Avg episode reward: [(0, '1649.068')]
[2026-01-08 15:51:13,184][103907] Fps is (10 sec: 3292.7, 60 sec: 3002.0, 300 sec: 2943.3). Total num frames: 8126464. Throughput: 0: 3037.3. Samples: 8122880. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:51:13,184][103907] Avg episode reward: [(0, '1711.442')]
[2026-01-08 15:51:13,192][103907] Saving new best policy, reward=1711.442!
[2026-01-08 15:51:18,193][103907] Fps is (10 sec: 3298.3, 60 sec: 3145.6, 300 sec: 2943.0). Total num frames: 8142848. Throughput: 0: 3084.2. Samples: 8142336. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:51:18,194][103907] Avg episode reward: [(0, '1696.968')]
[2026-01-08 15:51:23,342][103907] Fps is (10 sec: 3225.8, 60 sec: 3266.0, 300 sec: 2942.2). Total num frames: 8159232. Throughput: 0: 3078.3. Samples: 8151552. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:51:23,342][103907] Avg episode reward: [(0, '1669.389')]
[2026-01-08 15:51:28,410][103907] Fps is (10 sec: 3207.3, 60 sec: 3264.0, 300 sec: 2942.0). Total num frames: 8175616. Throughput: 0: 3135.6. Samples: 8171008. Policy #0 lag: (min: 47.0, avg: 50.0, max: 111.0)
[2026-01-08 15:51:28,411][103907] Avg episode reward: [(0, '1607.618')]
[2026-01-08 15:51:33,400][103907] Fps is (10 sec: 3258.0, 60 sec: 3266.2, 300 sec: 2941.9). Total num frames: 8192000. Throughput: 0: 3215.6. Samples: 8190976. Policy #0 lag: (min: 47.0, avg: 50.0, max: 111.0)
[2026-01-08 15:51:33,400][103907] Avg episode reward: [(0, '1622.440')]
[2026-01-08 15:51:37,600][103907] Signal inference workers to stop experience collection... (1500 times)
[2026-01-08 15:51:37,984][103907] InferenceWorker_p0-w0: stopping experience collection (1500 times)
[2026-01-08 15:51:37,988][103907] Signal inference workers to resume experience collection... (1500 times)
[2026-01-08 15:51:38,134][103907] InferenceWorker_p0-w0: resuming experience collection (1500 times)
[2026-01-08 15:51:38,369][103907] Fps is (10 sec: 3290.4, 60 sec: 3271.3, 300 sec: 2942.4). Total num frames: 8208384. Throughput: 0: 3212.4. Samples: 8200192. Policy #0 lag: (min: 47.0, avg: 50.0, max: 111.0)
[2026-01-08 15:51:38,369][103907] Avg episode reward: [(0, '1664.409')]
[2026-01-08 15:51:43,382][103907] Fps is (10 sec: 3282.5, 60 sec: 3265.7, 300 sec: 2944.1). Total num frames: 8224768. Throughput: 0: 3240.8. Samples: 8220160. Policy #0 lag: (min: 47.0, avg: 50.0, max: 111.0)
[2026-01-08 15:51:43,382][103907] Avg episode reward: [(0, '1676.545')]
[2026-01-08 15:51:48,418][103907] Fps is (10 sec: 3260.6, 60 sec: 3263.8, 300 sec: 2997.0). Total num frames: 8241152. Throughput: 0: 3240.6. Samples: 8240128. Policy #0 lag: (min: 47.0, avg: 50.0, max: 111.0)
[2026-01-08 15:51:48,419][103907] Avg episode reward: [(0, '1607.679')]
[2026-01-08 15:51:53,487][103907] Fps is (10 sec: 3243.0, 60 sec: 3264.7, 300 sec: 2996.3). Total num frames: 8257536. Throughput: 0: 3237.6. Samples: 8249344. Policy #0 lag: (min: 2.0, avg: 5.0, max: 66.0)
[2026-01-08 15:51:53,487][103907] Avg episode reward: [(0, '1570.792')]
[2026-01-08 15:51:53,492][103907] Saving /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_lidar_policy1_acc_08012026/checkpoint_p0/checkpoint_000032256_8257536.pth...
[2026-01-08 15:51:53,496][103907] Removing /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_lidar_policy1_acc_08012026/checkpoint_p0/checkpoint_000029440_7536640.pth
[2026-01-08 15:51:58,261][103907] Fps is (10 sec: 2497.0, 60 sec: 3137.0, 300 sec: 2971.5). Total num frames: 8265728. Throughput: 0: 3237.1. Samples: 8268800. Policy #0 lag: (min: 2.0, avg: 5.0, max: 66.0)
[2026-01-08 15:51:58,261][103907] Avg episode reward: [(0, '1585.113')]
[2026-01-08 15:52:03,210][103907] Fps is (10 sec: 1685.0, 60 sec: 3004.8, 300 sec: 2942.8). Total num frames: 8273920. Throughput: 0: 3218.7. Samples: 8287232. Policy #0 lag: (min: 2.0, avg: 5.0, max: 66.0)
[2026-01-08 15:52:03,210][103907] Avg episode reward: [(0, '1587.461')]
[2026-01-08 15:52:08,207][103907] Fps is (10 sec: 2471.0, 60 sec: 3006.3, 300 sec: 2943.1). Total num frames: 8290304. Throughput: 0: 3218.2. Samples: 8295936. Policy #0 lag: (min: 2.0, avg: 5.0, max: 66.0)
[2026-01-08 15:52:08,207][103907] Avg episode reward: [(0, '1600.882')]
[2026-01-08 15:52:13,179][103907] Fps is (10 sec: 3286.8, 60 sec: 3004.0, 300 sec: 2943.2). Total num frames: 8306688. Throughput: 0: 3225.1. Samples: 8315392. Policy #0 lag: (min: 2.0, avg: 5.0, max: 66.0)
[2026-01-08 15:52:13,180][103907] Avg episode reward: [(0, '1618.500')]
[2026-01-08 15:52:18,187][103907] Fps is (10 sec: 3283.3, 60 sec: 3004.1, 300 sec: 2943.9). Total num frames: 8323072. Throughput: 0: 3200.9. Samples: 8334336. Policy #0 lag: (min: 13.0, avg: 16.0, max: 77.0)
[2026-01-08 15:52:18,187][103907] Avg episode reward: [(0, '1621.106')]
[2026-01-08 15:52:23,189][103907] Fps is (10 sec: 3273.6, 60 sec: 3011.4, 300 sec: 2943.5). Total num frames: 8339456. Throughput: 0: 3187.1. Samples: 8343040. Policy #0 lag: (min: 13.0, avg: 16.0, max: 77.0)
[2026-01-08 15:52:23,189][103907] Avg episode reward: [(0, '1684.289')]
[2026-01-08 15:52:28,268][103907] Fps is (10 sec: 3250.5, 60 sec: 3010.9, 300 sec: 2973.3). Total num frames: 8355840. Throughput: 0: 3171.1. Samples: 8362496. Policy #0 lag: (min: 13.0, avg: 16.0, max: 77.0)
[2026-01-08 15:52:28,268][103907] Avg episode reward: [(0, '1660.886')]
[2026-01-08 15:52:33,222][103907] Fps is (10 sec: 3266.2, 60 sec: 3012.7, 300 sec: 2999.0). Total num frames: 8372224. Throughput: 0: 3165.5. Samples: 8381952. Policy #0 lag: (min: 13.0, avg: 16.0, max: 77.0)
[2026-01-08 15:52:33,222][103907] Avg episode reward: [(0, '1639.914')]
[2026-01-08 15:52:38,163][103907] Fps is (10 sec: 3311.5, 60 sec: 3014.1, 300 sec: 3000.3). Total num frames: 8388608. Throughput: 0: 3163.0. Samples: 8390656. Policy #0 lag: (min: 63.0, avg: 66.0, max: 127.0)
[2026-01-08 15:52:38,163][103907] Avg episode reward: [(0, '1622.102')]
[2026-01-08 15:52:43,191][103907] Fps is (10 sec: 3286.9, 60 sec: 3013.4, 300 sec: 2999.9). Total num frames: 8404992. Throughput: 0: 3156.6. Samples: 8410624. Policy #0 lag: (min: 63.0, avg: 66.0, max: 127.0)
[2026-01-08 15:52:43,191][103907] Avg episode reward: [(0, '1561.915')]
[2026-01-08 15:52:48,200][103907] Fps is (10 sec: 3264.7, 60 sec: 3014.7, 300 sec: 2999.6). Total num frames: 8421376. Throughput: 0: 3186.5. Samples: 8430592. Policy #0 lag: (min: 63.0, avg: 66.0, max: 127.0)
[2026-01-08 15:52:48,200][103907] Avg episode reward: [(0, '1566.249')]
[2026-01-08 15:52:53,198][103907] Fps is (10 sec: 3274.4, 60 sec: 3018.3, 300 sec: 2999.9). Total num frames: 8437760. Throughput: 0: 3197.8. Samples: 8439808. Policy #0 lag: (min: 63.0, avg: 66.0, max: 127.0)
[2026-01-08 15:52:53,198][103907] Avg episode reward: [(0, '1574.894')]
[2026-01-08 15:52:58,198][103907] Fps is (10 sec: 3277.3, 60 sec: 3143.5, 300 sec: 2998.7). Total num frames: 8454144. Throughput: 0: 3207.2. Samples: 8459776. Policy #0 lag: (min: 63.0, avg: 66.0, max: 127.0)
[2026-01-08 15:52:58,199][103907] Avg episode reward: [(0, '1657.783')]
[2026-01-08 15:52:59,763][103907] Signal inference workers to stop experience collection... (1550 times)
[2026-01-08 15:53:00,146][103907] InferenceWorker_p0-w0: stopping experience collection (1550 times)
[2026-01-08 15:53:00,147][103907] Signal inference workers to resume experience collection... (1550 times)
[2026-01-08 15:53:00,147][103907] InferenceWorker_p0-w0: resuming experience collection (1550 times)
[2026-01-08 15:53:03,157][103907] Fps is (10 sec: 3290.1, 60 sec: 3279.7, 300 sec: 2999.5). Total num frames: 8470528. Throughput: 0: 3233.4. Samples: 8479744. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:53:03,158][103907] Avg episode reward: [(0, '1684.345')]
[2026-01-08 15:53:08,149][103907] Fps is (10 sec: 3293.2, 60 sec: 3280.0, 300 sec: 3027.0). Total num frames: 8486912. Throughput: 0: 3222.8. Samples: 8487936. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:53:08,149][103907] Avg episode reward: [(0, '1651.337')]
[2026-01-08 15:53:13,245][103907] Fps is (10 sec: 3248.2, 60 sec: 3273.2, 300 sec: 3054.7). Total num frames: 8503296. Throughput: 0: 3232.9. Samples: 8507904. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:53:13,246][103907] Avg episode reward: [(0, '1623.577')]
[2026-01-08 15:53:18,246][103907] Fps is (10 sec: 3245.4, 60 sec: 3273.6, 300 sec: 3054.9). Total num frames: 8519680. Throughput: 0: 3240.9. Samples: 8527872. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:53:18,246][103907] Avg episode reward: [(0, '1608.561')]
[2026-01-08 15:53:23,212][103907] Fps is (10 sec: 3287.6, 60 sec: 3275.5, 300 sec: 3054.2). Total num frames: 8536064. Throughput: 0: 3250.5. Samples: 8537088. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:53:23,213][103907] Avg episode reward: [(0, '1595.355')]
[2026-01-08 15:53:28,230][103907] Fps is (10 sec: 3282.0, 60 sec: 3278.9, 300 sec: 3053.6). Total num frames: 8552448. Throughput: 0: 3228.5. Samples: 8556032. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:53:28,230][103907] Avg episode reward: [(0, '1602.756')]
[2026-01-08 15:53:33,228][103907] Fps is (10 sec: 3271.6, 60 sec: 3276.4, 300 sec: 3054.4). Total num frames: 8568832. Throughput: 0: 3206.5. Samples: 8574976. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:53:33,229][103907] Avg episode reward: [(0, '1621.053')]
[2026-01-08 15:53:38,244][103907] Fps is (10 sec: 3272.0, 60 sec: 3272.4, 300 sec: 3054.4). Total num frames: 8585216. Throughput: 0: 3239.3. Samples: 8585728. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:53:38,244][103907] Avg episode reward: [(0, '1665.128')]
[2026-01-08 15:53:43,261][103907] Fps is (10 sec: 3266.2, 60 sec: 3273.0, 300 sec: 3054.7). Total num frames: 8601600. Throughput: 0: 3192.7. Samples: 8603648. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:53:43,261][103907] Avg episode reward: [(0, '1635.068')]
[2026-01-08 15:53:48,181][103907] Fps is (10 sec: 3297.8, 60 sec: 3277.9, 300 sec: 3055.2). Total num frames: 8617984. Throughput: 0: 3195.5. Samples: 8623616. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:53:48,181][103907] Avg episode reward: [(0, '1630.185')]
[2026-01-08 15:53:53,222][103907] Fps is (10 sec: 3289.5, 60 sec: 3275.5, 300 sec: 3085.3). Total num frames: 8634368. Throughput: 0: 3248.7. Samples: 8634368. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:53:53,223][103907] Avg episode reward: [(0, '1596.814')]
[2026-01-08 15:53:53,376][103907] Saving /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_lidar_policy1_acc_08012026/checkpoint_p0/checkpoint_000033728_8634368.pth...
[2026-01-08 15:53:53,380][103907] Removing /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_lidar_policy1_acc_08012026/checkpoint_p0/checkpoint_000030784_7880704.pth
[2026-01-08 15:53:58,217][103907] Fps is (10 sec: 3264.9, 60 sec: 3275.8, 300 sec: 3110.7). Total num frames: 8650752. Throughput: 0: 3199.2. Samples: 8651776. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:53:58,217][103907] Avg episode reward: [(0, '1653.110')]
[2026-01-08 15:54:03,236][103907] Fps is (10 sec: 3272.3, 60 sec: 3272.5, 300 sec: 3110.7). Total num frames: 8667136. Throughput: 0: 3197.8. Samples: 8671744. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:54:03,236][103907] Avg episode reward: [(0, '1634.458')]
[2026-01-08 15:54:08,203][103907] Fps is (10 sec: 3281.4, 60 sec: 3273.8, 300 sec: 3111.0). Total num frames: 8683520. Throughput: 0: 3232.0. Samples: 8682496. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:54:08,203][103907] Avg episode reward: [(0, '1705.887')]
[2026-01-08 15:54:13,233][103907] Fps is (10 sec: 3277.8, 60 sec: 3277.5, 300 sec: 3110.0). Total num frames: 8699904. Throughput: 0: 3219.7. Samples: 8700928. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:54:13,233][103907] Avg episode reward: [(0, '1705.217')]
[2026-01-08 15:54:18,231][103907] Fps is (10 sec: 3267.7, 60 sec: 3277.6, 300 sec: 3110.7). Total num frames: 8716288. Throughput: 0: 3208.4. Samples: 8719360. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:54:18,231][103907] Avg episode reward: [(0, '1689.642')]
[2026-01-08 15:54:23,206][103907] Fps is (10 sec: 3285.7, 60 sec: 3277.2, 300 sec: 3109.6). Total num frames: 8732672. Throughput: 0: 3211.3. Samples: 8730112. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:54:23,206][103907] Avg episode reward: [(0, '1693.824')]
[2026-01-08 15:54:26,407][103907] Signal inference workers to stop experience collection... (1600 times)
[2026-01-08 15:54:26,407][103907] Signal inference workers to resume experience collection... (1600 times)
[2026-01-08 15:54:26,667][103907] InferenceWorker_p0-w0: stopping experience collection (1600 times)
[2026-01-08 15:54:26,668][103907] InferenceWorker_p0-w0: resuming experience collection (1600 times)
[2026-01-08 15:54:28,222][103907] Fps is (10 sec: 3279.6, 60 sec: 3277.2, 300 sec: 3110.1). Total num frames: 8749056. Throughput: 0: 3256.8. Samples: 8750080. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:54:28,223][103907] Avg episode reward: [(0, '1671.442')]
[2026-01-08 15:54:33,139][103907] Fps is (10 sec: 3298.8, 60 sec: 3281.7, 300 sec: 3140.9). Total num frames: 8765440. Throughput: 0: 3211.5. Samples: 8768000. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:54:33,140][103907] Avg episode reward: [(0, '1720.462')]
[2026-01-08 15:54:33,287][103907] Saving new best policy, reward=1720.462!
[2026-01-08 15:54:38,259][103907] Fps is (10 sec: 3264.7, 60 sec: 3276.0, 300 sec: 3164.5). Total num frames: 8781824. Throughput: 0: 3205.9. Samples: 8778752. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:54:38,260][103907] Avg episode reward: [(0, '1726.702')]
[2026-01-08 15:54:38,423][103907] Saving new best policy, reward=1726.702!
[2026-01-08 15:54:43,269][103907] Fps is (10 sec: 3234.8, 60 sec: 3276.3, 300 sec: 3164.7). Total num frames: 8798208. Throughput: 0: 3204.8. Samples: 8796160. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:54:43,270][103907] Avg episode reward: [(0, '1735.230')]
[2026-01-08 15:54:43,427][103907] Saving new best policy, reward=1735.230!
[2026-01-08 15:54:48,202][103907] Fps is (10 sec: 3295.8, 60 sec: 3275.6, 300 sec: 3165.5). Total num frames: 8814592. Throughput: 0: 3176.8. Samples: 8814592. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:54:48,202][103907] Avg episode reward: [(0, '1695.529')]
[2026-01-08 15:54:53,442][103907] Fps is (10 sec: 3221.2, 60 sec: 3264.9, 300 sec: 3163.2). Total num frames: 8830976. Throughput: 0: 3112.4. Samples: 8823296. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:54:53,442][103907] Avg episode reward: [(0, '1642.976')]
[2026-01-08 15:54:58,218][103907] Fps is (10 sec: 2453.6, 60 sec: 3140.2, 300 sec: 3138.3). Total num frames: 8839168. Throughput: 0: 3141.3. Samples: 8842240. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:54:58,218][103907] Avg episode reward: [(0, '1591.269')]
[2026-01-08 15:55:03,419][103907] Fps is (10 sec: 2463.3, 60 sec: 3130.7, 300 sec: 3136.4). Total num frames: 8855552. Throughput: 0: 3149.9. Samples: 8861696. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:55:03,419][103907] Avg episode reward: [(0, '1618.214')]
[2026-01-08 15:55:08,522][103907] Fps is (10 sec: 2385.0, 60 sec: 2987.8, 300 sec: 3106.3). Total num frames: 8863744. Throughput: 0: 3095.7. Samples: 8870400. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:55:08,523][103907] Avg episode reward: [(0, '1632.650')]
[2026-01-08 15:55:13,144][103907] Fps is (10 sec: 2526.9, 60 sec: 3008.2, 300 sec: 3139.6). Total num frames: 8880128. Throughput: 0: 3111.5. Samples: 8889856. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:55:13,145][103907] Avg episode reward: [(0, '1702.528')]
[2026-01-08 15:55:18,234][103907] Fps is (10 sec: 3374.2, 60 sec: 3003.6, 300 sec: 3164.8). Total num frames: 8896512. Throughput: 0: 3133.7. Samples: 8909312. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:55:18,234][103907] Avg episode reward: [(0, '1707.531')]
[2026-01-08 15:55:23,209][103907] Fps is (10 sec: 3255.9, 60 sec: 3003.6, 300 sec: 3165.4). Total num frames: 8912896. Throughput: 0: 3075.5. Samples: 8916992. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:55:23,209][103907] Avg episode reward: [(0, '1698.986')]
[2026-01-08 15:55:28,161][103907] Fps is (10 sec: 3300.7, 60 sec: 3006.8, 300 sec: 3166.2). Total num frames: 8929280. Throughput: 0: 3102.2. Samples: 8935424. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:55:28,162][103907] Avg episode reward: [(0, '1736.895')]
[2026-01-08 15:55:28,311][103907] Saving new best policy, reward=1736.895!
[2026-01-08 15:55:33,144][103907] Fps is (10 sec: 3298.2, 60 sec: 3003.5, 300 sec: 3167.0). Total num frames: 8945664. Throughput: 0: 3121.5. Samples: 8954880. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:55:33,144][103907] Avg episode reward: [(0, '1698.562')]
[2026-01-08 15:55:38,249][103907] Fps is (10 sec: 3248.2, 60 sec: 3004.2, 300 sec: 3165.0). Total num frames: 8962048. Throughput: 0: 3119.5. Samples: 8963072. Policy #0 lag: (min: 4.0, avg: 7.0, max: 68.0)
[2026-01-08 15:55:38,249][103907] Avg episode reward: [(0, '1715.916')]
[2026-01-08 15:55:43,168][103907] Fps is (10 sec: 3268.9, 60 sec: 3008.8, 300 sec: 3165.8). Total num frames: 8978432. Throughput: 0: 3121.0. Samples: 8982528. Policy #0 lag: (min: 4.0, avg: 7.0, max: 68.0)
[2026-01-08 15:55:43,169][103907] Avg episode reward: [(0, '1649.991')]
[2026-01-08 15:55:48,167][103907] Fps is (10 sec: 3303.9, 60 sec: 3005.5, 300 sec: 3166.8). Total num frames: 8994816. Throughput: 0: 3135.0. Samples: 9001984. Policy #0 lag: (min: 4.0, avg: 7.0, max: 68.0)
[2026-01-08 15:55:48,168][103907] Avg episode reward: [(0, '1628.781')]
[2026-01-08 15:55:53,174][103907] Fps is (10 sec: 3275.0, 60 sec: 3017.2, 300 sec: 3166.0). Total num frames: 9011200. Throughput: 0: 3176.2. Samples: 9012224. Policy #0 lag: (min: 4.0, avg: 7.0, max: 68.0)
[2026-01-08 15:55:53,174][103907] Avg episode reward: [(0, '1573.611')]
[2026-01-08 15:55:53,328][103907] Saving /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_lidar_policy1_acc_08012026/checkpoint_p0/checkpoint_000035200_9011200.pth...
[2026-01-08 15:55:53,332][103907] Removing /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_lidar_policy1_acc_08012026/checkpoint_p0/checkpoint_000032256_8257536.pth
[2026-01-08 15:55:55,390][103907] Signal inference workers to stop experience collection... (1650 times)
[2026-01-08 15:55:55,866][103907] InferenceWorker_p0-w0: stopping experience collection (1650 times)
[2026-01-08 15:55:55,868][103907] Signal inference workers to resume experience collection... (1650 times)
[2026-01-08 15:55:56,026][103907] InferenceWorker_p0-w0: resuming experience collection (1650 times)
[2026-01-08 15:55:58,198][103907] Fps is (10 sec: 3266.9, 60 sec: 3141.3, 300 sec: 3166.1). Total num frames: 9027584. Throughput: 0: 3079.7. Samples: 9028608. Policy #0 lag: (min: 4.0, avg: 7.0, max: 68.0)
[2026-01-08 15:55:58,198][103907] Avg episode reward: [(0, '1589.546')]
[2026-01-08 15:56:03,141][103907] Fps is (10 sec: 3287.5, 60 sec: 3154.8, 300 sec: 3167.0). Total num frames: 9043968. Throughput: 0: 3089.7. Samples: 9048064. Policy #0 lag: (min: 4.0, avg: 7.0, max: 68.0)
[2026-01-08 15:56:03,142][103907] Avg episode reward: [(0, '1605.214')]
[2026-01-08 15:56:08,253][103907] Fps is (10 sec: 3258.8, 60 sec: 3291.6, 300 sec: 3165.0). Total num frames: 9060352. Throughput: 0: 3125.8. Samples: 9057792. Policy #0 lag: (min: 4.0, avg: 7.0, max: 68.0)
[2026-01-08 15:56:08,253][103907] Avg episode reward: [(0, '1631.564')]
[2026-01-08 15:56:13,198][103907] Fps is (10 sec: 3258.3, 60 sec: 3273.9, 300 sec: 3165.7). Total num frames: 9076736. Throughput: 0: 3160.4. Samples: 9077760. Policy #0 lag: (min: 4.0, avg: 7.0, max: 68.0)
[2026-01-08 15:56:13,198][103907] Avg episode reward: [(0, '1659.888')]
[2026-01-08 15:56:18,174][103907] Fps is (10 sec: 3302.8, 60 sec: 3280.0, 300 sec: 3167.5). Total num frames: 9093120. Throughput: 0: 3092.7. Samples: 9094144. Policy #0 lag: (min: 4.0, avg: 7.0, max: 68.0)
[2026-01-08 15:56:18,175][103907] Avg episode reward: [(0, '1690.701')]
[2026-01-08 15:56:23,190][103907] Fps is (10 sec: 3279.4, 60 sec: 3277.8, 300 sec: 3168.1). Total num frames: 9109504. Throughput: 0: 3167.2. Samples: 9105408. Policy #0 lag: (min: 4.0, avg: 7.0, max: 68.0)
[2026-01-08 15:56:23,190][103907] Avg episode reward: [(0, '1654.252')]
[2026-01-08 15:56:28,180][103907] Fps is (10 sec: 3275.0, 60 sec: 3275.8, 300 sec: 3168.1). Total num frames: 9125888. Throughput: 0: 3162.2. Samples: 9124864. Policy #0 lag: (min: 7.0, avg: 10.0, max: 71.0)
[2026-01-08 15:56:28,180][103907] Avg episode reward: [(0, '1641.536')]
[2026-01-08 15:56:33,268][103907] Fps is (10 sec: 3251.4, 60 sec: 3270.0, 300 sec: 3166.8). Total num frames: 9142272. Throughput: 0: 3133.2. Samples: 9143296. Policy #0 lag: (min: 7.0, avg: 10.0, max: 71.0)
[2026-01-08 15:56:33,268][103907] Avg episode reward: [(0, '1620.059')]
[2026-01-08 15:56:38,179][103907] Fps is (10 sec: 3277.0, 60 sec: 3280.6, 300 sec: 3167.9). Total num frames: 9158656. Throughput: 0: 3117.2. Samples: 9152512. Policy #0 lag: (min: 7.0, avg: 10.0, max: 71.0)
[2026-01-08 15:56:38,179][103907] Avg episode reward: [(0, '1624.584')]
[2026-01-08 15:56:43,264][103907] Fps is (10 sec: 3278.0, 60 sec: 3271.6, 300 sec: 3167.4). Total num frames: 9175040. Throughput: 0: 3181.1. Samples: 9171968. Policy #0 lag: (min: 7.0, avg: 10.0, max: 71.0)
[2026-01-08 15:56:43,265][103907] Avg episode reward: [(0, '1684.508')]
[2026-01-08 15:56:48,222][103907] Fps is (10 sec: 3262.6, 60 sec: 3273.8, 300 sec: 3168.6). Total num frames: 9191424. Throughput: 0: 3168.7. Samples: 9190912. Policy #0 lag: (min: 7.0, avg: 10.0, max: 71.0)
[2026-01-08 15:56:48,223][103907] Avg episode reward: [(0, '1686.024')]
[2026-01-08 15:56:53,366][103907] Fps is (10 sec: 3243.9, 60 sec: 3266.3, 300 sec: 3192.4). Total num frames: 9207808. Throughput: 0: 3155.1. Samples: 9200128. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:56:53,366][103907] Avg episode reward: [(0, '1701.457')]
[2026-01-08 15:56:58,193][103907] Fps is (10 sec: 2464.7, 60 sec: 3140.5, 300 sec: 3193.7). Total num frames: 9216000. Throughput: 0: 3140.6. Samples: 9219072. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:56:58,194][103907] Avg episode reward: [(0, '1652.803')]
[2026-01-08 15:57:03,282][103907] Fps is (10 sec: 2478.4, 60 sec: 3132.9, 300 sec: 3192.7). Total num frames: 9232384. Throughput: 0: 3200.9. Samples: 9238528. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:57:03,282][103907] Avg episode reward: [(0, '1677.986')]
[2026-01-08 15:57:08,440][103907] Fps is (10 sec: 3198.0, 60 sec: 3130.5, 300 sec: 3190.7). Total num frames: 9248768. Throughput: 0: 3145.6. Samples: 9247744. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:57:08,440][103907] Avg episode reward: [(0, '1678.618')]
[2026-01-08 15:57:13,198][103907] Fps is (10 sec: 2478.5, 60 sec: 3003.7, 300 sec: 3165.6). Total num frames: 9256960. Throughput: 0: 3161.7. Samples: 9267200. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:57:13,198][103907] Avg episode reward: [(0, '1699.617')]
[2026-01-08 15:57:18,203][103907] Fps is (10 sec: 2517.1, 60 sec: 3002.3, 300 sec: 3165.6). Total num frames: 9273344. Throughput: 0: 3167.6. Samples: 9285632. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:57:18,203][103907] Avg episode reward: [(0, '1707.018')]
[2026-01-08 15:57:18,895][103907] Signal inference workers to stop experience collection... (1700 times)
[2026-01-08 15:57:19,290][103907] InferenceWorker_p0-w0: stopping experience collection (1700 times)
[2026-01-08 15:57:19,290][103907] Signal inference workers to resume experience collection... (1700 times)
[2026-01-08 15:57:19,290][103907] InferenceWorker_p0-w0: resuming experience collection (1700 times)
[2026-01-08 15:57:23,212][103907] Fps is (10 sec: 3272.2, 60 sec: 3002.6, 300 sec: 3166.3). Total num frames: 9289728. Throughput: 0: 3149.3. Samples: 9294336. Policy #0 lag: (min: 10.0, avg: 13.0, max: 74.0)
[2026-01-08 15:57:23,221][103907] Avg episode reward: [(0, '1703.482')]
[2026-01-08 15:57:28,233][103907] Fps is (10 sec: 3267.1, 60 sec: 3001.1, 300 sec: 3165.6). Total num frames: 9306112. Throughput: 0: 3153.9. Samples: 9313792. Policy #0 lag: (min: 10.0, avg: 13.0, max: 74.0)
[2026-01-08 15:57:28,233][103907] Avg episode reward: [(0, '1622.088')]
[2026-01-08 15:57:33,171][103907] Fps is (10 sec: 3290.3, 60 sec: 3008.6, 300 sec: 3165.6). Total num frames: 9322496. Throughput: 0: 3166.6. Samples: 9333248. Policy #0 lag: (min: 10.0, avg: 13.0, max: 74.0)
[2026-01-08 15:57:33,171][103907] Avg episode reward: [(0, '1656.757')]
[2026-01-08 15:57:38,261][103907] Fps is (10 sec: 3267.4, 60 sec: 2999.6, 300 sec: 3165.0). Total num frames: 9338880. Throughput: 0: 3170.4. Samples: 9342464. Policy #0 lag: (min: 10.0, avg: 13.0, max: 74.0)
[2026-01-08 15:57:38,262][103907] Avg episode reward: [(0, '1609.517')]
[2026-01-08 15:57:43,274][103907] Fps is (10 sec: 3243.4, 60 sec: 3003.3, 300 sec: 3164.9). Total num frames: 9355264. Throughput: 0: 3157.4. Samples: 9361408. Policy #0 lag: (min: 10.0, avg: 13.0, max: 74.0)
[2026-01-08 15:57:43,274][103907] Avg episode reward: [(0, '1648.406')]
[2026-01-08 15:57:48,272][103907] Fps is (10 sec: 3273.4, 60 sec: 3001.3, 300 sec: 3164.9). Total num frames: 9371648. Throughput: 0: 3141.0. Samples: 9379840. Policy #0 lag: (min: 6.0, avg: 9.0, max: 70.0)
[2026-01-08 15:57:48,272][103907] Avg episode reward: [(0, '1618.834')]
[2026-01-08 15:57:53,165][103907] Fps is (10 sec: 3313.0, 60 sec: 3013.8, 300 sec: 3166.1). Total num frames: 9388032. Throughput: 0: 3159.6. Samples: 9389056. Policy #0 lag: (min: 6.0, avg: 9.0, max: 70.0)
[2026-01-08 15:57:53,165][103907] Avg episode reward: [(0, '1654.327')]
[2026-01-08 15:57:53,321][103907] Saving /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_lidar_policy1_acc_08012026/checkpoint_p0/checkpoint_000036672_9388032.pth...
[2026-01-08 15:57:53,325][103907] Removing /home/mihir/workspaces/aerial_gym_simulator_ws/aerial_gym_simulator/aerial_gym/rl_training/sample_factory/aerialgym_examples/train_dir/magpie_lidar_policy1_acc_08012026/checkpoint_p0/checkpoint_000033728_8634368.pth
[2026-01-08 15:57:58,156][103907] Fps is (10 sec: 3315.4, 60 sec: 3142.2, 300 sec: 3165.7). Total num frames: 9404416. Throughput: 0: 3120.4. Samples: 9407488. Policy #0 lag: (min: 6.0, avg: 9.0, max: 70.0)
[2026-01-08 15:57:58,156][103907] Avg episode reward: [(0, '1664.527')]
[2026-01-08 15:58:03,270][103907] Fps is (10 sec: 3242.8, 60 sec: 3140.9, 300 sec: 3164.4). Total num frames: 9420800. Throughput: 0: 3135.6. Samples: 9426944. Policy #0 lag: (min: 6.0, avg: 9.0, max: 70.0)
[2026-01-08 15:58:03,270][103907] Avg episode reward: [(0, '1616.807')]
[2026-01-08 15:58:08,174][103907] Fps is (10 sec: 3270.7, 60 sec: 3154.2, 300 sec: 3166.5). Total num frames: 9437184. Throughput: 0: 3188.4. Samples: 9437696. Policy #0 lag: (min: 6.0, avg: 9.0, max: 70.0)
[2026-01-08 15:58:08,175][103907] Avg episode reward: [(0, '1645.427')]
[2026-01-08 15:58:13,156][103907] Fps is (10 sec: 3314.6, 60 sec: 3279.1, 300 sec: 3166.7). Total num frames: 9453568. Throughput: 0: 3134.3. Samples: 9454592. Policy #0 lag: (min: 5.0, avg: 8.0, max: 69.0)
[2026-01-08 15:58:13,156][103907] Avg episode reward: [(0, '1612.877')]
[2026-01-08 15:58:18,219][103907] Fps is (10 sec: 3262.2, 60 sec: 3275.9, 300 sec: 3165.7). Total num frames: 9469952. Throughput: 0: 3125.5. Samples: 9474048. Policy #0 lag: (min: 5.0, avg: 8.0, max: 69.0)
[2026-01-08 15:58:18,219][103907] Avg episode reward: [(0, '1651.033')]
[2026-01-08 15:58:23,182][103907] Fps is (10 sec: 3268.1, 60 sec: 3278.4, 300 sec: 3166.2). Total num frames: 9486336. Throughput: 0: 3157.2. Samples: 9484288. Policy #0 lag: (min: 5.0, avg: 8.0, max: 69.0)
[2026-01-08 15:58:23,182][103907] Avg episode reward: [(0, '1700.961')]
[2026-01-08 15:58:28,269][103907] Fps is (10 sec: 3260.4, 60 sec: 3274.8, 300 sec: 3165.3). Total num frames: 9502720. Throughput: 0: 3163.3. Samples: 9503744. Policy #0 lag: (min: 5.0, avg: 8.0, max: 69.0)
[2026-01-08 15:58:28,269][103907] Avg episode reward: [(0, '1713.072')]
[2026-01-08 15:58:33,167][103907] Fps is (10 sec: 3281.7, 60 sec: 3277.0, 300 sec: 3166.5). Total num frames: 9519104. Throughput: 0: 3124.8. Samples: 9520128. Policy #0 lag: (min: 5.0, avg: 8.0, max: 69.0)
[2026-01-08 15:58:33,168][103907] Avg episode reward: [(0, '1804.678')]
[2026-01-08 15:58:33,315][103907] Saving new best policy, reward=1804.678!
[2026-01-08 15:58:38,280][103907] Fps is (10 sec: 3273.1, 60 sec: 3275.8, 300 sec: 3165.5). Total num frames: 9535488. Throughput: 0: 3154.9. Samples: 9531392. Policy #0 lag: (min: 15.0, avg: 18.0, max: 79.0)
[2026-01-08 15:58:38,281][103907] Avg episode reward: [(0, '1804.562')]
